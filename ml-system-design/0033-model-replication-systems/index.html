<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Model Replication Systems - Arun Baby</title>
<meta name="description" content="“Ensuring your ML models are available everywhere, all the time.”">


  <meta name="author" content="Arun Baby">
  
  <meta property="article:author" content="Arun Baby">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Arun Baby">
<meta property="og:title" content="Model Replication Systems">
<meta property="og:url" content="https://www.arunbaby.com/ml-system-design/0033-model-replication-systems/">


  <meta property="og:description" content="“Ensuring your ML models are available everywhere, all the time.”">



  <meta property="og:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">



  <meta name="twitter:site" content="@arunbaby0">
  <meta name="twitter:title" content="Model Replication Systems">
  <meta name="twitter:description" content="“Ensuring your ML models are available everywhere, all the time.”">
  <meta name="twitter:url" content="https://www.arunbaby.com/ml-system-design/0033-model-replication-systems/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">
    
  

  



  <meta property="article:published_time" content="2025-12-02T22:27:09+05:30">





  

  


<link rel="canonical" href="https://www.arunbaby.com/ml-system-design/0033-model-replication-systems/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Baby Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          <span class="site-subtitle">Arun Baby</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/dsa/"
                
                
              >DSA</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ml-system-design/"
                
                
              >ML Systems</a>
            </li><li class="masthead__menu-item">
              <a
                href="/speech-tech/"
                
                
              >Speech Tech</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li><li class="masthead__menu-item">
              <a
                href="/statuses/"
                
                
              >Statuses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/contact/"
                
                
              >Contact</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main" class="no-author-sidebar">
  
  <div class="sidebar sticky">
  
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Model Replication Systems">
    <meta itemprop="description" content="“Ensuring your ML models are available everywhere, all the time.”">
    <meta itemprop="datePublished" content="2025-12-02T22:27:09+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://www.arunbaby.com/ml-system-design/0033-model-replication-systems/" itemprop="url">Model Replication Systems
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          19 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#1-the-problem-single-point-of-failure">1. The Problem: Single Point of Failure</a></li><li><a href="#2-why-replicate-models">2. Why Replicate Models?</a></li><li><a href="#3-replication-strategies">3. Replication Strategies</a><ul><li><a href="#strategy-1-active-active-multi-master">Strategy 1: Active-Active (Multi-Master)</a></li><li><a href="#strategy-2-active-passive-primary-standby">Strategy 2: Active-Passive (Primary-Standby)</a></li><li><a href="#strategy-3-geo-replication">Strategy 3: Geo-Replication</a></li></ul></li><li><a href="#4-model-synchronization-patterns">4. Model Synchronization Patterns</a><ul><li><a href="#pattern-1-push-based-deployment">Pattern 1: Push-Based Deployment</a></li><li><a href="#pattern-2-pull-based-deployment-polling">Pattern 2: Pull-Based Deployment (Polling)</a></li><li><a href="#pattern-3-event-driven-deployment">Pattern 3: Event-Driven Deployment</a></li></ul></li><li><a href="#5-deep-dive-canary-deployment">5. Deep Dive: Canary Deployment</a></li><li><a href="#6-deep-dive-blue-green-deployment">6. Deep Dive: Blue-Green Deployment</a></li><li><a href="#7-deep-dive-model-versioning-and-rollback">7. Deep Dive: Model Versioning and Rollback</a></li><li><a href="#8-deep-dive-handling-stateful-models">8. Deep Dive: Handling Stateful Models</a></li><li><a href="#9-deep-dive-cross-region-replication">9. Deep Dive: Cross-Region Replication</a></li><li><a href="#10-deep-dive-health-checks-and-auto-scaling">10. Deep Dive: Health Checks and Auto-Scaling</a></li><li><a href="#11-real-world-case-studies">11. Real-World Case Studies</a><ul><li><a href="#case-study-1-netflix-model-replication">Case Study 1: Netflix Model Replication</a></li><li><a href="#case-study-2-ubers-michelangelo">Case Study 2: Uber’s Michelangelo</a></li><li><a href="#case-study-3-spotify-recommendations">Case Study 3: Spotify Recommendations</a></li></ul></li><li><a href="#implementation-model-replication-with-docker--kubernetes">Implementation: Model Replication with Docker + Kubernetes</a></li><li><a href="#top-interview-questions">Top Interview Questions</a></li><li><a href="#12-deep-dive-shadow-deployment-dark-launch">12. Deep Dive: Shadow Deployment (Dark Launch)</a></li><li><a href="#13-deep-dive-gradual-traffic-shifting">13. Deep Dive: Gradual Traffic Shifting</a></li><li><a href="#14-deep-dive-model-performance-monitoring">14. Deep Dive: Model Performance Monitoring</a></li><li><a href="#15-deep-dive-cost-optimization">15. Deep Dive: Cost Optimization</a></li><li><a href="#16-deep-dive-security-considerations">16. Deep Dive: Security Considerations</a></li><li><a href="#17-deep-dive-disaster-recovery-drills">17. Deep Dive: Disaster Recovery Drills</a></li><li><a href="#18-production-war-stories">18. Production War Stories</a></li><li><a href="#19-deep-dive-ab-testing-infrastructure-for-model-replicas">19. Deep Dive: A/B Testing Infrastructure for Model Replicas</a></li><li><a href="#20-deep-dive-multi-armed-bandits-for-dynamic-model-selection">20. Deep Dive: Multi-Armed Bandits for Dynamic Model Selection</a></li><li><a href="#key-takeaways">Key Takeaways</a></li><li><a href="#summary">Summary</a></li></ul>
            </nav>
          </aside>
        
        <p><strong>“Ensuring your ML models are available everywhere, all the time.”</strong></p>

<h2 id="1-the-problem-single-point-of-failure">1. The Problem: Single Point of Failure</h2>

<p>Deploying an ML model to a single server is a recipe for disaster:</p>
<ul>
  <li><strong>Server crashes</strong> → Service unavailable.</li>
  <li><strong>Network partition</strong> → Users in Europe can’t reach a US-based server.</li>
  <li><strong>Traffic spike</strong> → Server overloaded.</li>
</ul>

<p><strong>Model Replication</strong> solves this by deploying multiple copies of the model across different servers, regions, or data centers.</p>

<h2 id="2-why-replicate-models">2. Why Replicate Models?</h2>

<p><strong>1. High Availability (HA):</strong></p>
<ul>
  <li>If one replica fails, traffic routes to healthy replicas.</li>
  <li>Target: 99.99% uptime (&lt; 53 minutes downtime per year).</li>
</ul>

<p><strong>2. Low Latency:</strong></p>
<ul>
  <li>Serve users from the nearest replica.</li>
  <li>US users → US server, EU users → EU server.</li>
  <li>Reduces latency from 200ms to 20ms.</li>
</ul>

<p><strong>3. Load Balancing:</strong></p>
<ul>
  <li>Distribute inference requests across replicas.</li>
  <li>Prevents any single server from being overwhelmed.</li>
</ul>

<p><strong>4. Disaster Recovery:</strong></p>
<ul>
  <li>If an entire data center goes down (fire, earthquake), other regions continue serving.</li>
</ul>

<h2 id="3-replication-strategies">3. Replication Strategies</h2>

<h3 id="strategy-1-active-active-multi-master">Strategy 1: Active-Active (Multi-Master)</h3>
<p>All replicas actively serve traffic simultaneously.</p>

<p><strong>Architecture:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>       Load Balancer
      /      |      \
  Replica1  Replica2  Replica3
  (US-West) (US-East) (EU-West)
</code></pre></div></div>

<p><strong>Pros:</strong></p>
<ul>
  <li>Full traffic distribution.</li>
  <li>Maximum throughput.</li>
</ul>

<p><strong>Cons:</strong></p>
<ul>
  <li>Requires synchronization if models have state (rare for inference).</li>
</ul>

<h3 id="strategy-2-active-passive-primary-standby">Strategy 2: Active-Passive (Primary-Standby)</h3>
<p>One replica serves traffic. Others are on standby.</p>

<p><strong>Architecture:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  Primary (Active)
       |
  Standby 1, Standby 2 (Passive)
</code></pre></div></div>

<p><strong>Pros:</strong></p>
<ul>
  <li>Simple to implement.</li>
  <li>Standby can be used for testing new models.</li>
</ul>

<p><strong>Cons:</strong></p>
<ul>
  <li>Underutilized resources (standby idles).</li>
  <li>Failover delay (10-60 seconds).</li>
</ul>

<h3 id="strategy-3-geo-replication">Strategy 3: Geo-Replication</h3>
<p>Replicas deployed in different geographic regions.</p>

<p><strong>Architecture:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>US-West Cluster &lt;---&gt; US-East Cluster &lt;---&gt; EU Cluster
</code></pre></div></div>

<p><strong>Pros:</strong></p>
<ul>
  <li>Complies with data residency laws (GDPR: EU data stays in EU).</li>
  <li>Low latency for global users.</li>
</ul>

<p><strong>Cons:</strong></p>
<ul>
  <li>Higher cost (multi-region infrastructure).</li>
  <li>Complex network topology.</li>
</ul>

<h2 id="4-model-synchronization-patterns">4. Model Synchronization Patterns</h2>

<p><strong>Challenge:</strong> How do we ensure all replicas serve the <strong>same</strong> model version?</p>

<h3 id="pattern-1-push-based-deployment">Pattern 1: Push-Based Deployment</h3>
<p>A central controller pushes new models to all replicas.</p>

<p><strong>Flow:</strong></p>
<ol>
  <li>Train new model.</li>
  <li>Upload to central storage (S3).</li>
  <li>Controller triggers deployment to all replicas.</li>
  <li>Replicas pull the model and reload.</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Pseudo-code for controller
</span><span class="k">def</span> <span class="nf">deploy_model</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">replicas</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">replica</span> <span class="ow">in</span> <span class="n">replicas</span><span class="p">:</span>
        <span class="n">replica</span><span class="p">.</span><span class="nf">pull_model</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
        <span class="n">replica</span><span class="p">.</span><span class="nf">reload</span><span class="p">()</span>
</code></pre></div></div>

<p><strong>Pros:</strong></p>
<ul>
  <li>Centralized control.</li>
  <li>Ensures consistency.</li>
</ul>

<p><strong>Cons:</strong></p>
<ul>
  <li>Single point of failure (controller).</li>
  <li>Deployment can be slow (sequential updates).</li>
</ul>

<h3 id="pattern-2-pull-based-deployment-polling">Pattern 2: Pull-Based Deployment (Polling)</h3>
<p>Each replica periodically checks for new models.</p>

<p><strong>Flow:</strong></p>
<ol>
  <li>Upload model to S3.</li>
  <li>Replicas poll S3 every 60 seconds.</li>
  <li>If new model detected, download and reload.</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">time</span>
<span class="kn">import</span> <span class="n">hashlib</span>

<span class="k">def</span> <span class="nf">poll_for_updates</span><span class="p">(</span><span class="n">model_url</span><span class="p">,</span> <span class="n">current_hash</span><span class="p">):</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">new_hash</span> <span class="o">=</span> <span class="nf">get_model_hash</span><span class="p">(</span><span class="n">model_url</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">new_hash</span> <span class="o">!=</span> <span class="n">current_hash</span><span class="p">:</span>
            <span class="nf">download_model</span><span class="p">(</span><span class="n">model_url</span><span class="p">)</span>
            <span class="nf">reload_model</span><span class="p">()</span>
            <span class="n">current_hash</span> <span class="o">=</span> <span class="n">new_hash</span>
        <span class="n">time</span><span class="p">.</span><span class="nf">sleep</span><span class="p">(</span><span class="mi">60</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Pros:</strong></p>
<ul>
  <li>Decentralized (no controller).</li>
  <li>Replicas update independently.</li>
</ul>

<p><strong>Cons:</strong></p>
<ul>
  <li>Polling overhead.</li>
  <li>Inconsistent state (replicas update at different times).</li>
</ul>

<h3 id="pattern-3-event-driven-deployment">Pattern 3: Event-Driven Deployment</h3>
<p>Replicas subscribe to a message queue (Kafka, SNS). Controller publishes a “new model available” event.</p>

<p><strong>Flow:</strong></p>
<ol>
  <li>Upload model to S3.</li>
  <li>Publish message to Kafka topic: <code class="language-plaintext highlighter-rouge">model-updates</code>.</li>
  <li>Replicas consume messages and download the new model.</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">kafka</span> <span class="kn">import</span> <span class="n">KafkaConsumer</span>

<span class="n">consumer</span> <span class="o">=</span> <span class="nc">KafkaConsumer</span><span class="p">(</span><span class="sh">'</span><span class="s">model-updates</span><span class="sh">'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">message</span> <span class="ow">in</span> <span class="n">consumer</span><span class="p">:</span>
    <span class="n">model_url</span> <span class="o">=</span> <span class="n">message</span><span class="p">.</span><span class="n">value</span>
    <span class="nf">download_model</span><span class="p">(</span><span class="n">model_url</span><span class="p">)</span>
    <span class="nf">reload_model</span><span class="p">()</span>
</code></pre></div></div>

<p><strong>Pros:</strong></p>
<ul>
  <li>Real-time updates.</li>
  <li>Decoupled controller and replicas.</li>
</ul>

<p><strong>Cons:</strong></p>
<ul>
  <li>Requires message queue infrastructure.</li>
  <li>Ordering guarantees needed.</li>
</ul>

<h2 id="5-deep-dive-canary-deployment">5. Deep Dive: Canary Deployment</h2>

<p><strong>Problem:</strong> A new model might have bugs. Rolling out to all replicas at once is risky.</p>

<p><strong>Solution:</strong> <strong>Canary Deployment</strong></p>
<ol>
  <li>Deploy new model to <strong>1%</strong> of replicas (canaries).</li>
  <li>Monitor metrics (latency, error rate, accuracy).</li>
  <li>If healthy, gradually increase to 10%, 50%, 100%.</li>
  <li>If unhealthy, rollback immediately.</li>
</ol>

<p><strong>Architecture:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Load Balancer
  |
  ├─ 99% traffic → Old Model (v1)
  └─  1% traffic → New Model (v2) [Canary]
</code></pre></div></div>

<p><strong>Implementation with Kubernetes:</strong></p>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">model-v1</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">99</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">model</span>
        <span class="na">image</span><span class="pi">:</span> <span class="s">model:v1</span>

<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">model-v2-canary</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">1</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">model</span>
        <span class="na">image</span><span class="pi">:</span> <span class="s">model:v2</span>
</code></pre></div></div>

<p><strong>Monitoring Canary:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">monitor_canary</span><span class="p">(</span><span class="n">canary_metrics</span><span class="p">,</span> <span class="n">baseline_metrics</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">canary_metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">error_rate</span><span class="sh">'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">baseline_metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">error_rate</span><span class="sh">'</span><span class="p">]</span> <span class="o">*</span> <span class="mf">1.5</span><span class="p">:</span>
        <span class="nf">rollback</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">canary_metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">p99_latency</span><span class="sh">'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">baseline_metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">p99_latency</span><span class="sh">'</span><span class="p">]</span> <span class="o">*</span> <span class="mf">1.2</span><span class="p">:</span>
        <span class="nf">rollback</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nf">promote_canary</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="6-deep-dive-blue-green-deployment">6. Deep Dive: Blue-Green Deployment</h2>

<p><strong>Concept:</strong> Maintain two identical environments: Blue (current) and Green (new).</p>

<p><strong>Flow:</strong></p>
<ol>
  <li><strong>Blue</strong> is live (serving 100% traffic).</li>
  <li>Deploy new model to <strong>Green</strong>.</li>
  <li>Test <strong>Green</strong> (smoke tests, load tests).</li>
  <li>Switch traffic from <strong>Blue</strong> to <strong>Green</strong> (atomic switch).</li>
  <li>If issues arise, switch back to <strong>Blue</strong> instantly.</li>
</ol>

<p><strong>Pros:</strong></p>
<ul>
  <li>Zero-downtime deployment.</li>
  <li>Instant rollback.</li>
</ul>

<p><strong>Cons:</strong></p>
<ul>
  <li>Requires 2x resources (both environments running).</li>
</ul>

<h2 id="7-deep-dive-model-versioning-and-rollback">7. Deep Dive: Model Versioning and Rollback</h2>

<p><strong>Challenge:</strong> How do we track which model version is deployed where?</p>

<p><strong>Solution: Model Registry</strong></p>
<ul>
  <li>Central database of all model versions.</li>
  <li>Each model tagged with: version, timestamp, accuracy metrics, deployment status.</li>
</ul>

<p><strong>Schema:</strong></p>
<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">models</span> <span class="p">(</span>
    <span class="n">model_id</span> <span class="n">UUID</span> <span class="k">PRIMARY</span> <span class="k">KEY</span><span class="p">,</span>
    <span class="k">version</span> <span class="nb">VARCHAR</span><span class="p">,</span>
    <span class="n">created_at</span> <span class="nb">TIMESTAMP</span><span class="p">,</span>
    <span class="n">accuracy</span> <span class="nb">FLOAT</span><span class="p">,</span>
    <span class="n">deployed_replicas</span> <span class="nb">INTEGER</span><span class="p">,</span>
    <span class="n">status</span> <span class="nb">VARCHAR</span>  <span class="c1">-- 'training', 'canary', 'production', 'deprecated'</span>
<span class="p">);</span>
</code></pre></div></div>

<p><strong>Rollback Strategy:</strong></p>
<ol>
  <li>Detect issue (alert triggered).</li>
  <li>Query model registry for last known good version.</li>
  <li>Trigger redeployment to all replicas.</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">rollback</span><span class="p">():</span>
    <span class="n">last_good_version</span> <span class="o">=</span> <span class="n">db</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span>
        <span class="sh">"</span><span class="s">SELECT version FROM models WHERE status=</span><span class="sh">'</span><span class="s">production</span><span class="sh">'</span><span class="s"> ORDER BY created_at DESC LIMIT 1</span><span class="sh">"</span>
    <span class="p">)</span>
    <span class="nf">deploy_model</span><span class="p">(</span><span class="n">last_good_version</span><span class="p">,</span> <span class="n">replicas</span><span class="o">=</span><span class="n">all_replicas</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="8-deep-dive-handling-stateful-models">8. Deep Dive: Handling Stateful Models</h2>

<p>Most inference models are <strong>stateless</strong> (same input → same output). But some models maintain state:</p>

<p><strong>Examples:</strong></p>
<ul>
  <li><strong>Recommendation Systems:</strong> User session history.</li>
  <li><strong>Chatbots:</strong> Conversation context.</li>
  <li><strong>Reinforcement Learning:</strong> Agent state.</li>
</ul>

<p><strong>Challenge with Replication:</strong>
If a user’s first request goes to Replica 1, the second request might go to Replica 2 (which doesn’t have the session state).</p>

<p><strong>Solution 1: Sticky Sessions</strong>
Route all requests from the same user to the same replica.</p>

<div class="language-nginx highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">upstream</span> <span class="s">backend</span> <span class="p">{</span>
    <span class="kn">ip_hash</span><span class="p">;</span>  <span class="c1"># Hash user IP to the same server</span>
    <span class="kn">server</span> <span class="nf">replica1</span><span class="p">:</span><span class="mi">8000</span><span class="p">;</span>
    <span class="kn">server</span> <span class="nf">replica2</span><span class="p">:</span><span class="mi">8000</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<p><strong>Cons:</strong> If a replica dies, user sessions are lost.</p>

<p><strong>Solution 2: Shared State Store (Redis)</strong>
All replicas read/write state to a central Redis cluster.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">redis</span>

<span class="n">redis_client</span> <span class="o">=</span> <span class="n">redis</span><span class="p">.</span><span class="nc">Redis</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">user_id</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
    <span class="c1"># Load user state
</span>    <span class="n">state</span> <span class="o">=</span> <span class="n">redis_client</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">user:</span><span class="si">{</span><span class="n">user_id</span><span class="si">}</span><span class="s">:state</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="c1"># Run inference
</span>    <span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
    
    <span class="c1"># Update state
</span>    <span class="n">redis_client</span><span class="p">.</span><span class="nf">set</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">user:</span><span class="si">{</span><span class="n">user_id</span><span class="si">}</span><span class="s">:state</span><span class="sh">"</span><span class="p">,</span> <span class="n">result</span><span class="p">[</span><span class="sh">'</span><span class="s">new_state</span><span class="sh">'</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">result</span><span class="p">[</span><span class="sh">'</span><span class="s">prediction</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div>

<p><strong>Pros:</strong> Stateless replicas, can route to any replica.
<strong>Cons:</strong> Redis becomes a bottleneck.</p>

<h2 id="9-deep-dive-cross-region-replication">9. Deep Dive: Cross-Region Replication</h2>

<p><strong>Scenario:</strong> Replicate a recommendation model across US, EU, and Asia.</p>

<p><strong>Challenges:</strong></p>
<ol>
  <li><strong>Model Artifact Size:</strong> 5 GB model → slow to transfer across continents.</li>
  <li><strong>Network Latency:</strong> EU → Asia = 300ms.</li>
  <li><strong>Cost:</strong> Cross-region data transfer is expensive ($0.02/GB in AWS).</li>
</ol>

<p><strong>Optimization 1: Delta Updates</strong>
Don’t transfer the entire model. Only send the changed weights.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">compute_delta</span><span class="p">(</span><span class="n">old_model</span><span class="p">,</span> <span class="n">new_model</span><span class="p">):</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">new_model</span><span class="p">.</span><span class="n">layers</span><span class="p">:</span>
        <span class="n">delta</span><span class="p">[</span><span class="n">layer</span><span class="p">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_model</span><span class="p">.</span><span class="n">weights</span><span class="p">[</span><span class="n">layer</span><span class="p">.</span><span class="n">name</span><span class="p">]</span> <span class="o">-</span> <span class="n">old_model</span><span class="p">.</span><span class="n">weights</span><span class="p">[</span><span class="n">layer</span><span class="p">.</span><span class="n">name</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">delta</span>

<span class="k">def</span> <span class="nf">apply_delta</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">delta</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">layer_name</span><span class="p">,</span> <span class="n">weight_diff</span> <span class="ow">in</span> <span class="n">delta</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
        <span class="n">model</span><span class="p">.</span><span class="n">weights</span><span class="p">[</span><span class="n">layer_name</span><span class="p">]</span> <span class="o">+=</span> <span class="n">weight_diff</span>
</code></pre></div></div>

<p><strong>Optimization 2: Model Compression</strong>
Compress the model before transfer (gzip, quantization).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">gzip</span>

<span class="c1"># Compress
</span><span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">'</span><span class="s">model.pkl</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">rb</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f_in</span><span class="p">:</span>
    <span class="k">with</span> <span class="n">gzip</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="sh">'</span><span class="s">model.pkl.gz</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">wb</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f_out</span><span class="p">:</span>
        <span class="n">f_out</span><span class="p">.</span><span class="nf">writelines</span><span class="p">(</span><span class="n">f_in</span><span class="p">)</span>

<span class="c1"># Transfer compressed file (5 GB → 1 GB)
</span></code></pre></div></div>

<p><strong>Optimization 3: Regional Model Stores</strong>
Replicate the model to regional S3 buckets.</p>
<ul>
  <li>US replicas pull from <code class="language-plaintext highlighter-rouge">s3://models-us-west/</code></li>
  <li>EU replicas pull from <code class="language-plaintext highlighter-rouge">s3://models-eu-west/</code></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_model_url</span><span class="p">(</span><span class="n">region</span><span class="p">):</span>
    <span class="n">base_url</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">s3://models-</span><span class="si">{</span><span class="n">region</span><span class="si">}</span><span class="sh">"</span>
    <span class="k">return</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">base_url</span><span class="si">}</span><span class="s">/model-v123.pkl</span><span class="sh">"</span>
</code></pre></div></div>

<h2 id="10-deep-dive-health-checks-and-auto-scaling">10. Deep Dive: Health Checks and Auto-Scaling</h2>

<p><strong>Health Check Types:</strong></p>
<ol>
  <li><strong>Liveness Probe:</strong> Is the server running?
    <ul>
      <li>HTTP GET <code class="language-plaintext highlighter-rouge">/health</code> → 200 OK.</li>
    </ul>
  </li>
  <li><strong>Readiness Probe:</strong> Is the server ready to serve traffic?
    <ul>
      <li>Check: Model loaded? Database connected?</li>
    </ul>
  </li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">fastapi</span> <span class="kn">import</span> <span class="n">FastAPI</span>

<span class="n">app</span> <span class="o">=</span> <span class="nc">FastAPI</span><span class="p">()</span>

<span class="n">model</span> <span class="o">=</span> <span class="bp">None</span>

<span class="nd">@app.on_event</span><span class="p">(</span><span class="sh">"</span><span class="s">startup</span><span class="sh">"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">load_model</span><span class="p">():</span>
    <span class="k">global</span> <span class="n">model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="nf">load_model_from_s3</span><span class="p">()</span>

<span class="nd">@app.get</span><span class="p">(</span><span class="sh">"</span><span class="s">/health</span><span class="sh">"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">liveness</span><span class="p">():</span>
    <span class="k">return</span> <span class="p">{</span><span class="sh">"</span><span class="s">status</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">alive</span><span class="sh">"</span><span class="p">}</span>

<span class="nd">@app.get</span><span class="p">(</span><span class="sh">"</span><span class="s">/ready</span><span class="sh">"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">readiness</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span><span class="sh">"</span><span class="s">status</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">not ready</span><span class="sh">"</span><span class="p">},</span> <span class="mi">503</span>
    <span class="k">return</span> <span class="p">{</span><span class="sh">"</span><span class="s">status</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">ready</span><span class="sh">"</span><span class="p">}</span>
</code></pre></div></div>

<p><strong>Auto-Scaling:</strong>
Scale replicas based on traffic.</p>

<p><strong>Kubernetes Horizontal Pod Autoscaler (HPA):</strong></p>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">autoscaling/v2</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">HorizontalPodAutoscaler</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">model-hpa</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">scaleTargetRef</span><span class="pi">:</span>
    <span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
    <span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">model</span>
  <span class="na">minReplicas</span><span class="pi">:</span> <span class="m">3</span>
  <span class="na">maxReplicas</span><span class="pi">:</span> <span class="m">100</span>
  <span class="na">metrics</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">type</span><span class="pi">:</span> <span class="s">Resource</span>
    <span class="na">resource</span><span class="pi">:</span>
      <span class="na">name</span><span class="pi">:</span> <span class="s">cpu</span>
      <span class="na">target</span><span class="pi">:</span>
        <span class="na">type</span><span class="pi">:</span> <span class="s">Utilization</span>
        <span class="na">averageUtilization</span><span class="pi">:</span> <span class="m">70</span>
</code></pre></div></div>

<p>When CPU &gt; 70%, Kubernetes spawns more pods. When CPU &lt; 70%, it scales down.</p>

<h2 id="11-real-world-case-studies">11. Real-World Case Studies</h2>

<h3 id="case-study-1-netflix-model-replication">Case Study 1: Netflix Model Replication</h3>
<p>Netflix uses <strong>A/B testing</strong> at scale across global replicas.</p>

<p><strong>Architecture:</strong></p>
<ul>
  <li>Deploy Model A to US-West.</li>
  <li>Deploy Model B to US-East.</li>
  <li>Compare engagement metrics (watch time).</li>
  <li>Winner gets deployed globally.</li>
</ul>

<h3 id="case-study-2-ubers-michelangelo">Case Study 2: Uber’s Michelangelo</h3>
<p>Uber’s ML platform deploys models to <strong>hundreds of cities</strong>.</p>

<p><strong>Challenge:</strong> Each city has different demand patterns.
<strong>Solution:</strong> City-specific models.</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">model-san-francisco-v10</code></li>
  <li><code class="language-plaintext highlighter-rouge">model-new-york-v12</code></li>
</ul>

<p><strong>Replication:</strong></p>
<ul>
  <li>Each city’s model is replicated 10x within that region’s data center.</li>
</ul>

<h3 id="case-study-3-spotify-recommendations">Case Study 3: Spotify Recommendations</h3>
<p>Spotify serves personalized playlists to 500M users.</p>

<p><strong>Architecture:</strong></p>
<ul>
  <li>50+ replicas per region.</li>
  <li>Models deployed via Kubernetes.</li>
  <li>Canary deployment for new models (1% → 100%).</li>
</ul>

<h2 id="implementation-model-replication-with-docker--kubernetes">Implementation: Model Replication with Docker + Kubernetes</h2>

<p><strong>Step 1: Dockerize the Model</strong></p>
<div class="language-dockerfile highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">FROM</span><span class="s"> python:3.9</span>
<span class="k">WORKDIR</span><span class="s"> /app</span>
<span class="k">COPY</span><span class="s"> requirements.txt .</span>
<span class="k">RUN </span>pip <span class="nb">install</span> <span class="nt">-r</span> requirements.txt
<span class="k">COPY</span><span class="s"> model.pkl model.pkl</span>
<span class="k">COPY</span><span class="s"> serve.py serve.py</span>
<span class="k">CMD</span><span class="s"> ["python", "serve.py"]</span>
</code></pre></div></div>

<p><strong>Step 2: Deploy to Kubernetes</strong></p>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">model-inference</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">10</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">model</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">metadata</span><span class="pi">:</span>
      <span class="na">labels</span><span class="pi">:</span>
        <span class="na">app</span><span class="pi">:</span> <span class="s">model</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">model</span>
        <span class="na">image</span><span class="pi">:</span> <span class="s">my-registry/model:v1</span>
        <span class="na">ports</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">containerPort</span><span class="pi">:</span> <span class="m">8000</span>
        <span class="na">resources</span><span class="pi">:</span>
          <span class="na">requests</span><span class="pi">:</span>
            <span class="na">memory</span><span class="pi">:</span> <span class="s2">"</span><span class="s">2Gi"</span>
            <span class="na">cpu</span><span class="pi">:</span> <span class="s2">"</span><span class="s">1"</span>
          <span class="na">limits</span><span class="pi">:</span>
            <span class="na">memory</span><span class="pi">:</span> <span class="s2">"</span><span class="s">4Gi"</span>
            <span class="na">cpu</span><span class="pi">:</span> <span class="s2">"</span><span class="s">2"</span>
</code></pre></div></div>

<p><strong>Step 3: Expose via Load Balancer</strong></p>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Service</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">model-service</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">type</span><span class="pi">:</span> <span class="s">LoadBalancer</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">model</span>
  <span class="na">ports</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">protocol</span><span class="pi">:</span> <span class="s">TCP</span>
    <span class="na">port</span><span class="pi">:</span> <span class="m">80</span>
    <span class="na">targetPort</span><span class="pi">:</span> <span class="m">8000</span>
</code></pre></div></div>

<h2 id="top-interview-questions">Top Interview Questions</h2>

<p><strong>Q1: How do you ensure all replicas serve the same model version?</strong>
<em>Answer:</em></p>
<ul>
  <li>Use a <strong>model registry</strong> with version tracking.</li>
  <li>Deploy atomically (all replicas pull the same version).</li>
  <li>Use checksums/hashes to verify model integrity.</li>
</ul>

<p><strong>Q2: What happens if a replica is serving an old model version?</strong>
<em>Answer:</em></p>
<ul>
  <li><strong>Monitoring:</strong> Track model version per replica.</li>
  <li><strong>Alert:</strong> If version mismatch detected, trigger alert.</li>
  <li><strong>Force Update:</strong> Controller sends a “reload model” command.</li>
</ul>

<p><strong>Q3: How do you handle model deployment in a multi-region setup?</strong>
<em>Answer:</em></p>
<ul>
  <li><strong>Regional Rollout:</strong> Deploy to one region first (canary).</li>
  <li><strong>Monitor:</strong> Check error rates, latency.</li>
  <li><strong>Progressive Rollout:</strong> If healthy, deploy to other regions.</li>
</ul>

<p><strong>Q4: What’s the difference between horizontal and vertical scaling for model replicas?</strong>
<em>Answer:</em></p>
<ul>
  <li><strong>Horizontal:</strong> Add more replicas (more servers). Better for handling high traffic.</li>
  <li><strong>Vertical:</strong> Increase resources per replica (more CPU/RAM). Better for larger models.</li>
</ul>

<p><strong>Q5: How do you minimize downtime during model updates?</strong>
<em>Answer:</em></p>
<ul>
  <li><strong>Rolling Update:</strong> Update replicas one at a time.</li>
  <li><strong>Blue-Green:</strong> Maintain two environments, switch traffic atomically.</li>
  <li><strong>Canary:</strong> Gradually shift traffic to the new model.</li>
</ul>

<h2 id="12-deep-dive-shadow-deployment-dark-launch">12. Deep Dive: Shadow Deployment (Dark Launch)</h2>

<p><strong>Concept:</strong> Deploy a new model alongside the old model, but don’t serve its predictions to users. Instead, log predictions for comparison.</p>

<p><strong>Architecture:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>User Request
    ↓
Load Balancer
    ↓
┌───────────────────────┐
│  Primary Model (v1)   │ → Response to User
│  Shadow Model (v2)    │ → Predictions logged (not served)
└───────────────────────┘
</code></pre></div></div>

<p><strong>Implementation:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">logging</span>

<span class="k">class</span> <span class="nc">ShadowPredictor</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">primary_model</span><span class="p">,</span> <span class="n">shadow_model</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">primary</span> <span class="o">=</span> <span class="n">primary_model</span>
        <span class="n">self</span><span class="p">.</span><span class="n">shadow</span> <span class="o">=</span> <span class="n">shadow_model</span>
    
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
        <span class="c1"># Primary prediction (served to user)
</span>        <span class="n">primary_pred</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">primary</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        
        <span class="c1"># Shadow prediction (async logging)
</span>        <span class="k">try</span><span class="p">:</span>
            <span class="n">shadow_pred</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">shadow</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
            <span class="n">logging</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Shadow pred: </span><span class="si">{</span><span class="n">shadow_pred</span><span class="si">}</span><span class="s">, Primary: </span><span class="si">{</span><span class="n">primary_pred</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logging</span><span class="p">.</span><span class="nf">error</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Shadow model failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">primary_pred</span>
</code></pre></div></div>

<p><strong>Benefits:</strong></p>
<ul>
  <li><strong>Zero Risk:</strong> Users never see shadow model predictions.</li>
  <li><strong>Real Production Data:</strong> Validate on actual user queries.</li>
  <li><strong>Performance Comparison:</strong> Compare latency, accuracy in real-time.</li>
</ul>

<p><strong>Use Case:</strong> Testing a radically different model architecture without risk.</p>

<h2 id="13-deep-dive-gradual-traffic-shifting">13. Deep Dive: Gradual Traffic Shifting</h2>

<p>More sophisticated than binary canary deployment, gradually shift traffic over hours/days.</p>

<p><strong>Strategy:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Hour 0:  0% v2,  100% v1
Hour 1:  5% v2,   95% v1
Hour 2: 10% v2,   90% v1
Hour 4: 25% v2,   75% v1
Hour 8: 50% v2,   50% v1
Hour 12: 100% v2,  0% v1
</code></pre></div></div>

<p><strong>Implementation with Feature Flags:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">random</span>

<span class="k">class</span> <span class="nc">FeatureFlag</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">rollout_percentage</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Start at 0%
</span>    
    <span class="k">def</span> <span class="nf">should_use_new_model</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">user_id</span><span class="p">):</span>
        <span class="c1"># Consistent hashing: same user always gets same experience
</span>        <span class="n">user_hash</span> <span class="o">=</span> <span class="nf">hash</span><span class="p">(</span><span class="n">user_id</span><span class="p">)</span> <span class="o">%</span> <span class="mi">100</span>
        <span class="k">return</span> <span class="n">user_hash</span> <span class="o">&lt;</span> <span class="n">self</span><span class="p">.</span><span class="n">rollout_percentage</span>
    
    <span class="k">def</span> <span class="nf">set_rollout</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">percentage</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">rollout_percentage</span> <span class="o">=</span> <span class="n">percentage</span>

<span class="c1"># Usage
</span><span class="n">flag</span> <span class="o">=</span> <span class="nc">FeatureFlag</span><span class="p">()</span>
<span class="n">flag</span><span class="p">.</span><span class="nf">set_rollout</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span>  <span class="c1"># 25% of users see new model
</span>
<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">user_id</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">flag</span><span class="p">.</span><span class="nf">should_use_new_model</span><span class="p">(</span><span class="n">user_id</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">model_v2</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">model_v1</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="14-deep-dive-model-performance-monitoring">14. Deep Dive: Model Performance Monitoring</h2>

<p><strong>Metrics to Track:</strong></p>

<p><strong>1. Latency Metrics:</strong></p>
<ul>
  <li><strong>P50 (Median):</strong> 50% of requests complete in X ms.</li>
  <li><strong>P95:</strong> 95% of requests complete in X ms.</li>
  <li><strong>P99:</strong> 99% of requests (worst 1%) complete in X ms.</li>
</ul>

<p><strong>Why P99 matters:</strong> Even if P50 is 10ms, P99 of 5000ms means some users have terrible experience.</p>

<p><strong>2. Throughput Metrics:</strong></p>
<ul>
  <li><strong>Requests Per Second (RPS):</strong> How many requests the replica can handle.</li>
  <li><strong>Saturation:</strong> % of capacity used. If &gt; 80%, scale up.</li>
</ul>

<p><strong>3. Error Metrics:</strong></p>
<ul>
  <li><strong>Error Rate:</strong> % of requests that fail.</li>
  <li><strong>Error Types:</strong> Timeout, Model Error, OOM, Network Error.</li>
</ul>

<p><strong>4. Business Metrics:</strong></p>
<ul>
  <li><strong>Click-Through Rate (CTR):</strong> For recommendation models.</li>
  <li><strong>Conversion Rate:</strong> For ranking models.</li>
  <li><strong>Revenue Per User:</strong> For personalization models.</li>
</ul>

<p><strong>Prometheus Example:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">prometheus_client</span> <span class="kn">import</span> <span class="n">Counter</span><span class="p">,</span> <span class="n">Histogram</span><span class="p">,</span> <span class="n">Gauge</span>

<span class="c1"># Counters
</span><span class="n">prediction_counter</span> <span class="o">=</span> <span class="nc">Counter</span><span class="p">(</span>
    <span class="sh">'</span><span class="s">model_predictions_total</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">Total predictions</span><span class="sh">'</span><span class="p">,</span>
    <span class="p">[</span><span class="sh">'</span><span class="s">model_version</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">replica_id</span><span class="sh">'</span><span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Histograms (for latency)
</span><span class="n">prediction_latency</span> <span class="o">=</span> <span class="nc">Histogram</span><span class="p">(</span>
    <span class="sh">'</span><span class="s">model_prediction_latency_seconds</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">Prediction latency</span><span class="sh">'</span><span class="p">,</span>
    <span class="p">[</span><span class="sh">'</span><span class="s">model_version</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">buckets</span><span class="o">=</span><span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Gauges (for current state)
</span><span class="n">active_replicas</span> <span class="o">=</span> <span class="nc">Gauge</span><span class="p">(</span>
    <span class="sh">'</span><span class="s">model_active_replicas</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">Number of active replicas</span><span class="sh">'</span><span class="p">,</span>
    <span class="p">[</span><span class="sh">'</span><span class="s">model_version</span><span class="sh">'</span><span class="p">]</span>
<span class="p">)</span>

<span class="c1">#Usage
</span><span class="nd">@app.post</span><span class="p">(</span><span class="sh">"</span><span class="s">/predict</span><span class="sh">"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">prediction_latency</span><span class="p">.</span><span class="nf">labels</span><span class="p">(</span><span class="n">model_version</span><span class="o">=</span><span class="sh">'</span><span class="s">v2</span><span class="sh">'</span><span class="p">).</span><span class="nf">time</span><span class="p">():</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
    
    <span class="n">prediction_counter</span><span class="p">.</span><span class="nf">labels</span><span class="p">(</span>
        <span class="n">model_version</span><span class="o">=</span><span class="sh">'</span><span class="s">v2</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">replica_id</span><span class="o">=</span><span class="nf">get_replica_id</span><span class="p">()</span>
    <span class="p">).</span><span class="nf">inc</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">result</span>
</code></pre></div></div>

<h2 id="15-deep-dive-cost-optimization">15. Deep Dive: Cost Optimization</h2>

<p>Replicating models is expensive. How do we minimize cost without sacrificing reliability?</p>

<p><strong>Strategy 1: Right-Sizing Replicas</strong>
Don’t over-provision. Use actual traffic data to determine replica count.</p>

<p><strong>Formula:</strong>
\[
\text{Required Replicas} = \frac{\text{Peak RPS}}{\text{RPS per Replica}} \times \text{Safety Factor}
\]</p>

<p><strong>Example:</strong></p>
<ul>
  <li>Peak traffic: 10,000 RPS</li>
  <li>Each replica handles: 500 RPS</li>
  <li>Safety factor: 1.5 (for spikes)</li>
  <li>Required: $(10,000 / 500) \times 1.5 = 30$ replicas</li>
</ul>

<p><strong>Strategy 2: Spot Instances for Non-Critical Replicas</strong>
AWS Spot Instances are 70% cheaper but can be terminated.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Kubernetes Node Selector for Spot Instances
</span><span class="n">spec</span><span class="p">:</span>
  <span class="n">nodeSelector</span><span class="p">:</span>
    <span class="n">instance</span><span class="o">-</span><span class="nb">type</span><span class="p">:</span> <span class="n">spot</span>
  <span class="n">tolerations</span><span class="p">:</span>
  <span class="o">-</span> <span class="n">key</span><span class="p">:</span> <span class="sh">"</span><span class="s">spot</span><span class="sh">"</span>
    <span class="n">operator</span><span class="p">:</span> <span class="sh">"</span><span class="s">Equal</span><span class="sh">"</span>
    <span class="n">value</span><span class="p">:</span> <span class="sh">"</span><span class="s">true</span><span class="sh">"</span>
    <span class="n">effect</span><span class="p">:</span> <span class="sh">"</span><span class="s">NoSchedule</span><span class="sh">"</span>
</code></pre></div></div>

<p><strong>Use Case:</strong> Use spot instances for 50% of replicas. If terminated, route to on-demand replicas.</p>

<p><strong>Strategy 3: Model Quantization</strong>
Reduce model size from FP32 to INT8.</p>
<ul>
  <li><strong>Size:</strong> 4 GB → 1 GB (4x reduction)</li>
  <li><strong>Inference Speed:</strong> 2-3x faster</li>
  <li><strong>Cost:</strong> Fit 4x more replicas per server</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>

<span class="c1"># Quantize model
</span><span class="n">quantized_model</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">quantization</span><span class="p">.</span><span class="nf">quantize_dynamic</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="p">{</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">},</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">qint8</span>
<span class="p">)</span>

<span class="c1"># Size comparison
</span><span class="n">original_size</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">getsize</span><span class="p">(</span><span class="sh">'</span><span class="s">model_fp32.pt</span><span class="sh">'</span><span class="p">)</span>
<span class="n">quantized_size</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">getsize</span><span class="p">(</span><span class="sh">'</span><span class="s">model_int8.pt</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Compression ratio: </span><span class="si">{</span><span class="n">original_size</span> <span class="o">/</span> <span class="n">quantized_size</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">x</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Strategy 4: Auto-Scaling with Predictive Scaling</strong>
Don’t wait for load to spike. Predict it.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">predict_traffic</span><span class="p">(</span><span class="n">hour_of_day</span><span class="p">,</span> <span class="n">day_of_week</span><span class="p">):</span>
    <span class="c1"># Historical average
</span>    <span class="n">baseline</span> <span class="o">=</span> <span class="n">historical_traffic</span><span class="p">[</span><span class="n">day_of_week</span><span class="p">][</span><span class="n">hour_of_day</span><span class="p">]</span>
    
    <span class="c1"># Scale up 5 minutes before predicted spike
</span>    <span class="k">return</span> <span class="nf">int</span><span class="p">(</span><span class="n">baseline</span> <span class="o">*</span> <span class="mf">1.2</span><span class="p">)</span>

<span class="c1"># Cron job runs every 5 minutes
</span><span class="n">current_hour</span> <span class="o">=</span> <span class="n">datetime</span><span class="p">.</span><span class="nf">now</span><span class="p">().</span><span class="n">hour</span>
<span class="n">predicted_rps</span> <span class="o">=</span> <span class="nf">predict_traffic</span><span class="p">(</span><span class="n">current_hour</span><span class="p">,</span> <span class="n">datetime</span><span class="p">.</span><span class="nf">now</span><span class="p">().</span><span class="nf">weekday</span><span class="p">())</span>
<span class="n">required_replicas</span> <span class="o">=</span> <span class="nf">calculate_replicas</span><span class="p">(</span><span class="n">predicted_rps</span><span class="p">)</span>
<span class="nf">scale_to</span><span class="p">(</span><span class="n">required_replicas</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="16-deep-dive-security-considerations">16. Deep Dive: Security Considerations</h2>

<p><strong>1. Model Theft Prevention:</strong>
Large models (GPT-4, Stable Diffusion) are valuable IP. Prevent extraction.</p>

<p><strong>Attack Vector:</strong> Adversary queries model repeatedly to reverse-engineer weights.
<strong>Defense:</strong> Rate limiting, query auditing.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">import</span> <span class="n">time</span>

<span class="k">class</span> <span class="nc">RateLimiter</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">max_requests_per_minute</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">requests</span> <span class="o">=</span> <span class="nf">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">limit</span> <span class="o">=</span> <span class="n">max_requests_per_minute</span>
    
    <span class="k">def</span> <span class="nf">allow_request</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">user_id</span><span class="p">):</span>
        <span class="n">now</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
        <span class="c1"># Remove requests older than 1 minute
</span>        <span class="n">self</span><span class="p">.</span><span class="n">requests</span><span class="p">[</span><span class="n">user_id</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">ts</span> <span class="k">for</span> <span class="n">ts</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">requests</span><span class="p">[</span><span class="n">user_id</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">now</span> <span class="o">-</span> <span class="n">ts</span> <span class="o">&lt;</span> <span class="mi">60</span>
        <span class="p">]</span>
        
        <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">requests</span><span class="p">[</span><span class="n">user_id</span><span class="p">])</span> <span class="o">&gt;=</span> <span class="n">self</span><span class="p">.</span><span class="n">limit</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">False</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">requests</span><span class="p">[</span><span class="n">user_id</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="n">now</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">True</span>
</code></pre></div></div>

<p><strong>2. Data Privacy:</strong>
Ensure replicas don’t log sensitive user data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">re</span>

<span class="k">def</span> <span class="nf">sanitize_logs</span><span class="p">(</span><span class="n">log_message</span><span class="p">):</span>
    <span class="c1"># Redact emails, phone numbers, SSNs
</span>    <span class="n">log_message</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]{2,}\b</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">[REDACTED_EMAIL]</span><span class="sh">'</span><span class="p">,</span> <span class="n">log_message</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="n">re</span><span class="p">.</span><span class="n">I</span><span class="p">)</span>
    <span class="n">log_message</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">\b\d{3}-\d{2}-\d{4}\b</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">[REDACTED_SSN]</span><span class="sh">'</span><span class="p">,</span> <span class="n">log_message</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">log_message</span>

<span class="n">logging</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="nf">sanitize_logs</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">User query: </span><span class="si">{</span><span class="n">user_input</span><span class="si">}</span><span class="sh">"</span><span class="p">))</span>
</code></pre></div></div>

<p><strong>3. Model Integrity:</strong>
Verify that the deployed model hasn’t been tampered with.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">hashlib</span>

<span class="k">def</span> <span class="nf">verify_model_integrity</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">expected_hash</span><span class="p">):</span>
    <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="sh">'</span><span class="s">rb</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">model_bytes</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="nf">read</span><span class="p">()</span>
        <span class="n">computed_hash</span> <span class="o">=</span> <span class="n">hashlib</span><span class="p">.</span><span class="nf">sha256</span><span class="p">(</span><span class="n">model_bytes</span><span class="p">).</span><span class="nf">hexdigest</span><span class="p">()</span>
    
    <span class="k">if</span> <span class="n">computed_hash</span> <span class="o">!=</span> <span class="n">expected_hash</span><span class="p">:</span>
        <span class="k">raise</span> <span class="nc">SecurityError</span><span class="p">(</span><span class="sh">"</span><span class="s">Model file has been tampered with!</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="bp">True</span>

<span class="c1"># On deployment
</span><span class="n">expected_hash</span> <span class="o">=</span> <span class="sh">"</span><span class="s">abc123...def</span><span class="sh">"</span>  <span class="c1"># From model registry
</span><span class="nf">verify_model_integrity</span><span class="p">(</span><span class="sh">'</span><span class="s">/models/model.pt</span><span class="sh">'</span><span class="p">,</span> <span class="n">expected_hash</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="17-deep-dive-disaster-recovery-drills">17. Deep Dive: Disaster Recovery Drills</h2>

<p><strong>Problem:</strong> You have multi-region replication. But have you tested failover?</p>

<p><strong>DR Drill Strategy:</strong></p>
<ol>
  <li><strong>Planned Outage:</strong> Intentionally take down a region.</li>
  <li><strong>Monitor:</strong> Verify traffic shifts to healthy regions.</li>
  <li><strong>Measure:</strong> Recovery time, user impact.</li>
  <li><strong>Document:</strong> Update runbooks.</li>
</ol>

<p><strong>Chaos Engineering with Netflix’s Chaos Monkey:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">random</span>

<span class="k">def</span> <span class="nf">chaos_monkey</span><span class="p">():</span>
    <span class="c1"># Randomly terminate 1 replica every hour
</span>    <span class="k">if</span> <span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.1</span><span class="p">:</span>  <span class="c1"># 10% chance
</span>        <span class="n">replica_id</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="nf">get_all_replicas</span><span class="p">())</span>
        <span class="n">logging</span><span class="p">.</span><span class="nf">warning</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Chaos Monkey terminating replica </span><span class="si">{</span><span class="n">replica_id</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="nf">terminate_replica</span><span class="p">(</span><span class="n">replica_id</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Result:</strong> Forces teams to build resilient systems.</p>

<h2 id="18-production-war-stories">18. Production War Stories</h2>

<p><strong>War Story 1: The Silent Canary Failure</strong>
A team deployed a canary model. Metrics looked good (latency, error rate). But revenue dropped 15%.
<strong>Root Cause:</strong> New model was serving <em>lower quality</em> recommendations. Users clicked less.
<strong>Lesson:</strong> Track business metrics, not just technical metrics.</p>

<p><strong>War Story 2: The Cross-Region Sync Disaster</strong>
A model was deployed to EU-West. The EU-East replica was 2 hours behind (polling delay).
<strong>Result:</strong> Users in Paris saw different recommendations than users in Berlin.
<strong>Lesson:</strong> Use event-driven deployment for consistency guarantees.</p>

<p><strong>War Story 3: The Thundering Herd</strong>
1000 replicas all polled S3 at the same time (every 60 seconds, on the minute).
<strong>Result:</strong> S3 rate limit errors. Models failed to update.
<strong>Lesson:</strong> Add jitter to polling intervals.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">time</span>
<span class="kn">import</span> <span class="n">random</span>

<span class="k">def</span> <span class="nf">poll_with_jitter</span><span class="p">(</span><span class="n">base_interval</span><span class="o">=</span><span class="mi">60</span><span class="p">):</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="c1"># Sleep 60s ± 10s
</span>        <span class="n">jitter</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="n">time</span><span class="p">.</span><span class="nf">sleep</span><span class="p">(</span><span class="n">base_interval</span> <span class="o">+</span> <span class="n">jitter</span><span class="p">)</span>
        <span class="nf">check_for_updates</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="19-deep-dive-ab-testing-infrastructure-for-model-replicas">19. Deep Dive: A/B Testing Infrastructure for Model Replicas</h2>

<p><strong>Problem:</strong> You have model v1 and v2. Which one is better?</p>

<p><strong>Solution:</strong> A/B test them on real users.</p>

<p><strong>Architecture:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>User Request
    ↓
Feature Flag Service (reads user_id)
    ↓
├─ 50% → Model v1 (Control)
└─ 50% → Model v2 (Treatment)
</code></pre></div></div>

<p><strong>Implementation:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">hashlib</span>

<span class="k">class</span> <span class="nc">ABTestRouter</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">experiments</span> <span class="o">=</span> <span class="p">{}</span>
    
    <span class="k">def</span> <span class="nf">create_experiment</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">exp_id</span><span class="p">,</span> <span class="n">control_model</span><span class="p">,</span> <span class="n">treatment_model</span><span class="p">,</span> <span class="n">traffic_split</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">experiments</span><span class="p">[</span><span class="n">exp_id</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">control</span><span class="sh">'</span><span class="p">:</span> <span class="n">control_model</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">treatment</span><span class="sh">'</span><span class="p">:</span> <span class="n">treatment_model</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">split</span><span class="sh">'</span><span class="p">:</span> <span class="n">traffic_split</span>
        <span class="p">}</span>
    
    <span class="k">def</span> <span class="nf">get_model</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">exp_id</span><span class="p">,</span> <span class="n">user_id</span><span class="p">):</span>
        <span class="n">exp</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">experiments</span><span class="p">[</span><span class="n">exp_id</span><span class="p">]</span>
        
        <span class="c1"># Consistent hashing: same user always gets same variant
</span>        <span class="n">user_hash</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">hashlib</span><span class="p">.</span><span class="nf">md5</span><span class="p">(</span><span class="nf">str</span><span class="p">(</span><span class="n">user_id</span><span class="p">).</span><span class="nf">encode</span><span class="p">()).</span><span class="nf">hexdigest</span><span class="p">(),</span> <span class="mi">16</span><span class="p">)</span>
        <span class="n">bucket</span> <span class="o">=</span> <span class="p">(</span><span class="n">user_hash</span> <span class="o">%</span> <span class="mi">100</span><span class="p">)</span> <span class="o">/</span> <span class="mf">100.0</span>
        
        <span class="k">if</span> <span class="n">bucket</span> <span class="o">&lt;</span> <span class="n">exp</span><span class="p">[</span><span class="sh">'</span><span class="s">split</span><span class="sh">'</span><span class="p">]:</span>
            <span class="k">return</span> <span class="n">exp</span><span class="p">[</span><span class="sh">'</span><span class="s">treatment</span><span class="sh">'</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">exp</span><span class="p">[</span><span class="sh">'</span><span class="s">control</span><span class="sh">'</span><span class="p">]</span>

<span class="c1"># Usage
</span><span class="n">router</span> <span class="o">=</span> <span class="nc">ABTestRouter</span><span class="p">()</span>
<span class="n">router</span><span class="p">.</span><span class="nf">create_experiment</span><span class="p">(</span>
    <span class="n">exp_id</span><span class="o">=</span><span class="sh">'</span><span class="s">model_v2_test</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">control_model</span><span class="o">=</span><span class="n">model_v1</span><span class="p">,</span>
    <span class="n">treatment_model</span><span class="o">=</span><span class="n">model_v2</span><span class="p">,</span>
    <span class="n">traffic_split</span><span class="o">=</span><span class="mf">0.1</span>  <span class="c1"># 10% treatment, 90% control
</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">user_id</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">router</span><span class="p">.</span><span class="nf">get_model</span><span class="p">(</span><span class="sh">'</span><span class="s">model_v2_test</span><span class="sh">'</span><span class="p">,</span> <span class="n">user_id</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Statistical Significance:</strong>
After 1 week, analyze results:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">scipy</span> <span class="kn">import</span> <span class="n">stats</span>

<span class="k">def</span> <span class="nf">analyze_ab_test</span><span class="p">(</span><span class="n">control_metrics</span><span class="p">,</span> <span class="n">treatment_metrics</span><span class="p">):</span>
    <span class="c1"># T-test for statistical significance
</span>    <span class="n">t_stat</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="nf">ttest_ind</span><span class="p">(</span>
        <span class="n">control_metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">ctr</span><span class="sh">'</span><span class="p">],</span>
        <span class="n">treatment_metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">ctr</span><span class="sh">'</span><span class="p">]</span>
    <span class="p">)</span>
    
    <span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">:</span>
        <span class="n">improvement</span> <span class="o">=</span> <span class="p">(</span><span class="n">treatment_metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">ctr</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">()</span> <span class="o">-</span> <span class="n">control_metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">ctr</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">())</span> <span class="o">/</span> <span class="n">control_metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">ctr</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">()</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Treatment is </span><span class="si">{</span><span class="n">improvement</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s">% better (p=</span><span class="si">{</span><span class="n">p_value</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">)</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">No significant difference</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="20-deep-dive-multi-armed-bandits-for-dynamic-model-selection">20. Deep Dive: Multi-Armed Bandits for Dynamic Model Selection</h2>

<p><strong>Problem:</strong> A/B tests are slow (weeks to reach significance). Can we adapt faster?</p>

<p><strong>Solution:</strong> Multi-Armed Bandits (Thompson Sampling).</p>

<p><strong>Concept:</strong></p>
<ul>
  <li>Start with equal traffic to all models.</li>
  <li>Gradually shift traffic to the best-performing model.</li>
  <li><strong>Result:</strong> Maximize reward while exploring.</li>
</ul>

<p><strong>Implementation:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">class</span> <span class="nc">ThompsonSamplingBandit</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">n_models</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="c1"># Beta distribution parameters (successes, failures)
</span>        <span class="n">self</span><span class="p">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">n_models</span><span class="p">)</span>  <span class="c1"># Prior: 1 success
</span>        <span class="n">self</span><span class="p">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">n_models</span><span class="p">)</span>   <span class="c1"># Prior: 1 failure
</span>    
    <span class="k">def</span> <span class="nf">select_model</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="c1"># Sample from Beta distributions
</span>        <span class="n">samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">beta</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">alpha</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">self</span><span class="p">.</span><span class="n">beta</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">alpha</span><span class="p">))]</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model_id</span><span class="p">,</span> <span class="n">reward</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">reward</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Success (user clicked)
</span>            <span class="n">self</span><span class="p">.</span><span class="n">alpha</span><span class="p">[</span><span class="n">model_id</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># Failure
</span>            <span class="n">self</span><span class="p">.</span><span class="n">beta</span><span class="p">[</span><span class="n">model_id</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="c1"># Usage
</span><span class="n">bandit</span> <span class="o">=</span> <span class="nc">ThompsonSamplingBandit</span><span class="p">(</span><span class="n">n_models</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>  <span class="c1"># 1000 requests
</span>    <span class="n">model_id</span> <span class="o">=</span> <span class="n">bandit</span><span class="p">.</span><span class="nf">select_model</span><span class="p">()</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">models</span><span class="p">[</span><span class="n">model_id</span><span class="p">].</span><span class="nf">predict</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
    
    <span class="c1"># Get user feedback (click = 1, no click = 0)
</span>    <span class="n">reward</span> <span class="o">=</span> <span class="nf">get_user_feedback</span><span class="p">()</span>
    
    <span class="n">bandit</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="n">reward</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Final traffic distribution:</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Model 1: </span><span class="si">{</span><span class="n">bandit</span><span class="p">.</span><span class="n">alpha</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">bandit</span><span class="p">.</span><span class="n">alpha</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">bandit</span><span class="p">.</span><span class="n">beta</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Model 2: </span><span class="si">{</span><span class="n">bandit</span><span class="p">.</span><span class="n">alpha</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">bandit</span><span class="p">.</span><span class="n">alpha</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">bandit</span><span class="p">.</span><span class="n">beta</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Model 3: </span><span class="si">{</span><span class="n">bandit</span><span class="p">.</span><span class="n">alpha</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">bandit</span><span class="p">.</span><span class="n">alpha</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">bandit</span><span class="p">.</span><span class="n">beta</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Benefit:</strong> Converges to the best model in days instead of weeks.</p>

<h2 id="key-takeaways">Key Takeaways</h2>

<ol>
  <li><strong>Replication is Essential:</strong> Single-server deployments are fragile.</li>
  <li><strong>Active-Active is Preferred:</strong> Maximizes resource utilization and throughput.</li>
  <li><strong>Canary Deployments:</strong> Reduce risk when rolling out new models.</li>
  <li><strong>Stateless is Simpler:</strong> Stateful models require sticky sessions or shared state stores.</li>
  <li><strong>Kubernetes is King:</strong> Industry standard for orchestrating model replicas.</li>
</ol>

<h2 id="summary">Summary</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Aspect</th>
      <th style="text-align: left">Insight</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><strong>Goal</strong></td>
      <td style="text-align: left">High availability, low latency, fault tolerance</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Strategies</strong></td>
      <td style="text-align: left">Active-Active, Active-Passive, Geo-Replication</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Deployment</strong></td>
      <td style="text-align: left">Canary, Blue-Green, Rolling Updates</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Challenges</strong></td>
      <td style="text-align: left">State management, version sync, cross-region costs</td>
    </tr>
  </tbody>
</table>

<hr />

<p><strong>Originally published at:</strong> <a href="https://www.arunbaby.com/ml-system-design/0033-model-replication-systems/">arunbaby.com/ml-system-design/0033-model-replication-systems</a></p>

<p><em>If you found this helpful, consider sharing it with others who might benefit.</em></p>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#distributed-systems" class="page__taxonomy-item p-category" rel="tag">distributed-systems</a><span class="sep">, </span>
    
      <a href="/tags/#high-availability" class="page__taxonomy-item p-category" rel="tag">high-availability</a><span class="sep">, </span>
    
      <a href="/tags/#model-serving" class="page__taxonomy-item p-category" rel="tag">model-serving</a><span class="sep">, </span>
    
      <a href="/tags/#replication" class="page__taxonomy-item p-category" rel="tag">replication</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#ml-system-design" class="page__taxonomy-item p-category" rel="tag">ml_system_design</a>
    
    </span>
  </p>


        
      </footer>

      <div class="page__related page__related--full">
  <h2 class="page__related-title">Related across topics</h2>
  <style>
    /* Make section span full content width and use 2 equal columns */
    .page__related--full { float: inline-start; width: 100%; padding: 0; }
    .cross-related-grid { display: grid; grid-template-columns: repeat(2, minmax(0, 1fr)); gap: 2rem; }
    @media (max-width: 768px) { .cross-related-grid { grid-template-columns: 1fr; } }
    /* Ensure archive cards stretch nicely in the grid */
    .cross-related-grid .list__item, .cross-related-grid .grid__item { width: auto; float: none; margin: 0; }
  </style>
  <div class="cross-related-grid">
    



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/dsa/0033-clone-graph/" rel="permalink">Clone Graph (DFS/BFS)
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          21 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“Creating a deep copy of a graph structure.”
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/speech-tech/0033-multi-region-speech-deployment/" rel="permalink">Multi-region Speech Deployment
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          11 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“Deploying speech models close to users for low-latency voice experiences.”
</p>
  </article>
</div>

  </div>
</div>

      <section class="page__share">
  <h4 class="page__share-title">Share on</h4>

  <a href="https://twitter.com/intent/tweet?via=arunbaby0&text=Model+Replication+Systems%20https%3A%2F%2Fwww.arunbaby.com%2Fml-system-design%2F0033-model-replication-systems%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.arunbaby.com%2Fml-system-design%2F0033-model-replication-systems%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.arunbaby.com/ml-system-design/0033-model-replication-systems/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/ml-system-design/0032-semantic-search-systems/" class="pagination--pager" title="Semantic Search Systems">Previous</a>
    
    
      <a href="/ml-system-design/0034-knowledge-graph-systems/" class="pagination--pager" title="Knowledge Graph Systems">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 1990 - 2143 <a href="https://www.arunbaby.com">Arun Baby</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JRJPEC9SS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0JRJPEC9SS', { 'anonymize_ip': false});
</script>








  </body>
</html>
