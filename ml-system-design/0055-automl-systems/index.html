<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>AutoML Systems - Arun Baby</title>
<meta name="description" content="“The best algorithm is the one you didn’t have to tune by hand. AutoML is about moving the engineer from ‘writing code’ to ‘writing the objective function’.”">


  <meta name="author" content="Arun Baby">
  
  <meta property="article:author" content="Arun Baby">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Arun Baby">
<meta property="og:title" content="AutoML Systems">
<meta property="og:url" content="https://www.arunbaby.com/ml-system-design/0055-automl-systems/">


  <meta property="og:description" content="“The best algorithm is the one you didn’t have to tune by hand. AutoML is about moving the engineer from ‘writing code’ to ‘writing the objective function’.”">



  <meta property="og:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">



  <meta name="twitter:site" content="@arunbaby0">
  <meta name="twitter:title" content="AutoML Systems">
  <meta name="twitter:description" content="“The best algorithm is the one you didn’t have to tune by hand. AutoML is about moving the engineer from ‘writing code’ to ‘writing the objective function’.”">
  <meta name="twitter:url" content="https://www.arunbaby.com/ml-system-design/0055-automl-systems/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">
    
  

  



  <meta property="article:published_time" content="2025-12-29T16:05:30+05:30">





  

  


<link rel="canonical" href="https://www.arunbaby.com/ml-system-design/0055-automl-systems/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Baby Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          <span class="site-subtitle">Arun Baby</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/dsa/"
                
                
              >DSA</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ml-system-design/"
                
                
              >ML Systems</a>
            </li><li class="masthead__menu-item">
              <a
                href="/speech-tech/"
                
                
              >Speech Tech</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ai-agents/"
                
                
              >AI Agents</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li><li class="masthead__menu-item">
              <a
                href="/statuses/"
                
                
              >Statuses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/contact/"
                
                
              >Contact</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main" class="no-author-sidebar">
  
  <div class="sidebar sticky">
  
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="AutoML Systems">
    <meta itemprop="description" content="“The best algorithm is the one you didn’t have to tune by hand. AutoML is about moving the engineer from ‘writing code’ to ‘writing the objective function’.”">
    <meta itemprop="datePublished" content="2025-12-29T16:05:30+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://www.arunbaby.com/ml-system-design/0055-automl-systems/" itemprop="url">AutoML Systems
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          17 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#1-introduction-to-automl">1. Introduction to AutoML</a><ul><li><a href="#11-what-is-automl">1.1 What is AutoML?</a></li><li><a href="#12-the-search-analogy">1.2 The “Search” Analogy</a></li></ul></li><li><a href="#2-the-automl-pipeline-architecture">2. The AutoML Pipeline Architecture</a><ul><li><a href="#21-hyperparameter-optimization-hpo">2.1 Hyperparameter Optimization (HPO)</a></li><li><a href="#22-neural-architecture-search-nas">2.2 Neural Architecture Search (NAS)</a></li><li><a href="#23-feature-engineering-automation">2.3 Feature Engineering Automation</a></li></ul></li><li><a href="#3-core-search-strategies">3. Core Search Strategies</a><ul><li><a href="#31-grid-search-vs-random-search">3.1 Grid Search vs. Random Search</a></li><li><a href="#32-bayesian-optimization-the-smart-way">3.2 Bayesian Optimization (The “Smart” Way)</a></li><li><a href="#33-tree-structured-parzen-estimator-tpe">3.3 Tree-structured Parzen Estimator (TPE)</a></li><li><a href="#34-multi-fidelity-optimization-hyperband">3.4 Multi-fidelity Optimization (Hyperband)</a></li></ul></li><li><a href="#4-system-design-for-automl-at-scale">4. System Design for AutoML at Scale</a><ul><li><a href="#41-master-worker-architecture">4.1 Master-Worker Architecture</a></li><li><a href="#42-handling-faults-at-scale">4.2 Handling Faults at Scale</a></li><li><a href="#43-data-management-and-sharding">4.3 Data Management and Sharding</a></li></ul></li><li><a href="#5-federated-and-multi-objective-automl">5. Federated and Multi-Objective AutoML</a><ul><li><a href="#51-multi-objective-optimization-nsga-ii">5.1 Multi-Objective Optimization (NSGA-II)</a></li><li><a href="#52-metadata-based-warm-starting">5.2 Metadata-based Warm Starting</a></li></ul></li><li><a href="#6-implementation-example-using-optuna">6. Implementation Example: Using Optuna</a></li><li><a href="#7-automl-for-tabular-vs-unstructured-data">7. AutoML for Tabular vs. Unstructured Data</a><ul><li><a href="#71-tabular-data">7.1 Tabular Data</a></li><li><a href="#72-unstructured-data-visionspeechnlp">7.2 Unstructured Data (Vision/Speech/NLP)</a></li></ul></li><li><a href="#8-ethics-fairness-and-bias-in-automl">8. Ethics, Fairness, and Bias in AutoML</a></li><li><a href="#9-thematic-link-constraint-satisfaction">9. Thematic Link: Constraint Satisfaction</a><ul><li><a href="#91-from-n-queens-to-bayesian-bounds">9.1 From N-Queens to Bayesian Bounds</a></li><li><a href="#92-resource-orchestration-agent-link">9.2 Resource Orchestration (Agent Link)</a></li></ul></li><li><a href="#10-interview-strategy-for-automl-system-design">10. Interview Strategy for AutoML System Design</a></li><li><a href="#11-population-based-training-pbt">11. Population-Based Training (PBT)</a></li><li><a href="#12-automl-for-small-data-transfer-learning-and-meta-features">12. AutoML for Small Data: Transfer Learning and Meta-Features</a></li><li><a href="#13-the-no-free-lunch-theorem-and-automl">13. The “No Free Lunch Theorem” and AutoML</a></li><li><a href="#14-automl-industrial-applications-case-studies">14. AutoML Industrial Applications: Case Studies</a><ul><li><a href="#141-healthcare-diagnostics-and-personalized-medicine">14.1 Healthcare: Diagnostics and Personalized Medicine</a></li><li><a href="#142-finance-fraud-detection-and-credit-scoring">14.2 Finance: Fraud Detection and Credit Scoring</a></li><li><a href="#143-retail-demand-forecasting-and-inventory-optimization">14.3 Retail: Demand Forecasting and Inventory Optimization</a></li></ul></li><li><a href="#15-comparative-analysis-of-automl-frameworks">15. Comparative Analysis of AutoML Frameworks</a></li><li><a href="#16-the-future-llms-for-automl-lmmo">16. The Future: LLMs for AutoML (LMMO)</a></li><li><a href="#17-designing-a-production-automl-system-a-7-step-blueprint">17. Designing a Production AutoML System: A 7-Step Blueprint</a></li><li><a href="#18-hierarchical-search-spaces-and-hypernetworks">18. Hierarchical Search Spaces and Hypernetworks</a></li><li><a href="#19-post-search-analysis-how-to-debug-an-automl-pipeline">19. Post-Search Analysis: How to Debug an AutoML Pipeline</a></li><li><a href="#20-automl-for-real-time-and-streaming-systems">20. AutoML for Real-time and Streaming Systems</a></li><li><a href="#21-human-guided-automl-interactive-nas">21. Human-Guided AutoML (Interactive NAS)</a></li><li><a href="#22-automl-for-large-language-models-llm-nas">22. AutoML for Large Language Models (LLM-NAS)</a></li><li><a href="#23-automl-for-edge-devices-micro-controllers">23. AutoML for Edge Devices (Micro-Controllers)</a></li><li><a href="#24-key-takeaways">24. Key Takeaways</a></li></ul>
            </nav>
          </aside>
        
        <p><strong>“The best algorithm is the one you didn’t have to tune by hand. AutoML is about moving the engineer from ‘writing code’ to ‘writing the objective function’.”</strong></p>

<h2 id="1-introduction-to-automl">1. Introduction to AutoML</h2>

<h3 id="11-what-is-automl">1.1 What is AutoML?</h3>
<p>Automated Machine Learning (AutoML) is the process of automating the end-to-end process of applying machine learning to real-world problems. Building an ML model required a PhD-level engineer to:</p>
<ol>
  <li><strong>Pre-process data</strong> (Imputation, scaling, encoding).</li>
  <li><strong>Engineer features</strong>.</li>
  <li><strong>Select an algorithm</strong> (XGBoost, Transformer, Random Forest).</li>
  <li><strong>Tune hyperparameters</strong> (Learning rate, depth, weight decay).</li>
</ol>

<p>AutoML aims to take the raw data and the objective (e.g., “Minimize RMSE”) and produce the best possible model without human intervention. This is not just about hyperparameter tuning; it encompasses the entire pipeline from data ingestion to model deployment.</p>

<h3 id="12-the-search-analogy">1.2 The “Search” Analogy</h3>
<p>Just as the <strong>N-Queens</strong> problem (the DSA topic) searches for a valid configuration of queens under constraints, AutoML searches for a valid “Machine Learning Pipeline” under constraints of time, memory, and budget. In N-Queens, we prune board positions that lead to attacks. In AutoML, we prune configurations that lead to poor performance or violate hardware constraints.</p>

<hr />

<h2 id="2-the-automl-pipeline-architecture">2. The AutoML Pipeline Architecture</h2>

<p>A modern AutoML system consists of three main search spaces:</p>

<h3 id="21-hyperparameter-optimization-hpo">2.1 Hyperparameter Optimization (HPO)</h3>
<p>This is the most common use case. We have fixed components (e.g., a ResNet-50) and we want to find the best settings.</p>
<ul>
  <li><strong>Continuous parameters</strong>: Learning rate (<code class="language-plaintext highlighter-rouge">0.0001</code> to <code class="language-plaintext highlighter-rouge">0.1</code>).</li>
  <li><strong>Discrete parameters</strong>: Batch size (<code class="language-plaintext highlighter-rouge">16, 32, 64</code>).</li>
  <li><strong>Categorical parameters</strong>: Optimizer (<code class="language-plaintext highlighter-rouge">Adam, SGD, RMSprop</code>).</li>
</ul>

<h3 id="22-neural-architecture-search-nas">2.2 Neural Architecture Search (NAS)</h3>
<p>Instead of a fixed backbone, the system searches for the <strong>topology</strong> of the neural network.</p>
<ul>
  <li>Which layers should connect?</li>
  <li>Should we use a <code class="language-plaintext highlighter-rouge">3x3</code> conv or a <code class="language-plaintext highlighter-rouge">5x5</code> conv?</li>
  <li>Where should the skip connections be?</li>
  <li><strong>Operations</strong>: Separable convolutions, dilated convolutions, attention heads.</li>
</ul>

<h3 id="23-feature-engineering-automation">2.3 Feature Engineering Automation</h3>
<p>Automatically creating polynomial features, interaction terms, or using deep learning to learn representations (embeddings). This also includes automated scaling, normalization, and handling of missing data using various imputation strategies (mean, median, iterative imputer).</p>

<hr />

<h2 id="3-core-search-strategies">3. Core Search Strategies</h2>

<h3 id="31-grid-search-vs-random-search">3.1 Grid Search vs. Random Search</h3>
<ul>
  <li><strong>Grid Search</strong>: Exhaustive and deterministic. Good for small spaces, but suffers from the “curse of dimensionality.”</li>
  <li><strong>Random Search</strong>: Often better than grid search because it focuses on important dimensions. It has been mathematically shown that for many ML tasks, only a few hyperparameters really matter. Random search is more likely to trial values for these “critical” parameters than Grid Search.</li>
</ul>

<h3 id="32-bayesian-optimization-the-smart-way">3.2 Bayesian Optimization (The “Smart” Way)</h3>
<p>Bayesian Optimization constructs a <strong>surrogate model</strong> (usually a <strong>Gaussian Process</strong>) to predict the performance of unseen configurations based on past results.</p>
<ul>
  <li>It calculates an <strong>Acquisition Function</strong> (like Expected Improvement or Upper Confidence Bound) to decide where to sample next.</li>
  <li>It balances <strong>Exploration</strong> (trying unknown regions) and <strong>Exploitation</strong> (searching near known good results).</li>
</ul>

<h3 id="33-tree-structured-parzen-estimator-tpe">3.3 Tree-structured Parzen Estimator (TPE)</h3>
<p>While Gaussian Processes are the “gold standard” for continuous spaces, they scale poorly (O(N^3)) with the number of trials. <strong>TPE</strong> (used in Optuna and Hyperopt) is a non-parametric Bayesian method that:</p>
<ul>
  <li>Models the probability <code class="language-plaintext highlighter-rouge">P(x|y)</code> of a configuration <code class="language-plaintext highlighter-rouge">x</code> given a metric <code class="language-plaintext highlighter-rouge">y</code>.</li>
  <li>It splits observations into “good” and “bad” based on a quantile.</li>
  <li>It calculates the ratio of the likelihoods and picks <code class="language-plaintext highlighter-rouge">x</code> that maximizes this ratio.</li>
  <li><strong>Why it’s better</strong>: It handles categorical and conditional parameters much more naturally than GP.</li>
</ul>

<h3 id="34-multi-fidelity-optimization-hyperband">3.4 Multi-fidelity Optimization (Hyperband)</h3>
<p>Why wait for 100 epochs to know a model is bad?</p>
<ul>
  <li><strong>Successive Halving</strong>: Start 100 models, train for 1 epoch. Kill the bottom 50. Train the remaining for 2 epochs. Kill the bottom 25.</li>
  <li><strong>Hyperband</strong>: A more robust version that handles the trade-off between the number of configurations and the resource budget per configuration. It runs several instances of successive halving with different “aggressiveness” levels to ensure that good models aren’t killed too early.</li>
</ul>

<hr />

<h2 id="4-system-design-for-automl-at-scale">4. System Design for AutoML at Scale</h2>

<h3 id="41-master-worker-architecture">4.1 Master-Worker Architecture</h3>
<ul>
  <li><strong>Optimizer (Master)</strong>: Decides the next configuration to test. Evaluates the surrogate model and updates the acquisition function.</li>
  <li><strong>Workers</strong>: Individual GPU nodes that train a model and report the final metric. They should be stateless to allow for easy scaling.</li>
  <li><strong>Metadata Store</strong>: A database (PostgreSQL/Redis) that stores trial logs, intermediate weights, metrics, and failure states.</li>
</ul>

<h3 id="42-handling-faults-at-scale">4.2 Handling Faults at Scale</h3>
<p>AutoML runs are long (days or weeks). Workers <strong>will</strong> fail.</p>
<ul>
  <li><strong>Stateless Workers</strong>: If a worker dies, the Master detects the heartbeat loss and re-assigns the trial.</li>
  <li><strong>Checkpointing</strong>: Every trial must periodically save weights to S3 or a shared file system. If a trial is interrupted, it should resume from the last epoch rather than restarting.</li>
  <li><strong>Elasticity</strong>: During the “Exploration” phase, you might spawn 1000 Low-Priority/Spot Instances. During the “Refinement” phase, you scale down to high-end dedicated A100s.</li>
</ul>

<h3 id="43-data-management-and-sharding">4.3 Data Management and Sharding</h3>
<p>Handling data across thousands of workers is a challenge:</p>
<ul>
  <li><strong>Local Caching</strong>: Workers should cache data locally to avoid network bottlenecks.</li>
  <li><strong>Data Sharding</strong>: For massive datasets, each worker might only see a shard of the data during early trials to speed up the loop.</li>
</ul>

<hr />

<h2 id="5-federated-and-multi-objective-automl">5. Federated and Multi-Objective AutoML</h2>

<h3 id="51-multi-objective-optimization-nsga-ii">5.1 Multi-Objective Optimization (NSGA-II)</h3>
<p>In production, you never just want “High Accuracy.” You want “High Accuracy + Low Latency + Low Power.”</p>
<ul>
  <li><strong>Pareto Efficiency</strong>: A configuration is Pareto optimal if you cannot improve one metric without making another worse.</li>
  <li><strong>NSGA-II (Non-dominated Sorting Genetic Algorithm)</strong>: An evolutionary algorithm that maintains a population of configurations and evolves them over time to find the best tradeoffs.</li>
</ul>

<h3 id="52-metadata-based-warm-starting">5.2 Metadata-based Warm Starting</h3>
<p>The “Cold Start” problem in AutoML is expensive. If you are tuning a ResNet on CIFAR-10, you shouldn’t start from scratch if you’ve already tuned 100 ResNets on similar datasets.</p>
<ul>
  <li><strong>Meta-Learning</strong>: The system stores “Meta-features” of previous datasets (statistical descriptions, dimensionality, class balance).</li>
  <li>When a new dataset arrives, the system finds the “Nearest Neighbor” dataset and seeds the search with the best configurations from that historical run.</li>
  <li>This can reduce search time by <strong>80-90%</strong>.</li>
</ul>

<hr />

<h2 id="6-implementation-example-using-optuna">6. Implementation Example: Using Optuna</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">optuna</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="n">torch.optim</span> <span class="k">as</span> <span class="n">optim</span>

<span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
    <span class="c1"># 1. Suggest parameters
</span>    <span class="n">lr</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_float</span><span class="p">(</span><span class="sh">"</span><span class="s">lr</span><span class="sh">"</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_categorical</span><span class="p">(</span><span class="sh">"</span><span class="s">optimizer</span><span class="sh">"</span><span class="p">,</span> <span class="p">[</span><span class="sh">"</span><span class="s">Adam</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">SGD</span><span class="sh">"</span><span class="p">])</span>
    <span class="n">n_layers</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_int</span><span class="p">(</span><span class="sh">"</span><span class="s">n_layers</span><span class="sh">"</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    
    <span class="c1"># 2. Build model dynamically
</span>    <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">in_features</span> <span class="o">=</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">):</span>
        <span class="n">out_features</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_int</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">n_units_l</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="sh">"</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="n">layers</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">))</span>
        <span class="n">layers</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">())</span>
        <span class="n">in_features</span> <span class="o">=</span> <span class="n">out_features</span>
    <span class="n">layers</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>
    
    <span class="c1"># 3. Setup training
</span>    <span class="n">optimizer</span> <span class="o">=</span> <span class="nf">getattr</span><span class="p">(</span><span class="n">optim</span><span class="p">,</span> <span class="n">optimizer_name</span><span class="p">)(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="c1"># ... Training loop (simplified) ...
</span>    
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
        <span class="c1"># model.train(...)
</span>        <span class="n">accuracy</span> <span class="o">=</span> <span class="mf">0.85</span> <span class="o">+</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">*</span> <span class="mf">0.01</span><span class="p">)</span> <span class="c1"># Simulated metric
</span>        
        <span class="c1"># 4. Report metric (with pruning support)
</span>        <span class="n">trial</span><span class="p">.</span><span class="nf">report</span><span class="p">(</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>
        
        <span class="c1"># Early stopping based on Hyperband/MedianPruner
</span>        <span class="k">if</span> <span class="n">trial</span><span class="p">.</span><span class="nf">should_prune</span><span class="p">():</span>
            <span class="k">raise</span> <span class="n">optuna</span><span class="p">.</span><span class="n">exceptions</span><span class="p">.</span><span class="nc">TrialPruned</span><span class="p">()</span>
        
        <span class="k">return</span> <span class="n">accuracy</span>

<span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="p">.</span><span class="nf">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="sh">"</span><span class="s">maximize</span><span class="sh">"</span><span class="p">,</span> <span class="n">pruner</span><span class="o">=</span><span class="n">optuna</span><span class="p">.</span><span class="n">pruners</span><span class="p">.</span><span class="nc">HyperbandPruner</span><span class="p">())</span>
<span class="n">study</span><span class="p">.</span><span class="nf">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Best trial parameters: </span><span class="si">{</span><span class="n">study</span><span class="p">.</span><span class="n">best_params</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<hr />

<h2 id="7-automl-for-tabular-vs-unstructured-data">7. AutoML for Tabular vs. Unstructured Data</h2>

<p>The strategy changes significantly based on the data type:</p>

<h3 id="71-tabular-data">7.1 Tabular Data</h3>
<p>Success is driven by <strong>Ensembling and Gradient Boosting</strong>. Systems like <strong>AutoGluon</strong> or <strong>H2O.ai</strong> usually win.</p>
<ul>
  <li>They focus on “Stacking” and “Bagging”.</li>
  <li>Instead of finding one best model, they combine dozens of LightGBM, CatBoost, and XGBoost models.</li>
  <li><strong>Multi-layer Stacking</strong>: The outputs of Level 1 models become features for Level 2 models.</li>
</ul>

<h3 id="72-unstructured-data-visionspeechnlp">7.2 Unstructured Data (Vision/Speech/NLP)</h3>
<p>Success is driven by <strong>Neural Architecture Search (NAS)</strong> and <strong>Pre-trained Model Selection</strong>.</p>
<ul>
  <li>Modern NAS (like DARTS or ENAS) uses weight sharing to avoid training thousands of models.</li>
  <li>The focus is on finding the right “Pattern” of connections (e.g., Dilated Convs for audio, Attention heads for text).</li>
</ul>

<hr />

<h2 id="8-ethics-fairness-and-bias-in-automl">8. Ethics, Fairness, and Bias in AutoML</h2>

<p>Automating model selection can amplify hidden biases in the data.</p>
<ul>
  <li><strong>The “Accuracy-Fairness” Tradeoff</strong>: If the objective function is purely weighted towards global accuracy, the system might select a model that performs perfectly on the majority group but fails miserably on a minority group.</li>
  <li><strong>Automated Fairness Constraints</strong>: Researchers now add “Fairness Metrics” (e.g., Disparate Impact, Equalized Odds) as <strong>Hard Constraints</strong> in the search space.</li>
  <li>If a model configuration violates these bounds, it is “pruned” just like a model that violates memory limits. This ensures that the AutoML explorer stays within the “Ethical Guardrails.”</li>
</ul>

<hr />

<h2 id="9-thematic-link-constraint-satisfaction">9. Thematic Link: Constraint Satisfaction</h2>

<h3 id="91-from-n-queens-to-bayesian-bounds">9.1 From N-Queens to Bayesian Bounds</h3>
<p>In the <strong>N-Queens</strong> problem, we use the “isSafe” check to prune board cells. In AutoML, we use the <strong>Lower Confidence Bound (LCB)</strong>. If the best possible performance a configuration could achieve (given its uncertainty) is lower than our current best, we prune the branch without ever training the model.</p>

<h3 id="92-resource-orchestration-agent-link">9.2 Resource Orchestration (Agent Link)</h3>
<p>Orchestrating an AutoML run across 500 GPUs is an <strong>Agent Orchestration</strong> problem (the AI Agents topic). You have “Search Agents” (Optimizer), “Training Agents” (Workers), and “Cleanup Agents.” They must coordinate to ensure no GPU remains idle, satisfying the “Budget Constraint” and “Time Constraint.”</p>

<hr />

<h2 id="10-interview-strategy-for-automl-system-design">10. Interview Strategy for AutoML System Design</h2>

<ol>
  <li><strong>Ask about the Budget</strong>: “Do we have 500 USD or 500,000 USD?” This determines if you use Random Search or a massive NAS Supernet.</li>
  <li><strong>Metric Selection</strong>: Propose a “Validation Strategy” (e.g., Stratified K-Fold) to ensure the AutoML doesn’t overfit.</li>
  <li><strong>The “Human in the Loop”</strong>: Mention how you provide a “Dashboard” (like Weights &amp; Biases or Tensorboard) for engineers to intervene.</li>
  <li><strong>Data Drifting</strong>: Ask how the system handles “Model Decay.” Does the AutoML search re-trigger if live metrics drop?</li>
</ol>

<h2 id="11-population-based-training-pbt">11. Population-Based Training (PBT)</h2>
<p>While Bayesian Optimization is a “Sequential” process (wait for result, update model, suggest next), <strong>Population-Based Training (PBT)</strong> is a “Parallel” process used at companies like DeepMind (for AlphaStar) and OpenAI.</p>
<ul>
  <li><strong>The Concept</strong>: Start 100 models with random parameters. Periodically, evaluate them.</li>
  <li><strong>The “Exploit” Step</strong>: Models with poor performance “Copy” the weights and hyperparameters of a high-performing model.</li>
  <li><strong>The “Explore” Step</strong>: The high-performing model’s hyperparameters are randomly “mutated” or “permuted” to find even better settings.</li>
  <li><strong>Why it’s revolutionary</strong>: It searches for a <strong>Hyperparameter Schedule</strong> (e.g., decaying the learning rate at exactly the right moment) rather than just a single static value.</li>
</ul>

<h2 id="12-automl-for-small-data-transfer-learning-and-meta-features">12. AutoML for Small Data: Transfer Learning and Meta-Features</h2>
<p>Many engineers think AutoML is only for “Big Data.” In reality, it is most powerful for <strong>Small Data</strong> where human bias is most dangerous.</p>
<ul>
  <li><strong>Automated Transfer Learning</strong>: Instead of tuning a model from scratch, the system searches for the best “Pre-trained Backbone” (e.g., EfficientNet vs. ViT) and then tunes only the “Adapter” or “Head” layers.</li>
  <li><strong>Few-Shot AutoML</strong>: Using Meta-Learning to predict the best hyperparameters for a new task using only a handful of labeled examples.</li>
</ul>

<h2 id="13-the-no-free-lunch-theorem-and-automl">13. The “No Free Lunch Theorem” and AutoML</h2>
<p>The <strong>No Free Lunch Theorem (NFL)</strong> states that no single optimization algorithm is universally better than others across all possible problems.</p>
<ul>
  <li>In AutoML, this means there is no “Magic Search Strategy.”</li>
  <li>A system that is great at tuning Transformers for NLP might be terrible at tuning XGBoost for credit scoring.</li>
  <li>This is why the best AutoML systems (like <strong>AutoGluon</strong>) focus on <strong>Portfolio Selection</strong>—they don’t use one searcher; they use a “Search for the Searcher.”</li>
</ul>

<hr />

<h2 id="14-automl-industrial-applications-case-studies">14. AutoML Industrial Applications: Case Studies</h2>

<h3 id="141-healthcare-diagnostics-and-personalized-medicine">14.1 Healthcare: Diagnostics and Personalized Medicine</h3>
<p>In healthcare, AutoML is used to search for models that analyze MRI scans or genomic sequences.</p>
<ul>
  <li><strong>The Challenge</strong>: Data is extremely high-dimensional and scarce.</li>
  <li><strong>The Role of AutoML</strong>: Automated Feature Engineering extracts texture and shape features from medical images that humans might miss.</li>
  <li><strong>Fairness</strong>: Ensuring the model doesn’t overfit to a specific hospital’s imaging equipment.</li>
</ul>

<h3 id="142-finance-fraud-detection-and-credit-scoring">14.2 Finance: Fraud Detection and Credit Scoring</h3>
<ul>
  <li><strong>The Challenge</strong>: The data is highly imbalanced (fraud is rare) and dynamic (scammers change tactics).</li>
  <li><strong>The Role of AutoML</strong>: Systems like <strong>H2O.ai</strong> are used to stack “Deep Learning” with “Gradient Boosted Trees.” AutoML automatically finds the best “Threshold” for stopping a transaction to balance customer friction vs. fraud loss.</li>
</ul>

<h3 id="143-retail-demand-forecasting-and-inventory-optimization">14.3 Retail: Demand Forecasting and Inventory Optimization</h3>
<ul>
  <li><strong>The Challenge</strong>: Managing 100,000+ SKUs across 1,000 stores.</li>
  <li><strong>The Role of AutoML</strong>: Automated search for <strong>Time Series</strong> models (e.g., Prophet, ARIMA, LSTM). The system selects a different model type for “Stable” products (like milk) vs. “Trendy” products (like electronics).</li>
</ul>

<h2 id="15-comparative-analysis-of-automl-frameworks">15. Comparative Analysis of AutoML Frameworks</h2>

<table>
  <thead>
    <tr>
      <th>Framework</th>
      <th>Best For</th>
      <th>Core Philosophy</th>
      <th>Scalability</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Optuna</strong></td>
      <td>Hyperparameters</td>
      <td>Bayesian (TPE)</td>
      <td>Single node / Master-Worker</td>
    </tr>
    <tr>
      <td><strong>Ray Tune</strong></td>
      <td>Large Clusters</td>
      <td>Distributied Execution</td>
      <td>Massive (PBT, Hyperband)</td>
    </tr>
    <tr>
      <td><strong>AutoGluon</strong></td>
      <td>Tabular Data</td>
      <td>Stacking &amp; Ensembling</td>
      <td>Multi-node</td>
    </tr>
    <tr>
      <td><strong>Microsoft NNI</strong></td>
      <td>NAS &amp; Pruning</td>
      <td>Visualizing Search</td>
      <td>Enterprise-grade</td>
    </tr>
  </tbody>
</table>

<h2 id="16-the-future-llms-for-automl-lmmo">16. The Future: LLMs for AutoML (LMMO)</h2>
<p>The latest research (e.g., Google’s “Large Language Models are Zero-Shot Optimizers”) suggests that LLMs can replace standard Bayesian Searchers.</p>
<ul>
  <li><strong>The Concept</strong>: Instead of a Gaussian Process, you feed the LLM a list of previous configurations and their scores: <code class="language-plaintext highlighter-rouge">{"lr": 0.1, "score": 0.8}, {"lr": 0.01, "score": 0.85}</code>.</li>
  <li>You ask the LLM: “What should be the next learning rate to maximize the score?”</li>
  <li><strong>Why it works</strong>: LLMs have encoded the “Common Sense” of deep learning in their training data. They know that a learning rate of <code class="language-plaintext highlighter-rouge">100</code> is likely bad, regardless of the dataset.</li>
</ul>

<h2 id="17-designing-a-production-automl-system-a-7-step-blueprint">17. Designing a Production AutoML System: A 7-Step Blueprint</h2>

<p>For a Senior System Design interview, propose this architecture:</p>
<ol>
  <li><strong>The Ingestion Layer</strong>: Automatic validation and meta-feature extraction of the input data.</li>
  <li><strong>The Search Area Definition</strong>: Dynamic generation of the search space based on the data type (Tabular vs. Sequence).</li>
  <li><strong>The Global Optimizer</strong>: Using TPE or Bayesian search to prioritize the first 100 trials.</li>
  <li><strong>The Distributed Scheduler</strong>: Spawning ephemeral GPU workers on Kubernetes (K8s) or AWS SageMaker.</li>
  <li><strong>The Multi-fidelity Pruner</strong>: Killing underperforming runs at the 10%, 25%, and 50% benchmarks.</li>
  <li><strong>The Stacking Engine</strong>: Combining the top 10 models into a final resilient ensemble.</li>
  <li><strong>The Evaluation Guardrail</strong>: Running the final model through fairness and robustness tests before generating the deployment artifact.</li>
</ol>

<h2 id="18-hierarchical-search-spaces-and-hypernetworks">18. Hierarchical Search Spaces and Hypernetworks</h2>
<p>One of the most complex areas of AutoML is searching through <strong>Conditional Spaces</strong>.</p>
<ul>
  <li>For example: “If the optimizer is Adam, tune the <code class="language-plaintext highlighter-rouge">beta_1</code> and <code class="language-plaintext highlighter-rouge">beta_2</code> parameters. If the optimizer is SGD, tune the Momentum parameter.”</li>
  <li><strong>Hypernetworks</strong>: A neural network that generates the weights for another neural network. Some NAS systems use a central Hypernetwork to predict the “optimal weights” for any proposed architecture in the search space, allowing for near-instantaneous evaluation without full training.</li>
</ul>

<h2 id="19-post-search-analysis-how-to-debug-an-automl-pipeline">19. Post-Search Analysis: How to Debug an AutoML Pipeline</h2>
<p>When an AutoML run fails to find a good model, it’s rarely because of the search algorithm. It’s usually a “Meta-Problem”:</p>
<ol>
  <li><strong>Search Space Mismatch</strong>: The range of hyperparameters was too narrow or too wide.</li>
  <li><strong>Metric Overfitting</strong>: The model performed well on the validation set but fails on the test set.
    <ul>
      <li><strong>Solution</strong>: Use <strong>Nested Cross-Validation</strong> to ensure the AutoML doesn’t “leak” information.</li>
    </ul>
  </li>
  <li><strong>Data Leakage</strong>: Features from the future were included in the training set. Even the best AutoML can’t fix bad data engineering.</li>
</ol>

<h2 id="20-automl-for-real-time-and-streaming-systems">20. AutoML for Real-time and Streaming Systems</h2>
<p>Most AutoML systems assume a static dataset. In the real world (e.g., high-frequency trading or sensor monitoring), data is a <strong>Stream</strong>.</p>
<ul>
  <li><strong>Continuous AutoML</strong>: The search process never stops. As the data distribution shifts (Concept Drift), the optimizer tries new configurations in the background.</li>
  <li><strong>Micro-Tuning</strong>: Instead of retraining the whole pipeline, the system performs “Micro-updates” to the top-level ensemble weights to adapt to the latest data trends.</li>
</ul>

<h2 id="21-human-guided-automl-interactive-nas">21. Human-Guided AutoML (Interactive NAS)</h2>
<p>The “Black Box” nature of AutoML can be problematic. <strong>Human-Guided AutoML</strong> allows an engineer to “steer” the search:</p>
<ul>
  <li><strong>Heuristic Seeding</strong>: The engineer tells the system: “I know from experience that kernel size 7 is better for this task.”</li>
  <li><strong>Interactive Pruning</strong>: The engineer looks at the intermediate training curves and manually kills trials that look “unstable,” even if the automated pruner hasn’t triggered yet.</li>
  <li>This hybrid approach combines <strong>Human Intuition</strong> with <strong>Machine Scale</strong>.</li>
</ul>

<h2 id="22-automl-for-large-language-models-llm-nas">22. AutoML for Large Language Models (LLM-NAS)</h2>
<p>Searching for the best Transformer architecture is the cutting edge of NAS.</p>
<ul>
  <li><strong>The Challenges</strong>: Training a single LLM costs millions of dollars. You cannot train 100 variations.</li>
  <li><strong>The Solution</strong>: <strong>One-Shot Estimators</strong>. You train a “Super-Transformer” with many heads and layers. You then use an evolutionary algorithm to find common sub-structures that maintain 95% of the performance with only 50% of the parameters.</li>
  <li><strong>MoE (Mixture of Experts)</strong>: AutoML is used to decide the “Routing” logic for experts, ensuring that the work is distributed efficiently across the GPU cluster.</li>
</ul>

<h2 id="23-automl-for-edge-devices-micro-controllers">23. AutoML for Edge Devices (Micro-Controllers)</h2>
<p>When your target is a device with 256KB of RAM, the search space changes from “Optimal Layers” to “Optimal Quantization.”</p>
<ul>
  <li><strong>Bit-width Search</strong>: The system decides if Layer 1 should be 8-bit, Layer 2 should be 4-bit, and Layer 3 should be 1-bit.</li>
  <li><strong>Hardware-In-The-Loop</strong>: The AutoML system actually flashes the model onto the micro-controller, measures the current draw (mAh), and uses that as the reward signal.</li>
</ul>

<hr />

<h2 id="24-key-takeaways">24. Key Takeaways</h2>

<ol>
  <li><strong>Pruning is Profit</strong>: The faster you can kill a bad model using Multi-fidelity logic, the more good configurations you can explore.</li>
  <li><strong>Search is Scaling</strong>: AutoML turns a “Hand-tuning” problem into a “Search and Optimization” problem, allowing one engineer to manage thousands of models.</li>
  <li><strong>Hardware-Awareness</strong>: A model is only “best” if it satisfies the physical constraints (Latency, Memory, Power) of the target device.</li>
</ol>

<hr />

<p><strong>Originally published at:</strong> <a href="https://www.arunbaby.com/ml-system-design/0055-automl-systems/">arunbaby.com/ml-system-design/0055-automl-systems</a></p>

<p><em>If you found this helpful, consider sharing it with others who might benefit.</em></p>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#automl" class="page__taxonomy-item p-category" rel="tag">automl</a><span class="sep">, </span>
    
      <a href="/tags/#bayesian-optimization" class="page__taxonomy-item p-category" rel="tag">bayesian-optimization</a><span class="sep">, </span>
    
      <a href="/tags/#gaussian-processes" class="page__taxonomy-item p-category" rel="tag">gaussian-processes</a><span class="sep">, </span>
    
      <a href="/tags/#hyperparameter-optimization" class="page__taxonomy-item p-category" rel="tag">hyperparameter-optimization</a><span class="sep">, </span>
    
      <a href="/tags/#neural-architecture-search" class="page__taxonomy-item p-category" rel="tag">neural-architecture-search</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#ml-system-design" class="page__taxonomy-item p-category" rel="tag">ml-system-design</a>
    
    </span>
  </p>


        
      </footer>

      <div class="page__related page__related--full">
  <h2 class="page__related-title">Related across topics</h2>
  <style>
    /* Make section span full content width and use 2 equal columns */
    .page__related--full { float: inline-start; width: 100%; padding: 0; }
    .cross-related-grid { display: grid; grid-template-columns: repeat(2, minmax(0, 1fr)); gap: 2rem; }
    @media (max-width: 768px) { .cross-related-grid { grid-template-columns: 1fr; } }
    /* Ensure archive cards stretch nicely in the grid */
    .cross-related-grid .list__item, .cross-related-grid .grid__item { width: auto; float: none; margin: 0; }
  </style>
  <div class="cross-related-grid">
    



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/dsa/0055-n-queens/" rel="permalink">N-Queens
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          18 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“The N-Queens problem is the ‘Hello World’ of constraint satisfaction—it teaches us how to prune the search tree before it consumes our CPU.”
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/speech-tech/0055-neural-architecture-search-for-speech/" rel="permalink">Neural Architecture Search for Speech
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          18 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“Speech models are uniquely sensitive to temporal resolution. Neural Architecture Search (NAS) is the science of finding the perfect balance between time, fr...</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ai-agents/0055-agent-orchestration/" rel="permalink">Agent Orchestration
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          19 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“Single agents are limited by their context window and specialized knowledge. Orchestration is the art of composing a symphony of agents to solve problems no...</p>
  </article>
</div>

  </div>
</div>

      <section class="page__share">
  <h4 class="page__share-title">Share on</h4>

  <a href="https://twitter.com/intent/tweet?via=arunbaby0&text=AutoML+Systems%20https%3A%2F%2Fwww.arunbaby.com%2Fml-system-design%2F0055-automl-systems%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.arunbaby.com%2Fml-system-design%2F0055-automl-systems%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.arunbaby.com/ml-system-design/0055-automl-systems/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/ml-system-design/0054-pattern-matching-in-ml/" class="pagination--pager" title="Pattern Matching in ML">Previous</a>
    
    
      <a href="/ml-system-design/0056-real-time-personalization/" class="pagination--pager" title="Real-time Personalization">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 1990 - 2143 <a href="https://www.arunbaby.com">Arun Baby</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JRJPEC9SS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0JRJPEC9SS', { 'anonymize_ip': false});
</script>








  </body>
</html>
