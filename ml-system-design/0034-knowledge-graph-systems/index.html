<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Knowledge Graph Systems - Arun Baby</title>
<meta name="description" content="“Structuring the world’s information into connected entities and relationships.”">


  <meta name="author" content="Arun Baby">
  
  <meta property="article:author" content="Arun Baby">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Arun Baby">
<meta property="og:title" content="Knowledge Graph Systems">
<meta property="og:url" content="https://www.arunbaby.com/ml-system-design/0034-knowledge-graph-systems/">


  <meta property="og:description" content="“Structuring the world’s information into connected entities and relationships.”">



  <meta property="og:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">



  <meta name="twitter:site" content="@arunbaby0">
  <meta name="twitter:title" content="Knowledge Graph Systems">
  <meta name="twitter:description" content="“Structuring the world’s information into connected entities and relationships.”">
  <meta name="twitter:url" content="https://www.arunbaby.com/ml-system-design/0034-knowledge-graph-systems/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">
    
  

  



  <meta property="article:published_time" content="2025-12-02T22:27:09+05:30">





  

  


<link rel="canonical" href="https://www.arunbaby.com/ml-system-design/0034-knowledge-graph-systems/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Baby Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          <span class="site-subtitle">Arun Baby</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/dsa/"
                
                
              >DSA</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ml-system-design/"
                
                
              >ML Systems</a>
            </li><li class="masthead__menu-item">
              <a
                href="/speech-tech/"
                
                
              >Speech Tech</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li><li class="masthead__menu-item">
              <a
                href="/statuses/"
                
                
              >Statuses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/contact/"
                
                
              >Contact</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main" class="no-author-sidebar">
  
  <div class="sidebar sticky">
  
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Knowledge Graph Systems">
    <meta itemprop="description" content="“Structuring the world’s information into connected entities and relationships.”">
    <meta itemprop="datePublished" content="2025-12-02T22:27:09+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://www.arunbaby.com/ml-system-design/0034-knowledge-graph-systems/" itemprop="url">Knowledge Graph Systems
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          17 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#1-what-is-a-knowledge-graph-kg">1. What is a Knowledge Graph (KG)?</a></li><li><a href="#2-data-model-rdf-vs-labeled-property-graph">2. Data Model: RDF vs. Labeled Property Graph</a><ul><li><a href="#1-resource-description-framework-rdf">1. Resource Description Framework (RDF)</a></li><li><a href="#2-labeled-property-graph-lpg">2. Labeled Property Graph (LPG)</a></li></ul></li><li><a href="#3-knowledge-graph-construction-pipeline">3. Knowledge Graph Construction Pipeline</a><ul><li><a href="#step-1-named-entity-recognition-ner">Step 1: Named Entity Recognition (NER)</a></li><li><a href="#step-2-entity-linking-resolution">Step 2: Entity Linking (Resolution)</a></li><li><a href="#step-3-relation-extraction-re">Step 3: Relation Extraction (RE)</a></li><li><a href="#step-4-knowledge-fusion">Step 4: Knowledge Fusion</a></li></ul></li><li><a href="#4-storage-architecture">4. Storage Architecture</a><ul><li><a href="#1-native-graph-databases-neo4j-amazon-neptune">1. Native Graph Databases (Neo4j, Amazon Neptune)</a></li><li><a href="#2-relational-backends-facebook-tao-linkedin-liquid">2. Relational Backends (Facebook TAO, LinkedIn Liquid)</a></li><li><a href="#3-distributed-key-value-stores-google-knowledge-graph">3. Distributed Key-Value Stores (Google Knowledge Graph)</a></li></ul></li><li><a href="#5-knowledge-graph-inference">5. Knowledge Graph Inference</a><ul><li><a href="#1-link-prediction-knowledge-graph-completion">1. Link Prediction (Knowledge Graph Completion)</a></li><li><a href="#2-knowledge-graph-embeddings-kge">2. Knowledge Graph Embeddings (KGE)</a></li><li><a href="#3-graph-neural-networks-gnns">3. Graph Neural Networks (GNNs)</a></li></ul></li><li><a href="#6-real-world-case-studies">6. Real-World Case Studies</a><ul><li><a href="#case-study-1-google-knowledge-graph">Case Study 1: Google Knowledge Graph</a></li><li><a href="#case-study-2-linkedin-economic-graph">Case Study 2: LinkedIn Economic Graph</a></li><li><a href="#case-study-3-pinterest-taste-graph">Case Study 3: Pinterest Taste Graph</a></li></ul></li><li><a href="#7-deep-dive-graph-rag-retrieval-augmented-generation">7. Deep Dive: Graph RAG (Retrieval Augmented Generation)</a></li><li><a href="#8-deep-dive-scaling-graph-databases">8. Deep Dive: Scaling Graph Databases</a></li><li><a href="#9-system-design-interview-design-a-kg-for-movies">9. System Design Interview: Design a KG for Movies</a></li><li><a href="#10-top-interview-questions">10. Top Interview Questions</a></li><li><a href="#11-summary">11. Summary</a></li><li><a href="#12-deep-dive-graph-neural-networks-gnns">12. Deep Dive: Graph Neural Networks (GNNs)</a></li><li><a href="#13-deep-dive-knowledge-graph-embeddings-kge-math">13. Deep Dive: Knowledge Graph Embeddings (KGE) Math</a></li><li><a href="#14-deep-dive-entity-linking-at-scale">14. Deep Dive: Entity Linking at Scale</a></li><li><a href="#15-deep-dive-graph-rag-implementation">15. Deep Dive: Graph RAG Implementation</a></li><li><a href="#16-deep-dive-temporal-knowledge-graphs">16. Deep Dive: Temporal Knowledge Graphs</a></li><li><a href="#17-deep-dive-quality-assurance-in-kgs">17. Deep Dive: Quality Assurance in KGs</a></li><li><a href="#18-deep-dive-federated-knowledge-graphs">18. Deep Dive: Federated Knowledge Graphs</a></li><li><a href="#19-system-design-real-time-fraud-detection-with-kg">19. System Design: Real-Time Fraud Detection with KG</a></li><li><a href="#20-advanced-neuro-symbolic-ai">20. Advanced: Neuro-Symbolic AI</a></li><li><a href="#21-summary">21. Summary</a></li><li><a href="#22-deep-dive-graph-databases-vs-relational-databases">22. Deep Dive: Graph Databases vs. Relational Databases</a></li><li><a href="#23-deep-dive-ontology-design">23. Deep Dive: Ontology Design</a></li><li><a href="#24-deep-dive-reasoning-engines">24. Deep Dive: Reasoning Engines</a></li><li><a href="#25-deep-dive-graph-visualization-tools">25. Deep Dive: Graph Visualization Tools</a></li><li><a href="#26-code-loading-data-into-neo4j">26. Code: Loading Data into Neo4j</a></li><li><a href="#27-summary">27. Summary</a></li><li><a href="#28-deep-dive-graph-partitioning-algorithms">28. Deep Dive: Graph Partitioning Algorithms</a></li><li><a href="#29-deep-dive-graph-query-optimization">29. Deep Dive: Graph Query Optimization</a></li><li><a href="#30-deep-dive-graph-analytics-algorithms">30. Deep Dive: Graph Analytics Algorithms</a></li><li><a href="#31-deep-dive-hardware-acceleration-for-graphs">31. Deep Dive: Hardware Acceleration for Graphs</a></li><li><a href="#32-summary">32. Summary</a></li></ul>
            </nav>
          </aside>
        
        <p><strong>“Structuring the world’s information into connected entities and relationships.”</strong></p>

<h2 id="1-what-is-a-knowledge-graph-kg">1. What is a Knowledge Graph (KG)?</h2>

<p>A Knowledge Graph is a structured representation of facts, consisting of <strong>entities</strong> (nodes) and <strong>relationships</strong> (edges).</p>

<ul>
  <li><strong>Entities:</strong> Real-world objects (e.g., “Barack Obama”, “Hawaii”, “President”).</li>
  <li><strong>Relationships:</strong> Connections between them (e.g., “born_in”, “role”).</li>
  <li><strong>Fact:</strong> <code class="language-plaintext highlighter-rouge">(Barack Obama, born_in, Hawaii)</code></li>
</ul>

<p><strong>Why use KGs?</strong></p>
<ul>
  <li><strong>Search:</strong> “Who is the wife of the 44th president?” requires traversing relationships.</li>
  <li><strong>Recommendations:</strong> “Users who liked ‘Inception’ also liked movies directed by ‘Christopher Nolan’”.</li>
  <li><strong>Q&amp;A Systems:</strong> Providing direct answers instead of just blue links.</li>
</ul>

<h2 id="2-data-model-rdf-vs-labeled-property-graph">2. Data Model: RDF vs. Labeled Property Graph</h2>

<p>There are two main ways to model KGs:</p>

<h3 id="1-resource-description-framework-rdf">1. Resource Description Framework (RDF)</h3>
<ul>
  <li><strong>Standard:</strong> W3C standard for semantic web.</li>
  <li><strong>Structure:</strong> Triples <code class="language-plaintext highlighter-rouge">(Subject, Predicate, Object)</code>.</li>
  <li><strong>Example:</strong>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">(DaVinci, painted, MonaLisa)</code></li>
      <li><code class="language-plaintext highlighter-rouge">(MonaLisa, located_in, Louvre)</code></li>
    </ul>
  </li>
  <li><strong>Query Language:</strong> SPARQL.</li>
  <li><strong>Pros:</strong> Great for interoperability, public datasets (DBpedia, Wikidata).</li>
  <li><strong>Cons:</strong> Verbose, hard to attach properties to edges (requires reification).</li>
</ul>

<h3 id="2-labeled-property-graph-lpg">2. Labeled Property Graph (LPG)</h3>
<ul>
  <li><strong>Structure:</strong> Nodes and edges have internal key-value properties.</li>
  <li><strong>Example:</strong>
    <ul>
      <li>Node: <code class="language-plaintext highlighter-rouge">Person {name: "DaVinci", born: 1452}</code></li>
      <li>Edge: <code class="language-plaintext highlighter-rouge">PAINTED {year: 1503}</code></li>
      <li>Node: <code class="language-plaintext highlighter-rouge">Artwork {title: "Mona Lisa"}</code></li>
    </ul>
  </li>
  <li><strong>Query Language:</strong> Cypher (Neo4j), Gremlin.</li>
  <li><strong>Pros:</strong> Intuitive, efficient for traversal, flexible schema.</li>
  <li><strong>Cons:</strong> Less standardized than RDF.</li>
</ul>

<p><strong>Industry Choice:</strong> Most tech companies (LinkedIn, Airbnb, Uber) use <strong>LPG</strong> for internal applications due to performance and flexibility.</p>

<h2 id="3-knowledge-graph-construction-pipeline">3. Knowledge Graph Construction Pipeline</h2>

<p>Building a KG from unstructured text (web pages, documents) is a massive NLP challenge.</p>

<h3 id="step-1-named-entity-recognition-ner">Step 1: Named Entity Recognition (NER)</h3>
<p>Identify entities in text.</p>
<ul>
  <li><strong>Input:</strong> “Elon Musk founded SpaceX in 2002.”</li>
  <li><strong>Output:</strong> <code class="language-plaintext highlighter-rouge">[Elon Musk] (PERSON)</code>, <code class="language-plaintext highlighter-rouge">[SpaceX] (ORG)</code>, <code class="language-plaintext highlighter-rouge">[2002] (DATE)</code>.</li>
  <li><strong>Model:</strong> BERT-NER, BiLSTM-CRF.</li>
</ul>

<h3 id="step-2-entity-linking-resolution">Step 2: Entity Linking (Resolution)</h3>
<p>Map the extracted mention to a unique ID in the KG.</p>
<ul>
  <li><strong>Challenge:</strong> “Michael Jordan” -&gt; Basketball player or ML researcher?</li>
  <li><strong>Solution:</strong> Contextual embeddings. Compare the context of the mention with the description of the candidate entities.</li>
</ul>

<h3 id="step-3-relation-extraction-re">Step 3: Relation Extraction (RE)</h3>
<p>Identify the relationship between entities.</p>
<ul>
  <li><strong>Input:</strong> “Elon Musk” and “SpaceX”.</li>
  <li><strong>Context:</strong> “…founded…”</li>
  <li><strong>Output:</strong> <code class="language-plaintext highlighter-rouge">founded_by(SpaceX, Elon Musk)</code>.</li>
  <li><strong>Model:</strong> Relation Classification heads on BERT.</li>
</ul>

<h3 id="step-4-knowledge-fusion">Step 4: Knowledge Fusion</h3>
<p>Merge facts from multiple sources.</p>
<ul>
  <li>Source A: <code class="language-plaintext highlighter-rouge">(Obama, born, Hawaii)</code></li>
  <li>Source B: <code class="language-plaintext highlighter-rouge">(Obama, birth_place, Honolulu)</code></li>
  <li><strong>Resolution:</strong> “Honolulu” is part of “Hawaii”. Merge or create hierarchy.</li>
</ul>

<h2 id="4-storage-architecture">4. Storage Architecture</h2>

<p>How do we store billions of nodes and trillions of edges?</p>

<h3 id="1-native-graph-databases-neo4j-amazon-neptune">1. Native Graph Databases (Neo4j, Amazon Neptune)</h3>
<ul>
  <li><strong>Storage:</strong> Index-free adjacency. Each node physically stores pointers to its neighbors.</li>
  <li><strong>Pros:</strong> $O(1)$ traversal per hop. Fast for deep queries.</li>
  <li><strong>Cons:</strong> Hard to shard (graph partitioning is NP-hard).</li>
</ul>

<h3 id="2-relational-backends-facebook-tao-linkedin-liquid">2. Relational Backends (Facebook TAO, LinkedIn Liquid)</h3>
<ul>
  <li><strong>Storage:</strong> MySQL/PostgreSQL sharded by ID.</li>
  <li><strong>Schema:</strong> <code class="language-plaintext highlighter-rouge">(id, type, data)</code> and <code class="language-plaintext highlighter-rouge">(id1, type, id2, time)</code>.</li>
  <li><strong>Pros:</strong> Extremely scalable, leverages existing DB infra.</li>
  <li><strong>Cons:</strong> Multi-hop queries require multiple DB lookups (higher latency).</li>
</ul>

<h3 id="3-distributed-key-value-stores-google-knowledge-graph">3. Distributed Key-Value Stores (Google Knowledge Graph)</h3>
<ul>
  <li><strong>Storage:</strong> BigTable / HBase.</li>
  <li><strong>Key:</strong> Subject ID.</li>
  <li><strong>Value:</strong> List of (Predicate, Object).</li>
  <li><strong>Pros:</strong> Massive write throughput.</li>
</ul>

<h2 id="5-knowledge-graph-inference">5. Knowledge Graph Inference</h2>

<p>We don’t just store facts; we infer <strong>new</strong> facts.</p>

<h3 id="1-link-prediction-knowledge-graph-completion">1. Link Prediction (Knowledge Graph Completion)</h3>
<p>Predict missing edges.</p>
<ul>
  <li><strong>Query:</strong> <code class="language-plaintext highlighter-rouge">(Tom Hanks, acted_in, ?)</code></li>
  <li><strong>Task:</strong> Rank all movies by probability.</li>
</ul>

<h3 id="2-knowledge-graph-embeddings-kge">2. Knowledge Graph Embeddings (KGE)</h3>
<p>Map entities and relations to vector space.</p>
<ul>
  <li><strong>TransE:</strong> $h + r \approx t$. The translation of head $h$ by relation $r$ should land near tail $t$.</li>
  <li><strong>RotatE:</strong> Models relations as rotations in complex space (handles symmetry/antisymmetry).</li>
  <li><strong>DistMult:</strong> Uses bilinear product.</li>
</ul>

<h3 id="3-graph-neural-networks-gnns">3. Graph Neural Networks (GNNs)</h3>
<ul>
  <li><strong>GraphSAGE / GAT:</strong> Aggregate information from neighbors to generate node embeddings.</li>
  <li><strong>Use Case:</strong> Node classification (is this account a bot?), Link prediction (friend recommendation).</li>
</ul>

<h2 id="6-real-world-case-studies">6. Real-World Case Studies</h2>

<h3 id="case-study-1-google-knowledge-graph">Case Study 1: Google Knowledge Graph</h3>
<ul>
  <li><strong>Scale:</strong> 500B+ facts.</li>
  <li><strong>Use:</strong> “Things, not strings.” Powers the info box on the right side of search results.</li>
  <li><strong>Innovation:</strong> Massive scale entity disambiguation using search logs.</li>
</ul>

<h3 id="case-study-2-linkedin-economic-graph">Case Study 2: LinkedIn Economic Graph</h3>
<ul>
  <li><strong>Entities:</strong> Members, Companies, Skills, Jobs, Schools.</li>
  <li><strong>Edges:</strong> <code class="language-plaintext highlighter-rouge">employed_by</code>, <code class="language-plaintext highlighter-rouge">has_skill</code>, <code class="language-plaintext highlighter-rouge">alumni_of</code>.</li>
  <li><strong>Use:</strong> “People You May Know”, Job Recommendations, Skill Gap Analysis.</li>
  <li><strong>Tech:</strong> “Liquid” (Graph DB built on top of relational sharding).</li>
</ul>

<h3 id="case-study-3-pinterest-taste-graph">Case Study 3: Pinterest Taste Graph</h3>
<ul>
  <li><strong>Entities:</strong> Users, Pins (Images), Boards.</li>
  <li><strong>Edges:</strong> <code class="language-plaintext highlighter-rouge">saved_to</code>, <code class="language-plaintext highlighter-rouge">clicked_on</code>.</li>
  <li><strong>Model:</strong> <strong>PinSage</strong> (GNN).</li>
  <li><strong>Innovation:</strong> Random-walk based sampling to train GNNs on billions of nodes.</li>
</ul>

<h2 id="7-deep-dive-graph-rag-retrieval-augmented-generation">7. Deep Dive: Graph RAG (Retrieval Augmented Generation)</h2>

<p>LLMs hallucinate. KGs provide ground truth.</p>

<p><strong>Architecture:</strong></p>
<ol>
  <li><strong>User Query:</strong> “What drugs interact with Aspirin?”</li>
  <li><strong>KG Lookup:</strong> Query KG for <code class="language-plaintext highlighter-rouge">(Aspirin, interacts_with, ?)</code>.</li>
  <li><strong>Context Retrieval:</strong> Get subgraph: <code class="language-plaintext highlighter-rouge">(Aspirin, interacts_with, Warfarin)</code>, <code class="language-plaintext highlighter-rouge">(Aspirin, interacts_with, Ibuprofen)</code>.</li>
  <li><strong>Prompt Augmentation:</strong> “Context: Aspirin interacts with Warfarin and Ibuprofen. Question: What drugs interact with Aspirin?”</li>
  <li><strong>LLM Generation:</strong> “Aspirin interacts with Warfarin and Ibuprofen…”</li>
</ol>

<p><strong>Pros:</strong> Factual accuracy, explainability (can cite the KG edge).</p>

<h2 id="8-deep-dive-scaling-graph-databases">8. Deep Dive: Scaling Graph Databases</h2>

<p><strong>Sharding Problem:</strong>
Cutting a graph cuts edges. Queries that traverse cuts are slow (network calls).</p>

<p><strong>Solution 1: Hash Partitioning</strong></p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">ShardID = hash(NodeID) % N</code>.</li>
  <li><strong>Pros:</strong> Even distribution.</li>
  <li><strong>Cons:</strong> Random cuts. A 3-hop query might hit 4 shards.</li>
</ul>

<p><strong>Solution 2: METIS (Graph Partitioning)</strong></p>
<ul>
  <li>Minimize edge cuts. Keep communities on the same shard.</li>
  <li><strong>Pros:</strong> Faster local traversals.</li>
  <li><strong>Cons:</strong> Hard to maintain as graph changes dynamically.</li>
</ul>

<p><strong>Solution 3: Replication (Facebook TAO)</strong></p>
<ul>
  <li>Cache the entire “social graph” in RAM across thousands of memcache nodes.</li>
  <li>Read-heavy workload optimization.</li>
</ul>

<h2 id="9-system-design-interview-design-a-kg-for-movies">9. System Design Interview: Design a KG for Movies</h2>

<p><strong>Requirements:</strong></p>
<ul>
  <li>Store Movies, Actors, Directors.</li>
  <li>Query: “Movies directed by Nolan starring DiCaprio”.</li>
  <li>Scale: 1M movies, 10M people.</li>
</ul>

<p><strong>Schema:</strong></p>
<ul>
  <li>Nodes: <code class="language-plaintext highlighter-rouge">Movie</code>, <code class="language-plaintext highlighter-rouge">Person</code>.</li>
  <li>Edges: <code class="language-plaintext highlighter-rouge">DIRECTED</code>, <code class="language-plaintext highlighter-rouge">ACTED_IN</code>.</li>
</ul>

<p><strong>Storage:</strong></p>
<ul>
  <li><strong>Neo4j</strong> (Single instance fits in RAM). 11M nodes is small.</li>
  <li>If 10B nodes -&gt; <strong>JanusGraph</strong> on Cassandra.</li>
</ul>

<p><strong>API:</strong></p>
<ul>
  <li>GraphQL is perfect for hierarchical graph queries.
    <div class="language-graphql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">query</span><span class="w"> </span><span class="p">{</span><span class="w">
</span><span class="n">director</span><span class="p">(</span><span class="n">name</span><span class="p">:</span><span class="w"> </span><span class="s2">"Christopher Nolan"</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="n">movies</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="n">title</span><span class="w">
    </span><span class="n">actors</span><span class="p">(</span><span class="n">name</span><span class="p">:</span><span class="w"> </span><span class="s2">"Leonardo DiCaprio"</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="n">name</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div>    </div>
  </li>
</ul>

<h2 id="10-top-interview-questions">10. Top Interview Questions</h2>

<p><strong>Q1: How do you handle entity resolution at scale?</strong>
<em>Answer:</em> Blocking (LSH) to find candidates, then pairwise classification (XGBoost/BERT) to verify.</p>

<p><strong>Q2: TransE vs GNNs?</strong>
<em>Answer:</em> TransE is shallow (lookup table). GNNs are deep (aggregate features). GNNs generalize to unseen nodes (inductive), TransE is transductive.</p>

<p><strong>Q3: How to update a KG in real-time?</strong>
<em>Answer:</em> Lambda architecture. Batch pipeline re-builds the high-quality graph nightly. Streaming pipeline adds temporary edges from Kafka events.</p>

<h2 id="11-summary">11. Summary</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Component</th>
      <th style="text-align: left">Technology</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><strong>Data Model</strong></td>
      <td style="text-align: left">Labeled Property Graph (LPG)</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Storage</strong></td>
      <td style="text-align: left">Neo4j, JanusGraph, Amazon Neptune</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Query</strong></td>
      <td style="text-align: left">Cypher, Gremlin, GraphQL</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Inference</strong></td>
      <td style="text-align: left">GraphSAGE, TransE</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Use Cases</strong></td>
      <td style="text-align: left">Search, RecSys, Fraud Detection</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Scale</strong></td>
      <td style="text-align: left">Billions of nodes, Trillions of edges</td>
    </tr>
  </tbody>
</table>

<h2 id="12-deep-dive-graph-neural-networks-gnns">12. Deep Dive: Graph Neural Networks (GNNs)</h2>

<p>Traditional embeddings (TransE) are “shallow” — they learn a unique vector for every node. They cannot generalize to new nodes without retraining. <strong>GNNs</strong> solve this.</p>

<p><strong>GraphSAGE (Graph Sample and Aggregate):</strong></p>
<ul>
  <li><strong>Idea:</strong> Generate node embeddings by sampling and aggregating features from a node’s local neighborhood.</li>
  <li><strong>Inductive:</strong> Can generate embeddings for unseen nodes if we know their features and neighbors.</li>
</ul>

<p><strong>Algorithm:</strong></p>
<ol>
  <li><strong>Sample:</strong> For each node, sample a fixed number of neighbors (e.g., 10).</li>
  <li><strong>Aggregate:</strong> Combine neighbor embeddings (Mean, LSTM, or Max Pooling).</li>
  <li><strong>Update:</strong> Concatenate self-embedding with aggregated neighbor embedding and pass through a Neural Network.</li>
  <li><strong>Repeat:</strong> Do this for $K$ layers (hops).</li>
</ol>

<p><strong>Code Snippet (PyTorch Geometric):</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">SAGEConv</span>

<span class="k">class</span> <span class="nc">GraphSAGE</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="nc">SAGEConv</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="nc">SAGEConv</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">):</span>
        <span class="c1"># x: Node feature matrix
</span>        <span class="c1"># edge_index: Graph connectivity
</span>        
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">relu</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">training</span><span class="p">)</span>
        
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</code></pre></div></div>

<p><strong>Graph Attention Networks (GAT):</strong></p>
<ul>
  <li><strong>Idea:</strong> Not all neighbors are equal. Learn <strong>attention weights</strong> to prioritize important neighbors.</li>
  <li><strong>Mechanism:</strong> Compute attention coefficient $\alpha_{ij}$ for edge $i \to j$.</li>
  <li><strong>Benefit:</strong> Better performance on noisy graphs.</li>
</ul>

<h2 id="13-deep-dive-knowledge-graph-embeddings-kge-math">13. Deep Dive: Knowledge Graph Embeddings (KGE) Math</h2>

<p>Let’s look at the math behind <strong>TransE</strong> and <strong>RotatE</strong>.</p>

<p><strong>TransE (Translating Embeddings):</strong></p>
<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td><strong>Score Function:</strong> $f(h, r, t) = -</td>
          <td> </td>
          <td>h + r - t</td>
          <td> </td>
          <td>$</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li><strong>Objective:</strong> Minimize margin-based ranking loss.
\(L = \sum_{(h,r,t) \in S} \sum_{(h',r,t') \in S'} [\gamma + f(h, r, t) - f(h', r, t')]_+\)</li>
  <li><strong>Limitation:</strong> Cannot model 1-to-N relations (e.g., <code class="language-plaintext highlighter-rouge">Teacher -&gt; Student</code>). If $h+r \approx t_1$ and $h+r \approx t_2$, then $t_1 \approx t_2$, forcing all students to be identical.</li>
</ul>

<p><strong>RotatE (Rotation Embeddings):</strong></p>
<ul>
  <li><strong>Idea:</strong> Map entities to the complex plane $\mathbb{C}$.</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td><strong>Relation:</strong> Rotation in complex space. $t = h \circ r$, where $</td>
          <td>r_i</td>
          <td>= 1$.</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li><strong>Capability:</strong> Can model:
    <ul>
      <li><strong>Symmetry:</strong> $r \circ r = 1$ (e.g., <code class="language-plaintext highlighter-rouge">spouse</code>).</li>
      <li><strong>Antisymmetry:</strong> $r \circ r \neq 1$ (e.g., <code class="language-plaintext highlighter-rouge">parent</code>).</li>
      <li><strong>Inversion:</strong> $r_2 = r_1^{-1}$ (e.g., <code class="language-plaintext highlighter-rouge">hypernym</code> vs <code class="language-plaintext highlighter-rouge">hyponym</code>).</li>
    </ul>
  </li>
</ul>

<h2 id="14-deep-dive-entity-linking-at-scale">14. Deep Dive: Entity Linking at Scale</h2>

<p>How do you link “MJ” to “Michael Jordan” (Basketball) vs “Michael Jackson” (Singer) when you have 100M entities?</p>

<p><strong>Two-Stage Pipeline:</strong></p>

<p><strong>Stage 1: Blocking / Candidate Generation (Recall)</strong></p>
<ul>
  <li><strong>Goal:</strong> Retrieve top-K (e.g., 100) candidates quickly.</li>
  <li><strong>Technique:</strong>
    <ul>
      <li><strong>Inverted Index:</strong> Map surface forms (“MJ”, “Mike”) to Entity IDs.</li>
      <li><strong>Dense Retrieval:</strong> Encode mention context and entity description into vectors. Use FAISS to find nearest neighbors.</li>
    </ul>
  </li>
</ul>

<p><strong>Stage 2: Re-Ranking (Precision)</strong></p>
<ul>
  <li><strong>Goal:</strong> Select the best match from candidates.</li>
  <li><strong>Model:</strong> Cross-Encoder (BERT).
    <ul>
      <li>Input: <code class="language-plaintext highlighter-rouge">[CLS] Mention Context [SEP] Entity Description [SEP]</code></li>
      <li>Output: Probability of match.</li>
    </ul>
  </li>
  <li><strong>Features:</strong>
    <ul>
      <li><strong>String Similarity:</strong> Edit distance.</li>
      <li><strong>Prior Probability:</strong> $P(Entity)$. “Michael Jordan” usually means the basketball player.</li>
      <li><strong>Coherence:</strong> Does this entity fit with other entities in the document? (e.g., “Chicago Bulls” is nearby).</li>
    </ul>
  </li>
</ul>

<h2 id="15-deep-dive-graph-rag-implementation">15. Deep Dive: Graph RAG Implementation</h2>

<p><strong>Retrieval Augmented Generation</strong> with Graphs is powerful for multi-hop reasoning.</p>

<p><strong>Scenario:</strong> “Who is the CEO of the company that acquired GitHub?”</p>

<p><strong>Vector RAG Failure:</strong></p>
<ul>
  <li>Vector search might find docs about “GitHub acquisition” and “Microsoft CEO”.</li>
  <li>But it might miss the connection if they are in separate documents.</li>
</ul>

<p><strong>Graph RAG Success:</strong></p>
<ol>
  <li><strong>Entity Linking:</strong> Extract “GitHub”. Link to <code class="language-plaintext highlighter-rouge">GitHub (Company)</code>.</li>
  <li><strong>Graph Traversal (1-hop):</strong> <code class="language-plaintext highlighter-rouge">GitHub -[ACQUIRED_BY]-&gt; Microsoft</code>.</li>
  <li><strong>Graph Traversal (2-hop):</strong> <code class="language-plaintext highlighter-rouge">Microsoft -[CEO_IS]-&gt; Satya Nadella</code>.</li>
  <li><strong>Context Construction:</strong> “GitHub was acquired by Microsoft. Microsoft’s CEO is Satya Nadella.”</li>
  <li><strong>LLM Answer:</strong> “Satya Nadella.”</li>
</ol>

<p><strong>Implementation Steps:</strong></p>
<ol>
  <li><strong>Ingest:</strong> Parse documents into triples <code class="language-plaintext highlighter-rouge">(Subject, Predicate, Object)</code>.</li>
  <li><strong>Index:</strong> Store triples in Neo4j.</li>
  <li><strong>Query:</strong>
    <ul>
      <li>Use LLM to generate Cypher query.</li>
      <li><code class="language-plaintext highlighter-rouge">MATCH (c:Company {name: "GitHub"})-[:ACQUIRED_BY]-&gt;(parent)-[:CEO]-&gt;(ceo) RETURN ceo.name</code></li>
    </ul>
  </li>
  <li><strong>Generate:</strong> Pass result to LLM for natural language response.</li>
</ol>

<h2 id="16-deep-dive-temporal-knowledge-graphs">16. Deep Dive: Temporal Knowledge Graphs</h2>

<p>Facts change over time.</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">(Obama, role, President)</code> is true only for <code class="language-plaintext highlighter-rouge">[2009, 2017]</code>.</li>
</ul>

<p><strong>Modeling Time:</strong></p>
<ol>
  <li><strong>Reification:</strong> Turn the edge into a node.
    <ul>
      <li><code class="language-plaintext highlighter-rouge">(Obama) -&gt; [Term] -&gt; (President)</code></li>
      <li><code class="language-plaintext highlighter-rouge">[Term]</code> has property <code class="language-plaintext highlighter-rouge">start: 2009</code>, <code class="language-plaintext highlighter-rouge">end: 2017</code>.</li>
    </ul>
  </li>
  <li><strong>Quadruples:</strong> Store <code class="language-plaintext highlighter-rouge">(Subject, Predicate, Object, Timestamp)</code>.</li>
  <li><strong>Temporal Embeddings:</strong> $f(h, r, t, \tau)$. The embedding evolves over time.</li>
</ol>

<h2 id="17-deep-dive-quality-assurance-in-kgs">17. Deep Dive: Quality Assurance in KGs</h2>

<p>Garbage In, Garbage Out. How to ensure KG quality?</p>

<p><strong>1. Schema Constraints (SHACL):</strong></p>
<ul>
  <li>Define rules: <code class="language-plaintext highlighter-rouge">Person</code> can only <code class="language-plaintext highlighter-rouge">marry</code> another <code class="language-plaintext highlighter-rouge">Person</code>.</li>
  <li><code class="language-plaintext highlighter-rouge">BirthDate</code> must be a valid date.</li>
</ul>

<p><strong>2. Consistency Checking:</strong></p>
<ul>
  <li>Logic rules: <code class="language-plaintext highlighter-rouge">born_in(X, Y) AND located_in(Y, Z) -&gt; born_in(X, Z)</code>.</li>
  <li>If KG says <code class="language-plaintext highlighter-rouge">born_in(Obama, Kenya)</code> but also <code class="language-plaintext highlighter-rouge">born_in(Obama, Hawaii)</code> and <code class="language-plaintext highlighter-rouge">Hawaii != Kenya</code>, flag contradiction.</li>
</ul>

<p><strong>3. Human-in-the-Loop:</strong></p>
<ul>
  <li>High-confidence facts -&gt; Auto-merge.</li>
  <li>Low-confidence facts -&gt; Send to human annotators (crowdsourcing).</li>
</ul>

<h2 id="18-deep-dive-federated-knowledge-graphs">18. Deep Dive: Federated Knowledge Graphs</h2>

<p>Enterprises often have data silos.</p>
<ul>
  <li><strong>HR Graph:</strong> Employees, Roles.</li>
  <li><strong>Sales Graph:</strong> Customers, Deals.</li>
  <li><strong>Product Graph:</strong> SKUs, Specs.</li>
</ul>

<p><strong>Challenge:</strong> Query across silos. “Which sales rep sold Product X to Customer Y?”</p>

<p><strong>Solution: Data Fabric / Virtual Graph</strong></p>
<ul>
  <li>Leave data where it is (SQL, NoSQL, APIs).</li>
  <li>Create a <strong>Virtual Semantic Layer</strong> on top.</li>
  <li>Map local schemas to a global ontology.</li>
  <li>Query Federation engine (e.g., Starogard) decomposes SPARQL/GraphQL query into sub-queries for each backend.</li>
</ul>

<h2 id="19-system-design-real-time-fraud-detection-with-kg">19. System Design: Real-Time Fraud Detection with KG</h2>

<p><strong>Problem:</strong> Detect credit card fraud.
<strong>Insight:</strong> Fraudsters often share attributes (same phone, same IP, same device) forming “rings”.</p>

<p><strong>Design:</strong></p>
<ol>
  <li><strong>Ingestion:</strong> Kafka stream of transactions.</li>
  <li><strong>Graph Update:</strong> Add node <code class="language-plaintext highlighter-rouge">Transaction</code>. Link to <code class="language-plaintext highlighter-rouge">User</code>, <code class="language-plaintext highlighter-rouge">Device</code>, <code class="language-plaintext highlighter-rouge">IP</code>.</li>
  <li><strong>Feature Extraction (Real-time):</strong>
    <ul>
      <li>Count connected components size.</li>
      <li>Cycle detection (User A -&gt; Card B -&gt; User C -&gt; Card A).</li>
      <li>PageRank (guilt by association).</li>
    </ul>
  </li>
  <li><strong>Inference:</strong> Pass graph features to XGBoost model.</li>
  <li><strong>Latency:</strong> &lt; 200ms.
    <ul>
      <li>Use in-memory graph (RedisGraph or Neo4j Causal Cluster).</li>
    </ul>
  </li>
</ol>

<h2 id="20-advanced-neuro-symbolic-ai">20. Advanced: Neuro-Symbolic AI</h2>

<p>Combining the learning capability of Neural Networks with the reasoning of Symbolic Logic (KGs).</p>

<p><strong>Concept:</strong></p>
<ul>
  <li><strong>Neural:</strong> Good at perception (images, text).</li>
  <li><strong>Symbolic:</strong> Good at reasoning, math, consistency.</li>
</ul>

<p><strong>Application:</strong></p>
<ul>
  <li><strong>Visual Question Answering (VQA):</strong>
    <ul>
      <li>Image: “A red cube on a blue cylinder.”</li>
      <li>Neural: Detect objects (Cube, Cylinder) and attributes (Red, Blue).</li>
      <li>Symbolic: Build scene graph. Query <code class="language-plaintext highlighter-rouge">on(Cube, Cylinder)</code>.</li>
    </ul>
  </li>
</ul>

<h2 id="21-summary">21. Summary</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Component</th>
      <th style="text-align: left">Technology</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><strong>Data Model</strong></td>
      <td style="text-align: left">Labeled Property Graph (LPG)</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Storage</strong></td>
      <td style="text-align: left">Neo4j, JanusGraph, Amazon Neptune</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Query</strong></td>
      <td style="text-align: left">Cypher, Gremlin, GraphQL</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Inference</strong></td>
      <td style="text-align: left">GraphSAGE, TransE</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Use Cases</strong></td>
      <td style="text-align: left">Search, RecSys, Fraud Detection</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Scale</strong></td>
      <td style="text-align: left">Billions of nodes, Trillions of edges</td>
    </tr>
  </tbody>
</table>

<h2 id="22-deep-dive-graph-databases-vs-relational-databases">22. Deep Dive: Graph Databases vs. Relational Databases</h2>

<p>When should you use a Graph DB over Postgres?</p>

<p><strong>Relational (SQL):</strong></p>
<ul>
  <li><strong>Data Model:</strong> Tables, Rows, Foreign Keys.</li>
  <li><strong>Join:</strong> Computed at query time. $O(N \log N)$ or $O(N^2)$.</li>
  <li><strong>Use Case:</strong> Structured data, transactions, aggregations.</li>
  <li><strong>Query:</strong> “Find all users who bought item X.” (1 Join).</li>
</ul>

<p><strong>Graph (Neo4j):</strong></p>
<ul>
  <li><strong>Data Model:</strong> Nodes, Edges.</li>
  <li><strong>Join:</strong> Pre-computed (edges are pointers). $O(1)$ per hop.</li>
  <li><strong>Use Case:</strong> Highly connected data, pathfinding.</li>
  <li><strong>Query:</strong> “Find all users who bought item X, and their friends who bought item Y.” (Multi-hop).</li>
</ul>

<p><strong>Benchmark:</strong>
For a 5-hop query on a social network:</p>
<ul>
  <li><strong>SQL:</strong> 10+ seconds (5 joins).</li>
  <li><strong>Graph:</strong> &lt; 100ms (pointer traversal).</li>
</ul>

<h2 id="23-deep-dive-ontology-design">23. Deep Dive: Ontology Design</h2>

<p>An <strong>Ontology</strong> is the schema of your Knowledge Graph.</p>

<p><strong>Components:</strong></p>
<ol>
  <li><strong>Classes:</strong> <code class="language-plaintext highlighter-rouge">Person</code>, <code class="language-plaintext highlighter-rouge">Company</code>, <code class="language-plaintext highlighter-rouge">City</code>.</li>
  <li><strong>Properties:</strong> <code class="language-plaintext highlighter-rouge">name</code> (string), <code class="language-plaintext highlighter-rouge">age</code> (int).</li>
  <li><strong>Relationships:</strong> <code class="language-plaintext highlighter-rouge">WORKS_AT</code> (Person -&gt; Company).</li>
  <li><strong>Inheritance:</strong> <code class="language-plaintext highlighter-rouge">Employee</code> is a subclass of <code class="language-plaintext highlighter-rouge">Person</code>.</li>
</ol>

<p><strong>Design Patterns:</strong></p>
<ul>
  <li><strong>Reification:</strong> Don’t just link <code class="language-plaintext highlighter-rouge">Actor -&gt; Movie</code>. Link <code class="language-plaintext highlighter-rouge">Actor -&gt; Role -&gt; Movie</code> to store “character name”.</li>
  <li><strong>Hierarchy:</strong> Use <code class="language-plaintext highlighter-rouge">subClassOf</code> sparingly. Too deep hierarchies make inference slow.</li>
</ul>

<p><strong>Example (OWL/Turtle):</strong></p>
<div class="language-turtle highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">:</span><span class="n">Person</span><span class="w"> </span><span class="k">a</span><span class="w"> </span><span class="nn">owl:</span><span class="n">Class</span><span class="w"> </span><span class="p">.</span><span class="w">
</span><span class="nn">:</span><span class="n">Employee</span><span class="w"> </span><span class="k">a</span><span class="w"> </span><span class="nn">owl:</span><span class="n">Class</span><span class="w"> </span><span class="p">;</span><span class="w">
    </span><span class="nn">rdfs:</span><span class="n">subClassOf</span><span class="w"> </span><span class="nn">:</span><span class="n">Person</span><span class="w"> </span><span class="p">.</span><span class="w">
</span><span class="nn">:</span><span class="n">worksAt</span><span class="w"> </span><span class="k">a</span><span class="w"> </span><span class="nn">owl:</span><span class="n">ObjectProperty</span><span class="w"> </span><span class="p">;</span><span class="w">
    </span><span class="nn">rdfs:</span><span class="n">domain</span><span class="w"> </span><span class="nn">:</span><span class="n">Employee</span><span class="w"> </span><span class="p">;</span><span class="w">
    </span><span class="nn">rdfs:</span><span class="n">range</span><span class="w"> </span><span class="nn">:</span><span class="n">Company</span><span class="w"> </span><span class="p">.</span><span class="w">
</span></code></pre></div></div>

<h2 id="24-deep-dive-reasoning-engines">24. Deep Dive: Reasoning Engines</h2>

<p>Reasoning allows inferring implicit facts.</p>

<p><strong>Types of Reasoning:</strong></p>
<ol>
  <li><strong>RDFS Reasoning:</strong>
    <ul>
      <li>Rule: <code class="language-plaintext highlighter-rouge">Employee subClassOf Person</code>.</li>
      <li>Fact: <code class="language-plaintext highlighter-rouge">John is Employee</code>.</li>
      <li>Inference: <code class="language-plaintext highlighter-rouge">John is Person</code>.</li>
    </ul>
  </li>
  <li><strong>Transitive Reasoning:</strong>
    <ul>
      <li>Rule: <code class="language-plaintext highlighter-rouge">partOf</code> is transitive.</li>
      <li>Fact: <code class="language-plaintext highlighter-rouge">Finger partOf Hand</code>, <code class="language-plaintext highlighter-rouge">Hand partOf Arm</code>.</li>
      <li>Inference: <code class="language-plaintext highlighter-rouge">Finger partOf Arm</code>.</li>
    </ul>
  </li>
  <li><strong>Inverse Reasoning:</strong>
    <ul>
      <li>Rule: <code class="language-plaintext highlighter-rouge">parentOf</code> inverseOf <code class="language-plaintext highlighter-rouge">childOf</code>.</li>
      <li>Fact: <code class="language-plaintext highlighter-rouge">A parentOf B</code>.</li>
      <li>Inference: <code class="language-plaintext highlighter-rouge">B childOf A</code>.</li>
    </ul>
  </li>
</ol>

<p><strong>Tools:</strong></p>
<ul>
  <li><strong>Jena Inference Engine</strong> (Java).</li>
  <li><strong>GraphDB</strong> (Ontotext).</li>
</ul>

<h2 id="25-deep-dive-graph-visualization-tools">25. Deep Dive: Graph Visualization Tools</h2>

<p>Visualizing 1B nodes is impossible. We need tools to explore subgraphs.</p>

<p><strong>Tools:</strong></p>
<ol>
  <li><strong>Gephi:</strong> Desktop tool. Good for static analysis of medium graphs (100k nodes).</li>
  <li><strong>Cytoscape:</strong> Bio-informatics focus. Good for protein interaction networks.</li>
  <li><strong>Neo4j Bloom:</strong> Interactive exploration. “Show me the shortest path between X and Y.”</li>
  <li><strong>KeyLines / ReGraph:</strong> JavaScript libraries for building web-based graph visualizers.</li>
</ol>

<p><strong>Visualization Techniques:</strong></p>
<ul>
  <li><strong>Force-Directed Layout:</strong> Simulates physics (nodes repel, edges attract).</li>
  <li><strong>Community Detection coloring:</strong> Color nodes by Louvain community.</li>
  <li><strong>Ego-Network:</strong> Only show node X and its immediate neighbors.</li>
</ul>

<h2 id="26-code-loading-data-into-neo4j">26. Code: Loading Data into Neo4j</h2>

<p>How to ingest data programmatically.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">neo4j</span> <span class="kn">import</span> <span class="n">GraphDatabase</span>

<span class="k">class</span> <span class="nc">KnowledgeGraphLoader</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">uri</span><span class="p">,</span> <span class="n">user</span><span class="p">,</span> <span class="n">password</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">driver</span> <span class="o">=</span> <span class="n">GraphDatabase</span><span class="p">.</span><span class="nf">driver</span><span class="p">(</span><span class="n">uri</span><span class="p">,</span> <span class="n">auth</span><span class="o">=</span><span class="p">(</span><span class="n">user</span><span class="p">,</span> <span class="n">password</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">close</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">driver</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">add_person</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">age</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">self</span><span class="p">.</span><span class="n">driver</span><span class="p">.</span><span class="nf">session</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
            <span class="n">session</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span>
                <span class="sh">"</span><span class="s">MERGE (p:Person {name: $name}) SET p.age = $age</span><span class="sh">"</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">age</span><span class="o">=</span><span class="n">age</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">add_friendship</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">name1</span><span class="p">,</span> <span class="n">name2</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">self</span><span class="p">.</span><span class="n">driver</span><span class="p">.</span><span class="nf">session</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
            <span class="n">session</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span>
                <span class="sh">"""</span><span class="s">
                MATCH (a:Person {name: $name1})
                MATCH (b:Person {name: $name2})
                MERGE (a)-[:FRIEND]-&gt;(b)
                </span><span class="sh">"""</span><span class="p">,</span>
                <span class="n">name1</span><span class="o">=</span><span class="n">name1</span><span class="p">,</span> <span class="n">name2</span><span class="o">=</span><span class="n">name2</span>
            <span class="p">)</span>

<span class="c1"># Usage
</span><span class="n">loader</span> <span class="o">=</span> <span class="nc">KnowledgeGraphLoader</span><span class="p">(</span><span class="sh">"</span><span class="s">bolt://localhost:7687</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">neo4j</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">password</span><span class="sh">"</span><span class="p">)</span>
<span class="n">loader</span><span class="p">.</span><span class="nf">add_person</span><span class="p">(</span><span class="sh">"</span><span class="s">Alice</span><span class="sh">"</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="n">loader</span><span class="p">.</span><span class="nf">add_person</span><span class="p">(</span><span class="sh">"</span><span class="s">Bob</span><span class="sh">"</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="n">loader</span><span class="p">.</span><span class="nf">add_friendship</span><span class="p">(</span><span class="sh">"</span><span class="s">Alice</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Bob</span><span class="sh">"</span><span class="p">)</span>
<span class="n">loader</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="27-summary">27. Summary</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Component</th>
      <th style="text-align: left">Technology</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><strong>Data Model</strong></td>
      <td style="text-align: left">Labeled Property Graph (LPG)</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Storage</strong></td>
      <td style="text-align: left">Neo4j, JanusGraph, Amazon Neptune</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Query</strong></td>
      <td style="text-align: left">Cypher, Gremlin, GraphQL</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Inference</strong></td>
      <td style="text-align: left">GraphSAGE, TransE</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Use Cases</strong></td>
      <td style="text-align: left">Search, RecSys, Fraud Detection</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Scale</strong></td>
      <td style="text-align: left">Billions of nodes, Trillions of edges</td>
    </tr>
  </tbody>
</table>

<h2 id="28-deep-dive-graph-partitioning-algorithms">28. Deep Dive: Graph Partitioning Algorithms</h2>

<p>To scale to billions of nodes, we must shard the graph.</p>

<p><strong>Problem:</strong> Minimizing “edge cuts” (edges that span across shards) to reduce network latency.</p>

<p><strong>Algorithm 1: METIS (Multilevel Graph Partitioning)</strong></p>
<ul>
  <li><strong>Phase 1 (Coarsening):</strong> Collapse adjacent nodes into super-nodes to create a smaller graph.</li>
  <li><strong>Phase 2 (Partitioning):</strong> Partition the coarse graph.</li>
  <li><strong>Phase 3 (Uncoarsening):</strong> Project the partition back to the original graph and refine.</li>
  <li><strong>Pros:</strong> High quality partitions.</li>
  <li><strong>Cons:</strong> Slow, requires global graph view (offline).</li>
</ul>

<p><strong>Algorithm 2: Fennel (Streaming Partitioning)</strong></p>
<ul>
  <li>Assign nodes to shards as they arrive in a stream.</li>
  <li><strong>Heuristic:</strong> Place node $v$ in shard $i$ that maximizes:
\(Score(v, i) = |N(v) \cap S_i| - \alpha (|S_i|)^{\gamma}\)
    <ul>
      <li>Term 1: Attraction (place where neighbors are).</li>
      <li>Term 2: Repulsion (load balancing).</li>
    </ul>
  </li>
  <li><strong>Pros:</strong> Fast, scalable, works for dynamic graphs.</li>
</ul>

<h2 id="29-deep-dive-graph-query-optimization">29. Deep Dive: Graph Query Optimization</h2>

<p>Just like SQL optimizers, Graph DBs need to plan queries.</p>

<p><strong>Query:</strong> <code class="language-plaintext highlighter-rouge">MATCH (p:Person)-[:LIVES_IN]-&gt;(c:City {name: 'London'})-[:HAS_RESTAURANT]-&gt;(r:Restaurant)</code></p>

<p><strong>Execution Plans:</strong></p>
<ol>
  <li><strong>Scan Person:</strong> Find all people, check if they live in London… (Bad, 1B people).</li>
  <li><strong>Index Scan City:</strong> Find ‘London’ (1 node). Traverse out to <code class="language-plaintext highlighter-rouge">Person</code> (8M nodes). Traverse out to <code class="language-plaintext highlighter-rouge">Restaurant</code> (20k nodes).</li>
  <li><strong>Bi-directional:</strong> Start at ‘London’, traverse both ways.</li>
</ol>

<p><strong>Cost-Based Optimizer:</strong></p>
<ul>
  <li>Uses statistics (node counts, degree distribution).</li>
  <li>“City” has cardinality 10,000. “Person” has 1B.</li>
  <li>Start with the most selective filter (<code class="language-plaintext highlighter-rouge">name='London'</code>).</li>
</ul>

<h2 id="30-deep-dive-graph-analytics-algorithms">30. Deep Dive: Graph Analytics Algorithms</h2>

<p>Beyond simple queries, we run global algorithms.</p>

<p><strong>1. PageRank:</strong></p>
<ul>
  <li>Measure node importance.</li>
  <li><strong>Use Case:</strong> Search ranking, finding influential Twitter users.</li>
  <li><strong>Update Rule:</strong> $PR(u) = (1-d) + d \sum_{v \in N_{in}(u)} \frac{PR(v)}{OutDegree(v)}$.</li>
</ul>

<p><strong>2. Louvain Modularity (Community Detection):</strong></p>
<ul>
  <li>Detect clusters of densely connected nodes.</li>
  <li><strong>Use Case:</strong> Fraud rings, topic detection.</li>
</ul>

<p><strong>3. Betweenness Centrality:</strong></p>
<ul>
  <li>Number of shortest paths passing through a node.</li>
  <li><strong>Use Case:</strong> Identifying bottlenecks in a supply chain or network router.</li>
</ul>

<h2 id="31-deep-dive-hardware-acceleration-for-graphs">31. Deep Dive: Hardware Acceleration for Graphs</h2>

<p>CPUs are bad at graph processing (random memory access = cache misses).</p>

<p><strong>Graphcore IPU (Intelligence Processing Unit):</strong></p>
<ul>
  <li><strong>Architecture:</strong> Massive MIMD (Multiple Instruction, Multiple Data).</li>
  <li><strong>Memory:</strong> In-processor memory (SRAM) instead of HBM.</li>
  <li><strong>Benefit:</strong> 10x-100x speedup for GNN training and random walks.</li>
</ul>

<p><strong>Cerebras Wafer-Scale Engine:</strong></p>
<ul>
  <li>A single chip the size of a wafer.</li>
  <li>Holds the entire graph in SRAM.</li>
  <li>Zero latency communication between cores.</li>
</ul>

<h2 id="32-summary">32. Summary</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Component</th>
      <th style="text-align: left">Technology</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><strong>Data Model</strong></td>
      <td style="text-align: left">Labeled Property Graph (LPG)</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Storage</strong></td>
      <td style="text-align: left">Neo4j, JanusGraph, Amazon Neptune</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Query</strong></td>
      <td style="text-align: left">Cypher, Gremlin, GraphQL</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Inference</strong></td>
      <td style="text-align: left">GraphSAGE, TransE</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Use Cases</strong></td>
      <td style="text-align: left">Search, RecSys, Fraud Detection</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Scale</strong></td>
      <td style="text-align: left">Billions of nodes, Trillions of edges</td>
    </tr>
  </tbody>
</table>

<hr />

<p><strong>Originally published at:</strong> <a href="https://www.arunbaby.com/ml-system-design/0034-knowledge-graph-systems/">arunbaby.com/ml-system-design/0034-knowledge-graph-systems</a></p>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#database" class="page__taxonomy-item p-category" rel="tag">database</a><span class="sep">, </span>
    
      <a href="/tags/#graph-neural-networks" class="page__taxonomy-item p-category" rel="tag">graph-neural-networks</a><span class="sep">, </span>
    
      <a href="/tags/#knowledge-graph" class="page__taxonomy-item p-category" rel="tag">knowledge-graph</a><span class="sep">, </span>
    
      <a href="/tags/#nlp" class="page__taxonomy-item p-category" rel="tag">nlp</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#ml-system-design" class="page__taxonomy-item p-category" rel="tag">ml_system_design</a>
    
    </span>
  </p>


        
      </footer>

      

      <section class="page__share">
  <h4 class="page__share-title">Share on</h4>

  <a href="https://twitter.com/intent/tweet?via=arunbaby0&text=Knowledge+Graph+Systems%20https%3A%2F%2Fwww.arunbaby.com%2Fml-system-design%2F0034-knowledge-graph-systems%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.arunbaby.com%2Fml-system-design%2F0034-knowledge-graph-systems%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.arunbaby.com/ml-system-design/0034-knowledge-graph-systems/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/ml-system-design/0033-model-replication-systems/" class="pagination--pager" title="Model Replication Systems">Previous</a>
    
    
      <a href="/ml-system-design/0035-boundary-detection-in-ml/" class="pagination--pager" title="Boundary Detection in ML">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 1990 - 2143 <a href="https://www.arunbaby.com">Arun Baby</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JRJPEC9SS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0JRJPEC9SS', { 'anonymize_ip': false});
</script>








  </body>
</html>
