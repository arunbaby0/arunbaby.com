<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Neural Architecture Search - Arun Baby</title>
<meta name="description" content="Design neural architecture search systems that automatically discover optimal model architectures using dynamic programming and path optimization—the same principles from grid path counting scaled to exponential search spaces.">


  <meta name="author" content="Arun Baby">
  
  <meta property="article:author" content="Arun Baby">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Arun Baby">
<meta property="og:title" content="Neural Architecture Search">
<meta property="og:url" content="https://www.arunbaby.com/ml-system-design/0021-neural-architecture-search/">


  <meta property="og:description" content="Design neural architecture search systems that automatically discover optimal model architectures using dynamic programming and path optimization—the same principles from grid path counting scaled to exponential search spaces.">



  <meta property="og:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">



  <meta name="twitter:site" content="@arunbaby0">
  <meta name="twitter:title" content="Neural Architecture Search">
  <meta name="twitter:description" content="Design neural architecture search systems that automatically discover optimal model architectures using dynamic programming and path optimization—the same principles from grid path counting scaled to exponential search spaces.">
  <meta name="twitter:url" content="https://www.arunbaby.com/ml-system-design/0021-neural-architecture-search/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">
    
  

  



  <meta property="article:published_time" content="2025-12-14T09:38:49+05:30">





  

  


<link rel="canonical" href="https://www.arunbaby.com/ml-system-design/0021-neural-architecture-search/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Baby Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          <span class="site-subtitle">Arun Baby</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/dsa/"
                
                
              >DSA</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ml-system-design/"
                
                
              >ML Systems</a>
            </li><li class="masthead__menu-item">
              <a
                href="/speech-tech/"
                
                
              >Speech Tech</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li><li class="masthead__menu-item">
              <a
                href="/statuses/"
                
                
              >Statuses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/contact/"
                
                
              >Contact</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main" class="no-author-sidebar">
  
  <div class="sidebar sticky">
  
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Neural Architecture Search">
    <meta itemprop="description" content="Design neural architecture search systems that automatically discover optimal model architectures using dynamic programming and path optimization—the same principles from grid path counting scaled to exponential search spaces.">
    <meta itemprop="datePublished" content="2025-12-14T09:38:49+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://www.arunbaby.com/ml-system-design/0021-neural-architecture-search/" itemprop="url">Neural Architecture Search
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          18 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#problem-statement">Problem Statement</a><ul><li><a href="#functional-requirements">Functional Requirements</a></li><li><a href="#non-functional-requirements">Non-Functional Requirements</a></li></ul></li><li><a href="#understanding-the-requirements">Understanding the Requirements</a><ul><li><a href="#why-nas">Why NAS?</a></li><li><a href="#scale-of-the-problem">Scale of the Problem</a></li><li><a href="#the-path-optimization-connection">The Path Optimization Connection</a></li></ul></li><li><a href="#high-level-architecture">High-Level Architecture</a><ul><li><a href="#key-components">Key Components</a></li></ul></li><li><a href="#component-deep-dives">Component Deep-Dives</a><ul><li><a href="#1-search-space-definition">1. Search Space Definition</a></li><li><a href="#2-search-strategy---reinforcement-learning">2. Search Strategy - Reinforcement Learning</a></li><li><a href="#3-search-strategy---differentiable-nas-darts">3. Search Strategy - Differentiable NAS (DARTS)</a></li><li><a href="#4-performance-estimation-strategies">4. Performance Estimation Strategies</a></li></ul></li><li><a href="#data-flow">Data Flow</a><ul><li><a href="#nas-pipeline">NAS Pipeline</a></li></ul></li><li><a href="#scaling-strategies">Scaling Strategies</a><ul><li><a href="#distributed-architecture-evaluation">Distributed Architecture Evaluation</a></li></ul></li><li><a href="#monitoring--metrics">Monitoring &amp; Metrics</a><ul><li><a href="#key-metrics">Key Metrics</a></li><li><a href="#visualization">Visualization</a></li></ul></li><li><a href="#failure-modes--mitigations">Failure Modes &amp; Mitigations</a></li><li><a href="#real-world-case-study-googles-efficientnet">Real-World Case Study: Google’s EfficientNet</a><ul><li><a href="#googles-nas-approach">Google’s NAS Approach</a></li><li><a href="#key-lessons">Key Lessons</a></li></ul></li><li><a href="#cost-analysis">Cost Analysis</a><ul><li><a href="#nas-vs-manual-design">NAS vs Manual Design</a></li></ul></li><li><a href="#advanced-topics">Advanced Topics</a><ul><li><a href="#1-once-for-all-networks">1. Once-For-All Networks</a></li><li><a href="#2-hardware-aware-nas">2. Hardware-Aware NAS</a></li><li><a href="#3-transfer-nas">3. Transfer NAS</a></li></ul></li><li><a href="#key-takeaways">Key Takeaways</a><ul><li><a href="#connection-to-thematic-link-dynamic-programming-and-path-optimization">Connection to Thematic Link: Dynamic Programming and Path Optimization</a></li></ul></li></ul>
            </nav>
          </aside>
        
        <p><strong>Design neural architecture search systems that automatically discover optimal model architectures using dynamic programming and path optimization—the same principles from grid path counting scaled to exponential search spaces.</strong></p>

<h2 id="problem-statement">Problem Statement</h2>

<p>Design a <strong>Neural Architecture Search (NAS) System</strong> that:</p>

<ol>
  <li><strong>Automatically discovers</strong> neural network architectures that outperform hand-designed models</li>
  <li><strong>Searches efficiently</strong> through exponentially large search spaces</li>
  <li><strong>Optimizes multiple objectives</strong> (accuracy, latency, memory, FLOPS)</li>
  <li><strong>Scales to production</strong> (finds models deployable on mobile/edge devices)</li>
  <li><strong>Supports different domains</strong> (vision, NLP, speech, multi-modal)</li>
</ol>

<h3 id="functional-requirements">Functional Requirements</h3>

<ol>
  <li><strong>Search space definition:</strong>
    <ul>
      <li>Define architecture space (layers, operations, connections)</li>
      <li>Support modular search (cells, blocks, stages)</li>
      <li>Enable constrained search (max latency, max params)</li>
    </ul>
  </li>
  <li><strong>Search strategy:</strong>
    <ul>
      <li>Reinforcement learning (controller RNN)</li>
      <li>Evolutionary algorithms (mutation, crossover)</li>
      <li>Gradient-based (DARTS, differentiable NAS)</li>
      <li>Random search (baseline)</li>
      <li>Bayesian optimization</li>
    </ul>
  </li>
  <li><strong>Performance estimation:</strong>
    <ul>
      <li>Train architectures to evaluate quality</li>
      <li>Early stopping for bad candidates</li>
      <li>Weight sharing / one-shot models (ENAS, DARTS)</li>
      <li>Performance predictors (surrogate models)</li>
    </ul>
  </li>
  <li><strong>Multi-objective optimization:</strong>
    <ul>
      <li>Accuracy vs latency</li>
      <li>Accuracy vs model size</li>
      <li>Accuracy vs FLOPS</li>
      <li>Pareto frontier identification</li>
    </ul>
  </li>
  <li><strong>Distributed search:</strong>
    <ul>
      <li>Parallel architecture evaluation</li>
      <li>Distributed training of candidates</li>
      <li>Efficient resource allocation</li>
    </ul>
  </li>
  <li><strong>Transfer and reuse:</strong>
    <ul>
      <li>Transfer architectures across tasks</li>
      <li>Re-use components from previous searches</li>
      <li>Meta-learning for search initialization</li>
    </ul>
  </li>
</ol>

<h3 id="non-functional-requirements">Non-Functional Requirements</h3>

<ol>
  <li><strong>Efficiency:</strong> Find good architecture in &lt;100 GPU days (vs manual design months)</li>
  <li><strong>Quality:</strong> Discovered models competitive with hand-designed ones</li>
  <li><strong>Generalizability:</strong> Architectures transfer across datasets</li>
  <li><strong>Interpretability:</strong> Understand why architecture works</li>
  <li><strong>Reproducibility:</strong> Same search produces same results</li>
</ol>

<h2 id="understanding-the-requirements">Understanding the Requirements</h2>

<h3 id="why-nas">Why NAS?</h3>

<p><strong>Manual architecture design is:</strong></p>
<ul>
  <li>Time-consuming (months of expert effort)</li>
  <li>Limited by human intuition and expertise</li>
  <li>Hard to optimize for specific constraints (mobile latency, memory)</li>
  <li>Difficult to explore unconventional designs</li>
</ul>

<p><strong>NAS automates:</strong></p>
<ul>
  <li>Architecture discovery</li>
  <li>Multi-objective optimization</li>
  <li>Hardware-aware design</li>
  <li>Cross-domain transfer</li>
</ul>

<h3 id="scale-of-the-problem">Scale of the Problem</h3>

<p><strong>Search space size:</strong></p>
<ul>
  <li>A simple NAS space with 6 layers, 5 operations per layer: 5^6 = 15,625 architectures</li>
  <li>NASNet search space: ~10^18 possible architectures</li>
  <li>Without smart search, infeasible to evaluate all</li>
</ul>

<p><strong>Computational cost:</strong></p>
<ul>
  <li>Training one model: 1-10 GPU days</li>
  <li>Naive search (10K architectures): 10K-100K GPU days</li>
  <li>Smart search (NAS): 100-1000 GPU days</li>
  <li><strong>Goal:</strong> Reduce by 10-100x through efficient search</li>
</ul>

<h3 id="the-path-optimization-connection">The Path Optimization Connection</h3>

<p>Just like <strong>Unique Paths</strong> counts paths through a grid using DP:</p>

<table>
  <thead>
    <tr>
      <th>Unique Paths</th>
      <th>Neural Architecture Search</th>
      <th>Speech Arch Search</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>m×n grid</td>
      <td>Layer×operation space</td>
      <td>Encoder×decoder configs</td>
    </tr>
    <tr>
      <td>Count all paths</td>
      <td>Count/evaluate architectures</td>
      <td>Evaluate speech models</td>
    </tr>
    <tr>
      <td>DP optimization</td>
      <td>DP/RL search</td>
      <td>DP search</td>
    </tr>
    <tr>
      <td>O(m×n) vs O(2^(m+n))</td>
      <td>Smart search vs brute force</td>
      <td>Efficient vs exhaustive</td>
    </tr>
    <tr>
      <td>Path reconstruction</td>
      <td>Architecture construction</td>
      <td>Model construction</td>
    </tr>
  </tbody>
</table>

<p>Both use <strong>dynamic programming / smart search</strong> to navigate exponentially large spaces efficiently.</p>

<h2 id="high-level-architecture">High-Level Architecture</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>┌─────────────────────────────────────────────────────────────────┐
│                Neural Architecture Search System                 │
└─────────────────────────────────────────────────────────────────┘

                       Search Controller
            ┌──────────────────────────────────┐
            │  Strategy: RL / EA / DARTS       │
            │  - Propose architectures         │
            │  - Update based on performance   │
            └──────────────┬───────────────────┘
                           │
                           ↓
                  ┌────────────────┐
                  │  Search Space  │
                  │  - Layers      │
                  │  - Operations  │
                  │  - Connections │
                  └────────┬───────┘
                           │
        ┌──────────────────┼──────────────────┐
        │                  │                  │
┌───────▼────────┐ ┌──────▼──────┐ ┌────────▼────────┐
│  Architecture  │ │ Performance │ │  Multi-obj      │
│  Evaluator     │ │ Predictor   │ │  Optimizer      │
│                │ │             │ │                 │
│ - Train model  │ │ - Surrogate │ │ - Pareto        │
│ - Measure acc  │ │ - Skip bad  │ │ - Constraints   │
│ - Measure lat  │ │   candidates│ │ - Trade-offs    │
└───────┬────────┘ └──────┬──────┘ └────────┬────────┘
        │                  │                  │
        └──────────────────┼──────────────────┘
                           │
                  ┌────────▼────────┐
                  │  Distributed    │
                  │  Training       │
                  │  - Worker pool  │
                  │  - GPU cluster  │
                  └────────┬────────┘
                           │
                  ┌────────▼────────┐
                  │  Results Store  │
                  │  - Architectures│
                  │  - Metrics      │
                  │  - Models       │
                  └─────────────────┘
</code></pre></div></div>

<h3 id="key-components">Key Components</h3>

<ol>
  <li><strong>Search Controller:</strong> Proposes new architectures to try</li>
  <li><strong>Search Space:</strong> Defines valid architecture configurations</li>
  <li><strong>Architecture Evaluator:</strong> Trains and evaluates architectures</li>
  <li><strong>Performance Predictor:</strong> Estimates performance without full training</li>
  <li><strong>Multi-objective Optimizer:</strong> Balances accuracy, latency, size</li>
  <li><strong>Distributed Training:</strong> Parallel evaluation of architectures</li>
  <li><strong>Results Store:</strong> Tracks all evaluated architectures</li>
</ol>

<h2 id="component-deep-dives">Component Deep-Dives</h2>

<h3 id="1-search-space-definition">1. Search Space Definition</h3>

<p>Define what architectures are possible:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span>
<span class="kn">from</span> <span class="n">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>

<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">Operation</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">A single operation in the search space.</span><span class="sh">"""</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">params</span><span class="p">:</span> <span class="n">Dict</span>

<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">SearchSpace</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    NAS search space definition.
    
    Similar to Unique Paths grid:
    - Grid dimensions → num_layers, ops_per_layer
    - Paths through grid → architectures through search space
    </span><span class="sh">"""</span>
    <span class="n">num_layers</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">operations</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Operation</span><span class="p">]</span>
    <span class="n">connections</span><span class="p">:</span> <span class="nb">str</span>  <span class="c1"># "sequential", "skip", "dense"
</span>    
    <span class="k">def</span> <span class="nf">count_architectures</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Count total possible architectures.
        
        Like counting paths in Unique Paths:
        - If sequential: ops_per_layer ^ num_layers
        - If with skip connections: much larger
        </span><span class="sh">"""</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">connections</span> <span class="o">==</span> <span class="sh">"</span><span class="s">sequential</span><span class="sh">"</span><span class="p">:</span>
            <span class="k">return</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">operations</span><span class="p">)</span> <span class="o">**</span> <span class="n">self</span><span class="p">.</span><span class="n">num_layers</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># With skip connections, combinatorially larger
</span>            <span class="k">return</span> <span class="o">-</span><span class="mi">1</span>  <span class="c1"># Too many to count exactly
</span>

<span class="c1"># Example search space
</span><span class="n">MOBILENET_SEARCH_SPACE</span> <span class="o">=</span> <span class="nc">SearchSpace</span><span class="p">(</span>
    <span class="n">num_layers</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">operations</span><span class="o">=</span><span class="p">[</span>
        <span class="nc">Operation</span><span class="p">(</span><span class="sh">"</span><span class="s">conv3x3</span><span class="sh">"</span><span class="p">,</span> <span class="p">{</span><span class="sh">"</span><span class="s">kernel_size</span><span class="sh">"</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="sh">"</span><span class="s">stride</span><span class="sh">"</span><span class="p">:</span> <span class="mi">1</span><span class="p">}),</span>
        <span class="nc">Operation</span><span class="p">(</span><span class="sh">"</span><span class="s">conv5x5</span><span class="sh">"</span><span class="p">,</span> <span class="p">{</span><span class="sh">"</span><span class="s">kernel_size</span><span class="sh">"</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="sh">"</span><span class="s">stride</span><span class="sh">"</span><span class="p">:</span> <span class="mi">1</span><span class="p">}),</span>
        <span class="nc">Operation</span><span class="p">(</span><span class="sh">"</span><span class="s">depthwise_conv3x3</span><span class="sh">"</span><span class="p">,</span> <span class="p">{</span><span class="sh">"</span><span class="s">kernel_size</span><span class="sh">"</span><span class="p">:</span> <span class="mi">3</span><span class="p">}),</span>
        <span class="nc">Operation</span><span class="p">(</span><span class="sh">"</span><span class="s">depthwise_conv5x5</span><span class="sh">"</span><span class="p">,</span> <span class="p">{</span><span class="sh">"</span><span class="s">kernel_size</span><span class="sh">"</span><span class="p">:</span> <span class="mi">5</span><span class="p">}),</span>
        <span class="nc">Operation</span><span class="p">(</span><span class="sh">"</span><span class="s">maxpool3x3</span><span class="sh">"</span><span class="p">,</span> <span class="p">{</span><span class="sh">"</span><span class="s">kernel_size</span><span class="sh">"</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="sh">"</span><span class="s">stride</span><span class="sh">"</span><span class="p">:</span> <span class="mi">1</span><span class="p">}),</span>
        <span class="nc">Operation</span><span class="p">(</span><span class="sh">"</span><span class="s">skip</span><span class="sh">"</span><span class="p">,</span> <span class="p">{}),</span>
    <span class="p">],</span>
    <span class="n">connections</span><span class="o">=</span><span class="sh">"</span><span class="s">skip</span><span class="sh">"</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">encode_architecture</span><span class="p">(</span><span class="n">arch_ops</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">search_space</span><span class="p">:</span> <span class="n">SearchSpace</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Encode architecture as string.
    
    Args:
        arch_ops: List of operation names per layer
        
    Returns:
        String encoding (for hashing/caching)
    </span><span class="sh">"""</span>
    <span class="k">return</span> <span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">arch_ops</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">decode_architecture</span><span class="p">(</span><span class="n">arch_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="sh">"""</span><span class="s">Decode architecture string to operation list.</span><span class="sh">"""</span>
    <span class="k">return</span> <span class="n">arch_string</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="2-search-strategy---reinforcement-learning">2. Search Strategy - Reinforcement Learning</h3>

<p>Use RL controller to generate architectures:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">NASController</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    RNN controller that generates architectures.
    
    Similar to DP in Unique Paths:
    - Build architecture layer-by-layer
    - Use previous decisions to inform next
    - Optimize for high reward (accuracy)
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">num_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">num_operations</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
        <span class="n">self</span><span class="p">.</span><span class="n">num_operations</span> <span class="o">=</span> <span class="n">num_operations</span>
        
        <span class="c1"># RNN to track state across layers
</span>        <span class="n">self</span><span class="p">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LSTM</span><span class="p">(</span>
            <span class="n">input_size</span><span class="o">=</span><span class="n">num_operations</span><span class="p">,</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span>
        
        <span class="c1"># Output layer: predict operation for next layer
</span>        <span class="n">self</span><span class="p">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_operations</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Generate an architecture.
        
        Returns:
            architecture: List of operation indices
            log_probs: Log probabilities for REINFORCE
        </span><span class="sh">"""</span>
        <span class="n">architecture</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">log_probs</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="c1"># Initial input
</span>        <span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">num_operations</span><span class="p">)</span>
        <span class="n">hidden</span> <span class="o">=</span> <span class="bp">None</span>
        
        <span class="c1"># Generate layer-by-layer (like DP building solution)
</span>        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">num_layers</span><span class="p">):</span>
            <span class="c1"># RNN step
</span>            <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">rnn</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
            
            <span class="c1"># Predict operation for this layer
</span>            <span class="n">logits</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="nf">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
            <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            
            <span class="c1"># Sample operation
</span>            <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">distributions</span><span class="p">.</span><span class="nc">Categorical</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">dist</span><span class="p">.</span><span class="nf">sample</span><span class="p">()</span>
            
            <span class="n">architecture</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">action</span><span class="p">.</span><span class="nf">item</span><span class="p">())</span>
            <span class="n">log_probs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">dist</span><span class="p">.</span><span class="nf">log_prob</span><span class="p">(</span><span class="n">action</span><span class="p">))</span>
            
            <span class="c1"># Next input is one-hot of chosen operation
</span>            <span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">num_operations</span><span class="p">)</span>
            <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">action</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
        
        <span class="k">return</span> <span class="n">architecture</span><span class="p">,</span> <span class="n">log_probs</span>
    
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">log_probs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">reward</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Update controller using REINFORCE.
        
        Args:
            log_probs: Log probabilities of sampled actions
            reward: Accuracy of generated architecture
            optimizer: Controller optimizer
        </span><span class="sh">"""</span>
        <span class="c1"># REINFORCE loss: -sum(log_prob * reward)
</span>        <span class="n">policy_loss</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">log_prob</span> <span class="ow">in</span> <span class="n">log_probs</span><span class="p">:</span>
            <span class="n">policy_loss</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="o">-</span><span class="n">log_prob</span> <span class="o">*</span> <span class="n">reward</span><span class="p">)</span>
        
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span><span class="n">policy_loss</span><span class="p">).</span><span class="nf">sum</span><span class="p">()</span>
        
        <span class="c1"># Update controller
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>


<span class="c1"># Training loop
</span><span class="k">def</span> <span class="nf">train_nas_controller</span><span class="p">(</span>
    <span class="n">controller</span><span class="p">:</span> <span class="n">NASController</span><span class="p">,</span>
    <span class="n">search_space</span><span class="p">:</span> <span class="n">SearchSpace</span><span class="p">,</span>
    <span class="n">num_iterations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Train NAS controller to generate good architectures.
    </span><span class="sh">"""</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">controller</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">):</span>
        <span class="c1"># Generate architecture
</span>        <span class="n">arch</span><span class="p">,</span> <span class="n">log_probs</span> <span class="o">=</span> <span class="nf">controller</span><span class="p">()</span>
        
        <span class="c1"># Evaluate architecture (train small model)
</span>        <span class="n">reward</span> <span class="o">=</span> <span class="nf">evaluate_architecture</span><span class="p">(</span><span class="n">arch</span><span class="p">,</span> <span class="n">search_space</span><span class="p">)</span>
        
        <span class="c1"># Update controller
</span>        <span class="n">controller</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">log_probs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">iteration</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Iteration </span><span class="si">{</span><span class="n">iteration</span><span class="si">}</span><span class="s">: Best reward = </span><span class="si">{</span><span class="n">reward</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="3-search-strategy---differentiable-nas-darts">3. Search Strategy - Differentiable NAS (DARTS)</h3>

<p>DARTS makes architecture search differentiable:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">DARTSSearchSpace</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Differentiable architecture search.
    
    Key idea: Instead of discrete choice, use weighted combination.
    Learn weights (architecture parameters) via gradient descent.
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">operations</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">]):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
        <span class="n">self</span><span class="p">.</span><span class="n">operations</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">(</span><span class="n">operations</span><span class="p">)</span>
        
        <span class="c1"># Architecture parameters (learnable weights for each operation)
</span>        <span class="n">self</span><span class="p">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span>
            <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">operations</span><span class="p">))</span>
        <span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Forward pass with weighted operations.
        
        Each layer computes weighted sum of all operations.
        </span><span class="sh">"""</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">num_layers</span><span class="p">):</span>
            <span class="c1"># Get architecture weights for this layer
</span>            <span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">alpha</span><span class="p">[</span><span class="n">layer</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            
            <span class="c1"># Compute weighted sum of operations
</span>            <span class="n">layer_output</span> <span class="o">=</span> <span class="nf">sum</span><span class="p">(</span>
                <span class="n">w</span> <span class="o">*</span> <span class="nf">op</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">op</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">operations</span><span class="p">)</span>
            <span class="p">)</span>
            
            <span class="n">x</span> <span class="o">=</span> <span class="n">layer_output</span>
        
        <span class="k">return</span> <span class="n">x</span>
    
    <span class="k">def</span> <span class="nf">get_best_architecture</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">
        Extract discrete architecture from learned weights.
        
        Choose operation with highest weight per layer.
        </span><span class="sh">"""</span>
        <span class="n">architecture</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">num_layers</span><span class="p">):</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">alpha</span><span class="p">[</span><span class="n">layer</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">best_op</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">weights</span><span class="p">).</span><span class="nf">item</span><span class="p">()</span>
            <span class="n">architecture</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">best_op</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">architecture</span>


<span class="c1"># DARTS training (bi-level optimization)
</span><span class="k">def</span> <span class="nf">train_darts</span><span class="p">(</span><span class="n">search_space</span><span class="p">:</span> <span class="n">DARTSSearchSpace</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">val_data</span><span class="p">,</span> <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Train DARTS to find optimal architecture.
    
    Bi-level optimization:
    - Inner loop: optimize model weights
    - Outer loop: optimize architecture parameters
    </span><span class="sh">"""</span>
    <span class="c1"># Model weights optimizer
</span>    <span class="n">model_optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">SGD</span><span class="p">(</span>
        <span class="n">search_space</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span>
        <span class="n">lr</span><span class="o">=</span><span class="mf">0.025</span><span class="p">,</span>
        <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span>
    <span class="p">)</span>
    
    <span class="c1"># Architecture parameters optimizer
</span>    <span class="n">arch_optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span>
        <span class="p">[</span><span class="n">search_space</span><span class="p">.</span><span class="n">alpha</span><span class="p">],</span>
        <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span>
    <span class="p">)</span>
    
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="c1"># Update model weights on train data
</span>        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">train_data</span><span class="p">:</span>
            <span class="n">model_optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="nf">search_space</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">]),</span> <span class="n">batch</span><span class="p">[</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">])</span>
            <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
            <span class="n">model_optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
        
        <span class="c1"># Update architecture parameters on val data
</span>        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">val_data</span><span class="p">:</span>
            <span class="n">arch_optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="nf">search_space</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">]),</span> <span class="n">batch</span><span class="p">[</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">])</span>
            <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
            <span class="n">arch_optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
    
    <span class="c1"># Extract final architecture
</span>    <span class="n">best_arch</span> <span class="o">=</span> <span class="n">search_space</span><span class="p">.</span><span class="nf">get_best_architecture</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">best_arch</span>
</code></pre></div></div>

<h3 id="4-performance-estimation-strategies">4. Performance Estimation Strategies</h3>

<p><strong>Problem:</strong> Training every architecture fully is too expensive.</p>

<p><strong>Solutions:</strong></p>

<p><strong>a) Early stopping:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">evaluate_with_early_stopping</span><span class="p">(</span>
    <span class="n">arch</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">train_data</span><span class="p">,</span>
    <span class="n">val_data</span><span class="p">,</span>
    <span class="n">max_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
    <span class="n">patience</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span>
<span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Train architecture with early stopping.
    
    Stop if validation accuracy doesn</span><span class="sh">'</span><span class="s">t improve for `patience` epochs.
    </span><span class="sh">"""</span>
    <span class="n">model</span> <span class="o">=</span> <span class="nf">build_model_from_arch</span><span class="p">(</span><span class="n">arch</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">())</span>
    
    <span class="n">best_val_acc</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">epochs_without_improvement</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">max_epochs</span><span class="p">):</span>
        <span class="c1"># Train
</span>        <span class="nf">train_one_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
        
        <span class="c1"># Validate
</span>        <span class="n">val_acc</span> <span class="o">=</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_data</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">val_acc</span> <span class="o">&gt;</span> <span class="n">best_val_acc</span><span class="p">:</span>
            <span class="n">best_val_acc</span> <span class="o">=</span> <span class="n">val_acc</span>
            <span class="n">epochs_without_improvement</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">epochs_without_improvement</span> <span class="o">+=</span> <span class="mi">1</span>
        
        <span class="c1"># Early stop
</span>        <span class="k">if</span> <span class="n">epochs_without_improvement</span> <span class="o">&gt;=</span> <span class="n">patience</span><span class="p">:</span>
            <span class="k">break</span>
    
    <span class="k">return</span> <span class="n">best_val_acc</span>
</code></pre></div></div>

<p><strong>b) Weight sharing (ENAS):</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SuperNet</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Super-network containing all possible operations.
    
    Different architectures share weights.
    Train once, evaluate many architectures quickly.
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">search_space</span><span class="p">:</span> <span class="n">SearchSpace</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="c1"># Create all operations (shared across architectures)
</span>        <span class="n">self</span><span class="p">.</span><span class="n">ops</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">([</span>
            <span class="nf">create_operation</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">search_space</span><span class="p">.</span><span class="n">operations</span>
        <span class="p">])</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">architecture</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Forward pass for specific architecture.
        
        Args:
            x: Input
            architecture: List of operation indices per layer
        </span><span class="sh">"""</span>
        <span class="k">for</span> <span class="n">layer</span><span class="p">,</span> <span class="n">op_idx</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">architecture</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">ops</span><span class="p">[</span><span class="n">op_idx</span><span class="p">](</span><span class="n">x</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">x</span>
    
    <span class="k">def</span> <span class="nf">evaluate_architecture</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">arch</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">val_data</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Evaluate architecture without training.
        
        Uses shared weights - much faster than training from scratch.
        </span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
        <span class="n">total_correct</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">total_samples</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">val_data</span><span class="p">:</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">forward</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">],</span> <span class="n">arch</span><span class="p">)</span>
                <span class="n">preds</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">total_correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">preds</span> <span class="o">==</span> <span class="n">batch</span><span class="p">[</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">]).</span><span class="nf">sum</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span>
                <span class="n">total_samples</span> <span class="o">+=</span> <span class="nf">len</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">])</span>
        
        <span class="k">return</span> <span class="n">total_correct</span> <span class="o">/</span> <span class="n">total_samples</span>
</code></pre></div></div>

<p><strong>c) Performance prediction:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>

<span class="k">class</span> <span class="nc">PerformancePredictor</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Predict architecture performance without training.
    
    Train a surrogate model: architecture features → accuracy.
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="nc">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">trained</span> <span class="o">=</span> <span class="bp">False</span>
    
    <span class="k">def</span> <span class="nf">extract_features</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">arch</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Extract features from architecture.
        
        Features:
        - Number of each operation type
        - Depth (number of layers)
        - Estimated FLOPs
        - Estimated params
        </span><span class="sh">"""</span>
        <span class="n">features</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="c1"># Count each operation type
</span>        <span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
        <span class="n">op_counts</span> <span class="o">=</span> <span class="nc">Counter</span><span class="p">(</span><span class="n">arch</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">op_idx</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">max</span><span class="p">(</span><span class="n">arch</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">features</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">op_counts</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">op_idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
        
        <span class="c1"># Add depth
</span>        <span class="n">features</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">arch</span><span class="p">))</span>
        
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">architectures</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span> <span class="n">accuracies</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]):</span>
        <span class="sh">"""</span><span class="s">Train predictor on evaluated architectures.</span><span class="sh">"""</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">self</span><span class="p">.</span><span class="nf">extract_features</span><span class="p">(</span><span class="n">arch</span><span class="p">)</span> <span class="k">for</span> <span class="n">arch</span> <span class="ow">in</span> <span class="n">architectures</span><span class="p">])</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">accuracies</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">trained</span> <span class="o">=</span> <span class="bp">True</span>
    
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">arch</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Predict accuracy for architecture.</span><span class="sh">"""</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">self</span><span class="p">.</span><span class="n">trained</span><span class="p">:</span>
            <span class="k">raise</span> <span class="nc">ValueError</span><span class="p">(</span><span class="sh">"</span><span class="s">Predictor not trained</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="n">features</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">extract_features</span><span class="p">(</span><span class="n">arch</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">features</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div>

<h2 id="data-flow">Data Flow</h2>

<h3 id="nas-pipeline">NAS Pipeline</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1. Initialize search
   └─&gt; Define search space
   └─&gt; Initialize controller (RL/EA/DARTS)
   └─&gt; Set up distributed workers

2. Search loop (1000-10000 iterations)
   └─&gt; Controller proposes architecture
   └─&gt; (Optional) Performance predictor filters bad candidates
   └─&gt; Evaluate architecture:
       - Train on subset of data
       - Measure accuracy, latency, size
   └─&gt; Update controller based on reward
   └─&gt; Store results

3. Post-processing
   └─&gt; Identify Pareto frontier (best accuracy-latency trade-offs)
   └─&gt; Retrain top candidates on full data
   └─&gt; Final evaluation on test set

4. Deployment
   └─&gt; Export best architecture
   └─&gt; Optimize for target hardware
   └─&gt; Deploy to production
</code></pre></div></div>

<h2 id="scaling-strategies">Scaling Strategies</h2>

<h3 id="distributed-architecture-evaluation">Distributed Architecture Evaluation</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">ray</span>

<span class="nd">@ray.remote</span><span class="p">(</span><span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ArchitectureWorker</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">Worker that evaluates architectures on GPU.</span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">search_space</span><span class="p">:</span> <span class="n">SearchSpace</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">search_space</span> <span class="o">=</span> <span class="n">search_space</span>
    
    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">arch</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">train_subset</span><span class="p">,</span> <span class="n">val_subset</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Evaluate architecture.
        
        Returns:
            Dictionary with accuracy, latency, params, flops
        </span><span class="sh">"""</span>
        <span class="c1"># Build model
</span>        <span class="n">model</span> <span class="o">=</span> <span class="nf">build_model_from_arch</span><span class="p">(</span><span class="n">arch</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">search_space</span><span class="p">)</span>
        
        <span class="c1"># Train briefly
</span>        <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_subset</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        
        <span class="c1"># Evaluate
</span>        <span class="n">accuracy</span> <span class="o">=</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_subset</span><span class="p">)</span>
        <span class="n">latency</span> <span class="o">=</span> <span class="nf">measure_latency</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="n">params</span> <span class="o">=</span> <span class="nf">count_parameters</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="n">flops</span> <span class="o">=</span> <span class="nf">estimate_flops</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="p">{</span>
            <span class="sh">"</span><span class="s">accuracy</span><span class="sh">"</span><span class="p">:</span> <span class="n">accuracy</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">latency_ms</span><span class="sh">"</span><span class="p">:</span> <span class="n">latency</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">params</span><span class="sh">"</span><span class="p">:</span> <span class="n">params</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">flops</span><span class="sh">"</span><span class="p">:</span> <span class="n">flops</span>
        <span class="p">}</span>


<span class="k">class</span> <span class="nc">DistributedNAS</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">Distributed NAS system.</span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">search_space</span><span class="p">:</span> <span class="n">SearchSpace</span><span class="p">,</span> <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">search_space</span> <span class="o">=</span> <span class="n">search_space</span>
        
        <span class="c1"># Create worker pool
</span>        <span class="n">self</span><span class="p">.</span><span class="n">workers</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">ArchitectureWorker</span><span class="p">.</span><span class="nf">remote</span><span class="p">(</span><span class="n">search_space</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_workers</span><span class="p">)</span>
        <span class="p">]</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">num_workers</span> <span class="o">=</span> <span class="n">num_workers</span>
    
    <span class="k">def</span> <span class="nf">search</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">controller</span><span class="p">:</span> <span class="n">NASController</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Distributed NAS search.
        
        Args:
            controller: Architecture generator
            num_iterations: Number of architectures to try
        </span><span class="sh">"""</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="c1"># Process in batches (parallel evaluation)
</span>        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">num_workers</span>
        
        <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
            <span class="c1"># Generate batch of architectures
</span>            <span class="n">architectures</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">log_probs_batch</span> <span class="o">=</span> <span class="p">[]</span>
            
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
                <span class="n">arch</span><span class="p">,</span> <span class="n">log_probs</span> <span class="o">=</span> <span class="nf">controller</span><span class="p">()</span>
                <span class="n">architectures</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">arch</span><span class="p">)</span>
                <span class="n">log_probs_batch</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">log_probs</span><span class="p">)</span>
            
            <span class="c1"># Evaluate in parallel
</span>            <span class="n">futures</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">self</span><span class="p">.</span><span class="n">workers</span><span class="p">[</span><span class="n">i</span> <span class="o">%</span> <span class="n">self</span><span class="p">.</span><span class="n">num_workers</span><span class="p">].</span><span class="n">evaluate</span><span class="p">.</span><span class="nf">remote</span><span class="p">(</span>
                    <span class="n">architectures</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                    <span class="nf">get_train_subset</span><span class="p">(),</span>
                    <span class="nf">get_val_subset</span><span class="p">()</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
            <span class="p">]</span>
            
            <span class="n">eval_results</span> <span class="o">=</span> <span class="n">ray</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">futures</span><span class="p">)</span>
            
            <span class="c1"># Update controller with rewards
</span>            <span class="k">for</span> <span class="n">arch</span><span class="p">,</span> <span class="n">log_probs</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">architectures</span><span class="p">,</span> <span class="n">log_probs_batch</span><span class="p">,</span> <span class="n">eval_results</span><span class="p">):</span>
                <span class="n">reward</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">]</span>
                <span class="n">controller</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">log_probs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">controller_optimizer</span><span class="p">)</span>
                <span class="n">results</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">arch</span><span class="p">,</span> <span class="n">result</span><span class="p">))</span>
        
        <span class="k">return</span> <span class="n">results</span>
</code></pre></div></div>

<h2 id="monitoring--metrics">Monitoring &amp; Metrics</h2>

<h3 id="key-metrics">Key Metrics</h3>

<p><strong>Search Progress:</strong></p>
<ul>
  <li>Best accuracy found so far</li>
  <li>Number of architectures evaluated</li>
  <li>Search efficiency (good arch per GPU day)</li>
  <li>Diversity of architectures explored</li>
</ul>

<p><strong>Architecture Quality:</strong></p>
<ul>
  <li>Accuracy vs latency scatter plot</li>
  <li>Pareto frontier (optimal trade-offs)</li>
  <li>Architecture complexity distribution (params, FLOPs)</li>
</ul>

<p><strong>Resource Usage:</strong></p>
<ul>
  <li>GPU utilization</li>
  <li>Training time per architecture</li>
  <li>Total GPU hours consumed</li>
</ul>

<h3 id="visualization">Visualization</h3>

<ul>
  <li>Architecture topology graphs</li>
  <li>Performance over search iterations</li>
  <li>Pareto frontier (accuracy vs latency/size)</li>
  <li>Operation frequency (which ops are most common in good models)</li>
</ul>

<h2 id="failure-modes--mitigations">Failure Modes &amp; Mitigations</h2>

<table>
  <thead>
    <tr>
      <th>Failure Mode</th>
      <th>Impact</th>
      <th>Mitigation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Search collapse</strong></td>
      <td>Controller generates same arch repeatedly</td>
      <td>Entropy regularization, exploration bonus</td>
    </tr>
    <tr>
      <td><strong>Overfitting to search</strong></td>
      <td>Arch good on val, bad on test</td>
      <td>Proper val/test splits, cross-validation</td>
    </tr>
    <tr>
      <td><strong>Poor weight sharing</strong></td>
      <td>ENAS/supernet gives misleading results</td>
      <td>Standalone training for top candidates</td>
    </tr>
    <tr>
      <td><strong>Hardware mismatch</strong></td>
      <td>Arch fast on A100, slow on mobile</td>
      <td>Include target hardware in eval</td>
    </tr>
    <tr>
      <td><strong>Expensive search</strong></td>
      <td>1000s of GPU days</td>
      <td>Early stopping, predictor, weight sharing</td>
    </tr>
  </tbody>
</table>

<h2 id="real-world-case-study-googles-efficientnet">Real-World Case Study: Google’s EfficientNet</h2>

<h3 id="googles-nas-approach">Google’s NAS Approach</h3>

<p><strong>Goal:</strong> Find architectures that are both accurate and efficient (mobile-friendly).</p>

<p><strong>Method:</strong></p>
<ul>
  <li>Multi-objective NAS optimizing accuracy and FLOPS</li>
  <li>Compound scaling (depth, width, resolution)</li>
  <li>Progressive search (coarse → fine)</li>
</ul>

<p><strong>Architecture:</strong></p>
<ul>
  <li>Search space: MobileNetV2-based</li>
  <li>Search strategy: Reinforcement learning</li>
  <li>Evaluation: Early stopping + supernet</li>
  <li>Scale: 1000 architectures evaluated, 100 GPU days</li>
</ul>

<p><strong>Results:</strong></p>
<ul>
  <li><strong>EfficientNet-B0:</strong> 77.1% top-1 on ImageNet, 390M FLOPs</li>
  <li><strong>10x more efficient</strong> than previous SOTA (at same accuracy)</li>
  <li><strong>Transfer learning:</strong> Worked across domains (detection, segmentation)</li>
</ul>

<h3 id="key-lessons">Key Lessons</h3>

<ol>
  <li><strong>Multi-objective is crucial:</strong> Accuracy alone isn’t enough</li>
  <li><strong>Progressive search:</strong> Start coarse, refine best candidates</li>
  <li><strong>Transfer across tasks:</strong> Good architecture for ImageNet → good for other vision tasks</li>
  <li><strong>Hardware-aware:</strong> Include latency/FLOPS in objective</li>
  <li><strong>Compound scaling:</strong> After finding base arch, scale systematically</li>
</ol>

<h2 id="cost-analysis">Cost Analysis</h2>

<h3 id="nas-vs-manual-design">NAS vs Manual Design</h3>

<table>
  <thead>
    <tr>
      <th>Approach</th>
      <th>Time</th>
      <th>GPU Cost</th>
      <th>Quality</th>
      <th>Notes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Manual design</td>
      <td>3-6 months</td>
      <td>100 GPU days</td>
      <td>Good</td>
      <td>Expert-dependent</td>
    </tr>
    <tr>
      <td>Random search</td>
      <td>N/A</td>
      <td>1000 GPU days</td>
      <td>Poor</td>
      <td>Baseline</td>
    </tr>
    <tr>
      <td>RL-based NAS</td>
      <td>1 month</td>
      <td>200 GPU days</td>
      <td>Better</td>
      <td>EfficientNet-style</td>
    </tr>
    <tr>
      <td>DARTS</td>
      <td>1 week</td>
      <td>4 GPU days</td>
      <td>Good</td>
      <td>Fast but less stable</td>
    </tr>
    <tr>
      <td>Transfer + fine-tune</td>
      <td>1 week</td>
      <td>10 GPU days</td>
      <td>Good</td>
      <td>Use existing NAS results</td>
    </tr>
  </tbody>
</table>

<p><strong>ROI Calculation:</strong></p>
<ul>
  <li>Manual design: 3 months engineer time ($60K) + 100 GPU days ($30K) = $90K</li>
  <li>NAS: 1 month engineer time ($20K) + 200 GPU days ($60K) = $80K</li>
  <li><strong>Savings:</strong> $10K + better model</li>
</ul>

<h2 id="advanced-topics">Advanced Topics</h2>

<h3 id="1-once-for-all-networks">1. Once-For-All Networks</h3>

<p>Train a single super-network that contains many sub-networks:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">OnceForAllNetwork</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Train once, deploy many architectures.
    
    Enables instant architecture selection without retraining.
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">supernet</span> <span class="o">=</span> <span class="nf">create_supernet</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">trained</span> <span class="o">=</span> <span class="bp">False</span>
    
    <span class="k">def</span> <span class="nf">train_supernet</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">train_data</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Train supernet to support all sub-architectures.
        
        Progressive shrinking strategy:
        - Train largest network first
        - Progressively train smaller sub-networks
        </span><span class="sh">"""</span>
        <span class="c1"># Implementation details...
</span>        <span class="k">pass</span>
    
    <span class="k">def</span> <span class="nf">extract_subnet</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target_latency_ms</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Extract sub-network meeting latency constraint.
        
        No training needed!
        </span><span class="sh">"""</span>
        <span class="c1"># Search for subnet with latency &lt; target
</span>        <span class="c1"># Use efficiency predictor
</span>        <span class="k">pass</span>
</code></pre></div></div>

<h3 id="2-hardware-aware-nas">2. Hardware-Aware NAS</h3>

<p>Include hardware metrics in search:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">hardware_aware_nas</span><span class="p">(</span><span class="n">search_space</span><span class="p">,</span> <span class="n">target_hardware</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Search for architectures optimized for specific hardware.
    
    Args:
        target_hardware: </span><span class="sh">"</span><span class="s">mobile</span><span class="sh">"</span><span class="s">, </span><span class="sh">"</span><span class="s">edge_tpu</span><span class="sh">"</span><span class="s">, </span><span class="sh">"</span><span class="s">nvidia_t4</span><span class="sh">"</span><span class="s">, etc.
    </span><span class="sh">"""</span>
    <span class="c1"># Measure latency on target hardware
</span>    <span class="k">def</span> <span class="nf">measure_latency_on_target</span><span class="p">(</span><span class="n">arch</span><span class="p">):</span>
        <span class="n">model</span> <span class="o">=</span> <span class="nf">build_model</span><span class="p">(</span><span class="n">arch</span><span class="p">)</span>
        <span class="c1"># Deploy to target, measure
</span>        <span class="k">return</span> <span class="nf">measure_on_hardware</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">target_hardware</span><span class="p">)</span>
    
    <span class="c1"># Multi-objective: accuracy + latency on target
</span>    <span class="k">def</span> <span class="nf">fitness</span><span class="p">(</span><span class="n">arch</span><span class="p">):</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="nf">evaluate_accuracy</span><span class="p">(</span><span class="n">arch</span><span class="p">)</span>
        <span class="n">lat</span> <span class="o">=</span> <span class="nf">measure_latency_on_target</span><span class="p">(</span><span class="n">arch</span><span class="p">)</span>
        
        <span class="c1"># Combine (accuracy high, latency low)
</span>        <span class="k">return</span> <span class="n">acc</span> <span class="o">-</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">lat</span>  <span class="c1"># Weight latency penalty
</span></code></pre></div></div>

<h3 id="3-transfer-nas">3. Transfer NAS</h3>

<p>Transfer architectures across tasks:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">transfer_nas</span><span class="p">(</span><span class="n">source_task</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">target_task</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Transfer NAS results from source to target task.
    
    Example: ImageNet → COCO detection
    </span><span class="sh">"""</span>
    <span class="c1"># Load architectures found on source task
</span>    <span class="n">source_archs</span> <span class="o">=</span> <span class="nf">load_nas_results</span><span class="p">(</span><span class="n">source_task</span><span class="p">)</span>
    
    <span class="c1"># Top-K from source
</span>    <span class="n">top_archs</span> <span class="o">=</span> <span class="nf">sorted</span><span class="p">(</span><span class="n">source_archs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]</span>
    
    <span class="c1"># Fine-tune on target task
</span>    <span class="n">target_results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">arch</span> <span class="ow">in</span> <span class="n">top_archs</span><span class="p">:</span>
        <span class="c1"># Build model with source architecture
</span>        <span class="n">model</span> <span class="o">=</span> <span class="nf">build_model_from_arch</span><span class="p">(</span><span class="n">arch</span><span class="p">[</span><span class="sh">'</span><span class="s">architecture</span><span class="sh">'</span><span class="p">])</span>
        
        <span class="c1"># Fine-tune on target task
</span>        <span class="nf">fine_tune</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">target_task_data</span><span class="p">)</span>
        
        <span class="c1"># Evaluate
</span>        <span class="n">target_acc</span> <span class="o">=</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">target_task_test_data</span><span class="p">)</span>
        <span class="n">target_results</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">arch</span><span class="p">,</span> <span class="n">target_acc</span><span class="p">))</span>
    
    <span class="c1"># Best transferred architecture
</span>    <span class="n">best</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">target_results</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">best</span>
</code></pre></div></div>

<h2 id="key-takeaways">Key Takeaways</h2>

<p>✅ <strong>NAS automates architecture design</strong> - discovers models competitive with or better than hand-designed ones</p>

<p>✅ <strong>Search space is exponential</strong> - like paths in a grid, exponentially many architectures</p>

<p>✅ <strong>DP and smart search</strong> reduce complexity - from infeasible to practical</p>

<p>✅ <strong>Multiple search strategies</strong> - RL (flexible), DARTS (fast), evolutionary (robust)</p>

<p>✅ <strong>Weight sharing critical</strong> - enables evaluating 1000s of architectures efficiently</p>

<p>✅ <strong>Multi-objective optimization</strong> - accuracy vs latency vs size</p>

<p>✅ <strong>Hardware-aware NAS</strong> - optimize for target deployment platform</p>

<p>✅ <strong>Transfer learning works</strong> - architectures transfer across tasks</p>

<p>✅ <strong>Same DP principles</strong> as Unique Paths - break into subproblems, build optimal solution</p>

<p>✅ <strong>Production deployment</strong> - once-for-all networks, progressive search, cost-aware</p>

<h3 id="connection-to-thematic-link-dynamic-programming-and-path-optimization">Connection to Thematic Link: Dynamic Programming and Path Optimization</h3>

<p>All three Day 21 topics use <strong>DP for path optimization</strong>:</p>

<p><strong>DSA (Unique Paths):</strong></p>
<ul>
  <li>Count paths in m×n grid using DP</li>
  <li>Recurrence: paths(i,j) = paths(i-1,j) + paths(i,j-1)</li>
  <li>Reduces O(2^(m+n)) to O(m×n)</li>
</ul>

<p><strong>ML System Design (Neural Architecture Search):</strong></p>
<ul>
  <li>Search through exponential architecture space</li>
  <li>Use DP/RL/gradient-based methods to find optimal</li>
  <li>Build architectures from optimal sub-architectures</li>
</ul>

<p><strong>Speech Tech (Speech Architecture Search):</strong></p>
<ul>
  <li>Search encoder/decoder configurations</li>
  <li>Use DP to evaluate speech model paths</li>
  <li>Find optimal ASR/TTS architectures</li>
</ul>

<p>The <strong>unifying principle</strong>: navigate exponentially large search spaces by breaking into subproblems, solving optimally, and building up the final solution—whether counting grid paths, finding neural architectures, or designing speech models.</p>

<hr />

<p><strong>Originally published at:</strong> <a href="https://www.arunbaby.com/ml-system-design/0021-neural-architecture-search/">arunbaby.com/ml-system-design/0021-neural-architecture-search</a></p>

<p><em>If you found this helpful, consider sharing it with others who might benefit.</em></p>


        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#automl" class="page__taxonomy-item p-category" rel="tag">automl</a><span class="sep">, </span>
    
      <a href="/tags/#model-design" class="page__taxonomy-item p-category" rel="tag">model-design</a><span class="sep">, </span>
    
      <a href="/tags/#nas" class="page__taxonomy-item p-category" rel="tag">nas</a><span class="sep">, </span>
    
      <a href="/tags/#neural-architecture-search" class="page__taxonomy-item p-category" rel="tag">neural-architecture-search</a><span class="sep">, </span>
    
      <a href="/tags/#optimization" class="page__taxonomy-item p-category" rel="tag">optimization</a><span class="sep">, </span>
    
      <a href="/tags/#reinforcement-learning" class="page__taxonomy-item p-category" rel="tag">reinforcement-learning</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#ml-system-design" class="page__taxonomy-item p-category" rel="tag">ml-system-design</a>
    
    </span>
  </p>


        
      </footer>

      <div class="page__related page__related--full">
  <h2 class="page__related-title">Related across topics</h2>
  <style>
    /* Make section span full content width and use 2 equal columns */
    .page__related--full { float: inline-start; width: 100%; padding: 0; }
    .cross-related-grid { display: grid; grid-template-columns: repeat(2, minmax(0, 1fr)); gap: 2rem; }
    @media (max-width: 768px) { .cross-related-grid { grid-template-columns: 1fr; } }
    /* Ensure archive cards stretch nicely in the grid */
    .cross-related-grid .list__item, .cross-related-grid .grid__item { width: auto; float: none; margin: 0; }
  </style>
  <div class="cross-related-grid">
    



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/dsa/0021-unique-paths/" rel="permalink">Unique Paths
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          23 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Master grid path counting with dynamic programming—the same optimization technique used in neural architecture search and speech model design.
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/speech-tech/0021-speech-architecture-search/" rel="permalink">Speech Architecture Search
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          11 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Design neural architecture search systems for speech models that automatically discover optimal ASR/TTS architectures—using dynamic programming and path opti...</p>
  </article>
</div>

  </div>
</div>

      <section class="page__share">
  <h4 class="page__share-title">Share on</h4>

  <a href="https://twitter.com/intent/tweet?via=arunbaby0&text=Neural+Architecture+Search%20https%3A%2F%2Fwww.arunbaby.com%2Fml-system-design%2F0021-neural-architecture-search%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.arunbaby.com%2Fml-system-design%2F0021-neural-architecture-search%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.arunbaby.com/ml-system-design/0021-neural-architecture-search/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/ml-system-design/0020-online-learning-systems/" class="pagination--pager" title="Online Learning Systems">Previous</a>
    
    
      <a href="/ml-system-design/0022-cost-optimization-for-ml/" class="pagination--pager" title="Cost Optimization for ML">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 1990 - 2143 <a href="https://www.arunbaby.com">Arun Baby</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JRJPEC9SS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0JRJPEC9SS', { 'anonymize_ip': false});
</script>








  </body>
</html>
