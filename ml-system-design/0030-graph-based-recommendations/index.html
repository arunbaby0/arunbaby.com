<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Graph-based Recommendation Systems - Arun Baby</title>
<meta name="description" content="“Leveraging the connection structure to predict what users will love.”">


  <meta name="author" content="Arun Baby">
  
  <meta property="article:author" content="Arun Baby">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Arun Baby">
<meta property="og:title" content="Graph-based Recommendation Systems">
<meta property="og:url" content="https://www.arunbaby.com/ml-system-design/0030-graph-based-recommendations/">


  <meta property="og:description" content="“Leveraging the connection structure to predict what users will love.”">



  <meta property="og:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">



  <meta name="twitter:site" content="@arunbaby0">
  <meta name="twitter:title" content="Graph-based Recommendation Systems">
  <meta name="twitter:description" content="“Leveraging the connection structure to predict what users will love.”">
  <meta name="twitter:url" content="https://www.arunbaby.com/ml-system-design/0030-graph-based-recommendations/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">
    
  

  



  <meta property="article:published_time" content="2025-12-29T16:05:30+05:30">





  

  


<link rel="canonical" href="https://www.arunbaby.com/ml-system-design/0030-graph-based-recommendations/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Baby Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          <span class="site-subtitle">Arun Baby</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/dsa/"
                
                
              >DSA</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ml-system-design/"
                
                
              >ML Systems</a>
            </li><li class="masthead__menu-item">
              <a
                href="/speech-tech/"
                
                
              >Speech Tech</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ai-agents/"
                
                
              >AI Agents</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li><li class="masthead__menu-item">
              <a
                href="/statuses/"
                
                
              >Statuses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/contact/"
                
                
              >Contact</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main" class="no-author-sidebar">
  
  <div class="sidebar sticky">
  
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Graph-based Recommendation Systems">
    <meta itemprop="description" content="“Leveraging the connection structure to predict what users will love.”">
    <meta itemprop="datePublished" content="2025-12-29T16:05:30+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://www.arunbaby.com/ml-system-design/0030-graph-based-recommendations/" itemprop="url">Graph-based Recommendation Systems
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          13 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#1-why-graph-based-recommendations">1. Why Graph-based Recommendations?</a></li><li><a href="#2-graph-representation">2. Graph Representation</a><ul><li><a href="#homogeneous-graph">Homogeneous Graph</a></li><li><a href="#heterogeneous-graph">Heterogeneous Graph</a></li><li><a href="#bipartite-graph">Bipartite Graph</a></li></ul></li><li><a href="#3-traditional-graph-based-approaches">3. Traditional Graph-Based Approaches</a><ul><li><a href="#approach-1-collaborative-filtering-on-graphs">Approach 1: Collaborative Filtering on Graphs</a></li><li><a href="#approach-2-node2vec">Approach 2: Node2Vec</a></li></ul></li><li><a href="#4-graph-neural-networks-gnns">4. Graph Neural Networks (GNNs)</a><ul><li><a href="#message-passing-framework">Message Passing Framework</a></li><li><a href="#graph-convolutional-network-gcn">Graph Convolutional Network (GCN)</a></li><li><a href="#graphsage-sampling-and-aggregation">GraphSAGE (Sampling and Aggregation)</a></li></ul></li><li><a href="#5-pinterests-pinsage">5. Pinterest’s PinSage</a></li><li><a href="#6-linkedins-skills-graph">6. LinkedIn’s Skills Graph</a></li><li><a href="#deep-dive-training-at-scale-billion-edge-graphs">Deep Dive: Training at Scale (Billion-Edge Graphs)</a><ul><li><a href="#solution-1-mini-batch-training-with-neighbor-sampling">Solution 1: Mini-Batch Training with Neighbor Sampling</a></li><li><a href="#solution-2-distributed-training">Solution 2: Distributed Training</a></li></ul></li><li><a href="#deep-dive-cold-start-with-side-information">Deep Dive: Cold Start with Side Information</a></li><li><a href="#deep-dive-temporal-graphs-dynamic-recommendations">Deep Dive: Temporal Graphs (Dynamic Recommendations)</a></li><li><a href="#deep-dive-knowledge-graph-embeddings-transe-distmult">Deep Dive: Knowledge Graph Embeddings (TransE, DistMult)</a></li><li><a href="#deep-dive-graph-augmentation-for-robustness">Deep Dive: Graph Augmentation for Robustness</a></li><li><a href="#deep-dive-explainability-with-gnn-gnnexplainer">Deep Dive: Explainability with GNN (GNNExplainer)</a></li><li><a href="#deep-dive-negative-sampling-strategies">Deep Dive: Negative Sampling Strategies</a></li><li><a href="#deep-dive-fairness-in-graph-based-recommendations">Deep Dive: Fairness in Graph-based Recommendations</a></li><li><a href="#deep-dive-graph-based-bandits-exploration-vs-exploitation">Deep Dive: Graph-based Bandits (Exploration vs. Exploitation)</a></li><li><a href="#implementation-full-gnn-recommender">Implementation: Full GNN Recommender</a></li><li><a href="#top-interview-questions">Top Interview Questions</a></li><li><a href="#key-takeaways">Key Takeaways</a></li><li><a href="#summary">Summary</a></li></ul>
            </nav>
          </aside>
        
        <p><strong>“Leveraging the connection structure to predict what users will love.”</strong></p>

<h2 id="1-why-graph-based-recommendations">1. Why Graph-based Recommendations?</h2>

<p>Traditional recommender systems use <strong>user-item matrices</strong>. Graph-based systems model the entire <strong>interaction network</strong>.</p>

<p><strong>Example: Social Media</strong>
``
Users: Alice, Bob, Charlie
Items: Post1, Post2, Post3</p>

<p>Graph:
Alice –likes–&gt; Post1 &lt;–likes– Bob
 | |
 +–follows–&gt; Charlie
 |
 created
 |
 Post2
``</p>

<p><strong>Advantages of Graphs:</strong></p>
<ol>
  <li><strong>Richer Context:</strong> Capture multi-hop relationships (friend-of-friend recommendations).</li>
  <li><strong>Heterogeneous:</strong> Mix users, items, tags, locations in one graph.</li>
  <li><strong>Explainability:</strong> “We recommend this post because your friend Bob liked it.”</li>
  <li><strong>Cold Start:</strong> New users can benefit from their social connections.</li>
</ol>

<h2 id="2-graph-representation">2. Graph Representation</h2>

<h3 id="homogeneous-graph">Homogeneous Graph</h3>
<p>All nodes and edges are the same type.
<strong>Example:</strong> Friendship network (all nodes are users, all edges are “friends”).</p>

<h3 id="heterogeneous-graph">Heterogeneous Graph</h3>
<p>Multiple node/edge types.
<strong>Example:</strong> E-commerce</p>
<ul>
  <li>Nodes: Users, Products, Brands, Categories</li>
  <li>Edges: User –bought–&gt; Product, Product –belongs_to–&gt; Category</li>
</ul>

<h3 id="bipartite-graph">Bipartite Graph</h3>
<p>Two types of nodes with edges only between different types.
<strong>Example:</strong> User-Item interactions.</p>

<p><strong>Adjacency Matrix:</strong>
\[
A_{ij} = 
\begin{cases}
1 &amp; \text{if user } i \text{ interacted with item } j <br />
0 &amp; \text{otherwise}
\end{cases}
\]</p>

<h2 id="3-traditional-graph-based-approaches">3. Traditional Graph-Based Approaches</h2>

<h3 id="approach-1-collaborative-filtering-on-graphs">Approach 1: Collaborative Filtering on Graphs</h3>

<p><strong>Idea:</strong> If users A and B both liked items X and Y, recommend to A what B liked but A hasn’t seen.</p>

<p><strong>Graph Random Walk:</strong></p>
<ol>
  <li>Start at user node.</li>
  <li>Walk to liked items.</li>
  <li>Walk to other users who liked those items.</li>
  <li>Walk to items those users liked.</li>
  <li>Recommend items with highest visit frequency.</li>
</ol>

<p>``python
def personalized_pagerank(graph, user_node, damping=0.85, iterations=100):
 scores = {node: 0 for node in graph.nodes}
 scores[user_node] = 1.0</p>

<p>for _ in range(iterations):
 new_scores = {node: 0 for node in graph.nodes}
 for node in graph.nodes:
 for neighbor in graph.neighbors(node):
 new_scores[neighbor] += damping * scores[node] / len(list(graph.neighbors(node)))
 new_scores[node] += (1 - damping) if node == user_node else 0
 scores = new_scores</p>

<p>return scores</p>

<h1 id="recommend-top-k-items-with-highest-scores">Recommend top-K items with highest scores</h1>
<p>``</p>

<p><strong>Time Complexity:</strong> \(O(I \cdot E)\) where I is iterations and E is number of edges.</p>

<h3 id="approach-2-node2vec">Approach 2: Node2Vec</h3>

<p><strong>Idea:</strong> Learn node embeddings by treating random walks as “sentences” and applying Skip-Gram (Word2Vec).</p>

<p><strong>Algorithm:</strong></p>
<ol>
  <li>Generate random walks starting from each node.</li>
  <li>Treat walks as sentences: <code class="language-plaintext highlighter-rouge">[UserA, Item1, UserB, Item3, ...]</code>.</li>
  <li>Train Skip-Gram to predict context nodes given target node.</li>
</ol>

<p>``python
from node2vec import Node2Vec</p>

<h1 id="generate-walks">Generate walks</h1>
<p>walks = Node2Vec(graph, dimensions=128, walk_length=80, num_walks=10, workers=4)</p>

<h1 id="train-skip-gram">Train Skip-Gram</h1>
<p>model = walks.fit(window=10, min_count=1, batch_words=4)</p>

<h1 id="get-embeddings">Get embeddings</h1>
<p>user_embedding = model.wv[‘UserA’]
item_embedding = model.wv[‘Item1’]</p>

<h1 id="recommend-by-cosine-similarity">Recommend by cosine similarity</h1>
<p>recommended_items = model.wv.most_similar(‘UserA’, topn=10)
``</p>

<p><strong>Pros:</strong></p>
<ul>
  <li>Simple and effective.</li>
  <li>Works on any graph.</li>
</ul>

<p><strong>Cons:</strong></p>
<ul>
  <li>Doesn’t use node features (only structure).</li>
  <li>Expensive for large graphs (millions of walks).</li>
</ul>

<h2 id="4-graph-neural-networks-gnns">4. Graph Neural Networks (GNNs)</h2>

<p><strong>Core Idea:</strong> Aggregate information from neighbors to update node representations.</p>

<h3 id="message-passing-framework">Message Passing Framework</h3>

<p><strong>General Form:</strong>
\[
h_v^{(k+1)} = \text{UPDATE}\left(h_v^{(k)}, \text{AGGREGATE}({h_u^{(k)} : u \in \mathcal{N}(v)})\right)
\]</p>

<ul>
  <li>\(h_v^{(k)}\): Representation of node \(v\) at layer \(k\).</li>
  <li>\(\mathcal{N}(v)\): Neighbors of \(v\).</li>
</ul>

<p><strong>After K layers:</strong> Node \(v\) has aggregated information from \(K\)-hop neighbors.</p>

<h3 id="graph-convolutional-network-gcn">Graph Convolutional Network (GCN)</h3>

<p><strong>Update Rule:</strong>
\[
H^{(k+1)} = \sigma\left(\tilde{D}^{-1/2} \tilde{A} \tilde{D}^{-1/2} H^{(k)} W^{(k)}\right)
\]</p>

<ul>
  <li>\(\tilde{A} = A + I\) (adjacency matrix + self-loops).</li>
  <li>\(\tilde{D}\): Degree matrix of \(\tilde{A}\).</li>
  <li>\(W^{(k)}\): Learnable weight matrix.</li>
</ul>

<p><strong>Implementation:</strong>
``python
import torch
import torch.nn as nn
from torch_geometric.nn import GCNConv</p>

<p>class GCNRecommender(nn.Module):
 def <strong>init</strong>(self, num_users, num_items, embedding_dim=128):
 super().<strong>init</strong>()
 self.user_embedding = nn.Embedding(num_users, embedding_dim)
 self.item_embedding = nn.Embedding(num_items, embedding_dim)</p>

<p>self.conv1 = GCNConv(embedding_dim, 256)
 self.conv2 = GCNConv(256, 128)</p>

<p>def forward(self, edge_index):
 # edge_index: [2, num_edges] (source and target nodes)</p>

<p># Initialize embeddings
 x = torch.cat([self.user_embedding.weight, self.item_embedding.weight], dim=0)</p>

<p># Message passing
 x = self.conv1(x, edge_index)
 x = F.relu(x)
 x = self.conv2(x, edge_index)</p>

<p>return x # [num_nodes, 128]</p>

<h1 id="predict-interaction-score">Predict interaction score</h1>
<p>user_emb = embeddings[user_id]
item_emb = embeddings[item_id]
score = torch.dot(user_emb, item_emb)
``</p>

<h3 id="graphsage-sampling-and-aggregation">GraphSAGE (Sampling and Aggregation)</h3>

<p><strong>Problem:</strong> GCN needs the full adjacency matrix (doesn’t scale to billions of edges).</p>

<p><strong>Solution:</strong> Sample a fixed number of neighbors.</p>

<p><strong>Algorithm:</strong>
``python
class GraphSAGE(nn.Module):
 def <strong>init</strong>(self, in_dim, hidden_dim):
 super().<strong>init</strong>()
 self.linear = nn.Linear(in_dim * 2, hidden_dim) # Concat self + aggregated</p>

<p>def forward(self, x, edge_index, num_samples=10):
 # x: [num_nodes, in_dim]
 # edge_index: [2, num_edges]</p>

<p>aggregated = []
 for node in range(x.size(0)):
 # Sample neighbors
 neighbors = edge_index[1][edge_index[0] == node]
 if len(neighbors) &gt; num_samples:
 neighbors = neighbors[torch.randperm(len(neighbors))[:num_samples]]</p>

<p># Aggregate (mean pooling)
 neighbor_embs = x[neighbors]
 agg = neighbor_embs.mean(dim=0)
 aggregated.append(agg)</p>

<p>aggregated = torch.stack(aggregated)</p>

<p># Concat self + aggregated
 combined = torch.cat([x, aggregated], dim=1)
 output = F.relu(self.linear(combined))</p>

<p>return output
``</p>

<p><strong>Benefit:</strong> \(O(K \cdot S \cdot D)\) where K = layers, S = samples per node, D = embedding dim (independent of graph size!).</p>

<h2 id="5-pinterests-pinsage">5. Pinterest’s PinSage</h2>

<p><strong>PinSage</strong> is the largest-scale GNN in production (3B nodes, 18B edges).</p>

<p><strong>Key Innovations:</strong></p>
<ol>
  <li><strong>Importance-based Sampling:</strong> Sample neighbors with highest visit frequency (from random walks).</li>
  <li><strong>Hard Negative Mining:</strong> For each positive interaction, sample negative items similar to the positive (harder to distinguish).</li>
  <li><strong>Multi-GPU Training:</strong> Distribute graph across GPUs.</li>
  <li><strong>MapReduce Inference:</strong> Precompute embeddings offline using Spark.</li>
</ol>

<p><strong>Architecture:</strong>
<code class="language-plaintext highlighter-rouge">
Input: Pin features (image, text) + Graph structure
 |
 v
3 layers of GraphSAGE (neighbor sampling)
 |
 v
Pin Embedding (256-dim)
 |
 v
Cosine Similarity → Recommendations
</code></p>

<p><strong>Results:</strong></p>
<ul>
  <li><strong>Offline:</strong> +40% recall@100 over baseline.</li>
  <li><strong>Online:</strong> +20% engagement (repins, clicks).</li>
</ul>

<h2 id="6-linkedins-skills-graph">6. LinkedIn’s Skills Graph</h2>

<p>LinkedIn models <strong>Users, Jobs, Skills, Companies</strong> as a heterogeneous graph.</p>

<p><strong>Example Query:</strong>
“Recommend jobs for a user with skills in Python, ML.”</p>

<p><strong>Solution: Meta-Path-Based Random Walk</strong></p>
<ul>
  <li>Meta-path: User –has_skill–&gt; Skill &lt;–requires– Job</li>
  <li>Walk: <code class="language-plaintext highlighter-rouge">[UserA, Python, Job1, ML, UserB, Scala, Job2]</code></li>
  <li>Recommend jobs that appear frequently in walks starting from UserA.</li>
</ul>

<p><strong>Heterogeneous GNN:</strong>
``python
class HeteroGNN(nn.Module):
 def <strong>init</strong>(self):
 self.user_conv = GCNConv(128, 256)
 self.job_conv = GCNConv(128, 256)
 self.skill_conv = GCNConv(128, 256)</p>

<p>def forward(self, user_features, job_features, skill_features, edges):
 # edges: {(‘user’, ‘has_skill’, ‘skill’): edge_index, …}</p>

<p>user_emb = self.user_conv(user_features, edges[(‘user’, ‘has_skill’, ‘skill’)])
 job_emb = self.job_conv(job_features, edges[(‘job’, ‘requires’, ‘skill’)])
 skill_emb = self.skill_conv(skill_features, edges[(‘user’, ‘has_skill’, ‘skill’)])</p>

<p>return user_emb, job_emb, skill_emb
``</p>

<h2 id="deep-dive-training-at-scale-billion-edge-graphs">Deep Dive: Training at Scale (Billion-Edge Graphs)</h2>

<p><strong>Challenge:</strong> Graph doesn’t fit in GPU memory.</p>

<h3 id="solution-1-mini-batch-training-with-neighbor-sampling">Solution 1: Mini-Batch Training with Neighbor Sampling</h3>

<p><strong>Cluster-GCN:</strong></p>
<ol>
  <li>Partition the graph into clusters (Louvain algorithm).</li>
  <li>Sample a batch of clusters.</li>
  <li>Train GNN on subgraph induced by those clusters.</li>
</ol>

<p><strong>Benefit:</strong> Each mini-batch is a small, densely connected subgraph.</p>

<h3 id="solution-2-distributed-training">Solution 2: Distributed Training</h3>

<p><strong>DistDGL (Distributed Deep Graph Library):</strong></p>
<ul>
  <li><strong>Graph Store:</strong> Distributed across multiple machines (sharded by node ID).</li>
  <li><strong>Sampling:</strong> Each worker samples locally and fetches remote neighbors via RPC.</li>
  <li><strong>Aggregation:</strong> Use MPI All-Reduce to aggregate gradients.</li>
</ul>

<p><strong>Scalability:</strong> Trains on graphs with 100B+ edges (Alibaba’s product graph).</p>

<h2 id="deep-dive-cold-start-with-side-information">Deep Dive: Cold Start with Side Information</h2>

<p><strong>Problem:</strong> New user has no interactions.</p>

<p><strong>Solution: Use Content Features</strong>
``python
class HybridGNN(nn.Module):
 def <strong>init</strong>(self):
 self.text_encoder = BERTModel() # Encode user bio, item description
 self.image_encoder = ResNet() # Encode user profile pic, item image
 self.gnn = GraphSAGE()</p>

<p>def forward(self, text, image, edge_index):
 text_emb = self.text_encoder(text)
 image_emb = self.image_encoder(image)</p>

<p># Initial embedding = concat(text, image)
 x_init = torch.cat([text_emb, image_emb], dim=1)</p>

<p># Message passing
 x_final = self.gnn(x_init, edge_index)</p>

<p>return x_final
``</p>

<p><strong>For new users:</strong> Use \(x_{\text{init}}\) directly (no graph info yet).</p>

<h2 id="deep-dive-temporal-graphs-dynamic-recommendations">Deep Dive: Temporal Graphs (Dynamic Recommendations)</h2>

<p><strong>Problem:</strong> User preferences change over time.</p>

<p><strong>Solution: Temporal GNN</strong>
``python
class TemporalGNN(nn.Module):
 def <strong>init</strong>(self):
 self.gru = nn.GRU(input_size=128, hidden_size=256)
 self.gnn = GraphSAGE()</p>

<p>def forward(self, snapshots):
 # snapshots: List of (features, edge_index) at different timestamps</p>

<p>h_t = None
 for features, edge_index in snapshots:
 x = self.gnn(features, edge_index)
 x, h_t = self.gru(x.unsqueeze(0), h_t)</p>

<p>return x # Final embedding incorporates temporal dynamics
``</p>

<p><strong>Use Case:</strong> Reddit recommending trending posts (graph changes every minute).</p>

<h2 id="deep-dive-knowledge-graph-embeddings-transe-distmult">Deep Dive: Knowledge Graph Embeddings (TransE, DistMult)</h2>

<p><strong>Knowledge Graph:</strong> Entities and Relations.
<strong>Example:</strong>
<code class="language-plaintext highlighter-rouge">
(Python, is_a, Programming Language)
(TensorFlow, used_for, Deep Learning)
(Alice, knows, Python)
</code></p>

<p><strong>TransE:</strong>
Embed entities and relations in the same space.
\[
h + r \approx t
\]
where \(h\) = head entity, \(r\) = relation, \(t\) = tail entity.</p>

<p><strong>Loss:</strong>
\[
\mathcal{L} = \sum_{(h, r, t) \in \mathcal{T}} \max(0, \gamma + d(h + r, t) - d(h’ + r, t’))
\]
where \((h’, r, t’)\) is a negative sample.</p>

<p><strong>Application:</strong> Amazon’s product knowledge graph for recommendations.</p>

<h2 id="deep-dive-graph-augmentation-for-robustness">Deep Dive: Graph Augmentation for Robustness</h2>

<p><strong>Problem:</strong> Sparse graphs lead to poor embeddings.</p>

<p><strong>Solutions:</strong></p>
<ol>
  <li><strong>Edge Dropout:</strong> Randomly remove edges during training (forces model to not rely on single edges).</li>
  <li><strong>Node Mixup:</strong> Interpolate between node features: \(x_{\text{mix}} = \lambda x_i + (1 - \lambda) x_j\).</li>
  <li><strong>Virtual Nodes:</strong> Add a global node connected to all nodes (helps with long-range dependencies).</li>
</ol>

<p><code class="language-plaintext highlighter-rouge">python
def graph_augmentation(edge_index, drop_rate=0.1):
 num_edges = edge_index.size(1)
 mask = torch.rand(num_edges) &gt; drop_rate
 return edge_index[:, mask]
</code></p>

<h2 id="deep-dive-explainability-with-gnn-gnnexplainer">Deep Dive: Explainability with GNN (GNNExplainer)</h2>

<p><strong>Problem:</strong> Why did the model recommend Item X to User Y?</p>

<p><strong>GNNExplainer:</strong> Find the minimal subgraph that most influences the prediction.</p>

<p><strong>Algorithm:</strong></p>
<ol>
  <li>Given a node \(v\) and prediction \(y\), find a subgraph \(G_S\).</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Maximize \(MI(Y, G_S) = H(Y) - H(Y</td>
          <td>G = G_S)\) (mutual information).</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>Optimize via gradient descent with edge mask.</li>
</ol>

<p><strong>Output:</strong> “We recommended this movie because you liked these 3 similar movies (highlighted subgraph).”</p>

<h2 id="deep-dive-negative-sampling-strategies">Deep Dive: Negative Sampling Strategies</h2>

<p><strong>Problem:</strong> For each positive interaction (User –likes–&gt; Item), we need negatives.</p>

<p><strong>Strategies:</strong></p>
<ol>
  <li><strong>Random:</strong> Sample random items (easy negatives, model learns quickly but not well).</li>
  <li><strong>Popularity-based:</strong> Sample popular items (harder, but can bias toward popular items).</li>
  <li><strong>Hard Negatives:</strong> Sample items similar to the positive item (e.g., using k-NN on item embeddings).</li>
</ol>

<p><strong>Dynamic Hard Negative Mining:</strong>
``python</p>
<h1 id="during-training">During training</h1>
<p>positive_items = batch[‘items’]
positive_embs = item_embeddings[positive_items]</p>

<h1 id="find-k-nearest-items-in-embedding-space">Find K nearest items in embedding space</h1>
<p>hard_negatives = faiss_index.search(positive_embs, K)</p>

<p>loss = bpr_loss(user_emb, positive_embs, item_embeddings[hard_negatives])
``</p>

<h2 id="deep-dive-fairness-in-graph-based-recommendations">Deep Dive: Fairness in Graph-based Recommendations</h2>

<p><strong>Problem:</strong> Graph structure can encode bias (e.g., popular items get more exposure).</p>

<p><strong>Metrics:</strong></p>
<ul>
  <li><strong>Exposure Fairness:</strong> Items with equal quality should get equal exposure.</li>
  <li><strong>Demographic Parity:</strong> Recommendations should be similar across demographic groups.</li>
</ul>

<p><strong>Debiasing:</strong></p>
<ol>
  <li><strong>Re-weighting:</strong> Upweight interactions with underrepresented items.</li>
  <li><strong>Adversarial Training:</strong> Train a discriminator to predict user demographics from embeddings. Maximize recommendation loss, minimize discriminator accuracy.</li>
</ol>

<p>``python
class FairGNN(nn.Module):
 def forward(self, x, edge_index):
 emb = self.gnn(x, edge_index)</p>

<p># Recommendation loss
 rec_loss = self.recommendation_loss(emb)</p>

<p># Fairness loss (fool the discriminator)
 demographics_pred = self.discriminator(emb)
 fair_loss = -self.discriminator_loss(demographics_pred, true_demographics)</p>

<p>total_loss = rec_loss + lambda * fair_loss
 return total_loss
``</p>

<h2 id="deep-dive-graph-based-bandits-exploration-vs-exploitation">Deep Dive: Graph-based Bandits (Exploration vs. Exploitation)</h2>

<p><strong>Problem:</strong> Should we recommend popular items (exploitation) or explore new items?</p>

<p><strong>LinUCB with Graphs:</strong>
\[
\text{Score}(item) = \theta^T x_{item} + \alpha \sqrt{x_{item}^T A^{-1} x_{item}}
\]
where the second term is the uncertainty (exploration bonus).</p>

<p><strong>Graph Extension:</strong>
Use GNN to compute \(x_{\text{item}}\) (includes neighborhood information).</p>

<h2 id="implementation-full-gnn-recommender">Implementation: Full GNN Recommender</h2>

<p>``python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import SAGEConv
from torch_geometric.data import Data</p>

<p>class GraphRecommender(nn.Module):
 def <strong>init</strong>(self, num_users, num_items, embedding_dim=128, hidden_dim=256):
 super().<strong>init</strong>()
 self.num_users = num_users</p>

<p># Initial embeddings
 self.user_embedding = nn.Embedding(num_users, embedding_dim)
 self.item_embedding = nn.Embedding(num_items, embedding_dim)</p>

<p># GNN layers
 self.conv1 = SAGEConv(embedding_dim, hidden_dim)
 self.conv2 = SAGEConv(hidden_dim, embedding_dim)</p>

<p>def forward(self, edge_index):
 # Concat user and item embeddings
 x = torch.cat([self.user_embedding.weight, self.item_embedding.weight], dim=0)</p>

<p># Message passing
 x = self.conv1(x, edge_index)
 x = F.relu(x)
 x = F.dropout(x, p=0.5, training=self.training)
 x = self.conv2(x, edge_index)</p>

<p>return x</p>

<p>def predict(self, user_emb, item_emb):
 # Dot product
 return (user_emb * item_emb).sum(dim=1)</p>

<h1 id="training">Training</h1>
<p>def train(model, data, optimizer, num_epochs=100):
 for epoch in range(num_epochs):
 model.train()
 optimizer.zero_grad()</p>

<p># Forward pass
 embeddings = model(data.edge_index)</p>

<p># BPR Loss (Bayesian Personalized Ranking)
 user_embs = embeddings[data.pos_edges[0]]
 pos_item_embs = embeddings[data.pos_edges[1]]
 neg_item_embs = embeddings[data.neg_edges]</p>

<p>pos_scores = model.predict(user_embs, pos_item_embs)
 neg_scores = model.predict(user_embs, neg_item_embs)</p>

<p>loss = -torch.log(torch.sigmoid(pos_scores - neg_scores)).mean()</p>

<p>loss.backward()
 optimizer.step()</p>

<p>if epoch % 10 == 0:
 print(f’Epoch {epoch}, Loss: {loss.item():.4f}’)</p>

<h1 id="inference">Inference</h1>
<p>@torch.no_grad()
def recommend(model, user_id, top_k=10):
 model.eval()
 embeddings = model(data.edge_index)</p>

<p>user_emb = embeddings[user_id]
 item_embs = embeddings[model.num_users:] # All items</p>

<p>scores = model.predict(user_emb.unsqueeze(0), item_embs)
 top_items = scores.argsort(descending=True)[:top_k]</p>

<p>return top_items
``</p>

<h2 id="top-interview-questions">Top Interview Questions</h2>

<p><strong>Q1: How do you handle graphs that don’t fit in memory?</strong>
<em>Answer:</em>
Use <strong>neighbor sampling</strong> (GraphSAGE) to limit the number of neighbors aggregated. Use <strong>distributed training</strong> (DistDGL) to shard the graph across machines. For inference, precompute embeddings offline.</p>

<p><strong>Q2: GNNs vs. Matrix Factorization: when to use which?</strong>
<em>Answer:</em></p>
<ul>
  <li><strong>Matrix Factorization:</strong> Simpler, faster, works well if you only care about direct user-item interactions.</li>
  <li><strong>GNNs:</strong> Better when you have rich graph structure (social connections, item similarities, multi-hop relationships).</li>
</ul>

<p><strong>Q3: How do you evaluate graph-based recommenders?</strong>
<em>Answer:</em></p>
<ul>
  <li><strong>Offline:</strong> Recall@K, NDCG@K, Hit Rate.</li>
  <li><strong>Online:</strong> A/B test (CTR, engagement).</li>
  <li><strong>Graph-specific:</strong> Coverage (% of items recommended), Diversity (how different are recommended items).</li>
</ul>

<p><strong>Q4: How do you handle new users/items (cold start)?</strong>
<em>Answer:</em>
Use <strong>content features</strong> (text, images) in addition to graph structure. For new items with no interactions, compute initial embedding from content. As interactions occur, refine embedding via GNN.</p>

<h2 id="key-takeaways">Key Takeaways</h2>

<ol>
  <li><strong>Graphs Capture Structure:</strong> Use connections (social, similarity) for better recommendations.</li>
  <li><strong>GNNs are SOTA:</strong> Message passing aggregates multi-hop information.</li>
  <li><strong>Scalability Challenges:</strong> Use sampling (GraphSAGE) and distributed training (DistDGL).</li>
  <li><strong>Real-World Systems:</strong> Pinterest (PinSAGE), LinkedIn (Skills Graph), Alibaba (Product Graph).</li>
  <li><strong>Hybrid Approaches:</strong> Combine graph structure + content features for cold start robustness.</li>
</ol>

<h2 id="summary">Summary</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Aspect</th>
      <th style="text-align: left">Insight</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><strong>Core Idea</strong></td>
      <td style="text-align: left">Aggregate neighbor information to learn node embeddings</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Key Architectures</strong></td>
      <td style="text-align: left">GCN, GraphSAGE, GAT, PinSage</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Challenges</strong></td>
      <td style="text-align: left">Scalability, cold start, fairness</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Applications</strong></td>
      <td style="text-align: left">Social media, e-commerce, job recommendations</td>
    </tr>
  </tbody>
</table>

<hr />

<p><strong>Originally published at:</strong> <a href="https://www.arunbaby.com/ml-system-design/0030-graph-based-recommendations/">arunbaby.com/ml-system-design/0030-graph-based-recommendations</a></p>

<p><em>If you found this helpful, consider sharing it with others who might benefit.</em></p>


        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#gnn" class="page__taxonomy-item p-category" rel="tag">gnn</a><span class="sep">, </span>
    
      <a href="/tags/#graphs" class="page__taxonomy-item p-category" rel="tag">graphs</a><span class="sep">, </span>
    
      <a href="/tags/#link-prediction" class="page__taxonomy-item p-category" rel="tag">link prediction</a><span class="sep">, </span>
    
      <a href="/tags/#recommendations" class="page__taxonomy-item p-category" rel="tag">recommendations</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#ml-system-design" class="page__taxonomy-item p-category" rel="tag">ml_system_design</a>
    
    </span>
  </p>


        
      </footer>

      <div class="page__related page__related--full">
  <h2 class="page__related-title">Related across topics</h2>
  <style>
    /* Make section span full content width and use 2 equal columns */
    .page__related--full { float: inline-start; width: 100%; padding: 0; }
    .cross-related-grid { display: grid; grid-template-columns: repeat(2, minmax(0, 1fr)); gap: 2rem; }
    @media (max-width: 768px) { .cross-related-grid { grid-template-columns: 1fr; } }
    /* Ensure archive cards stretch nicely in the grid */
    .cross-related-grid .list__item, .cross-related-grid .grid__item { width: auto; float: none; margin: 0; }
  </style>
  <div class="cross-related-grid">
    



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/dsa/0030-number-of-islands/" rel="permalink">Number of Islands
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          15 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“Counting connected components in a 2D grid.”
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/speech-tech/0030-social-voice-networks/" rel="permalink">Social Voice Networks
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          11 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“Building recommendation and moderation systems for voice-based social platforms.”
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ai-agents/0030-agent-communication-protocols/" rel="permalink">Agent Communication Protocols: The Language of Cooperation
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          19 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“The final frontier: Standardizing the Agent-to-Agent dialogue.”
</p>
  </article>
</div>

  </div>
</div>

      <section class="page__share">
  <h4 class="page__share-title">Share on</h4>

  <a href="https://twitter.com/intent/tweet?via=arunbaby0&text=Graph-based+Recommendation+Systems%20https%3A%2F%2Fwww.arunbaby.com%2Fml-system-design%2F0030-graph-based-recommendations%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.arunbaby.com%2Fml-system-design%2F0030-graph-based-recommendations%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.arunbaby.com/ml-system-design/0030-graph-based-recommendations/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/ml-system-design/0029-hierarchical-classification/" class="pagination--pager" title="Hierarchical Classification Systems">Previous</a>
    
    
      <a href="/ml-system-design/0031-ml-pipeline-dependencies/" class="pagination--pager" title="ML Pipeline Dependencies &amp; Orchestration">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 1990 - 2143 <a href="https://www.arunbaby.com">Arun Baby</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JRJPEC9SS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0JRJPEC9SS', { 'anonymize_ip': false});
</script>








  </body>
</html>
