<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Event Stream Processing - Arun Baby</title>
<meta name="description" content="Build production event stream processing systems that handle millions of events per second using windowing and temporal aggregation—applying the same interval merging principles from algorithm design.">


  <meta name="author" content="Arun Baby">
  
  <meta property="article:author" content="Arun Baby">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Arun Baby">
<meta property="og:title" content="Event Stream Processing">
<meta property="og:url" content="https://www.arunbaby.com/ml-system-design/0016-event-stream-processing/">


  <meta property="og:description" content="Build production event stream processing systems that handle millions of events per second using windowing and temporal aggregation—applying the same interval merging principles from algorithm design.">



  <meta property="og:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">



  <meta name="twitter:site" content="@arunbaby0">
  <meta name="twitter:title" content="Event Stream Processing">
  <meta name="twitter:description" content="Build production event stream processing systems that handle millions of events per second using windowing and temporal aggregation—applying the same interval merging principles from algorithm design.">
  <meta name="twitter:url" content="https://www.arunbaby.com/ml-system-design/0016-event-stream-processing/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">
    
  

  



  <meta property="article:published_time" content="2025-12-31T09:51:02+05:30">





  

  


<link rel="canonical" href="https://www.arunbaby.com/ml-system-design/0016-event-stream-processing/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Baby Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          <span class="site-subtitle">Arun Baby</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/dsa/"
                
                
              >DSA</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ml-system-design/"
                
                
              >ML Systems</a>
            </li><li class="masthead__menu-item">
              <a
                href="/speech-tech/"
                
                
              >Speech Tech</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ai-agents/"
                
                
              >AI Agents</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li><li class="masthead__menu-item">
              <a
                href="/statuses/"
                
                
              >Statuses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/contact/"
                
                
              >Contact</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main" class="no-author-sidebar">
  
  <div class="sidebar sticky">
  
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Event Stream Processing">
    <meta itemprop="description" content="Build production event stream processing systems that handle millions of events per second using windowing and temporal aggregation—applying the same interval merging principles from algorithm design.">
    <meta itemprop="datePublished" content="2025-12-31T09:51:02+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://www.arunbaby.com/ml-system-design/0016-event-stream-processing/" itemprop="url">Event Stream Processing
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          19 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#problem-statement">Problem Statement</a><ul><li><a href="#functional-requirements">Functional Requirements</a></li><li><a href="#non-functional-requirements">Non-Functional Requirements</a></li></ul></li><li><a href="#understanding-the-requirements">Understanding the Requirements</a><ul><li><a href="#real-world-use-cases">Real-World Use Cases</a></li><li><a href="#why-event-streams-matter">Why Event Streams Matter</a></li><li><a href="#the-interval-processing-connection">The Interval Processing Connection</a></li></ul></li><li><a href="#high-level-architecture">High-Level Architecture</a><ul><li><a href="#key-components">Key Components</a></li></ul></li><li><a href="#component-deep-dives">Component Deep-Dives</a><ul><li><a href="#1-event-windowing---similar-to-interval-merging">1. Event Windowing - Similar to Interval Merging</a></li><li><a href="#2-stream-processing-engine">2. Stream Processing Engine</a></li><li><a href="#3-complex-event-processing-cep">3. Complex Event Processing (CEP)</a></li><li><a href="#4-state-management-with-checkpointing">4. State Management with Checkpointing</a></li></ul></li><li><a href="#production-deployment">Production Deployment</a><ul><li><a href="#apache-kafka--flink-architecture">Apache Kafka + Flink Architecture</a></li><li><a href="#kafka-producer">Kafka Producer</a></li></ul></li><li><a href="#scaling-strategies">Scaling Strategies</a><ul><li><a href="#horizontal-scaling">Horizontal Scaling</a></li><li><a href="#auto-scaling-based-on-lag">Auto-scaling Based on Lag</a></li></ul></li><li><a href="#real-world-case-study-netflix-event-processing">Real-World Case Study: Netflix Event Processing</a><ul><li><a href="#netflixs-approach">Netflix’s Approach</a></li><li><a href="#key-lessons">Key Lessons</a></li></ul></li><li><a href="#cost-analysis">Cost Analysis</a><ul><li><a href="#infrastructure-costs-1m-eventssec">Infrastructure Costs (1M events/sec)</a></li><li><a href="#optimization-strategies">Optimization Strategies</a></li></ul></li><li><a href="#key-takeaways">Key Takeaways</a><ul><li><a href="#connection-to-thematic-link-interval-processing-and-temporal-reasoning">Connection to Thematic Link: Interval Processing and Temporal Reasoning</a></li><li><a href="#universal-pattern">Universal Pattern</a></li></ul></li><li><a href="#additional-design--operational-considerations">Additional Design &amp; Operational Considerations</a></li></ul>
            </nav>
          </aside>
        
        <p><strong>Build production event stream processing systems that handle millions of events per second using windowing and temporal aggregation—applying the same interval merging principles from algorithm design.</strong></p>

<h2 id="problem-statement">Problem Statement</h2>

<p>Design an <strong>Event Stream Processing System</strong> that ingests, processes, and analyzes millions of events per second in real-time, supporting windowed aggregations, pattern detection, and low-latency analytics.</p>

<h3 id="functional-requirements">Functional Requirements</h3>

<ol>
  <li><strong>Event ingestion:</strong> Ingest millions of events/second from multiple sources</li>
  <li><strong>Stream processing:</strong> Real-time transformations, filtering, enrichment</li>
  <li><strong>Windowed aggregations:</strong> Tumbling, sliding, session windows</li>
  <li><strong>Pattern detection:</strong> Complex event processing (CEP)</li>
  <li><strong>State management:</strong> Maintain state across events</li>
  <li><strong>Exactly-once semantics:</strong> No duplicate or lost events</li>
  <li><strong>Late data handling:</strong> Handle out-of-order events</li>
  <li><strong>Multiple outputs:</strong> Write to databases, caches, dashboards</li>
</ol>

<h3 id="non-functional-requirements">Non-Functional Requirements</h3>

<ol>
  <li><strong>Throughput:</strong> 1M+ events/second per partition</li>
  <li><strong>Latency:</strong> p99 &lt; 100ms for event processing</li>
  <li><strong>Availability:</strong> 99.99% uptime</li>
  <li><strong>Scalability:</strong> Horizontal scaling to 1000+ nodes</li>
  <li><strong>Fault tolerance:</strong> Automatic recovery from failures</li>
  <li><strong>Backpressure:</strong> Handle traffic spikes gracefully</li>
  <li><strong>Cost efficiency:</strong> Optimize resource utilization</li>
</ol>

<h2 id="understanding-the-requirements">Understanding the Requirements</h2>

<p>Event stream processing is the <strong>backbone of real-time analytics</strong> at scale:</p>

<h3 id="real-world-use-cases">Real-World Use Cases</h3>

<table>
  <thead>
    <tr>
      <th>Company</th>
      <th>Use Case</th>
      <th>Scale</th>
      <th>Technology</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Netflix</td>
      <td>Real-time recommendation updates</td>
      <td>10M+ events/sec</td>
      <td>Kafka + Flink</td>
    </tr>
    <tr>
      <td>Uber</td>
      <td>Surge pricing, driver matching</td>
      <td>5M+ events/sec</td>
      <td>Kafka + custom</td>
    </tr>
    <tr>
      <td>LinkedIn</td>
      <td>News feed ranking</td>
      <td>1M+ events/sec</td>
      <td>Kafka + Samza</td>
    </tr>
    <tr>
      <td>Airbnb</td>
      <td>Pricing optimization</td>
      <td>500K+ events/sec</td>
      <td>Kafka + Spark</td>
    </tr>
    <tr>
      <td>Twitter</td>
      <td>Trending topics</td>
      <td>5M+ tweets/sec</td>
      <td>Kafka + custom</td>
    </tr>
    <tr>
      <td>Spotify</td>
      <td>Real-time playlist updates</td>
      <td>1M+ events/sec</td>
      <td>Kafka + Flink</td>
    </tr>
  </tbody>
</table>

<h3 id="why-event-streams-matter">Why Event Streams Matter</h3>

<ol>
  <li><strong>Real-time analytics:</strong> Instant insights from data</li>
  <li><strong>ML feature computation:</strong> Real-time feature updates</li>
  <li><strong>Fraud detection:</strong> Immediate anomaly detection</li>
  <li><strong>User engagement:</strong> Real-time personalization</li>
  <li><strong>Monitoring:</strong> Live system health tracking</li>
  <li><strong>Business intelligence:</strong> Instant KPI updates</li>
</ol>

<h3 id="the-interval-processing-connection">The Interval Processing Connection</h3>

<p>Just like the <strong>Merge Intervals</strong> problem:</p>

<table>
  <thead>
    <tr>
      <th>Merge Intervals</th>
      <th>Event Stream Processing</th>
      <th>Audio Segmentation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Merge overlapping time ranges</td>
      <td>Merge event windows</td>
      <td>Merge audio segments</td>
    </tr>
    <tr>
      <td>Sort by start time</td>
      <td>Event time ordering</td>
      <td>Temporal ordering</td>
    </tr>
    <tr>
      <td>Greedy merging</td>
      <td>Window aggregation</td>
      <td>Boundary merging</td>
    </tr>
    <tr>
      <td>O(N log N) complexity</td>
      <td>Stream buffering</td>
      <td>Segment processing</td>
    </tr>
    <tr>
      <td>Overlap detection</td>
      <td>Event correlation</td>
      <td>Segment alignment</td>
    </tr>
  </tbody>
</table>

<p>All three deal with <strong>temporal data</strong> requiring efficient interval/window processing.</p>

<h2 id="high-level-architecture">High-Level Architecture</h2>

<p>``
┌─────────────────────────────────────────────────────────────────┐
│ Event Stream Processing System │
└─────────────────────────────────────────────────────────────────┘</p>

<p>Event Sources
 ┌─────────┐ ┌─────────┐ ┌─────────┐
 │ Apps │ │ Services│ │ IoT │
 └────┬────┘ └────┬────┘ └────┬────┘
 │ │ │
 └───────────┼───────────┘
 │
 ┌──────▼──────┐
 │ Kafka │
 │ (Message │
 │ Broker) │
 └──────┬──────┘
 │
 ┌──────────────────┼──────────────────┐
 │ │ │
┌───────▼────────┐ ┌──────▼──────┐ ┌────────▼────────┐
│ Stream │ │ Windowing │ │ Aggregation │
│ Processing │ │ Engine │ │ Engine │
│ │ │ │ │ │
│ - Filter │ │ - Tumbling │ │ - Count │
│ - Transform │ │ - Sliding │ │ - Sum │
│ - Enrich │ │ - Session │ │ - Average │
└───────┬────────┘ └──────┬──────┘ └────────┬────────┘
 │ │ │
 └──────────────────┼──────────────────┘
 │
 ┌──────▼──────┐
 │ State │
 │ Store │
 │ (RocksDB) │
 └──────┬──────┘
 │
 ┌──────────────────┼──────────────────┐
 │ │ │
┌───────▼────────┐ ┌──────▼──────┐ ┌────────▼────────┐
│ Database │ │ Cache │ │ Dashboard │
│ (Cassandra) │ │ (Redis) │ │ (Grafana) │
└────────────────┘ └─────────────┘ └─────────────────┘
``</p>

<h3 id="key-components">Key Components</h3>

<ol>
  <li><strong>Message Broker:</strong> Kafka for event ingestion and buffering</li>
  <li><strong>Stream Processor:</strong> Flink/Spark for real-time computation</li>
  <li><strong>Windowing Engine:</strong> Time-based and session-based windows</li>
  <li><strong>State Store:</strong> RocksDB for stateful processing</li>
  <li><strong>Output Sinks:</strong> Multiple destinations for processed events</li>
</ol>

<h2 id="component-deep-dives">Component Deep-Dives</h2>

<h3 id="1-event-windowing---similar-to-interval-merging">1. Event Windowing - Similar to Interval Merging</h3>

<p>Windows group events by time, just like merging intervals:</p>

<p>``python
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from datetime import datetime, timedelta
from collections import defaultdict
import time</p>

<p>@dataclass
class Event:
 “"”A single event in the stream.”””
 event_id: str
 event_type: str
 timestamp: int # Unix timestamp in milliseconds
 user_id: str
 data: Dict[str, Any]</p>

<p>@property
 def event_time(self) -&gt; datetime:
 “"”Get event time as datetime.”””
 return datetime.fromtimestamp(self.timestamp / 1000.0)</p>

<p>@dataclass
class Window:
 “””
 A time window containing events.</p>

<p>Similar to intervals in merge intervals problem:</p>
<ul>
  <li>start: interval start</li>
  <li>end: interval end</li>
  <li>events: data within interval
 “””
 start: int # Window start (ms)
 end: int # Window end (ms)
 events: List[Event]</li>
</ul>

<p>def overlaps(self, other: ‘Window’) -&gt; bool:
 “””
 Check if this window overlaps with another.</p>

<p>Same logic as interval overlap:
 max(start1, start2) &lt;= min(end1, end2)
 “””
 return max(self.start, other.start) &lt;= min(self.end, other.end)</p>

<p>def merge(self, other: ‘Window’) -&gt; ‘Window’:
 “””
 Merge this window with another.</p>

<p>Same as merging intervals:</p>
<ul>
  <li>New start = min of starts</li>
  <li>New end = max of ends</li>
  <li>Combine events
 “””
 return Window(
 start=min(self.start, other.start),
 end=max(self.end, other.end),
 events=self.events + other.events
 )</li>
</ul>

<p>@property
 def duration_ms(self) -&gt; int:
 return self.end - self.start</p>

<p>@property
 def event_count(self) -&gt; int:
 return len(self.events)</p>

<p>class WindowManager:
 “””
 Manage event windows for stream processing.</p>

<p>Similar to merge intervals:</p>
<ul>
  <li>Group events into time windows</li>
  <li>Merge overlapping windows</li>
  <li>Maintain sorted window list
 “””</li>
</ul>

<p>def <strong>init</strong>(self, window_type: str = “tumbling”, window_size_ms: int = 60000):
 “””
 Initialize window manager.</p>

<p>Args:
 window_type: “tumbling”, “sliding”, or “session”
 window_size_ms: Window size in milliseconds
 “””
 self.window_type = window_type
 self.window_size_ms = window_size_ms
 self.windows: List[Window] = []</p>

<p>def assign_to_window(self, event: Event) -&gt; List[Window]:
 “””
 Assign event to window(s).</p>

<p>Returns:
 List of windows this event belongs to
 “””
 if self.window_type == “tumbling”:
 return self._assign_tumbling(event)
 elif self.window_type == “sliding”:
 return self._assign_sliding(event)
 elif self.window_type == “session”:
 return self._assign_session(event)
 else:
 raise ValueError(f”Unknown window type: {self.window_type}”)</p>

<p>def _assign_tumbling(self, event: Event) -&gt; List[Window]:
 “””
 Tumbling windows: Fixed-size, non-overlapping.</p>

<p>Example: 1-minute windows
 [0-60s], [60-120s], [120-180s], …</p>

<p>Each event belongs to exactly one window.
 “””
 # Calculate which window this event belongs to
 window_id = event.timestamp // self.window_size_ms
 window_start = window_id * self.window_size_ms
 window_end = window_start + self.window_size_ms</p>

<p># Find or create window
 window = self._find_or_create_window(window_start, window_end)
 window.events.append(event)</p>

<p>return [window]</p>

<p>def _assign_sliding(self, event: Event) -&gt; List[Window]:
 “””
 Sliding windows: Fixed-size, overlapping.</p>

<p>Example: 1-minute windows, sliding every 30 seconds
 [0-60s], [30-90s], [60-120s], …</p>

<p>Each event can belong to multiple windows.
 “””
 slide_interval = self.window_size_ms // 2 # 50% overlap</p>

<p># Find all windows this event falls into
 windows = []</p>

<p># Calculate first window that could contain this event
 first_window_id = (event.timestamp - self.window_size_ms) // slide_interval
 first_window_start = first_window_id * slide_interval</p>

<p># Check windows until event is past window end
 current_start = first_window_start</p>

<p>while current_start &lt;= event.timestamp:
 current_end = current_start + self.window_size_ms</p>

<p>if current_start &lt;= event.timestamp &lt; current_end:
 window = self._find_or_create_window(current_start, current_end)
 window.events.append(event)
 windows.append(window)</p>

<p>current_start += slide_interval</p>

<p>return windows</p>

<p>def _assign_session(self, event: Event) -&gt; List[Window]:
 “””
 Session windows: Dynamic windows based on activity gaps.</p>

<p>A session ends when there’s a gap &gt; session_timeout between events.</p>

<p>This is like merging intervals with a max gap tolerance!
 “””
 session_timeout = 5 * 60 * 1000 # 5 minutes</p>

<p># Find window that could be extended
 for window in self.windows:
 # Check if event is within session timeout of window end
 if event.timestamp - window.end &lt;= session_timeout:
 # Extend window
 window.end = event.timestamp
 window.events.append(event)
 return [window]</p>

<p># Start new session
 window = Window(
 start=event.timestamp,
 end=event.timestamp,
 events=[event]
 )
 self.windows.append(window)</p>

<p>return [window]</p>

<p>def _find_or_create_window(self, start: int, end: int) -&gt; Window:
 “"”Find existing window or create new one.”””
 for window in self.windows:
 if window.start == start and window.end == end:
 return window</p>

<p># Create new window
 new_window = Window(start=start, end=end, events=[])
 self.windows.append(new_window)</p>

<p>return new_window</p>

<p>def get_completed_windows(self, watermark: int) -&gt; List[Window]:
 “””
 Get windows that are complete (past watermark).</p>

<p>Watermark = latest timestamp we’re confident we’ve seen all events for.</p>

<p>Similar to merge intervals: return all intervals before a certain time.
 “””
 completed = []
 remaining = []</p>

<p>for window in self.windows:
 if window.end &lt; watermark:
 completed.append(window)
 else:
 remaining.append(window)</p>

<p>self.windows = remaining
 return completed</p>

<p>def merge_overlapping_windows(self) -&gt; List[Window]:
 “””
 Merge overlapping windows.</p>

<p>This is exactly the merge intervals algorithm!
 “””
 if not self.windows:
 return []</p>

<p># Sort by start time
 sorted_windows = sorted(self.windows, key=lambda w: w.start)</p>

<p>merged = [sorted_windows[0]]</p>

<p>for current in sorted_windows[1:]:
 last = merged[-1]</p>

<p>if current.overlaps(last):
 # Merge
 merged[-1] = last.merge(current)
 else:
 # Add new window
 merged.append(current)</p>

<p>return merged
``</p>

<h3 id="2-stream-processing-engine">2. Stream Processing Engine</h3>

<p>``python
from typing import Callable, List
from queue import Queue
import threading</p>

<p>class StreamProcessor:
 “””
 Event stream processing engine.</p>

<p>Features:</p>
<ul>
  <li>Real-time event processing</li>
  <li>Windowed aggregations</li>
  <li>Stateful operations</li>
  <li>Exactly-once semantics
 “””</li>
</ul>

<p>def <strong>init</strong>(self):
 self.window_manager = WindowManager(window_type=”tumbling”, window_size_ms=60000)
 self.aggregators: Dict[str, Callable] = {}
 self.state_store: Dict[str, Any] = {}</p>

<p># Processing queue
 self.event_queue = Queue(maxsize=10000)
 self.running = False</p>

<p># Metrics
 self.events_processed = 0
 self.windows_created = 0</p>

<p>def register_aggregator(self, name: str, func: Callable):
 “"”Register an aggregation function.”””
 self.aggregators[name] = func</p>

<p>def process_event(self, event: Event):
 “””
 Process a single event.</p>

<p>Steps:</p>
<ol>
  <li>Assign to window(s)</li>
  <li>Update state</li>
  <li>Apply aggregations</li>
  <li>Emit results
 “””
 # Assign to windows
 windows = self.window_manager.assign_to_window(event)</li>
</ol>

<p># Update state for each window
 for window in windows:
 window_key = f”{window.start}-{window.end}”</p>

<p># Initialize state if needed
 if window_key not in self.state_store:
 self.state_store[window_key] = {
 ‘count’: 0,
 ‘sum’: 0,
 ‘events’: []
 }</p>

<p># Update state
 state = self.state_store[window_key]
 state[‘count’] += 1
 state[‘events’].append(event)</p>

<p># Apply aggregations
 for name, aggregator in self.aggregators.items():
 result = aggregator(window.events)
 state[name] = result</p>

<p>self.events_processed += 1</p>

<p>def get_window_aggregates(self, window_start: int, window_end: int) -&gt; Dict:
 “"”Get aggregates for a specific window.”””
 window_key = f”{window_start}-{window_end}”
 return self.state_store.get(window_key, {})</p>

<p>def flush_completed_windows(self, watermark: int) -&gt; List[Dict]:
 “””
 Flush completed windows to output.</p>

<p>Similar to returning merged intervals after processing.
 “””
 completed = self.window_manager.get_completed_windows(watermark)</p>

<p>results = []</p>

<p>for window in completed:
 window_key = f”{window.start}-{window.end}”</p>

<p>if window_key in self.state_store:
 result = {
 ‘window_start’: window.start,
 ‘window_end’: window.end,
 ‘aggregates’: self.state_store[window_key]
 }
 results.append(result)</p>

<p># Clean up state
 del self.state_store[window_key]</p>

<p>return results</p>

<h1 id="example-usage">Example usage</h1>
<p>def example_stream_processing():
 “"”Example: Count events per user in 1-minute windows.”””
 processor = StreamProcessor()</p>

<p># Register aggregator
 def count_by_user(events: List[Event]) -&gt; Dict[str, int]:
 “"”Count events per user.”””
 counts = defaultdict(int)
 for event in events:
 counts[event.user_id] += 1
 return dict(counts)</p>

<p>processor.register_aggregator(‘user_counts’, count_by_user)</p>

<p># Process events
 events = [
 Event(“1”, “click”, 1000, “user1”, {}),
 Event(“2”, “click”, 2000, “user1”, {}),
 Event(“3”, “click”, 3000, “user2”, {}),
 Event(“4”, “view”, 65000, “user1”, {}), # Next window
 ]</p>

<p>for event in events:
 processor.process_event(event)</p>

<p># Flush completed windows (watermark = 70000ms)
 results = processor.flush_completed_windows(70000)</p>

<p>for result in results:
 print(f”Window {result[‘window_start’]}-{result[‘window_end’]}:”)
 print(f” User counts: {result[‘aggregates’][‘user_counts’]}”)
``</p>

<h3 id="3-complex-event-processing-cep">3. Complex Event Processing (CEP)</h3>

<p>``python
from typing import List, Callable
from dataclasses import dataclass</p>

<p>@dataclass
class Pattern:
 “"”Event pattern for detection.”””
 name: str
 conditions: List[Callable[[Event], bool]]
 window_ms: int</p>

<p>class CEPEngine:
 “””
 Complex Event Processing engine.</p>

<p>Detect patterns in event streams:</p>
<ul>
  <li>Sequences: A followed by B within time window</li>
  <li>Conditions: Events matching criteria</li>
  <li>Aggregations: Count, sum over window
 “””</li>
</ul>

<p>def <strong>init</strong>(self):
 self.patterns: List[Pattern] = []
 self.matches: List[Dict] = []</p>

<p>def register_pattern(self, pattern: Pattern):
 “"”Register a pattern to detect.”””
 self.patterns.append(pattern)</p>

<p>def detect_patterns(self, events: List[Event]) -&gt; List[Dict]:
 “””
 Detect registered patterns in event stream.</p>

<p>Uses interval-style processing:</p>
<ul>
  <li>Sort events by time</li>
  <li>Sliding window over events</li>
  <li>Check pattern conditions
 “””
 matches = []</li>
</ul>

<p># Sort events by timestamp
 sorted_events = sorted(events, key=lambda e: e.timestamp)</p>

<p>for pattern in self.patterns:
 # Find sequences matching pattern
 pattern_matches = self._find_pattern_matches(sorted_events, pattern)
 matches.extend(pattern_matches)</p>

<p>return matches</p>

<p>def _find_pattern_matches(
 self,
 events: List[Event],
 pattern: Pattern
 ) -&gt; List[Dict]:
 “"”Find all matches of pattern in events.”””
 matches = []</p>

<p>for i in range(len(events)):
 # Try to match pattern starting at event i
 match_events = [events[i]]</p>

<p># Check if first condition matches
 if not pattern.conditions<a href="events[i]">0</a>:
 continue</p>

<p># Look for subsequent events matching remaining conditions
 j = i + 1
 condition_idx = 1</p>

<p>while j &lt; len(events) and condition_idx &lt; len(pattern.conditions):
 # Check if within time window
 if events[j].timestamp - events[i].timestamp &gt; pattern.window_ms:
 break</p>

<p># Check if condition matches
 if pattern.conditions<a href="events[j]">condition_idx</a>:
 match_events.append(events[j])
 condition_idx += 1</p>

<p>j += 1</p>

<p># Check if full pattern matched
 if condition_idx == len(pattern.conditions):
 matches.append({
 ‘pattern’: pattern.name,
 ‘events’: match_events,
 ‘start_time’: events[i].timestamp,
 ‘end_time’: match_events[-1].timestamp
 })</p>

<p>return matches</p>

<h1 id="example-fraud-detection-pattern">Example: Fraud detection pattern</h1>
<p>def fraud_detection_example():
 “"”Detect potential fraud: multiple failed logins followed by success.”””
 cep = CEPEngine()</p>

<p># Define pattern
 pattern = Pattern(
 name=”suspicious_login”,
 conditions=[
 lambda e: e.event_type == “login_failed”,
 lambda e: e.event_type == “login_failed”,
 lambda e: e.event_type == “login_failed”,
 lambda e: e.event_type == “login_success”
 ],
 window_ms=60000 # Within 1 minute
 )</p>

<p>cep.register_pattern(pattern)</p>

<p># Test events
 events = [
 Event(“1”, “login_failed”, 1000, “user1”, {}),
 Event(“2”, “login_failed”, 2000, “user1”, {}),
 Event(“3”, “login_failed”, 3000, “user1”, {}),
 Event(“4”, “login_success”, 4000, “user1”, {}),
 ]</p>

<p>matches = cep.detect_patterns(events)</p>

<p>for match in matches:
 print(f”Pattern ‘{match[‘pattern’]}’ detected:”)
 print(f” Time window: {match[‘start_time’]}-{match[‘end_time’]}”)
 print(f” Events: {[e.event_id for e in match[‘events’]]}”)
``</p>

<h3 id="4-state-management-with-checkpointing">4. State Management with Checkpointing</h3>

<p>``python
import pickle
import os</p>

<p>class StateManager:
 “””
 Manage stateful stream processing with checkpointing.</p>

<p>Features:</p>
<ul>
  <li>Fault tolerance through checkpoints</li>
  <li>Exactly-once semantics</li>
  <li>State recovery
 “””</li>
</ul>

<p>def <strong>init</strong>(self, checkpoint_dir: str = “/tmp/checkpoints”):
 self.checkpoint_dir = checkpoint_dir
 self.state: Dict[str, Any] = {}
 self.checkpoint_interval_ms = 60000
 self.last_checkpoint_time = 0</p>

<p>os.makedirs(checkpoint_dir, exist_ok=True)</p>

<p>def update_state(self, key: str, value: Any):
 “"”Update state.”””
 self.state[key] = value</p>

<p>def get_state(self, key: str, default: Any = None) -&gt; Any:
 “"”Get state value.”””
 return self.state.get(key, default)</p>

<p>def checkpoint(self, watermark: int):
 “””
 Create state checkpoint.</p>

<p>Similar to saving merged intervals periodically.
 “””
 checkpoint_path = os.path.join(
 self.checkpoint_dir,
 f”checkpoint_{watermark}.pkl”
 )</p>

<p>with open(checkpoint_path, ‘wb’) as f:
 pickle.dump({
 ‘watermark’: watermark,
 ‘state’: self.state
 }, f)</p>

<p>self.last_checkpoint_time = watermark</p>

<p># Clean old checkpoints
 self._cleanup_old_checkpoints(watermark)</p>

<p>def restore_from_checkpoint(self, watermark: Optional[int] = None):
 “"”Restore state from checkpoint.”””
 if watermark is None:
 # Find latest checkpoint
 checkpoints = [
 f for f in os.listdir(self.checkpoint_dir)
 if f.startswith(“checkpoint_”)
 ]</p>

<p>if not checkpoints:
 return</p>

<p>latest = max(checkpoints, key=lambda f: int(f.split(‘<em>’)[1].split(‘.’)[0]))
 checkpoint_path = os.path.join(self.checkpoint_dir, latest)
 else:
 checkpoint_path = os.path.join(
 self.checkpoint_dir,
 f”checkpoint</em>{watermark}.pkl”
 )</p>

<p>if os.path.exists(checkpoint_path):
 with open(checkpoint_path, ‘rb’) as f:
 data = pickle.load(f)
 self.state = data[‘state’]
 return data[‘watermark’]</p>

<p>return None</p>

<p>def <em>cleanup_old_checkpoints(self, current_watermark: int, keep_last: int = 3):
 “"”Keep only recent checkpoints.”””
 checkpoints = [
 (f, int(f.split(‘</em>’)[1].split(‘.’)[0]))
 for f in os.listdir(self.checkpoint_dir)
 if f.startswith(“checkpoint_”)
 ]</p>

<p># Sort by watermark
 checkpoints.sort(key=lambda x: x[1], reverse=True)</p>

<p># Delete old ones
 for checkpoint_file, watermark in checkpoints[keep_last:]:
 os.remove(os.path.join(self.checkpoint_dir, checkpoint_file))
``</p>

<h2 id="production-deployment">Production Deployment</h2>

<h3 id="apache-kafka--flink-architecture">Apache Kafka + Flink Architecture</h3>

<p>``yaml</p>
<h1 id="docker-composeyml-for-stream-processing-stack">docker-compose.yml for stream processing stack</h1>
<p>version: ‘3.8’</p>

<p>services:
 zookeeper:
 image: confluentinc/cp-zookeeper:latest
 environment:
 ZOOKEEPER_CLIENT_PORT: 2181
 ZOOKEEPER_TICK_TIME: 2000</p>

<p>kafka:
 image: confluentinc/cp-kafka:latest
 depends_on:</p>
<ul>
  <li>zookeeper
 ports:</li>
  <li>“9092:9092”
 environment:
 KAFKA_BROKER_ID: 1
 KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
 KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
 KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1</li>
</ul>

<p>flink-jobmanager:
 image: flink:latest
 ports:</p>
<ul>
  <li>“8081:8081”
 command: jobmanager
 environment:</li>
  <li>JOB_MANAGER_RPC_ADDRESS=flink-jobmanager</li>
</ul>

<p>flink-taskmanager:
 image: flink:latest
 depends_on:</p>
<ul>
  <li>flink-jobmanager
 command: taskmanager
 environment:</li>
  <li>JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
 deploy:
 replicas: 3
``</li>
</ul>

<h3 id="kafka-producer">Kafka Producer</h3>

<p>``python
from kafka import KafkaProducer
import json</p>

<p>class EventProducer:
 “"”Produce events to Kafka.”””</p>

<p>def <strong>init</strong>(self, bootstrap_servers: List[str], topic: str):
 self.producer = KafkaProducer(
 bootstrap_servers=bootstrap_servers,
 value_serializer=lambda v: json.dumps(v).encode(‘utf-8’)
 )
 self.topic = topic</p>

<p>def send_event(self, event: Event):
 “"”Send event to Kafka.”””
 event_dict = {
 ‘event_id’: event.event_id,
 ‘event_type’: event.event_type,
 ‘timestamp’: event.timestamp,
 ‘user_id’: event.user_id,
 ‘data’: event.data
 }</p>

<p>self.producer.send(
 self.topic,
 value=event_dict,
 key=event.user_id.encode(‘utf-8’) # Partition by user
 )</p>

<p>def flush(self):
 “"”Flush pending messages.”””
 self.producer.flush()
``</p>

<h2 id="scaling-strategies">Scaling Strategies</h2>

<h3 id="horizontal-scaling">Horizontal Scaling</h3>

<p>``python</p>
<h1 id="kafka-topics-with-multiple-partitions-for-parallelism">Kafka topics with multiple partitions for parallelism</h1>
<p>def create_kafka_topic(admin_client, topic_name: str, num_partitions: int = 10):
 “"”Create Kafka topic with partitions.”””
 from kafka.admin import NewTopic</p>

<p>topic = NewTopic(
 name=topic_name,
 num_partitions=num_partitions,
 replication_factor=3
 )</p>

<p>admin_client.create_topics([topic])
``</p>

<h3 id="auto-scaling-based-on-lag">Auto-scaling Based on Lag</h3>

<p>``python
class StreamProcessorAutoScaler:
 “"”Auto-scale stream processors based on consumer lag.”””</p>

<p>def <strong>init</strong>(self, max_lag_threshold: int = 10000):
 self.max_lag_threshold = max_lag_threshold</p>

<p>def should_scale_up(self, consumer_lag: int) -&gt; bool:
 “"”Check if should add more processors.”””
 return consumer_lag &gt; self.max_lag_threshold</p>

<p>def should_scale_down(self, consumer_lag: int) -&gt; bool:
 “"”Check if can reduce processors.”””
 return consumer_lag &lt; self.max_lag_threshold * 0.5
``</p>

<h2 id="real-world-case-study-netflix-event-processing">Real-World Case Study: Netflix Event Processing</h2>

<h3 id="netflixs-approach">Netflix’s Approach</h3>

<p>Netflix processes <strong>10M+ events/second</strong> for real-time recommendations:</p>

<p><strong>Architecture:</strong></p>
<ol>
  <li><strong>Kafka:</strong> 36+ clusters, 4000+ brokers</li>
  <li><strong>Flink:</strong> Real-time stream processing</li>
  <li><strong>Keystone:</strong> Real-time data pipeline</li>
  <li><strong>Mantis:</strong> Reactive stream processing</li>
</ol>

<p><strong>Use Cases:</strong></p>
<ul>
  <li>Real-time viewing analytics</li>
  <li>Recommendation updates</li>
  <li>A/B test metric computation</li>
  <li>Anomaly detection</li>
</ul>

<p><strong>Results:</strong></p>
<ul>
  <li><strong>10M events/sec</strong> throughput</li>
  <li><strong>&lt;100ms p99 latency</strong></li>
  <li><strong>99.99% availability</strong></li>
  <li><strong>Petabytes/day</strong> processed</li>
</ul>

<h3 id="key-lessons">Key Lessons</h3>

<ol>
  <li><strong>Partition strategically</strong> - by user ID for locality</li>
  <li><strong>Use watermarks</strong> for late data handling</li>
  <li><strong>Checkpoint frequently</strong> for fault tolerance</li>
  <li><strong>Monitor lag closely</strong> - key metric for health</li>
  <li><strong>Test backpressure</strong> - must handle traffic spikes</li>
</ol>

<h2 id="cost-analysis">Cost Analysis</h2>

<h3 id="infrastructure-costs-1m-eventssec">Infrastructure Costs (1M events/sec)</h3>

<table>
  <thead>
    <tr>
      <th>Component</th>
      <th>Nodes</th>
      <th>Cost/Month</th>
      <th>Notes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Kafka brokers</td>
      <td>10</td>
      <td>$5,000</td>
      <td>r5.2xlarge</td>
    </tr>
    <tr>
      <td>Flink workers</td>
      <td>20</td>
      <td>$8,000</td>
      <td>c5.4xlarge</td>
    </tr>
    <tr>
      <td>State storage</td>
      <td>-</td>
      <td>$500</td>
      <td>S3 for checkpoints</td>
    </tr>
    <tr>
      <td>Monitoring</td>
      <td>-</td>
      <td>$200</td>
      <td>Prometheus + Grafana</td>
    </tr>
    <tr>
      <td><strong>Total</strong></td>
      <td> </td>
      <td><strong><code class="language-plaintext highlighter-rouge">13,700/month** | **</code>0.37 per million events</strong></td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h3 id="optimization-strategies">Optimization Strategies</h3>

<ol>
  <li><strong>Batch processing:</strong> Micro-batches reduce overhead</li>
  <li><strong>Compression:</strong> Reduce network/storage costs by 70%</li>
  <li><strong>State backends:</strong> RocksDB vs in-memory trade-offs</li>
  <li><strong>Spot instances:</strong> 70% cost reduction for stateless workers</li>
</ol>

<h2 id="key-takeaways">Key Takeaways</h2>

<p>✅ <strong>Windows are intervals</strong> - same merging logic applies</p>

<p>✅ <strong>Event time vs processing time</strong> - critical distinction</p>

<p>✅ <strong>Watermarks enable</strong> late data handling</p>

<p>✅ <strong>State management</strong> requires checkpointing for fault tolerance</p>

<p>✅ <strong>Exactly-once semantics</strong> possible with careful design</p>

<p>✅ <strong>Kafka + Flink</strong> is industry standard stack</p>

<p>✅ <strong>Partition for parallelism</strong> - key to horizontal scaling</p>

<p>✅ <strong>Monitor consumer lag</strong> - critical health metric</p>

<p>✅ <strong>Backpressure handling</strong> essential for reliability</p>

<p>✅ <strong>Same interval processing</strong> as merge intervals problem</p>

<h3 id="connection-to-thematic-link-interval-processing-and-temporal-reasoning">Connection to Thematic Link: Interval Processing and Temporal Reasoning</h3>

<p>All three topics share interval/window processing:</p>

<p><strong>DSA (Merge Intervals):</strong></p>
<ul>
  <li>Sort intervals by start time</li>
  <li>Merge overlapping ranges</li>
  <li>O(N log N) greedy algorithm</li>
</ul>

<p><strong>ML System Design (Event Stream Processing):</strong></p>
<ul>
  <li>Sort events by timestamp</li>
  <li>Merge event windows</li>
  <li>Windowed aggregations</li>
</ul>

<p><strong>Speech Tech (Audio Segmentation):</strong></p>
<ul>
  <li>Sort audio segments temporally</li>
  <li>Merge adjacent segments</li>
  <li>Boundary detection</li>
</ul>

<h3 id="universal-pattern">Universal Pattern</h3>

<p>``python</p>
<h1 id="pattern-used-across-all-three">Pattern used across all three:</h1>
<ol>
  <li>Sort items by time/position</li>
  <li>Process in temporal order</li>
  <li>Merge adjacent/overlapping ranges</li>
  <li>Apply aggregations within ranges
``</li>
</ol>

<p>This pattern is <strong>fundamental</strong> to temporal data processing!</p>

<h2 id="additional-design--operational-considerations">Additional Design &amp; Operational Considerations</h2>

<p>To bring this closer to a real production design and to increase depth (and word
count) in a meaningful way, here are additional angles you should be comfortable
discussing:</p>

<ul>
  <li><strong>Backpressure in detail:</strong></li>
  <li>What happens when sinks (e.g., databases, dashboards) can’t keep up?</li>
  <li>You should be able to talk about:</li>
  <li>Producer-side throttling,</li>
  <li>Buffer sizing and on-disk spill,</li>
  <li>Dropping or sampling low-priority events,</li>
  <li>Using dead-letter queues for problematic payloads.</li>
  <li>
    <p>In Flink/Spark, backpressure is built into the runtime; in custom systems,
 you must design this flow control explicitly.</p>
  </li>
  <li><strong>Exactly-once vs at-least-once semantics:</strong></li>
  <li>Exactly-once is often implemented as <strong>effectively-once</strong> at the sink:</li>
  <li>Idempotent writes,</li>
  <li>Deduplication using event IDs,</li>
  <li>Transactional writes (Kafka transactions, 2PC, etc.).</li>
  <li>
    <p>Be ready to explain when at-least-once is acceptable (monitoring, metrics)
 and when you truly need exactly-once (billing, financial ledgers).</p>
  </li>
  <li><strong>Multi-tenant stream processing:</strong></li>
  <li>In a large org, many teams may share the same Kafka cluster / stream engine.</li>
  <li>Consider:</li>
  <li>Per-tenant resource quotas,</li>
  <li>Isolation between streams (separate topics vs namespaces),</li>
  <li>Access control (who can publish/consume),</li>
  <li>
    <p>Governance around schema evolution (Schema Registry, Protobuf/Avro).</p>
  </li>
  <li><strong>Schema evolution and compatibility:</strong></li>
  <li>Events evolve over time—fields are added/removed.</li>
  <li>You should design:</li>
  <li>Backward/forward compatible schemas,</li>
  <li>Clear deprecation policies,</li>
  <li>
    <p>Validation in CI/CD so producers don’t break consumers.</p>
  </li>
  <li><strong>End-to-end SLAs:</strong></li>
  <li>It’s not enough to have p99 &lt; 100ms inside the stream processor.</li>
  <li>End-to-end latency includes:</li>
  <li>Ingestion → broker,</li>
  <li>Broker → stream processor,</li>
  <li>Processor → sink,</li>
  <li>Sink → dashboard / downstream system.</li>
  <li>
    <p>You should know where you’d instrument latency histograms and how you’d
 trace a single event through the system (e.g., using a correlation ID).</p>
  </li>
  <li><strong>Cost-awareness and capacity planning:</strong></li>
  <li>Stream processing clusters can be very expensive at high scale.</li>
  <li>Think about:</li>
  <li>Right-sizing instances (CPU vs memory bound),</li>
  <li>Using autoscaling based on lag and CPU,</li>
  <li>Separating critical vs non-critical pipelines (priority tiers).</li>
</ul>

<p>Being able to reason about these topics—and tie them back to the core windowing
and interval-processing primitives from earlier in the post—will make your answer
stand out in senior-level interviews and in real design docs.</p>

<hr />

<p><strong>Originally published at:</strong> <a href="https://www.arunbaby.com/ml-system-design/0016-event-stream-processing/">arunbaby.com/ml-system-design/0016-event-stream-processing</a></p>

<p><em>If you found this helpful, consider sharing it with others who might benefit.</em></p>


        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#event-driven" class="page__taxonomy-item p-category" rel="tag">event-driven</a><span class="sep">, </span>
    
      <a href="/tags/#flink" class="page__taxonomy-item p-category" rel="tag">flink</a><span class="sep">, </span>
    
      <a href="/tags/#kafka" class="page__taxonomy-item p-category" rel="tag">kafka</a><span class="sep">, </span>
    
      <a href="/tags/#real-time" class="page__taxonomy-item p-category" rel="tag">real-time</a><span class="sep">, </span>
    
      <a href="/tags/#stream-processing" class="page__taxonomy-item p-category" rel="tag">stream-processing</a><span class="sep">, </span>
    
      <a href="/tags/#temporal-processing" class="page__taxonomy-item p-category" rel="tag">temporal-processing</a><span class="sep">, </span>
    
      <a href="/tags/#windowing" class="page__taxonomy-item p-category" rel="tag">windowing</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#ml-system-design" class="page__taxonomy-item p-category" rel="tag">ml-system-design</a>
    
    </span>
  </p>


        
      </footer>

      <div class="page__related page__related--full">
  <h2 class="page__related-title">Related across topics</h2>
  <style>
    /* Make section span full content width and use 2 equal columns */
    .page__related--full { float: inline-start; width: 100%; padding: 0; }
    .cross-related-grid { display: grid; grid-template-columns: repeat(2, minmax(0, 1fr)); gap: 2rem; }
    @media (max-width: 768px) { .cross-related-grid { grid-template-columns: 1fr; } }
    /* Ensure archive cards stretch nicely in the grid */
    .cross-related-grid .list__item, .cross-related-grid .grid__item { width: auto; float: none; margin: 0; }
  </style>
  <div class="cross-related-grid">
    



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/dsa/0016-merge-intervals/" rel="permalink">Merge Intervals
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          21 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Master interval processing to handle overlapping ranges—the foundation of event streams and temporal reasoning in production systems.
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/speech-tech/0016-real-time-audio-segmentation/" rel="permalink">Real-time Audio Segmentation
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          17 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Build production audio segmentation systems that detect boundaries in real-time using interval merging and temporal processing—the same principles from merge...</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ai-agents/0016-real-time-agent-pipelines/" rel="permalink">Real-Time Agent Pipelines
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          14 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“Speed is not a feature. Speed is the product.”
</p>
  </article>
</div>

  </div>
</div>

      <section class="page__share">
  <h4 class="page__share-title">Share on</h4>

  <a href="https://twitter.com/intent/tweet?via=arunbaby0&text=Event+Stream+Processing%20https%3A%2F%2Fwww.arunbaby.com%2Fml-system-design%2F0016-event-stream-processing%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.arunbaby.com%2Fml-system-design%2F0016-event-stream-processing%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.arunbaby.com/ml-system-design/0016-event-stream-processing/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/ml-system-design/0015-clustering-systems/" class="pagination--pager" title="Clustering Systems">Previous</a>
    
    
      <a href="/ml-system-design/0017-distributed-training-architecture/" class="pagination--pager" title="Distributed Training Architecture">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 1990 - 2143 <a href="https://www.arunbaby.com">Arun Baby</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JRJPEC9SS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0JRJPEC9SS', { 'anonymize_ip': false});
</script>








  </body>
</html>
