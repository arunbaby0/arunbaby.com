<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Transfer Learning Systems - Arun Baby</title>
<meta name="description" content="“Why learn from scratch when you can stand on the shoulders of giants?”">


  <meta name="author" content="Arun Baby">
  
  <meta property="article:author" content="Arun Baby">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Arun Baby">
<meta property="og:title" content="Transfer Learning Systems">
<meta property="og:url" content="https://www.arunbaby.com/ml-system-design/0046-transfer-learning/">


  <meta property="og:description" content="“Why learn from scratch when you can stand on the shoulders of giants?”">



  <meta property="og:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">



  <meta name="twitter:site" content="@arunbaby0">
  <meta name="twitter:title" content="Transfer Learning Systems">
  <meta name="twitter:description" content="“Why learn from scratch when you can stand on the shoulders of giants?”">
  <meta name="twitter:url" content="https://www.arunbaby.com/ml-system-design/0046-transfer-learning/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">
    
  

  



  <meta property="article:published_time" content="2025-12-21T22:46:31+05:30">





  

  


<link rel="canonical" href="https://www.arunbaby.com/ml-system-design/0046-transfer-learning/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Baby Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          <span class="site-subtitle">Arun Baby</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/dsa/"
                
                
              >DSA</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ml-system-design/"
                
                
              >ML Systems</a>
            </li><li class="masthead__menu-item">
              <a
                href="/speech-tech/"
                
                
              >Speech Tech</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ai-agents/"
                
                
              >AI Agents</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li><li class="masthead__menu-item">
              <a
                href="/statuses/"
                
                
              >Statuses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/contact/"
                
                
              >Contact</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main" class="no-author-sidebar">
  
  <div class="sidebar sticky">
  
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Transfer Learning Systems">
    <meta itemprop="description" content="“Why learn from scratch when you can stand on the shoulders of giants?”">
    <meta itemprop="datePublished" content="2025-12-21T22:46:31+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://www.arunbaby.com/ml-system-design/0046-transfer-learning/" itemprop="url">Transfer Learning Systems
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          26 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#1-problem-statement">1. Problem Statement</a><ul><li><a href="#functional-requirements">Functional Requirements</a></li><li><a href="#non-functional-requirements">Non-Functional Requirements</a></li></ul></li><li><a href="#2-understanding-transfer-learning">2. Understanding Transfer Learning</a><ul><li><a href="#why-transfer-learning">Why Transfer Learning?</a></li><li><a href="#the-knowledge-transfer-analogy">The Knowledge Transfer Analogy</a></li><li><a href="#types-of-transfer-learning">Types of Transfer Learning</a></li></ul></li><li><a href="#3-high-level-architecture">3. High-Level Architecture</a></li><li><a href="#4-component-deep-dives">4. Component Deep-Dives</a><ul><li><a href="#41-model-registry">4.1 Model Registry</a></li><li><a href="#42-adaptation-manager">4.2 Adaptation Manager</a></li><li><a href="#43-training-engine">4.3 Training Engine</a></li></ul></li><li><a href="#5-domain-adaptation">5. Domain Adaptation</a></li><li><a href="#6-evaluation-and-monitoring">6. Evaluation and Monitoring</a></li><li><a href="#7-real-world-case-study-bert-fine-tuning-at-scale">7. Real-World Case Study: BERT Fine-Tuning at Scale</a><ul><li><a href="#netflix-recommendation-personalization">Netflix Recommendation Personalization</a></li></ul></li><li><a href="#8-cost-analysis">8. Cost Analysis</a></li><li><a href="#9-common-failure-modes">9. Common Failure Modes</a><ul><li><a href="#failure-mode-1-negative-transfer">Failure Mode 1: Negative Transfer</a></li><li><a href="#failure-mode-2-catastrophic-forgetting">Failure Mode 2: Catastrophic Forgetting</a></li><li><a href="#failure-mode-3-underfitting-target-task">Failure Mode 3: Underfitting Target Task</a></li></ul></li><li><a href="#10-connection-to-cross-lingual-speech-transfer">10. Connection to Cross-Lingual Speech Transfer</a></li><li><a href="#11-key-takeaways">11. Key Takeaways</a></li></ul>
            </nav>
          </aside>
        
        <p><strong>“Why learn from scratch when you can stand on the shoulders of giants?”</strong></p>

<h2 id="1-problem-statement">1. Problem Statement</h2>

<p>Design a <strong>transfer learning system</strong> that enables efficient knowledge transfer from large pretrained models to downstream tasks. The system should support multiple transfer strategies (fine-tuning, feature extraction, domain adaptation), manage model versioning, and optimize for both training efficiency and inference performance.</p>

<h3 id="functional-requirements">Functional Requirements</h3>

<ol>
  <li><strong>Model Registry</strong>: Store and version pretrained models (BERT, GPT, ResNet, Whisper, etc.)</li>
  <li><strong>Adaptation Pipeline</strong>: Support multiple transfer strategies:
    <ul>
      <li>Full fine-tuning</li>
      <li>Partial fine-tuning (layer freezing)</li>
      <li>Feature extraction (frozen backbone)</li>
      <li>Adapter modules (LoRA, prefix tuning)</li>
    </ul>
  </li>
  <li><strong>Domain Adaptation</strong>: Handle distribution shift between source and target domains</li>
  <li><strong>Multi-task Transfer</strong>: Transfer to multiple downstream tasks from one pretrained model</li>
  <li><strong>Evaluation Framework</strong>: Measure transfer effectiveness and negative transfer detection</li>
</ol>

<h3 id="non-functional-requirements">Non-Functional Requirements</h3>

<ul>
  <li><strong>Scale</strong>: Handle models from 100M to 100B+ parameters</li>
  <li><strong>Efficiency</strong>: 10-100x faster than training from scratch</li>
  <li><strong>Storage</strong>: Efficient storage of model variants (&lt; 5% overhead per adaptation)</li>
  <li><strong>Latency</strong>: Training job startup &lt; 5 minutes</li>
  <li><strong>Reproducibility</strong>: Deterministic results with fixed seeds</li>
</ul>

<h2 id="2-understanding-transfer-learning">2. Understanding Transfer Learning</h2>

<h3 id="why-transfer-learning">Why Transfer Learning?</h3>

<p>Transfer learning addresses the fundamental challenge of machine learning: <strong>insufficient labeled data for the target task</strong>. By leveraging knowledge from related tasks or domains, we can:</p>

<ol>
  <li><strong>Reduce data requirements</strong>: Achieve good performance with 10-100x less labeled data</li>
  <li><strong>Speed up training</strong>: Converge in hours instead of weeks</li>
  <li><strong>Improve generalization</strong>: Pretrained features capture universal patterns</li>
  <li><strong>Lower compute costs</strong>: Avoid training massive models from scratch</li>
</ol>

<h3 id="the-knowledge-transfer-analogy">The Knowledge Transfer Analogy</h3>

<p>Think of pretrained models like experienced professionals:</p>
<ul>
  <li><strong>Medical school (pretraining)</strong>: Learn fundamental anatomy, biology, chemistry</li>
  <li><strong>Specialization (fine-tuning)</strong>: Adapt to cardiology, neurology, or oncology</li>
  <li><strong>The key insight</strong>: Core knowledge transfers; only domain-specific details need learning</li>
</ul>

<h3 id="types-of-transfer-learning">Types of Transfer Learning</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>┌─────────────────────────────────────────────────────────────────┐
│                    Transfer Learning Taxonomy                    │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌──────────────────┐  ┌──────────────────┐  ┌───────────────┐  │
│  │ Inductive TL     │  │ Transductive TL  │  │ Unsupervised  │  │
│  │                  │  │                  │  │ TL            │  │
│  │ - Same domain    │  │ - Different      │  │ - No labels   │  │
│  │ - Different task │  │   domains        │  │ - Feature     │  │
│  │ - Fine-tuning    │  │ - Same task      │  │   transfer    │  │
│  │ - Multi-task     │  │ - Domain adapt.  │  │               │  │
│  └──────────────────┘  └──────────────────┘  └───────────────┘  │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
</code></pre></div></div>

<h2 id="3-high-level-architecture">3. High-Level Architecture</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>┌─────────────────────────────────────────────────────────────────────────┐
│                     Transfer Learning System Architecture                │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐                  │
│  │   Model     │    │  Adaptation │    │  Training   │                  │
│  │  Registry   │───▶│   Manager   │───▶│   Engine    │                  │
│  │             │    │             │    │             │                  │
│  └─────────────┘    └─────────────┘    └─────────────┘                  │
│        ▲                  │                   │                         │
│        │                  ▼                   ▼                         │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐                  │
│  │   Storage   │    │   Config    │    │   Compute   │                  │
│  │   Layer     │    │   Engine    │    │   Manager   │                  │
│  │             │    │             │    │             │                  │
│  └─────────────┘    └─────────────┘    └─────────────┘                  │
│        │                  │                   │                         │
│        ▼                  ▼                   ▼                         │
│  ┌─────────────────────────────────────────────────────────────────┐    │
│  │                     Evaluation &amp; Monitoring                      │    │
│  │  ┌──────────┐  ┌───────────────┐  ┌────────────┐  ┌──────────┐  │    │
│  │  │ Transfer │  │   Negative    │  │ Performance│  │ Cost     │  │    │
│  │  │ Metrics  │  │   Transfer    │  │ Tracking   │  │ Analysis │  │    │
│  │  │          │  │   Detection   │  │            │  │          │  │    │
│  │  └──────────┘  └───────────────┘  └────────────┘  └──────────┘  │    │
│  └─────────────────────────────────────────────────────────────────┘    │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
</code></pre></div></div>

<h2 id="4-component-deep-dives">4. Component Deep-Dives</h2>

<h3 id="41-model-registry">4.1 Model Registry</h3>

<p>The model registry stores pretrained models with rich metadata:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span><span class="p">,</span> <span class="n">field</span>
<span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Any</span>
<span class="kn">from</span> <span class="n">enum</span> <span class="kn">import</span> <span class="n">Enum</span>
<span class="kn">import</span> <span class="n">hashlib</span>
<span class="kn">import</span> <span class="n">json</span>

<span class="k">class</span> <span class="nc">ModelDomain</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="n">NLP</span> <span class="o">=</span> <span class="sh">"</span><span class="s">nlp</span><span class="sh">"</span>
    <span class="n">VISION</span> <span class="o">=</span> <span class="sh">"</span><span class="s">vision</span><span class="sh">"</span>
    <span class="n">SPEECH</span> <span class="o">=</span> <span class="sh">"</span><span class="s">speech</span><span class="sh">"</span>
    <span class="n">MULTIMODAL</span> <span class="o">=</span> <span class="sh">"</span><span class="s">multimodal</span><span class="sh">"</span>

<span class="k">class</span> <span class="nc">PretrainingObjective</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="n">MASKED_LM</span> <span class="o">=</span> <span class="sh">"</span><span class="s">masked_lm</span><span class="sh">"</span>           <span class="c1"># BERT-style
</span>    <span class="n">CAUSAL_LM</span> <span class="o">=</span> <span class="sh">"</span><span class="s">causal_lm</span><span class="sh">"</span>           <span class="c1"># GPT-style
</span>    <span class="n">CONTRASTIVE</span> <span class="o">=</span> <span class="sh">"</span><span class="s">contrastive</span><span class="sh">"</span>       <span class="c1"># CLIP-style
</span>    <span class="n">RECONSTRUCTION</span> <span class="o">=</span> <span class="sh">"</span><span class="s">reconstruction</span><span class="sh">"</span> <span class="c1"># Autoencoder
</span>    <span class="n">DENOISING</span> <span class="o">=</span> <span class="sh">"</span><span class="s">denoising</span><span class="sh">"</span>           <span class="c1"># Diffusion models
</span>
<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">PretrainedModelMetadata</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">Rich metadata for pretrained models supporting transfer decisions.</span><span class="sh">"""</span>
    
    <span class="c1"># Identity
</span>    <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">model_family</span><span class="p">:</span> <span class="nb">str</span>  <span class="c1"># "bert", "gpt", "resnet", "whisper"
</span>    <span class="n">version</span><span class="p">:</span> <span class="nb">str</span>
    
    <span class="c1"># Architecture
</span>    <span class="n">architecture</span><span class="p">:</span> <span class="nb">str</span>  <span class="c1"># "encoder-only", "decoder-only", "encoder-decoder"
</span>    <span class="n">num_parameters</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">num_layers</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span>
    
    <span class="c1"># Pretraining info
</span>    <span class="n">domain</span><span class="p">:</span> <span class="n">ModelDomain</span>
    <span class="n">objective</span><span class="p">:</span> <span class="n">PretrainingObjective</span>
    <span class="n">pretraining_data</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>  <span class="c1"># Dataset names
</span>    <span class="n">pretraining_tokens</span><span class="p">:</span> <span class="nb">int</span>
    
    <span class="c1"># Transfer recommendations
</span>    <span class="n">recommended_tasks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
    <span class="n">recommended_lr_range</span><span class="p">:</span> <span class="nb">tuple</span>
    <span class="n">recommended_batch_size</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">freezable_layers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
    
    <span class="c1"># Performance baselines
</span>    <span class="n">benchmark_scores</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="nf">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="nb">dict</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">get_transfer_compatibility</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">target_task</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Estimate transfer compatibility score.</span><span class="sh">"""</span>
        <span class="c1"># Based on empirical transfer learning research
</span>        <span class="n">task_compatibility</span> <span class="o">=</span> <span class="p">{</span>
            <span class="p">(</span><span class="sh">"</span><span class="s">nlp</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">sentiment</span><span class="sh">"</span><span class="p">):</span> <span class="mf">0.95</span><span class="p">,</span>
            <span class="p">(</span><span class="sh">"</span><span class="s">nlp</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">ner</span><span class="sh">"</span><span class="p">):</span> <span class="mf">0.90</span><span class="p">,</span>
            <span class="p">(</span><span class="sh">"</span><span class="s">nlp</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">qa</span><span class="sh">"</span><span class="p">):</span> <span class="mf">0.85</span><span class="p">,</span>
            <span class="p">(</span><span class="sh">"</span><span class="s">nlp</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">summarization</span><span class="sh">"</span><span class="p">):</span> <span class="mf">0.80</span><span class="p">,</span>
            <span class="p">(</span><span class="sh">"</span><span class="s">vision</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">classification</span><span class="sh">"</span><span class="p">):</span> <span class="mf">0.95</span><span class="p">,</span>
            <span class="p">(</span><span class="sh">"</span><span class="s">vision</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">detection</span><span class="sh">"</span><span class="p">):</span> <span class="mf">0.85</span><span class="p">,</span>
            <span class="p">(</span><span class="sh">"</span><span class="s">vision</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">segmentation</span><span class="sh">"</span><span class="p">):</span> <span class="mf">0.80</span><span class="p">,</span>
            <span class="p">(</span><span class="sh">"</span><span class="s">speech</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">asr</span><span class="sh">"</span><span class="p">):</span> <span class="mf">0.95</span><span class="p">,</span>
            <span class="p">(</span><span class="sh">"</span><span class="s">speech</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">speaker_id</span><span class="sh">"</span><span class="p">):</span> <span class="mf">0.85</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">return</span> <span class="n">task_compatibility</span><span class="p">.</span><span class="nf">get</span><span class="p">((</span><span class="n">self</span><span class="p">.</span><span class="n">domain</span><span class="p">.</span><span class="n">value</span><span class="p">,</span> <span class="n">target_task</span><span class="p">),</span> <span class="mf">0.5</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">ModelRegistry</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Central registry for pretrained models.
    
    Design decisions:
    - Hierarchical storage: family/version/variant
    - Lazy loading: metadata first, weights on demand
    - Deduplication: shared base weights via delta storage
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">storage_backend</span><span class="p">,</span> <span class="n">cache_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">storage</span> <span class="o">=</span> <span class="n">storage_backend</span>
        <span class="n">self</span><span class="p">.</span><span class="n">cache_dir</span> <span class="o">=</span> <span class="n">cache_dir</span>
        <span class="n">self</span><span class="p">.</span><span class="n">metadata_cache</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">PretrainedModelMetadata</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
    
    <span class="k">def</span> <span class="nf">register_model</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span> 
        <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">model_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">metadata</span><span class="p">:</span> <span class="n">PretrainedModelMetadata</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Register a new pretrained model.
        
        Returns a unique model hash for deduplication.
        </span><span class="sh">"""</span>
        <span class="c1"># Compute content hash for deduplication
</span>        <span class="n">model_hash</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_compute_model_hash</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
        
        <span class="c1"># Check for duplicates
</span>        <span class="k">if</span> <span class="n">existing</span> <span class="p">:</span><span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_find_by_hash</span><span class="p">(</span><span class="n">model_hash</span><span class="p">):</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Model already exists as </span><span class="si">{</span><span class="n">existing</span><span class="si">}</span><span class="s">, creating alias</span><span class="sh">"</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">existing</span>
        
        <span class="c1"># Store model with metadata
</span>        <span class="n">storage_path</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">metadata</span><span class="p">.</span><span class="n">model_family</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">metadata</span><span class="p">.</span><span class="n">version</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">model_id</span><span class="si">}</span><span class="sh">"</span>
        <span class="n">self</span><span class="p">.</span><span class="n">storage</span><span class="p">.</span><span class="nf">upload</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">storage_path</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">storage</span><span class="p">.</span><span class="nf">upload_json</span><span class="p">(</span>
            <span class="n">metadata</span><span class="p">.</span><span class="n">__dict__</span><span class="p">,</span> 
            <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">storage_path</span><span class="si">}</span><span class="s">/metadata.json</span><span class="sh">"</span>
        <span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">metadata_cache</span><span class="p">[</span><span class="n">model_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">metadata</span>
        <span class="k">return</span> <span class="n">model_hash</span>
    
    <span class="k">def</span> <span class="nf">get_model</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span> 
        <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> 
        <span class="n">load_weights</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Retrieve model and metadata.
        
        Args:
            model_id: Model identifier
            load_weights: Whether to load weights (memory intensive)
        
        Returns:
            (metadata, weights_path or None)
        </span><span class="sh">"""</span>
        <span class="n">metadata</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_get_metadata</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">load_weights</span><span class="p">:</span>
            <span class="n">weights_path</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_download_weights</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">weights_path</span>
        
        <span class="k">return</span> <span class="n">metadata</span><span class="p">,</span> <span class="bp">None</span>
    
    <span class="k">def</span> <span class="nf">list_compatible_models</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span> 
        <span class="n">target_task</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">min_compatibility</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.7</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">PretrainedModelMetadata</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">Find models suitable for a target task.</span><span class="sh">"""</span>
        <span class="n">compatible</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">model_id</span><span class="p">,</span> <span class="n">metadata</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">metadata_cache</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">metadata</span><span class="p">.</span><span class="nf">get_transfer_compatibility</span><span class="p">(</span><span class="n">target_task</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">score</span> <span class="o">&gt;=</span> <span class="n">min_compatibility</span><span class="p">:</span>
                <span class="n">compatible</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">score</span><span class="p">,</span> <span class="n">metadata</span><span class="p">))</span>
        
        <span class="c1"># Sort by compatibility score
</span>        <span class="n">compatible</span><span class="p">.</span><span class="nf">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">m</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">compatible</span><span class="p">]</span>
    
    <span class="k">def</span> <span class="nf">_compute_model_hash</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Compute SHA256 hash of model weights for deduplication.</span><span class="sh">"""</span>
        <span class="n">hasher</span> <span class="o">=</span> <span class="n">hashlib</span><span class="p">.</span><span class="nf">sha256</span><span class="p">()</span>
        <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="sh">'</span><span class="s">rb</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="nf">iter</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">f</span><span class="p">.</span><span class="nf">read</span><span class="p">(</span><span class="mi">8192</span><span class="p">),</span> <span class="sa">b</span><span class="sh">''</span><span class="p">):</span>
                <span class="n">hasher</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">hasher</span><span class="p">.</span><span class="nf">hexdigest</span><span class="p">()[:</span><span class="mi">16</span><span class="p">]</span>
    
    <span class="k">def</span> <span class="nf">_get_metadata</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">PretrainedModelMetadata</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">model_id</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">metadata_cache</span><span class="p">:</span>
            <span class="n">metadata_json</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">storage</span><span class="p">.</span><span class="nf">download_json</span><span class="p">(</span>
                <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">model_id</span><span class="si">}</span><span class="s">/metadata.json</span><span class="sh">"</span>
            <span class="p">)</span>
            <span class="n">self</span><span class="p">.</span><span class="n">metadata_cache</span><span class="p">[</span><span class="n">model_id</span><span class="p">]</span> <span class="o">=</span> <span class="nc">PretrainedModelMetadata</span><span class="p">(</span>
                <span class="o">**</span><span class="n">metadata_json</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">metadata_cache</span><span class="p">[</span><span class="n">model_id</span><span class="p">]</span>
    
    <span class="k">def</span> <span class="nf">_download_weights</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Download weights to local cache.</span><span class="sh">"""</span>
        <span class="n">local_path</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">self</span><span class="p">.</span><span class="n">cache_dir</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">model_id</span><span class="si">}</span><span class="s">/weights.pt</span><span class="sh">"</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">exists</span><span class="p">(</span><span class="n">local_path</span><span class="p">):</span>
            <span class="n">self</span><span class="p">.</span><span class="n">storage</span><span class="p">.</span><span class="nf">download</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">model_id</span><span class="si">}</span><span class="s">/weights.pt</span><span class="sh">"</span><span class="p">,</span> <span class="n">local_path</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">local_path</span>
    
    <span class="k">def</span> <span class="nf">_find_by_hash</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model_hash</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">Find existing model by hash.</span><span class="sh">"""</span>
        <span class="c1"># Implementation: query hash index
</span>        <span class="k">pass</span>
</code></pre></div></div>

<h3 id="42-adaptation-manager">4.2 Adaptation Manager</h3>

<p>The core component that handles different transfer strategies:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Optional</span>

<span class="k">class</span> <span class="nc">AdaptationStrategy</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Base class for transfer learning strategies.</span><span class="sh">"""</span>
    
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">prepare_model</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Prepare the model for adaptation.</span><span class="sh">"""</span>
        <span class="k">pass</span>
    
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">get_trainable_parameters</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">nn</span><span class="p">.</span><span class="n">Parameter</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">Return parameters to be trained.</span><span class="sh">"""</span>
        <span class="k">pass</span>
    
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">get_optimizer_groups</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span> 
        <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span> 
        <span class="n">base_lr</span><span class="p">:</span> <span class="nb">float</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">Parameter groups with potentially different learning rates.</span><span class="sh">"""</span>
        <span class="k">pass</span>


<span class="k">class</span> <span class="nc">FullFineTuning</span><span class="p">(</span><span class="n">AdaptationStrategy</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Fine-tune all parameters.
    
    Best for:
    - Large target datasets
    - Significant domain shift
    - When compute is not a constraint
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">lr_decay_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.95</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">lr_decay_factor</span> <span class="o">=</span> <span class="n">lr_decay_factor</span>
    
    <span class="k">def</span> <span class="nf">prepare_model</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">:</span>
        <span class="c1"># All parameters trainable
</span>        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">():</span>
            <span class="n">param</span><span class="p">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="k">return</span> <span class="n">model</span>
    
    <span class="k">def</span> <span class="nf">get_trainable_parameters</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">nn</span><span class="p">.</span><span class="n">Parameter</span><span class="p">]:</span>
        <span class="k">return</span> <span class="nf">list</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">())</span>
    
    <span class="k">def</span> <span class="nf">get_optimizer_groups</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span> 
        <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span> 
        <span class="n">base_lr</span><span class="p">:</span> <span class="nb">float</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">
        Apply discriminative learning rates:
        - Earlier layers: lower LR (more universal features)
        - Later layers: higher LR (more task-specific)
        </span><span class="sh">"""</span>
        <span class="n">groups</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">num_layers</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="nf">list</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">named_modules</span><span class="p">()))</span>
        
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">module</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">named_modules</span><span class="p">()):</span>
            <span class="k">if</span> <span class="nf">list</span><span class="p">(</span><span class="n">module</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()):</span>
                <span class="c1"># Calculate layer-wise LR
</span>                <span class="n">depth_ratio</span> <span class="o">=</span> <span class="n">i</span> <span class="o">/</span> <span class="n">num_layers</span>
                <span class="n">lr</span> <span class="o">=</span> <span class="n">base_lr</span> <span class="o">*</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">lr_decay_factor</span> <span class="o">**</span> <span class="p">(</span><span class="n">num_layers</span> <span class="o">-</span> <span class="n">i</span><span class="p">))</span>
                
                <span class="n">groups</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span>
                    <span class="sh">'</span><span class="s">params</span><span class="sh">'</span><span class="p">:</span> <span class="n">module</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span>
                    <span class="sh">'</span><span class="s">lr</span><span class="sh">'</span><span class="p">:</span> <span class="n">lr</span><span class="p">,</span>
                    <span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">:</span> <span class="n">name</span>
                <span class="p">})</span>
        
        <span class="k">return</span> <span class="n">groups</span>


<span class="k">class</span> <span class="nc">PartialFineTuning</span><span class="p">(</span><span class="n">AdaptationStrategy</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Freeze early layers, fine-tune later layers.
    
    Best for:
    - Limited target data
    - Similar source and target domains
    - When preventing catastrophic forgetting is important
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span> 
        <span class="n">freeze_until</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
        <span class="n">freeze_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
        <span class="n">freeze_layers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Configure freezing strategy.
        
        Args:
            freeze_until: Freeze all layers until (and including) this one
            freeze_ratio: Freeze this fraction of layers from the start
            freeze_layers: Explicit list of layer names to freeze
        </span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="n">freeze_until</span> <span class="o">=</span> <span class="n">freeze_until</span>
        <span class="n">self</span><span class="p">.</span><span class="n">freeze_ratio</span> <span class="o">=</span> <span class="n">freeze_ratio</span>
        <span class="n">self</span><span class="p">.</span><span class="n">freeze_layers</span> <span class="o">=</span> <span class="n">freeze_layers</span> <span class="ow">or</span> <span class="p">[]</span>
    
    <span class="k">def</span> <span class="nf">prepare_model</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">:</span>
        <span class="c1"># First, freeze everything
</span>        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">():</span>
            <span class="n">param</span><span class="p">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="bp">False</span>
        
        <span class="c1"># Then selectively unfreeze
</span>        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">freeze_until</span><span class="p">:</span>
            <span class="n">found_marker</span> <span class="o">=</span> <span class="bp">False</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">named_modules</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">freeze_until</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                    <span class="n">found_marker</span> <span class="o">=</span> <span class="bp">True</span>
                <span class="k">elif</span> <span class="n">found_marker</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">module</span><span class="p">.</span><span class="nf">parameters</span><span class="p">():</span>
                        <span class="n">param</span><span class="p">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="bp">True</span>
        
        <span class="k">elif</span> <span class="n">self</span><span class="p">.</span><span class="n">freeze_ratio</span><span class="p">:</span>
            <span class="n">all_modules</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">named_modules</span><span class="p">())</span>
            <span class="n">freeze_count</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">all_modules</span><span class="p">)</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">freeze_ratio</span><span class="p">)</span>
            
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">module</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">all_modules</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">freeze_count</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">module</span><span class="p">.</span><span class="nf">parameters</span><span class="p">():</span>
                        <span class="n">param</span><span class="p">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="bp">True</span>
        
        <span class="k">elif</span> <span class="n">self</span><span class="p">.</span><span class="n">freeze_layers</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">named_parameters</span><span class="p">():</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nf">any</span><span class="p">(</span><span class="n">fl</span> <span class="ow">in</span> <span class="n">name</span> <span class="k">for</span> <span class="n">fl</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">freeze_layers</span><span class="p">):</span>
                    <span class="n">param</span><span class="p">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="bp">True</span>
        
        <span class="k">return</span> <span class="n">model</span>
    
    <span class="k">def</span> <span class="nf">get_trainable_parameters</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">nn</span><span class="p">.</span><span class="n">Parameter</span><span class="p">]:</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="p">.</span><span class="n">requires_grad</span><span class="p">]</span>
    
    <span class="k">def</span> <span class="nf">get_optimizer_groups</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span> 
        <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span> 
        <span class="n">base_lr</span><span class="p">:</span> <span class="nb">float</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]:</span>
        <span class="k">return</span> <span class="p">[{</span><span class="sh">'</span><span class="s">params</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="nf">get_trainable_parameters</span><span class="p">(</span><span class="n">model</span><span class="p">),</span> <span class="sh">'</span><span class="s">lr</span><span class="sh">'</span><span class="p">:</span> <span class="n">base_lr</span><span class="p">}]</span>


<span class="k">class</span> <span class="nc">LoRAAdaptation</span><span class="p">(</span><span class="n">AdaptationStrategy</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Low-Rank Adaptation: Add trainable low-rank matrices.
    
    Best for:
    - Very large models (billions of parameters)
    - Multiple task adaptation (each task gets its own LoRA)
    - Storage-efficient (&lt; 1% of original model size)
    
    Paper: </span><span class="sh">"</span><span class="s">LoRA: Low-Rank Adaptation of Large Language Models</span><span class="sh">"</span><span class="s"> (Hu et al., 2021)
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span> 
        <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>
        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
        <span class="n">target_modules</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
        <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span>
    <span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">rank</span>
        <span class="n">self</span><span class="p">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="n">self</span><span class="p">.</span><span class="n">target_modules</span> <span class="o">=</span> <span class="n">target_modules</span> <span class="ow">or</span> <span class="p">[</span><span class="sh">'</span><span class="s">q_proj</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">v_proj</span><span class="sh">'</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>
        <span class="n">self</span><span class="p">.</span><span class="n">scaling</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">/</span> <span class="n">rank</span>
    
    <span class="k">def</span> <span class="nf">prepare_model</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">:</span>
        <span class="c1"># Freeze all original parameters
</span>        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">():</span>
            <span class="n">param</span><span class="p">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="bp">False</span>
        
        <span class="c1"># Add LoRA layers
</span>        <span class="n">self</span><span class="p">.</span><span class="nf">_inject_lora_layers</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">model</span>
    
    <span class="k">def</span> <span class="nf">_inject_lora_layers</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Inject LoRA adapters into target modules.</span><span class="sh">"""</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">named_modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nf">any</span><span class="p">(</span><span class="n">target</span> <span class="ow">in</span> <span class="n">name</span> <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">target_modules</span><span class="p">):</span>
                <span class="k">if</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">):</span>
                    <span class="c1"># Replace with LoRA-enhanced linear
</span>                    <span class="n">lora_layer</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_create_lora_linear</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
                    <span class="n">self</span><span class="p">.</span><span class="nf">_replace_module</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lora_layer</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_create_lora_linear</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">original</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Create a LoRA-enhanced linear layer.</span><span class="sh">"""</span>
        
        <span class="k">class</span> <span class="nc">LoRALinear</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
            <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">original</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">scaling</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
                <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
                <span class="n">self</span><span class="p">.</span><span class="n">original</span> <span class="o">=</span> <span class="n">original</span>
                <span class="n">self</span><span class="p">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">rank</span>
                <span class="n">self</span><span class="p">.</span><span class="n">scaling</span> <span class="o">=</span> <span class="n">scaling</span>
                
                <span class="c1"># Low-rank matrices
</span>                <span class="n">self</span><span class="p">.</span><span class="n">lora_A</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span>
                    <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">original</span><span class="p">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">rank</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>
                <span class="p">)</span>
                <span class="n">self</span><span class="p">.</span><span class="n">lora_B</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Parameter</span><span class="p">(</span>
                    <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">original</span><span class="p">.</span><span class="n">out_features</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="n">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
            
            <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
                <span class="c1"># Original frozen forward
</span>                <span class="n">original_out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">original</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                
                <span class="c1"># LoRA forward: x @ A @ B * scaling
</span>                <span class="n">lora_out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">@</span> <span class="n">self</span><span class="p">.</span><span class="n">lora_A</span> <span class="o">@</span> <span class="n">self</span><span class="p">.</span><span class="n">lora_B</span>
                
                <span class="k">return</span> <span class="n">original_out</span> <span class="o">+</span> <span class="n">lora_out</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">scaling</span>
        
        <span class="k">return</span> <span class="nc">LoRALinear</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">rank</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">scaling</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_replace_module</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">new_module</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Replace a nested module by name.</span><span class="sh">"""</span>
        <span class="n">parts</span> <span class="o">=</span> <span class="n">name</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">.</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">parent</span> <span class="o">=</span> <span class="n">model</span>
        <span class="k">for</span> <span class="n">part</span> <span class="ow">in</span> <span class="n">parts</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">parent</span> <span class="o">=</span> <span class="nf">getattr</span><span class="p">(</span><span class="n">parent</span><span class="p">,</span> <span class="n">part</span><span class="p">)</span>
        <span class="nf">setattr</span><span class="p">(</span><span class="n">parent</span><span class="p">,</span> <span class="n">parts</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">new_module</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">get_trainable_parameters</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">nn</span><span class="p">.</span><span class="n">Parameter</span><span class="p">]:</span>
        <span class="c1"># Only LoRA parameters are trainable
</span>        <span class="k">return</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">named_parameters</span><span class="p">()</span> 
                <span class="k">if</span> <span class="sh">'</span><span class="s">lora_A</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">n</span> <span class="ow">or</span> <span class="sh">'</span><span class="s">lora_B</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">n</span><span class="p">]</span>
    
    <span class="k">def</span> <span class="nf">get_optimizer_groups</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span> 
        <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span> 
        <span class="n">base_lr</span><span class="p">:</span> <span class="nb">float</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]:</span>
        <span class="k">return</span> <span class="p">[{</span><span class="sh">'</span><span class="s">params</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="nf">get_trainable_parameters</span><span class="p">(</span><span class="n">model</span><span class="p">),</span> <span class="sh">'</span><span class="s">lr</span><span class="sh">'</span><span class="p">:</span> <span class="n">base_lr</span><span class="p">}]</span>
    
    <span class="k">def</span> <span class="nf">merge_lora_weights</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Merge LoRA weights into original weights for inference.
        
        This eliminates LoRA overhead at inference time.
        </span><span class="sh">"""</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">named_modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nf">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="sh">'</span><span class="s">lora_A</span><span class="sh">'</span><span class="p">)</span> <span class="ow">and</span> <span class="nf">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="sh">'</span><span class="s">lora_B</span><span class="sh">'</span><span class="p">):</span>
                <span class="c1"># Merge: W_new = W_original + A @ B * scaling
</span>                <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
                    <span class="n">delta</span> <span class="o">=</span> <span class="n">module</span><span class="p">.</span><span class="n">lora_A</span> <span class="o">@</span> <span class="n">module</span><span class="p">.</span><span class="n">lora_B</span> <span class="o">*</span> <span class="n">module</span><span class="p">.</span><span class="n">scaling</span>
                    <span class="n">module</span><span class="p">.</span><span class="n">original</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="nf">add_</span><span class="p">(</span><span class="n">delta</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
                
                <span class="c1"># Remove LoRA components
</span>                <span class="k">del</span> <span class="n">module</span><span class="p">.</span><span class="n">lora_A</span>
                <span class="k">del</span> <span class="n">module</span><span class="p">.</span><span class="n">lora_B</span>
        
        <span class="k">return</span> <span class="n">model</span>


<span class="k">class</span> <span class="nc">AdaptationManager</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Orchestrates the transfer learning process.
    
    Responsibilities:
    - Strategy selection
    - Model preparation
    - Training configuration
    - Adaptation tracking
    </span><span class="sh">"""</span>
    
    <span class="n">STRATEGY_MAP</span> <span class="o">=</span> <span class="p">{</span>
        <span class="sh">'</span><span class="s">full</span><span class="sh">'</span><span class="p">:</span> <span class="n">FullFineTuning</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">partial</span><span class="sh">'</span><span class="p">:</span> <span class="n">PartialFineTuning</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">lora</span><span class="sh">'</span><span class="p">:</span> <span class="n">LoRAAdaptation</span><span class="p">,</span>
    <span class="p">}</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model_registry</span><span class="p">:</span> <span class="n">ModelRegistry</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">registry</span> <span class="o">=</span> <span class="n">model_registry</span>
        <span class="n">self</span><span class="p">.</span><span class="n">adaptations</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
    
    <span class="k">def</span> <span class="nf">create_adaptation</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">base_model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">target_task</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">strategy</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">strategy_config</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
        <span class="n">training_config</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Create a new adaptation from a pretrained model.
        
        Returns adaptation_id for tracking.
        </span><span class="sh">"""</span>
        <span class="c1"># Generate unique adaptation ID
</span>        <span class="n">adaptation_id</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">base_model_id</span><span class="si">}</span><span class="s">_</span><span class="si">{</span><span class="n">target_task</span><span class="si">}</span><span class="s">_</span><span class="si">{</span><span class="n">strategy</span><span class="si">}</span><span class="s">_</span><span class="si">{</span><span class="nf">hash</span><span class="p">(</span><span class="nf">str</span><span class="p">(</span><span class="n">strategy_config</span><span class="p">))</span><span class="si">}</span><span class="sh">"</span>
        
        <span class="c1"># Get base model
</span>        <span class="n">metadata</span><span class="p">,</span> <span class="n">weights_path</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">registry</span><span class="p">.</span><span class="nf">get_model</span><span class="p">(</span><span class="n">base_model_id</span><span class="p">)</span>
        
        <span class="c1"># Validate compatibility
</span>        <span class="n">compatibility</span> <span class="o">=</span> <span class="n">metadata</span><span class="p">.</span><span class="nf">get_transfer_compatibility</span><span class="p">(</span><span class="n">target_task</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">compatibility</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Warning: Low transfer compatibility (</span><span class="si">{</span><span class="n">compatibility</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">)</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="c1"># Select and configure strategy
</span>        <span class="n">strategy_class</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">STRATEGY_MAP</span><span class="p">[</span><span class="n">strategy</span><span class="p">]</span>
        <span class="n">strategy_instance</span> <span class="o">=</span> <span class="nf">strategy_class</span><span class="p">(</span><span class="o">**</span><span class="n">strategy_config</span><span class="p">)</span>
        
        <span class="c1"># Store adaptation config
</span>        <span class="n">self</span><span class="p">.</span><span class="n">adaptations</span><span class="p">[</span><span class="n">adaptation_id</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">base_model</span><span class="sh">'</span><span class="p">:</span> <span class="n">base_model_id</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">target_task</span><span class="sh">'</span><span class="p">:</span> <span class="n">target_task</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">strategy</span><span class="sh">'</span><span class="p">:</span> <span class="n">strategy</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">strategy_config</span><span class="sh">'</span><span class="p">:</span> <span class="n">strategy_config</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">training_config</span><span class="sh">'</span><span class="p">:</span> <span class="n">training_config</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">status</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">created</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">compatibility_score</span><span class="sh">'</span><span class="p">:</span> <span class="n">compatibility</span>
        <span class="p">}</span>
        
        <span class="k">return</span> <span class="n">adaptation_id</span>
    
    <span class="k">def</span> <span class="nf">recommend_strategy</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">base_model_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">target_dataset_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">compute_budget_hours</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">target_task</span><span class="p">:</span> <span class="nb">str</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">
        Recommend transfer strategy based on constraints.
        
        Decision factors:
        - Dataset size: Small → freeze more, large → fine-tune more
        - Compute budget: Limited → LoRA/partial, ample → full
        - Domain similarity: Similar → partial, different → full
        </span><span class="sh">"""</span>
        <span class="n">metadata</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">registry</span><span class="p">.</span><span class="nf">get_model</span><span class="p">(</span><span class="n">base_model_id</span><span class="p">,</span> <span class="n">load_weights</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">compatibility</span> <span class="o">=</span> <span class="n">metadata</span><span class="p">.</span><span class="nf">get_transfer_compatibility</span><span class="p">(</span><span class="n">target_task</span><span class="p">)</span>
        
        <span class="n">recommendation</span> <span class="o">=</span> <span class="p">{}</span>
        
        <span class="c1"># Dataset size heuristics
</span>        <span class="n">params_per_sample_ratio</span> <span class="o">=</span> <span class="n">metadata</span><span class="p">.</span><span class="n">num_parameters</span> <span class="o">/</span> <span class="n">target_dataset_size</span>
        
        <span class="k">if</span> <span class="n">params_per_sample_ratio</span> <span class="o">&gt;</span> <span class="mi">1000</span><span class="p">:</span>
            <span class="c1"># Very little data relative to model size
</span>            <span class="n">recommendation</span><span class="p">[</span><span class="sh">'</span><span class="s">strategy</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="sh">'</span><span class="s">lora</span><span class="sh">'</span>
            <span class="n">recommendation</span><span class="p">[</span><span class="sh">'</span><span class="s">reason</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Limited data; use parameter-efficient adaptation</span><span class="sh">"</span>
            <span class="n">recommendation</span><span class="p">[</span><span class="sh">'</span><span class="s">config</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">rank</span><span class="sh">'</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="sh">'</span><span class="s">alpha</span><span class="sh">'</span><span class="p">:</span> <span class="mi">8</span><span class="p">}</span>
        
        <span class="k">elif</span> <span class="n">params_per_sample_ratio</span> <span class="o">&gt;</span> <span class="mi">100</span><span class="p">:</span>
            <span class="c1"># Moderate data
</span>            <span class="n">recommendation</span><span class="p">[</span><span class="sh">'</span><span class="s">strategy</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="sh">'</span><span class="s">partial</span><span class="sh">'</span>
            <span class="n">recommendation</span><span class="p">[</span><span class="sh">'</span><span class="s">reason</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Moderate data; freeze early layers</span><span class="sh">"</span>
            <span class="n">recommendation</span><span class="p">[</span><span class="sh">'</span><span class="s">config</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">freeze_ratio</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.7</span><span class="p">}</span>
        
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Abundant data
</span>            <span class="n">recommendation</span><span class="p">[</span><span class="sh">'</span><span class="s">strategy</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="sh">'</span><span class="s">full</span><span class="sh">'</span>
            <span class="n">recommendation</span><span class="p">[</span><span class="sh">'</span><span class="s">reason</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Sufficient data for full fine-tuning</span><span class="sh">"</span>
            <span class="n">recommendation</span><span class="p">[</span><span class="sh">'</span><span class="s">config</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">lr_decay_factor</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.95</span><span class="p">}</span>
        
        <span class="c1"># Compute budget adjustments
</span>        <span class="n">estimated_hours</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_estimate_training_time</span><span class="p">(</span>
            <span class="n">metadata</span><span class="p">,</span> 
            <span class="n">target_dataset_size</span><span class="p">,</span>
            <span class="n">recommendation</span><span class="p">[</span><span class="sh">'</span><span class="s">strategy</span><span class="sh">'</span><span class="p">]</span>
        <span class="p">)</span>
        
        <span class="k">if</span> <span class="n">estimated_hours</span> <span class="o">&gt;</span> <span class="n">compute_budget_hours</span><span class="p">:</span>
            <span class="c1"># Reduce compute requirements
</span>            <span class="k">if</span> <span class="n">recommendation</span><span class="p">[</span><span class="sh">'</span><span class="s">strategy</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="sh">'</span><span class="s">full</span><span class="sh">'</span><span class="p">:</span>
                <span class="n">recommendation</span><span class="p">[</span><span class="sh">'</span><span class="s">strategy</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="sh">'</span><span class="s">partial</span><span class="sh">'</span>
                <span class="n">recommendation</span><span class="p">[</span><span class="sh">'</span><span class="s">config</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">freeze_ratio</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">}</span>
            <span class="k">elif</span> <span class="n">recommendation</span><span class="p">[</span><span class="sh">'</span><span class="s">strategy</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="sh">'</span><span class="s">partial</span><span class="sh">'</span><span class="p">:</span>
                <span class="n">recommendation</span><span class="p">[</span><span class="sh">'</span><span class="s">strategy</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="sh">'</span><span class="s">lora</span><span class="sh">'</span>
                <span class="n">recommendation</span><span class="p">[</span><span class="sh">'</span><span class="s">config</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">rank</span><span class="sh">'</span><span class="p">:</span> <span class="mi">8</span><span class="p">}</span>
        
        <span class="c1"># Domain similarity adjustments
</span>        <span class="k">if</span> <span class="n">compatibility</span> <span class="o">&lt;</span> <span class="mf">0.7</span><span class="p">:</span>
            <span class="c1"># Significant domain shift - need more aggressive adaptation
</span>            <span class="k">if</span> <span class="n">recommendation</span><span class="p">[</span><span class="sh">'</span><span class="s">strategy</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="sh">'</span><span class="s">lora</span><span class="sh">'</span><span class="p">:</span>
                <span class="n">recommendation</span><span class="p">[</span><span class="sh">'</span><span class="s">config</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">rank</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">16</span>  <span class="c1"># Higher rank
</span>            <span class="k">elif</span> <span class="n">recommendation</span><span class="p">[</span><span class="sh">'</span><span class="s">strategy</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="sh">'</span><span class="s">partial</span><span class="sh">'</span><span class="p">:</span>
                <span class="n">recommendation</span><span class="p">[</span><span class="sh">'</span><span class="s">config</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">freeze_ratio</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.3</span>  <span class="c1"># Train more
</span>        
        <span class="k">return</span> <span class="n">recommendation</span>
    
    <span class="k">def</span> <span class="nf">_estimate_training_time</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">metadata</span><span class="p">:</span> <span class="n">PretrainedModelMetadata</span><span class="p">,</span>
        <span class="n">dataset_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">strategy</span><span class="p">:</span> <span class="nb">str</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Estimate training time in hours.</span><span class="sh">"""</span>
        <span class="c1"># Rough estimates based on strategy
</span>        <span class="n">trainable_ratio</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">full</span><span class="sh">'</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">partial</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">lora</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.01</span>
        <span class="p">}</span>
        
        <span class="c1"># Base time: 1 epoch per GB of model per 1M samples
</span>        <span class="n">base_time</span> <span class="o">=</span> <span class="p">(</span><span class="n">metadata</span><span class="p">.</span><span class="n">num_parameters</span> <span class="o">/</span> <span class="mf">1e9</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">dataset_size</span> <span class="o">/</span> <span class="mf">1e6</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">base_time</span> <span class="o">*</span> <span class="n">trainable_ratio</span><span class="p">[</span><span class="n">strategy</span><span class="p">]</span>
</code></pre></div></div>

<h3 id="43-training-engine">4.3 Training Engine</h3>

<p>The component that executes the adaptation:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="n">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="n">torch.optim</span> <span class="kn">import</span> <span class="n">AdamW</span>
<span class="kn">from</span> <span class="n">torch.optim.lr_scheduler</span> <span class="kn">import</span> <span class="n">CosineAnnealingLR</span>
<span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Optional</span>
<span class="kn">import</span> <span class="n">time</span>
<span class="kn">from</span> <span class="n">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>

<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">TrainingConfig</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">Configuration for transfer learning training.</span><span class="sh">"""</span>
    <span class="n">num_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span>
    <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">2e-5</span>
    <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.01</span>
    <span class="n">warmup_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span>
    <span class="n">max_grad_norm</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">early_stopping_patience</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">evaluation_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">save_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">500</span>
    <span class="n">mixed_precision</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="n">gradient_accumulation_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>


<span class="k">class</span> <span class="nc">TransferLearningTrainer</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Trainer optimized for transfer learning.
    
    Key features:
    - Warmup for stability
    - Gradient clipping
    - Early stopping
    - Negative transfer detection
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">strategy</span><span class="p">:</span> <span class="n">AdaptationStrategy</span><span class="p">,</span>
        <span class="n">config</span><span class="p">:</span> <span class="n">TrainingConfig</span><span class="p">,</span>
        <span class="n">train_dataloader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
        <span class="n">eval_dataloader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
        <span class="n">compute_metrics</span><span class="p">:</span> <span class="n">Callable</span>
    <span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">strategy</span><span class="p">.</span><span class="nf">prepare_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">strategy</span> <span class="o">=</span> <span class="n">strategy</span>
        <span class="n">self</span><span class="p">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
        <span class="n">self</span><span class="p">.</span><span class="n">train_loader</span> <span class="o">=</span> <span class="n">train_dataloader</span>
        <span class="n">self</span><span class="p">.</span><span class="n">eval_loader</span> <span class="o">=</span> <span class="n">eval_dataloader</span>
        <span class="n">self</span><span class="p">.</span><span class="n">compute_metrics</span> <span class="o">=</span> <span class="n">compute_metrics</span>
        
        <span class="c1"># Setup optimizer with strategy-specific groups
</span>        <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_create_optimizer</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_create_scheduler</span><span class="p">()</span>
        
        <span class="c1"># Mixed precision
</span>        <span class="n">self</span><span class="p">.</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">amp</span><span class="p">.</span><span class="nc">GradScaler</span><span class="p">()</span> <span class="k">if</span> <span class="n">config</span><span class="p">.</span><span class="n">mixed_precision</span> <span class="k">else</span> <span class="bp">None</span>
        
        <span class="c1"># Tracking
</span>        <span class="n">self</span><span class="p">.</span><span class="n">best_metric</span> <span class="o">=</span> <span class="nf">float</span><span class="p">(</span><span class="sh">'</span><span class="s">-inf</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">patience_counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">self</span><span class="p">.</span><span class="n">training_history</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">baseline_performance</span> <span class="o">=</span> <span class="bp">None</span>
    
    <span class="k">def</span> <span class="nf">_create_optimizer</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Optimizer</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Create optimizer with strategy-specific parameter groups.</span><span class="sh">"""</span>
        <span class="n">param_groups</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">strategy</span><span class="p">.</span><span class="nf">get_optimizer_groups</span><span class="p">(</span>
            <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">,</span> 
            <span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">learning_rate</span>
        <span class="p">)</span>
        
        <span class="k">return</span> <span class="nc">AdamW</span><span class="p">(</span>
            <span class="n">param_groups</span><span class="p">,</span>
            <span class="n">lr</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">weight_decay</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">weight_decay</span>
        <span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_create_scheduler</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Create learning rate scheduler with warmup.</span><span class="sh">"""</span>
        <span class="n">total_steps</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">train_loader</span><span class="p">)</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">num_epochs</span>
        <span class="n">warmup_steps</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">total_steps</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">warmup_ratio</span><span class="p">)</span>
        
        <span class="c1"># Custom scheduler with linear warmup + cosine decay
</span>        <span class="k">def</span> <span class="nf">lr_lambda</span><span class="p">(</span><span class="n">step</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">step</span> <span class="o">&lt;</span> <span class="n">warmup_steps</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">step</span> <span class="o">/</span> <span class="n">warmup_steps</span>
            
            <span class="n">progress</span> <span class="o">=</span> <span class="p">(</span><span class="n">step</span> <span class="o">-</span> <span class="n">warmup_steps</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">total_steps</span> <span class="o">-</span> <span class="n">warmup_steps</span><span class="p">)</span>
            <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cos</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">progress</span> <span class="o">*</span> <span class="mf">3.14159</span><span class="p">)))</span>
        
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">lr_scheduler</span><span class="p">.</span><span class="nc">LambdaLR</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_lambda</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">
        Run the transfer learning training loop.
        
        Returns training metrics and history.
        </span><span class="sh">"""</span>
        <span class="c1"># Evaluate baseline (before any training)
</span>        <span class="n">self</span><span class="p">.</span><span class="n">baseline_performance</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_evaluate</span><span class="p">()</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Baseline performance: </span><span class="si">{</span><span class="n">self</span><span class="p">.</span><span class="n">baseline_performance</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="n">device</span> <span class="o">=</span> <span class="nf">next</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()).</span><span class="n">device</span>
        <span class="n">global_step</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">num_epochs</span><span class="p">):</span>
            <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
            <span class="n">epoch_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">epoch_start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
            
            <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">train_loader</span><span class="p">):</span>
                <span class="c1"># Move batch to device
</span>                <span class="n">batch</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">.</span><span class="nf">items</span><span class="p">()}</span>
                
                <span class="c1"># Forward pass with mixed precision
</span>                <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">amp</span><span class="p">.</span><span class="nf">autocast</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">mixed_precision</span><span class="p">):</span>
                    <span class="n">outputs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">loss</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">gradient_accumulation_steps</span>
                
                <span class="c1"># Backward pass
</span>                <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">scaler</span><span class="p">:</span>
                    <span class="n">self</span><span class="p">.</span><span class="n">scaler</span><span class="p">.</span><span class="nf">scale</span><span class="p">(</span><span class="n">loss</span><span class="p">).</span><span class="nf">backward</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
                
                <span class="c1"># Gradient accumulation
</span>                <span class="nf">if </span><span class="p">(</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">gradient_accumulation_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="c1"># Gradient clipping
</span>                    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">scaler</span><span class="p">:</span>
                        <span class="n">self</span><span class="p">.</span><span class="n">scaler</span><span class="p">.</span><span class="nf">unscale_</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">)</span>
                    
                    <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">clip_grad_norm_</span><span class="p">(</span>
                        <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> 
                        <span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">max_grad_norm</span>
                    <span class="p">)</span>
                    
                    <span class="c1"># Optimizer step
</span>                    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">scaler</span><span class="p">:</span>
                        <span class="n">self</span><span class="p">.</span><span class="n">scaler</span><span class="p">.</span><span class="nf">step</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">)</span>
                        <span class="n">self</span><span class="p">.</span><span class="n">scaler</span><span class="p">.</span><span class="nf">update</span><span class="p">()</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
                    
                    <span class="n">self</span><span class="p">.</span><span class="n">scheduler</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
                    <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
                    <span class="n">global_step</span> <span class="o">+=</span> <span class="mi">1</span>
                
                <span class="n">epoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">gradient_accumulation_steps</span>
                
                <span class="c1"># Evaluation
</span>                <span class="k">if</span> <span class="n">global_step</span> <span class="o">%</span> <span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">evaluation_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">metrics</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_evaluate</span><span class="p">()</span>
                    <span class="n">self</span><span class="p">.</span><span class="nf">_check_negative_transfer</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>
                    
                    <span class="n">self</span><span class="p">.</span><span class="n">training_history</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span>
                        <span class="sh">'</span><span class="s">step</span><span class="sh">'</span><span class="p">:</span> <span class="n">global_step</span><span class="p">,</span>
                        <span class="sh">'</span><span class="s">epoch</span><span class="sh">'</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
                        <span class="sh">'</span><span class="s">metrics</span><span class="sh">'</span><span class="p">:</span> <span class="n">metrics</span><span class="p">,</span>
                        <span class="sh">'</span><span class="s">lr</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">scheduler</span><span class="p">.</span><span class="nf">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="p">})</span>
                    
                    <span class="c1"># Early stopping check
</span>                    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="nf">_check_early_stopping</span><span class="p">(</span><span class="n">metrics</span><span class="p">):</span>
                        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Early stopping at step </span><span class="si">{</span><span class="n">global_step</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
                        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">_finalize_training</span><span class="p">()</span>
            
            <span class="n">epoch_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">epoch_start</span>
            <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">epoch_loss</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">train_loader</span><span class="p">)</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s">: loss=</span><span class="si">{</span><span class="n">avg_loss</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">, time=</span><span class="si">{</span><span class="n">epoch_time</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s">s</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">_finalize_training</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">_evaluate</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">Evaluate the model on the evaluation set.</span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
        <span class="n">all_preds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">all_labels</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">eval_loader</span><span class="p">:</span>
                <span class="n">device</span> <span class="o">=</span> <span class="nf">next</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()).</span><span class="n">device</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">.</span><span class="nf">items</span><span class="p">()}</span>
                
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
                <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>
                
                <span class="n">preds</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">logits</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">all_preds</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span><span class="n">preds</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">())</span>
                <span class="n">all_labels</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="sh">'</span><span class="s">labels</span><span class="sh">'</span><span class="p">].</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">())</span>
        
        <span class="n">metrics</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">compute_metrics</span><span class="p">(</span><span class="n">all_preds</span><span class="p">,</span> <span class="n">all_labels</span><span class="p">)</span>
        <span class="n">metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">eval_loss</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">eval_loader</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">metrics</span>
    
    <span class="k">def</span> <span class="nf">_check_negative_transfer</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">current_metrics</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]):</span>
        <span class="sh">"""</span><span class="s">
        Detect and warn about negative transfer.
        
        Negative transfer occurs when pretrained knowledge hurts performance.
        </span><span class="sh">"""</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">baseline_performance</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">return</span>
        
        <span class="n">primary_metric</span> <span class="o">=</span> <span class="sh">'</span><span class="s">f1</span><span class="sh">'</span> <span class="k">if</span> <span class="sh">'</span><span class="s">f1</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">current_metrics</span> <span class="k">else</span> <span class="nf">list</span><span class="p">(</span><span class="n">current_metrics</span><span class="p">.</span><span class="nf">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="k">if</span> <span class="n">current_metrics</span><span class="p">[</span><span class="n">primary_metric</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">self</span><span class="p">.</span><span class="n">baseline_performance</span><span class="p">[</span><span class="n">primary_metric</span><span class="p">]</span> <span class="o">*</span> <span class="mf">0.95</span><span class="p">:</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">⚠️ Warning: Possible negative transfer detected!</span><span class="sh">"</span><span class="p">)</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">  Baseline: </span><span class="si">{</span><span class="n">self</span><span class="p">.</span><span class="n">baseline_performance</span><span class="p">[</span><span class="n">primary_metric</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">  Current:  </span><span class="si">{</span><span class="n">current_metrics</span><span class="p">[</span><span class="n">primary_metric</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
            <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">  Consider: reducing learning rate, freezing more layers, or different pretrained model</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_check_early_stopping</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">metrics</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Check if training should stop early.</span><span class="sh">"""</span>
        <span class="n">primary_metric</span> <span class="o">=</span> <span class="sh">'</span><span class="s">f1</span><span class="sh">'</span> <span class="k">if</span> <span class="sh">'</span><span class="s">f1</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">metrics</span> <span class="k">else</span> <span class="nf">list</span><span class="p">(</span><span class="n">metrics</span><span class="p">.</span><span class="nf">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">current</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">[</span><span class="n">primary_metric</span><span class="p">]</span>
        
        <span class="k">if</span> <span class="n">current</span> <span class="o">&gt;</span> <span class="n">self</span><span class="p">.</span><span class="n">best_metric</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">best_metric</span> <span class="o">=</span> <span class="n">current</span>
            <span class="n">self</span><span class="p">.</span><span class="n">patience_counter</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="c1"># Save best model
</span>            <span class="n">self</span><span class="p">.</span><span class="nf">_save_checkpoint</span><span class="p">(</span><span class="sh">'</span><span class="s">best</span><span class="sh">'</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">patience_counter</span> <span class="o">+=</span> <span class="mi">1</span>
        
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">patience_counter</span> <span class="o">&gt;=</span> <span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">early_stopping_patience</span>
    
    <span class="k">def</span> <span class="nf">_save_checkpoint</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Save model checkpoint.</span><span class="sh">"""</span>
        <span class="n">checkpoint</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">model_state_dict</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">(),</span>
            <span class="sh">'</span><span class="s">optimizer_state_dict</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">(),</span>
            <span class="sh">'</span><span class="s">scheduler_state_dict</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">scheduler</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">(),</span>
            <span class="sh">'</span><span class="s">best_metric</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">best_metric</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">training_history</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">training_history</span>
        <span class="p">}</span>
        <span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="sa">f</span><span class="sh">"</span><span class="s">checkpoints/</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s">.pt</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_finalize_training</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">Finalize training and return summary.</span><span class="sh">"""</span>
        <span class="n">final_metrics</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_evaluate</span><span class="p">()</span>
        
        <span class="k">return</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">final_metrics</span><span class="sh">'</span><span class="p">:</span> <span class="n">final_metrics</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">baseline_metrics</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">baseline_performance</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">improvement</span><span class="sh">'</span><span class="p">:</span> <span class="p">{</span>
                <span class="n">k</span><span class="p">:</span> <span class="n">final_metrics</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">baseline_performance</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">final_metrics</span>
            <span class="p">},</span>
            <span class="sh">'</span><span class="s">best_metric</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">best_metric</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">total_steps</span><span class="sh">'</span><span class="p">:</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">training_history</span><span class="p">),</span>
            <span class="sh">'</span><span class="s">history</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">training_history</span>
        <span class="p">}</span>
</code></pre></div></div>

<h2 id="5-domain-adaptation">5. Domain Adaptation</h2>

<p>When source and target domains differ significantly:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">DomainAdaptation</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Handle domain shift between pretraining and target domains.
    
    Techniques:
    - Gradual unfreezing
    - Domain-adversarial training
    - Self-training with pseudo-labels
    </span><span class="sh">"""</span>
    
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">gradual_unfreeze</span><span class="p">(</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">train_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
        <span class="n">num_stages</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Gradually unfreeze layers during training.
        
        This helps adaptation when there</span><span class="sh">'</span><span class="s">s significant domain shift.
        </span><span class="sh">"""</span>
        <span class="n">modules</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">named_modules</span><span class="p">())</span>
        <span class="n">stage_size</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">modules</span><span class="p">)</span> <span class="o">//</span> <span class="n">num_stages</span>
        
        <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_stages</span><span class="p">):</span>
            <span class="c1"># Unfreeze next batch of layers
</span>            <span class="n">start_idx</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">modules</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">stage</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">stage_size</span>
            
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">module</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">modules</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">start_idx</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">module</span><span class="p">.</span><span class="nf">parameters</span><span class="p">():</span>
                        <span class="n">param</span><span class="p">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="bp">True</span>
            
            <span class="c1"># Train for this stage
</span>            <span class="n">trainable_count</span> <span class="o">=</span> <span class="nf">sum</span><span class="p">(</span>
                <span class="n">p</span><span class="p">.</span><span class="nf">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="p">.</span><span class="n">requires_grad</span>
            <span class="p">)</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Stage </span><span class="si">{</span><span class="n">stage</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">trainable_count</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s"> trainable parameters</span><span class="sh">"</span><span class="p">)</span>
            
            <span class="nf">train_fn</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">domain_adversarial_training</span><span class="p">(</span>
        <span class="n">feature_extractor</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">task_classifier</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">domain_classifier</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">source_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
        <span class="n">target_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
        <span class="n">lambda_domain</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span>
    <span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Domain Adversarial Neural Network (DANN) training.
        
        The domain classifier tries to distinguish source from target.
        The feature extractor tries to fool the domain classifier
        while performing well on the task.
        </span><span class="sh">"""</span>
        
        <span class="k">class</span> <span class="nc">GradientReversal</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">autograd</span><span class="p">.</span><span class="n">Function</span><span class="p">):</span>
            <span class="nd">@staticmethod</span>
            <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">):</span>
                <span class="n">ctx</span><span class="p">.</span><span class="n">lambda_</span> <span class="o">=</span> <span class="n">lambda_</span>
                <span class="k">return</span> <span class="n">x</span><span class="p">.</span><span class="nf">clone</span><span class="p">()</span>
            
            <span class="nd">@staticmethod</span>
            <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">):</span>
                <span class="k">return</span> <span class="o">-</span><span class="n">ctx</span><span class="p">.</span><span class="n">lambda_</span> <span class="o">*</span> <span class="n">grad_output</span><span class="p">,</span> <span class="bp">None</span>
        
        <span class="c1"># Training loop would alternate between:
</span>        <span class="c1"># 1. Task loss on source domain
</span>        <span class="c1"># 2. Domain classification loss (with gradient reversal)
</span>        
        <span class="c1"># This encourages domain-invariant features
</span>        <span class="k">pass</span>
    
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">self_training</span><span class="p">(</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">labeled_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
        <span class="n">unlabeled_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
        <span class="n">confidence_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
        <span class="n">num_iterations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Self-training: Generate pseudo-labels for unlabeled data.
        
        Useful when target domain has limited labels.
        </span><span class="sh">"""</span>
        <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">):</span>
            <span class="c1"># Step 1: Train on labeled data
</span>            <span class="c1"># ... training code ...
</span>            
            <span class="c1"># Step 2: Generate pseudo-labels for unlabeled data
</span>            <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
            <span class="n">pseudo_labels</span> <span class="o">=</span> <span class="p">[]</span>
            
            <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
                <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">unlabeled_loader</span><span class="p">:</span>
                    <span class="n">logits</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="sh">'</span><span class="s">input_ids</span><span class="sh">'</span><span class="p">])</span>
                    <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                    <span class="n">max_probs</span><span class="p">,</span> <span class="n">predictions</span> <span class="o">=</span> <span class="n">probs</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                    
                    <span class="c1"># Only keep high-confidence predictions
</span>                    <span class="n">confident_mask</span> <span class="o">=</span> <span class="n">max_probs</span> <span class="o">&gt;</span> <span class="n">confidence_threshold</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="sh">'</span><span class="s">input_ids</span><span class="sh">'</span><span class="p">])):</span>
                        <span class="k">if</span> <span class="n">confident_mask</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                            <span class="n">pseudo_labels</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span>
                                <span class="sh">'</span><span class="s">input_ids</span><span class="sh">'</span><span class="p">:</span> <span class="n">batch</span><span class="p">[</span><span class="sh">'</span><span class="s">input_ids</span><span class="sh">'</span><span class="p">][</span><span class="n">i</span><span class="p">],</span>
                                <span class="sh">'</span><span class="s">label</span><span class="sh">'</span><span class="p">:</span> <span class="n">predictions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                            <span class="p">})</span>
            
            <span class="c1"># Step 3: Add pseudo-labeled data to training set
</span>            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Iteration </span><span class="si">{</span><span class="n">iteration</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">pseudo_labels</span><span class="p">)</span><span class="si">}</span><span class="s"> pseudo-labels</span><span class="sh">"</span><span class="p">)</span>
            
            <span class="c1"># Step 4: Retrain with combined data
</span>            <span class="c1"># ... training code with pseudo-labels ...
</span></code></pre></div></div>

<h2 id="6-evaluation-and-monitoring">6. Evaluation and Monitoring</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">TransferEvaluationMetrics</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">Comprehensive metrics for evaluating transfer learning.</span><span class="sh">"""</span>
    
    <span class="c1"># Task performance
</span>    <span class="n">task_accuracy</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">task_f1</span><span class="p">:</span> <span class="nb">float</span>
    
    <span class="c1"># Transfer effectiveness
</span>    <span class="n">transfer_ratio</span><span class="p">:</span> <span class="nb">float</span>  <span class="c1"># Performance vs training from scratch
</span>    <span class="n">sample_efficiency</span><span class="p">:</span> <span class="nb">float</span>  <span class="c1"># Samples needed for equivalent performance
</span>    
    <span class="c1"># Adaptation quality
</span>    <span class="n">forgetting_score</span><span class="p">:</span> <span class="nb">float</span>  <span class="c1"># Performance drop on source tasks
</span>    <span class="n">generalization_gap</span><span class="p">:</span> <span class="nb">float</span>  <span class="c1"># Train vs eval performance difference
</span>    
    <span class="c1"># Efficiency
</span>    <span class="n">trainable_parameter_ratio</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">training_time_hours</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">memory_peak_gb</span><span class="p">:</span> <span class="nb">float</span>


<span class="k">class</span> <span class="nc">TransferEvaluator</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Evaluate transfer learning effectiveness.
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">adapted_model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">scratch_model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">],</span>
        <span class="n">source_eval_loader</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">DataLoader</span><span class="p">],</span>
        <span class="n">target_eval_loader</span><span class="p">:</span> <span class="n">DataLoader</span>
    <span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">adapted_model</span> <span class="o">=</span> <span class="n">adapted_model</span>
        <span class="n">self</span><span class="p">.</span><span class="n">scratch_model</span> <span class="o">=</span> <span class="n">scratch_model</span>
        <span class="n">self</span><span class="p">.</span><span class="n">source_loader</span> <span class="o">=</span> <span class="n">source_eval_loader</span>
        <span class="n">self</span><span class="p">.</span><span class="n">target_loader</span> <span class="o">=</span> <span class="n">target_eval_loader</span>
    
    <span class="k">def</span> <span class="nf">compute_transfer_ratio</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        How much better is transfer learning vs training from scratch?
        
        Ratio &gt; 1.0 means transfer learning is better.
        </span><span class="sh">"""</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">scratch_model</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">None</span>
        
        <span class="n">adapted_score</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_evaluate</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">adapted_model</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">target_loader</span><span class="p">)</span>
        <span class="n">scratch_score</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_evaluate</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">scratch_model</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">target_loader</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">adapted_score</span> <span class="o">/</span> <span class="nf">max</span><span class="p">(</span><span class="n">scratch_score</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">compute_forgetting_score</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Measure catastrophic forgetting on source domain.
        
        Lower is better (less forgetting).
        </span><span class="sh">"""</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">source_loader</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">None</span>
        
        <span class="c1"># Compare performance on source domain before/after adaptation
</span>        <span class="n">source_score</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_evaluate</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">adapted_model</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">source_loader</span><span class="p">)</span>
        
        <span class="c1"># Ideally compare to original pretrained model performance
</span>        <span class="c1"># For now, return absolute source performance
</span>        <span class="k">return</span> <span class="n">source_score</span>
    
    <span class="k">def</span> <span class="nf">compute_sample_efficiency</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">target_performance</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">training_samples</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">
        Measure how many samples needed to reach target performance.
        </span><span class="sh">"""</span>
        <span class="c1"># Train with increasing amounts of data
</span>        <span class="c1"># Return samples needed for transfer vs scratch
</span>        <span class="k">pass</span>
    
    <span class="k">def</span> <span class="nf">_evaluate</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Evaluate model on dataloader.</span><span class="sh">"""</span>
        <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
                <span class="n">preds</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">logits</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">preds</span> <span class="o">==</span> <span class="n">batch</span><span class="p">[</span><span class="sh">'</span><span class="s">labels</span><span class="sh">'</span><span class="p">]).</span><span class="nf">sum</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span>
                <span class="n">total</span> <span class="o">+=</span> <span class="nf">len</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="sh">'</span><span class="s">labels</span><span class="sh">'</span><span class="p">])</span>
        
        <span class="k">return</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
    
    <span class="k">def</span> <span class="nf">generate_report</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Generate a comprehensive transfer learning report.</span><span class="sh">"""</span>
        <span class="n">transfer_ratio</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">compute_transfer_ratio</span><span class="p">()</span>
        <span class="n">forgetting</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">compute_forgetting_score</span><span class="p">()</span>
        
        <span class="n">report</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"""</span><span class="s">
        ╔══════════════════════════════════════════════════════════╗
        ║            Transfer Learning Evaluation Report            ║
        ╠══════════════════════════════════════════════════════════╣
        ║ Transfer Ratio:        </span><span class="si">{</span><span class="n">transfer_ratio</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">x                        ║
        ║ Forgetting Score:      </span><span class="si">{</span><span class="n">forgetting</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">                            ║
        ║ Target Performance:    </span><span class="si">{</span><span class="n">self</span><span class="p">.</span><span class="nf">_evaluate</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">adapted_model</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">target_loader</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">                            ║
        ╚══════════════════════════════════════════════════════════╝
        </span><span class="sh">"""</span>
        <span class="k">return</span> <span class="n">report</span>
</code></pre></div></div>

<h2 id="7-real-world-case-study-bert-fine-tuning-at-scale">7. Real-World Case Study: BERT Fine-Tuning at Scale</h2>

<h3 id="netflix-recommendation-personalization">Netflix Recommendation Personalization</h3>

<p>Netflix uses transfer learning to personalize recommendations:</p>

<p><strong>Architecture:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>┌─────────────────────────────────────────────────────────────────┐
│              Netflix Personalization Transfer Learning          │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌──────────────┐    ┌──────────────┐    ┌──────────────┐      │
│  │ Global Model │    │ Region Model │    │  User Model  │      │
│  │ (Pretrained) │───▶│ (Fine-tuned) │───▶│  (LoRA/few)  │      │
│  │              │    │              │    │              │      │
│  │ 500M users   │    │ ~10M users   │    │ Per-user     │      │
│  │ General      │    │ Regional     │    │ Personalized │      │
│  │ patterns     │    │ preferences  │    │ tastes       │      │
│  └──────────────┘    └──────────────┘    └──────────────┘      │
│                                                                 │
│  Training Cost:      Inference:         Update Frequency:      │
│  $100K+ once         &lt;10ms p99          Daily/Hourly           │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
</code></pre></div></div>

<p><strong>Key Decisions:</strong></p>
<ol>
  <li><strong>Hierarchical transfer</strong>: Global → Regional → User</li>
  <li><strong>LoRA for user models</strong>: &lt; 1MB per user, instant adaptation</li>
  <li><strong>Continuous adaptation</strong>: User models update with new interactions</li>
  <li><strong>Fallback strategy</strong>: New users use regional model until enough data</li>
</ol>

<h2 id="8-cost-analysis">8. Cost Analysis</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">estimate_transfer_learning_costs</span><span class="p">(</span>
    <span class="n">model_params</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">target_dataset_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">strategy</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">compute_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">"</span><span class="s">a100</span><span class="sh">"</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
    <span class="sh">"""</span><span class="s">
    Estimate costs for transfer learning vs training from scratch.
    </span><span class="sh">"""</span>
    
    <span class="c1"># GPU costs (per hour)
</span>    <span class="n">gpu_costs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="sh">"</span><span class="s">a100</span><span class="sh">"</span><span class="p">:</span> <span class="mf">3.50</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">v100</span><span class="sh">"</span><span class="p">:</span> <span class="mf">1.50</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">t4</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.35</span>
    <span class="p">}</span>
    
    <span class="c1"># Training time estimates (hours)
</span>    <span class="n">params_billions</span> <span class="o">=</span> <span class="n">model_params</span> <span class="o">/</span> <span class="mf">1e9</span>
    <span class="n">data_millions</span> <span class="o">=</span> <span class="n">target_dataset_size</span> <span class="o">/</span> <span class="mf">1e6</span>
    
    <span class="c1"># Scratch training: ~1 hour per billion params per 10M samples
</span>    <span class="n">scratch_hours</span> <span class="o">=</span> <span class="n">params_billions</span> <span class="o">*</span> <span class="n">data_millions</span> <span class="o">*</span> <span class="mi">10</span>
    
    <span class="c1"># Transfer learning: much faster
</span>    <span class="n">transfer_multipliers</span> <span class="o">=</span> <span class="p">{</span>
        <span class="sh">'</span><span class="s">full</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>      <span class="c1"># 10% of scratch time
</span>        <span class="sh">'</span><span class="s">partial</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.05</span><span class="p">,</span>  <span class="c1"># 5% of scratch time
</span>        <span class="sh">'</span><span class="s">lora</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.02</span>      <span class="c1"># 2% of scratch time
</span>    <span class="p">}</span>
    
    <span class="n">transfer_hours</span> <span class="o">=</span> <span class="n">scratch_hours</span> <span class="o">*</span> <span class="n">transfer_multipliers</span><span class="p">[</span><span class="n">strategy</span><span class="p">]</span>
    
    <span class="n">hourly_rate</span> <span class="o">=</span> <span class="n">gpu_costs</span><span class="p">[</span><span class="n">compute_type</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="p">{</span>
        <span class="sh">'</span><span class="s">scratch_cost</span><span class="sh">'</span><span class="p">:</span> <span class="n">scratch_hours</span> <span class="o">*</span> <span class="n">hourly_rate</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">transfer_cost</span><span class="sh">'</span><span class="p">:</span> <span class="n">transfer_hours</span> <span class="o">*</span> <span class="n">hourly_rate</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">savings</span><span class="sh">'</span><span class="p">:</span> <span class="p">(</span><span class="n">scratch_hours</span> <span class="o">-</span> <span class="n">transfer_hours</span><span class="p">)</span> <span class="o">*</span> <span class="n">hourly_rate</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">savings_percent</span><span class="sh">'</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">transfer_hours</span> <span class="o">/</span> <span class="n">scratch_hours</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">scratch_hours</span><span class="sh">'</span><span class="p">:</span> <span class="n">scratch_hours</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">transfer_hours</span><span class="sh">'</span><span class="p">:</span> <span class="n">transfer_hours</span>
    <span class="p">}</span>


<span class="c1"># Example
</span><span class="n">costs</span> <span class="o">=</span> <span class="nf">estimate_transfer_learning_costs</span><span class="p">(</span>
    <span class="n">model_params</span><span class="o">=</span><span class="mi">7_000_000_000</span><span class="p">,</span>  <span class="c1"># 7B params
</span>    <span class="n">target_dataset_size</span><span class="o">=</span><span class="mi">100_000</span><span class="p">,</span>  <span class="c1"># 100K samples
</span>    <span class="n">strategy</span><span class="o">=</span><span class="sh">'</span><span class="s">lora</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">compute_type</span><span class="o">=</span><span class="sh">'</span><span class="s">a100</span><span class="sh">'</span>
<span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Scratch training: $</span><span class="si">{</span><span class="n">costs</span><span class="p">[</span><span class="sh">'</span><span class="s">scratch_cost</span><span class="sh">'</span><span class="p">]</span><span class="si">:</span><span class="p">,.</span><span class="mi">0</span><span class="n">f</span><span class="si">}</span><span class="s"> (</span><span class="si">{</span><span class="n">costs</span><span class="p">[</span><span class="sh">'</span><span class="s">scratch_hours</span><span class="sh">'</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="si">}</span><span class="s"> hours)</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Transfer learning: $</span><span class="si">{</span><span class="n">costs</span><span class="p">[</span><span class="sh">'</span><span class="s">transfer_cost</span><span class="sh">'</span><span class="p">]</span><span class="si">:</span><span class="p">,.</span><span class="mi">0</span><span class="n">f</span><span class="si">}</span><span class="s"> (</span><span class="si">{</span><span class="n">costs</span><span class="p">[</span><span class="sh">'</span><span class="s">transfer_hours</span><span class="sh">'</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="si">}</span><span class="s"> hours)</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Savings: $</span><span class="si">{</span><span class="n">costs</span><span class="p">[</span><span class="sh">'</span><span class="s">savings</span><span class="sh">'</span><span class="p">]</span><span class="si">:</span><span class="p">,.</span><span class="mi">0</span><span class="n">f</span><span class="si">}</span><span class="s"> (</span><span class="si">{</span><span class="n">costs</span><span class="p">[</span><span class="sh">'</span><span class="s">savings_percent</span><span class="sh">'</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="si">}</span><span class="s">%)</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="9-common-failure-modes">9. Common Failure Modes</h2>

<h3 id="failure-mode-1-negative-transfer">Failure Mode 1: Negative Transfer</h3>

<p><strong>Symptoms:</strong> Performance worse than training from scratch
<strong>Causes:</strong></p>
<ul>
  <li>Source and target domains too different</li>
  <li>Pretrained features encode wrong inductive biases</li>
</ul>

<p><strong>Solutions:</strong></p>
<ul>
  <li>Use domain-adversarial training</li>
  <li>Select a more appropriate pretrained model</li>
  <li>Train from scratch on combined data</li>
</ul>

<h3 id="failure-mode-2-catastrophic-forgetting">Failure Mode 2: Catastrophic Forgetting</h3>

<p><strong>Symptoms:</strong> Performance on source tasks degrades
<strong>Causes:</strong></p>
<ul>
  <li>Learning rate too high</li>
  <li>Training too long</li>
  <li>Fine-tuning all layers</li>
</ul>

<p><strong>Solutions:</strong></p>
<ul>
  <li>Use elastic weight consolidation (EWC)</li>
  <li>Freeze early layers</li>
  <li>Use smaller learning rates</li>
</ul>

<h3 id="failure-mode-3-underfitting-target-task">Failure Mode 3: Underfitting Target Task</h3>

<p><strong>Symptoms:</strong> Poor performance despite sufficient data
<strong>Causes:</strong></p>
<ul>
  <li>Too many frozen layers</li>
  <li>Learning rate too low</li>
  <li>Not enough training epochs</li>
</ul>

<p><strong>Solutions:</strong></p>
<ul>
  <li>Gradually unfreeze layers</li>
  <li>Increase learning rate</li>
  <li>Train longer with early stopping</li>
</ul>

<h2 id="10-connection-to-cross-lingual-speech-transfer">10. Connection to Cross-Lingual Speech Transfer</h2>

<p>Transfer learning principles directly apply to cross-lingual speech systems:</p>

<table>
  <thead>
    <tr>
      <th>Concept</th>
      <th>NLP Transfer Learning</th>
      <th>Speech Cross-Lingual Transfer</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Source data</td>
      <td>English text corpus</td>
      <td>High-resource languages</td>
    </tr>
    <tr>
      <td>Target task</td>
      <td>Sentiment in French</td>
      <td>ASR in low-resource language</td>
    </tr>
    <tr>
      <td>Frozen layers</td>
      <td>Word embeddings</td>
      <td>Acoustic encoder</td>
    </tr>
    <tr>
      <td>Fine-tuned layers</td>
      <td>Classification head</td>
      <td>Language-specific decoder</td>
    </tr>
    <tr>
      <td>Domain adaptation</td>
      <td>Text style transfer</td>
      <td>Accent adaptation</td>
    </tr>
  </tbody>
</table>

<p>Both rely on the insight that <strong>lower-level representations are more universal</strong> (word subunits, phonemes) while <strong>higher-level representations are task-specific</strong> (sentiment, language grammar).</p>

<h2 id="11-key-takeaways">11. Key Takeaways</h2>

<ol>
  <li><strong>Strategy Selection Matters</strong>
    <ul>
      <li>Small data → LoRA or partial fine-tuning</li>
      <li>Large data + shift → Full fine-tuning with discriminative LRs</li>
      <li>Multiple tasks → LoRA with task-specific adapters</li>
    </ul>
  </li>
  <li><strong>Monitor for Negative Transfer</strong>
    <ul>
      <li>Always evaluate against a baseline</li>
      <li>Watch for performance degradation early in training</li>
    </ul>
  </li>
  <li><strong>Efficiency Compounds</strong>
    <ul>
      <li>LoRA: 100x fewer trainable parameters</li>
      <li>Partial fine-tuning: 10x faster convergence</li>
      <li>Proper LR scheduling: 2-3x better final performance</li>
    </ul>
  </li>
  <li><strong>Hierarchical Transfer Works Best</strong>
    <ul>
      <li>Global → Domain → Task-specific</li>
      <li>Each level can use different strategies</li>
    </ul>
  </li>
  <li><strong>Production Considerations</strong>
    <ul>
      <li>Merge LoRA weights for inference efficiency</li>
      <li>Version both base models and adapters</li>
      <li>A/B test transfer strategies</li>
    </ul>
  </li>
</ol>

<hr />

<p><strong>Originally published at:</strong> <a href="https://www.arunbaby.com/ml-system-design/0046-transfer-learning/">arunbaby.com/ml-system-design/0046-transfer-learning</a></p>

<p><em>If you found this helpful, consider sharing it with others who might benefit.</em></p>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#domain-adaptation" class="page__taxonomy-item p-category" rel="tag">domain-adaptation</a><span class="sep">, </span>
    
      <a href="/tags/#fine-tuning" class="page__taxonomy-item p-category" rel="tag">fine-tuning</a><span class="sep">, </span>
    
      <a href="/tags/#knowledge-transfer" class="page__taxonomy-item p-category" rel="tag">knowledge-transfer</a><span class="sep">, </span>
    
      <a href="/tags/#ml-infrastructure" class="page__taxonomy-item p-category" rel="tag">ml-infrastructure</a><span class="sep">, </span>
    
      <a href="/tags/#model-adaptation" class="page__taxonomy-item p-category" rel="tag">model-adaptation</a><span class="sep">, </span>
    
      <a href="/tags/#pretrained-models" class="page__taxonomy-item p-category" rel="tag">pretrained-models</a><span class="sep">, </span>
    
      <a href="/tags/#transfer-learning" class="page__taxonomy-item p-category" rel="tag">transfer-learning</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#ml-system-design" class="page__taxonomy-item p-category" rel="tag">ml-system-design</a>
    
    </span>
  </p>


        
      </footer>

      <div class="page__related page__related--full">
  <h2 class="page__related-title">Related across topics</h2>
  <style>
    /* Make section span full content width and use 2 equal columns */
    .page__related--full { float: inline-start; width: 100%; padding: 0; }
    .cross-related-grid { display: grid; grid-template-columns: repeat(2, minmax(0, 1fr)); gap: 2rem; }
    @media (max-width: 768px) { .cross-related-grid { grid-template-columns: 1fr; } }
    /* Ensure archive cards stretch nicely in the grid */
    .cross-related-grid .list__item, .cross-related-grid .grid__item { width: auto; float: none; margin: 0; }
  </style>
  <div class="cross-related-grid">
    



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/dsa/0046-binary-tree-max-path-sum/" rel="permalink">Binary Tree Maximum Path Sum
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          17 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“Every path has a peak—find the one with the maximum sum.”
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/speech-tech/0046-cross-lingual-speech-transfer/" rel="permalink">Cross-Lingual Speech Transfer
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          17 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“Teach a model one language and it learns to hear them all.”
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ai-agents/0046-token-efficiency-optimization/" rel="permalink">Token Efficiency Optimization
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          22 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“Every token has a cost—make each one count.”
</p>
  </article>
</div>

  </div>
</div>

      <section class="page__share">
  <h4 class="page__share-title">Share on</h4>

  <a href="https://twitter.com/intent/tweet?via=arunbaby0&text=Transfer+Learning+Systems%20https%3A%2F%2Fwww.arunbaby.com%2Fml-system-design%2F0046-transfer-learning%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.arunbaby.com%2Fml-system-design%2F0046-transfer-learning%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.arunbaby.com/ml-system-design/0046-transfer-learning/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/ml-system-design/0045-rag-systems/" class="pagination--pager" title="RAG Systems">Previous</a>
    
    
      <a href="/ml-system-design/0047-model-serialization/" class="pagination--pager" title="Model Serialization Systems">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 1990 - 2143 <a href="https://www.arunbaby.com">Arun Baby</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JRJPEC9SS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0JRJPEC9SS', { 'anonymize_ip': false});
</script>








  </body>
</html>
