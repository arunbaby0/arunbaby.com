<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Real-time Personalization - Arun Baby</title>
<meta name="description" content="“Generalization is the goal of ML, but Personalization is the goal of Products. Real-time personalization is about capturing the intent of the ‘now’.”">


  <meta name="author" content="Arun Baby">
  
  <meta property="article:author" content="Arun Baby">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Arun Baby">
<meta property="og:title" content="Real-time Personalization">
<meta property="og:url" content="https://www.arunbaby.com/ml-system-design/0056-real-time-personalization/">


  <meta property="og:description" content="“Generalization is the goal of ML, but Personalization is the goal of Products. Real-time personalization is about capturing the intent of the ‘now’.”">



  <meta property="og:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">



  <meta name="twitter:site" content="@arunbaby0">
  <meta name="twitter:title" content="Real-time Personalization">
  <meta name="twitter:description" content="“Generalization is the goal of ML, but Personalization is the goal of Products. Real-time personalization is about capturing the intent of the ‘now’.”">
  <meta name="twitter:url" content="https://www.arunbaby.com/ml-system-design/0056-real-time-personalization/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">
    
  

  



  <meta property="article:published_time" content="2025-12-31T09:51:02+05:30">





  

  


<link rel="canonical" href="https://www.arunbaby.com/ml-system-design/0056-real-time-personalization/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Baby Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          <span class="site-subtitle">Arun Baby</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/dsa/"
                
                
              >DSA</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ml-system-design/"
                
                
              >ML Systems</a>
            </li><li class="masthead__menu-item">
              <a
                href="/speech-tech/"
                
                
              >Speech Tech</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ai-agents/"
                
                
              >AI Agents</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li><li class="masthead__menu-item">
              <a
                href="/statuses/"
                
                
              >Statuses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/contact/"
                
                
              >Contact</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main" class="no-author-sidebar">
  
  <div class="sidebar sticky">
  
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Real-time Personalization">
    <meta itemprop="description" content="“Generalization is the goal of ML, but Personalization is the goal of Products. Real-time personalization is about capturing the intent of the ‘now’.”">
    <meta itemprop="datePublished" content="2025-12-31T09:51:02+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://www.arunbaby.com/ml-system-design/0056-real-time-personalization/" itemprop="url">Real-time Personalization
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          18 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#1-introduction-the-death-of-the-static-app">1. Introduction: The Death of the “Static” App</a></li><li><a href="#2-industry-standard-the-multi-stage-pipeline">2. Industry Standard: The Multi-Stage Pipeline</a></li><li><a href="#2-the-core-challenge-the-latencyquality-trade-off">2. The Core Challenge: The Latency/Quality Trade-off</a></li><li><a href="#3-high-level-architecture-the-lambdakappa-evolution">3. High-Level Architecture: The Lambda/Kappa Evolution</a><ul><li><a href="#31-the-batch-layer-past-intents">3.1 The Batch Layer (Past Intents)</a></li><li><a href="#32-the-nearlinestreaming-layer-recent-intents">3.2 The Nearline/Streaming Layer (Recent Intents)</a></li><li><a href="#33-the-onlineserving-layer-instant-intent">3.3 The Online/Serving Layer (Instant Intent)</a></li></ul></li><li><a href="#4-component-deep-dive-the-feature-store">4. Component Deep-Dive: The Feature Store</a><ul><li><a href="#41-feature-consistency-the-training-serving-skew">4.1 Feature Consistency: The “Training-Serving Skew”</a></li><li><a href="#42-dynamic-windowing">4.2 Dynamic Windowing</a></li></ul></li><li><a href="#5-candidate-retrieval-finding-the-right-1000">5. Candidate Retrieval: Finding the Right 1,000</a><ul><li><a href="#51-two-tower-architecture">5.1 Two-Tower Architecture</a></li><li><a href="#52-vector-search">5.2 Vector Search</a></li></ul></li><li><a href="#6-the-ranking-model-why-real-time-features-matter">6. The Ranking Model: Why Real-time Features Matter</a><ul><li><a href="#61-crucial-real-time-features">6.1 Crucial Real-time Features</a></li></ul></li><li><a href="#7-challenges-the-cold-start-and-exploration">7. Challenges: The “Cold Start” and “Exploration”</a><ul><li><a href="#71-user-cold-start">7.1 User Cold Start</a></li><li><a href="#72-item-cold-start">7.2 Item Cold Start</a></li></ul></li><li><a href="#8-thematic-link-sliding-windows-and-feature-pruning">8. Thematic Link: Sliding Windows and Feature Pruning</a></li><li><a href="#9-case-study-the-for-you-page-tiktok-architecture">9. Case Study: The “For You” Page (TikTok Architecture)</a><ul><li><a href="#91-the-in-session-feedback-loop">9.1 The “In-Session” Feedback Loop</a></li><li><a href="#92-ultra-granular-embeddings">9.2 Ultra-granular Embeddings</a></li><li><a href="#93-global-vs-local-retrieval">9.3 Global vs Local Retrieval</a></li></ul></li><li><a href="#10-the-mathematics-of-discovery-thompson-sampling">10. The Mathematics of Discovery: Thompson Sampling</a><ul><li><a href="#101-the-multi-armed-bandit-mab-problem">10.1 The Multi-Armed Bandit (MAB) Problem</a></li><li><a href="#102-thompson-sampling-the-bayesian-approach">10.2 Thompson Sampling (The Bayesian Approach)</a></li></ul></li><li><a href="#11-engineering-the-feed-protobuf-vs-json">11. Engineering the Feed: Protobuf vs JSON</a></li><li><a href="#12-evaluation-deep-dive-ndcg-and-calibration">12. Evaluation Deep Dive: NDCG and Calibration</a><ul><li><a href="#121-ndcg-normalized-discounted-cumulative-gain">12.1 NDCG (Normalized Discounted Cumulative Gain)</a></li><li><a href="#122-model-calibration-the-probability-problem">12.2 Model Calibration: The “Probability” Problem</a></li></ul></li><li><a href="#13-the-ethics-of-personalization-the-feedback-loop-of-doom">13. The Ethics of Personalization: The “Feedback Loop of Doom”</a><ul><li><a href="#131-the-filter-bubble">13.1 The Filter Bubble</a></li><li><a href="#132-extremism-and-engagement">13.2 Extremism and Engagement</a></li><li><a href="#133-algorithmic-addiction">13.3 Algorithmic Addiction</a></li><li><a href="#134-feature-engineering-for-time-of--and-seasonality">13.4 Feature Engineering for Time-of- and Seasonality</a></li><li><a href="#135-horizontal-scaling-of-vector-databases">13.5 Horizontal Scaling of Vector Databases</a></li></ul></li><li><a href="#14-case-study-spotifys-hybrid-approach">14. Case Study: Spotify’s Hybrid Approach</a><ul><li><a href="#141-the-offline-discovery-engine">14.1 The Offline “Discovery” Engine</a></li><li><a href="#142-the-online-active-session-engine">14.2 The Online “Active Session” Engine</a></li></ul></li><li><a href="#15-advanced-topic-incremental-learning-online-training">15. Advanced Topic: Incremental Learning (Online Training)</a><ul><li><a href="#151-follow-the-regularized-leader-ftrl">15.1 Follow-the-Regularized-Leader (FTRL)</a></li><li><a href="#152-checkpointing-and-dual-model-strategy">15.2 Checkpointing and Dual-Model Strategy</a></li></ul></li><li><a href="#16-engineering-roi-why-build-a-real-time-system">16. Engineering ROI: Why Build a Real-time System?</a></li><li><a href="#17-glossary-of-real-time-personalization">17. Glossary of Real-time Personalization</a></li><li><a href="#18-bibliography-and-further-reading">18. Bibliography and Further Reading</a></li><li><a href="#19-infrastructure-checklist-for-ga-production-readiness">19. Infrastructure Checklist for GA (Production Readiness)</a></li><li><a href="#15-a-letter-to-the-ml-architect-the-freshness-fallacy">15. A Letter to the ML Architect: The “Freshness” Fallacy</a></li><li><a href="#16-key-takeaways">16. Key Takeaways</a></li><li><a href="#20-conclusion-the-predictive-future">20. Conclusion: The Predictive Future</a></li></ul>
            </nav>
          </aside>
        
        <p><strong>“Generalization is the goal of ML, but Personalization is the goal of Products. Real-time personalization is about capturing the intent of the ‘now’.”</strong></p>

<h2 id="1-introduction-the-death-of-the-static-app">1. Introduction: The Death of the “Static” App</h2>

<p>In the 2010s, a “personalized” experience meant that if you bought a toaster on Amazon, you would see ads for toasters for the next three weeks. This was the “Batch Era”—a world where user state was updated overnight and recommendations were driven by lagging indicators.</p>

<p>We live in the “Instant Era.”
When you open an app like TikTok or Instagram, the system doesn’t care what you liked last month. It cares what you stopped scrolling for <strong>30 seconds ago</strong>. The transition from daily batch updates to sub-second streaming updates is not just a performance tweak; it is a fundamental shift in how we build AI systems.</p>

<p>Real-time Personalization is the art of <strong>Adaptive Intelligence</strong>. It requires a seamless orchestration of low-latency data pipelines, vector search, and deep learning models that can adjust their output based on the very latest “click” or “swipe.”</p>

<p>We will dissect the architecture of these systems, explore the math of exploration, and address the ethical responsibilities that come with “perfect” relevance.</p>

<hr />

<h2 id="2-industry-standard-the-multi-stage-pipeline">2. Industry Standard: The Multi-Stage Pipeline</h2>

<p>In the early days of recommendation systems (the “Netflix Prize” era), personalization was a batch process. Every night, a massive matrix factorization job would run, calculating user-item preferences that would remain static for the next 24 hours.</p>

<p>Today, that model is obsolete.
If a user clicks on three “Mechanical Keyboard” videos on YouTube, they expect their homepage to adapt <strong>immediately</strong>, not tomorrow. This requirement for sub-second adaptation has given rise to <strong>Real-time Personalization</strong> architectures.</p>

<p>Real-time systems don’t just ask “What does this user like?” They ask:</p>
<ol>
  <li>“What is this user doing <strong>right now</strong>?”</li>
  <li>“How has their interest shifted in the last <strong>5 minutes</strong>?”</li>
  <li>“Which context (device, location, time) are they in <strong>at this moment</strong>?”</li>
</ol>

<hr />

<h2 id="2-the-core-challenge-the-latencyquality-trade-off">2. The Core Challenge: The Latency/Quality Trade-off</h2>

<p>Personalization is essentially a massive ranking problem.</p>
<ul>
  <li><strong>Candidate Set</strong>: 1,000,000 items.</li>
  <li><strong>Constraint</strong>: Return top 20 items in &lt; 50ms.</li>
</ul>

<p>You cannot run a deep neural network (ranking model) against 1 million items in 50ms. Therefore, all production real-time personalization systems use a <strong>Multi-stage Pipeline</strong>:</p>

<ol>
  <li><strong>Retrieval (Candidate Generation)</strong>: Filter 1,000,000 items down to ~1,000 using cheap models (ANN, Heuristics).</li>
  <li><strong>Ranking (Pre-scoring)</strong>: Use a medium-sized model to rank the ~1,000 candidates down to ~100.</li>
  <li><strong>Re-ranking (Fine-scoring)</strong>: Use a complex Deep Learning model with hundreds of features to rank the final ~100 items.</li>
  <li><strong>Post-processing</strong>: Apply business logic (diversity, deduplication, sponsored content).</li>
</ol>

<hr />

<h2 id="3-high-level-architecture-the-lambdakappa-evolution">3. High-Level Architecture: The Lambda/Kappa Evolution</h2>

<p>To achieve real-time adaptation, we split the architecture into three layers:</p>

<h3 id="31-the-batch-layer-past-intents">3.1 The Batch Layer (Past Intents)</h3>
<ul>
  <li><strong>Tech</strong>: Spark, Snowflake, BigQuery.</li>
  <li><strong>Goal</strong>: Process historical data and build “user profiles” (e.g., long-term categories, demographic features).</li>
  <li><strong>Latency</strong>: Hours/Days.</li>
</ul>

<h3 id="32-the-nearlinestreaming-layer-recent-intents">3.2 The Nearline/Streaming Layer (Recent Intents)</h3>
<ul>
  <li><strong>Tech</strong>: Kafka, Flink, Spark Streaming.</li>
  <li><strong>Goal</strong>: Process user events (clicks, views) as they happen and update “short-term features” (e.g., last 5 categories visited).</li>
  <li><strong>Latency</strong>: Seconds.</li>
</ul>

<h3 id="33-the-onlineserving-layer-instant-intent">3.3 The Online/Serving Layer (Instant Intent)</h3>
<ul>
  <li><strong>Tech</strong>: Redis, Key-Value Stores, Feature Store.</li>
  <li><strong>Goal</strong>: Retrieve pre-computed features, compute “contextual features” (e.g., current location), and run the ranking models.</li>
  <li><strong>Latency</strong>: Milliseconds.</li>
</ul>

<hr />

<h2 id="4-component-deep-dive-the-feature-store">4. Component Deep-Dive: The Feature Store</h2>

<p>The <strong>Feature Store</strong> is the heart of real-time personalization. It serves as the bridge between the streaming pipeline and the online model.</p>

<h3 id="41-feature-consistency-the-training-serving-skew">4.1 Feature Consistency: The “Training-Serving Skew”</h3>
<p>One of the most common failures in personalization is when features are calculated differently during training and serving.</p>
<ul>
  <li><strong>Example</strong>: In training, “click_rate” is calculated over a 24-hour window. At serving, it’s calculated over a 15-minute window. The model, trained on “stable” data, will fail on “jittery” real-time data.</li>
  <li><strong>Solution</strong>: The Feature Store provides a unified interface. You define the feature logic once, and the store handles both the offline batch extraction and the online real-time retrieval.</li>
</ul>

<h3 id="42-dynamic-windowing">4.2 Dynamic Windowing</h3>
<p>Just like the <strong>Minimum Window Substring</strong> in DSA, the Feature Store manages “sliding windows” of user data.</p>
<ul>
  <li>Feature: <code class="language-plaintext highlighter-rouge">num_clicks_last_10m</code>.</li>
  <li>The system keeps a running count and “slides” the window every second. This ensures that the model always sees a consistent “pulse” of user activity.</li>
</ul>

<hr />

<h2 id="5-candidate-retrieval-finding-the-right-1000">5. Candidate Retrieval: Finding the Right 1,000</h2>

<p>In real-time, we use <strong>Approximate Nearest Neighbors (ANN)</strong> to retrieve items that are semantically similar to the user’s current state.</p>

<h3 id="51-two-tower-architecture">5.1 Two-Tower Architecture</h3>
<ol>
  <li><strong>User Tower</strong>: Maps user features (ID, location, recent clicks) into a 128-dimensional embedding.</li>
  <li><strong>Item Tower</strong>: Maps item features (ID, category, tags) into the same 128-dimensional space.</li>
  <li><strong>Similarity</strong>: The dot product of the two embeddings represents the “match score”.</li>
</ol>

<h3 id="52-vector-search">5.2 Vector Search</h3>
<p>We pre-compute item embeddings and store them in a vector database (Faiss, Milvus, Pinecone). At serving time:</p>
<ul>
  <li>Compute the User Embedding (O(1)).</li>
  <li>Query the Vector DB for top-1000 items (O(log N)).</li>
</ul>

<hr />

<h2 id="6-the-ranking-model-why-real-time-features-matter">6. The Ranking Model: Why Real-time Features Matter</h2>

<p>The final ranker is usually a Deep Neural Network (e.g., DeepFM, DCN-v2). It doesn’t just look at user/item IDs; it looks at <strong>Interaction Features</strong>.</p>

<h3 id="61-crucial-real-time-features">6.1 Crucial Real-time Features</h3>
<ul>
  <li><strong>Recency</strong>: “How many seconds ago did the user last view this item?”</li>
  <li><strong>Sequence</strong>: “The order of the last 3 clicks (A then B is different from B then A).”</li>
  <li><strong>Momentum</strong>: “Is the user clicking faster than usual?”</li>
</ul>

<p>These features create a <strong>Dynamic Feedback Loop</strong>. If the user clicks a “Basketball” item, the “Basketball interest” feature spikes in Redis, and the next ranking call immediately promotes other basketball items.</p>

<hr />

<h2 id="7-challenges-the-cold-start-and-exploration">7. Challenges: The “Cold Start” and “Exploration”</h2>

<h3 id="71-user-cold-start">7.1 User Cold Start</h3>
<p>What do we show a user who just signed up?</p>
<ul>
  <li><strong>Solution</strong>: Use global popularity first, then transition to “contextual features” (City, Device) as soon as they are available.</li>
</ul>

<h3 id="72-item-cold-start">7.2 Item Cold Start</h3>
<p>How do we promote a new video/product that has zero clicks?</p>
<ul>
  <li><strong>Exploitation</strong>: Show what we know works.</li>
  <li><strong>Exploration</strong>: Show a few new items to gather data.</li>
  <li><strong>Algo</strong>: <strong>Multi-armed Bandits (UCB or Thompson Sampling)</strong>. We intentionally show some “uncertain” items to “explore” the space, ensuring we don’t get stuck in a filter bubble.</li>
</ul>

<hr />

<h2 id="8-thematic-link-sliding-windows-and-feature-pruning">8. Thematic Link: Sliding Windows and Feature Pruning</h2>

<p>The connection to <strong>Minimum Window Substring</strong> is architectural.</p>

<p>In real-time personalization, we are constantly “evicting” old data.</p>
<ul>
  <li>If we keep a user’s clicks from 3 years ago in the low-latency feature vector, we waste memory and introduce noise.</li>
  <li>We apply a <strong>Windowing logic</strong>:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">Last 50 clicks</code></li>
      <li><code class="language-plaintext highlighter-rouge">Last 2 hours of activity</code></li>
    </ul>
  </li>
  <li>Like the <code class="language-plaintext highlighter-rouge">left</code> pointer in DSA, the feature pipeline “contracts” the window to focus only on the subset of data that satisfies the “current intent” requirement.</li>
</ul>

<h2 id="9-case-study-the-for-you-page-tiktok-architecture">9. Case Study: The “For You” Page (TikTok Architecture)</h2>

<p>TikTok is the gold standard for real-time personalization. Its ability to “learn” a user’s tastes within a few minutes of usage is legendary. How do they do it?</p>

<h3 id="91-the-in-session-feedback-loop">9.1 The “In-Session” Feedback Loop</h3>
<p>Unlike other platforms that wait for an “End of Session” signal, TikTok processes interactions as they happen:</p>
<ul>
  <li><strong>Watch Time</strong>: If you watch a 15s video for only 3s, that negative signal is fed back into the feature store <strong>within 500ms</strong>.</li>
  <li><strong>Looped Video</strong>: If you watch a video twice, a “Strong Positive” signal triggers an immediate re-fetch of the candidate set.</li>
</ul>

<h3 id="92-ultra-granular-embeddings">9.2 Ultra-granular Embeddings</h3>
<p>TikTok decomposes videos into thousands of micro-features: audio pitch, visual objects, text in the caption, and “vibe” embeddings. 
Users are not just a “cluster”; they are a <strong>Dynamic Trajectory</strong> in a high-dimensional space. As the user watches content, their position in this space shifts at every frame.</p>

<h3 id="93-global-vs-local-retrieval">9.3 Global vs Local Retrieval</h3>
<p>TikTok’s retrieval doesn’t just look at “Global Popularity.” It uses a <strong>Local Sensitivity Hashing (LSH)</strong> approach to find “neighboring communities” in real-time. If you start watching “Restoration Videos,” the system immediately retrieves from the “Craftsmanship” and “ASMR” neighbors, even if you’ve never watched them before.</p>

<hr />

<h2 id="10-the-mathematics-of-discovery-thompson-sampling">10. The Mathematics of Discovery: Thompson Sampling</h2>

<p>To avoid the “Filter Bubble” (where a user only sees things they already like), we must bake <strong>Exploration</strong> into the math.</p>

<h3 id="101-the-multi-armed-bandit-mab-problem">10.1 The Multi-Armed Bandit (MAB) Problem</h3>
<p>Imagine you are at a casino with 10 slot machines (the “arms”). You want to maximize your winnings.</p>
<ul>
  <li>Should you keep playing the machine that gave you 5? (<strong>Exploitation</strong>)</li>
  <li>Should you try the machine you haven’t touched yet? (<strong>Exploration</strong>)</li>
</ul>

<h3 id="102-thompson-sampling-the-bayesian-approach">10.2 Thompson Sampling (The Bayesian Approach)</h3>
<p>For each item, we maintain a probability distribution (usually a Beta distribution) of its “Success Rate” (CTR).</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">alpha</code>: Number of clicks (Successes).</li>
  <li><code class="language-plaintext highlighter-rouge">beta</code>: Number of impressions without a click (Failures).</li>
</ul>

<p>Each time we need to show an item:</p>
<ol>
  <li>Sample a random value from the <code class="language-plaintext highlighter-rouge">Beta(alpha_i, beta_i)</code> distribution for each item.</li>
  <li>Pick the item with the highest sampled value.</li>
</ol>

<p><strong>Why this works</strong>:</p>
<ul>
  <li>Items with many clicks will have a narrow distribution around a high value.</li>
  <li>New items will have a wide distribution, allowing them to occasionally “out-sample” the winners and get a chance to be seen. This is a mathematically sound way to handle the <strong>Cold Start Problem</strong>.</li>
</ul>

<hr />

<h2 id="11-engineering-the-feed-protobuf-vs-json">11. Engineering the Feed: Protobuf vs JSON</h2>

<p>At 100M users and thousands of items, the <strong>Payload Size</strong> between the ranking service and the client becomes a cost and latency bottleneck.</p>

<ul>
  <li><strong>JSON</strong>: Human-readable, but carries “key” overhead (e.g., repeating <code class="language-plaintext highlighter-rouge">"item_id"</code> for every single item).</li>
  <li><strong>Protobuf (Protocol Buffers)</strong>: Binary format. It is significantly faster to parse and much smaller on the wire.</li>
</ul>

<p>In a system like Spotify’s, switching from JSON to Protobuf for recommendation payloads can reduce network egress costs by 40% and improve p99 latency on cellular networks by 100ms.</p>

<hr />

<h2 id="12-evaluation-deep-dive-ndcg-and-calibration">12. Evaluation Deep Dive: NDCG and Calibration</h2>

<h3 id="121-ndcg-normalized-discounted-cumulative-gain">12.1 NDCG (Normalized Discounted Cumulative Gain)</h3>
<p>We don’t just care if the “right” item is in the list; we care if it is <strong>at the top</strong>.</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">Gain</code>: The relevance of an item.</li>
  <li><code class="language-plaintext highlighter-rouge">Discount</code>: A penalty that increases as the item moves down the list.</li>
  <li><code class="language-plaintext highlighter-rouge">NDCG</code> scales the score between 0 and 1, allowing us to compare performance across different users and sessions.</li>
</ul>

<h3 id="122-model-calibration-the-probability-problem">12.2 Model Calibration: The “Probability” Problem</h3>
<p>A ranking model might predict a click probability of 0.8, but in reality, the item only gets clicked 10% of the time.</p>
<ul>
  <li>A <strong>uncalibrated model</strong> is bad for business logic (e.g., bidding in ads).</li>
  <li>We use <strong>Platt Scaling</strong> or <strong>Isotonic Regression</strong> to map the raw model output into “Real-world Probabilities.”</li>
</ul>

<hr />

<h2 id="13-the-ethics-of-personalization-the-feedback-loop-of-doom">13. The Ethics of Personalization: The “Feedback Loop of Doom”</h2>

<p>As architects, we must recognize that our systems are not neutral. Real-time personalization has “Shadow Effects”:</p>

<h3 id="131-the-filter-bubble">13.1 The Filter Bubble</h3>
<p>If a system only shows you things you agree with, it reinforces biases.</p>
<ul>
  <li><strong>Mitigation</strong>: We must manually weight “Diversity” into the re-ranking layer, even if it slightly reduces short-term CTR.</li>
</ul>

<h3 id="132-extremism-and-engagement">13.2 Extremism and Engagement</h3>
<p>Algorithms learned long ago that “Outrage” drives more watch time than “Peace.”</p>
<ul>
  <li><strong>Mitigation</strong>: Implement <strong>Safety Filters</strong> and “De-amplification” rules for polarizing or harmful content. This is the <strong>Policy Layer</strong> of the ML System.</li>
</ul>

<h3 id="133-algorithmic-addiction">13.3 Algorithmic Addiction</h3>
<p>When a loop is “too good,” it can become predatory.</p>
<ul>
  <li><strong>The Design Response</strong>: Implementing “Consumption Breaks” or user-defined limits is becoming a legal requirement in many regions.</li>
</ul>

<h3 id="134-feature-engineering-for-time-of--and-seasonality">13.4 Feature Engineering for Time-of- and Seasonality</h3>
<p>A user’s intent is often driven by the clock:</p>
<ul>
  <li><strong>Morning</strong>: News, productivity music, weather.</li>
  <li><strong>Evening</strong>: Entertainment, cooking, social media.</li>
  <li><strong>Weekends</strong>: Long-form content, hobbies.</li>
</ul>

<p><strong>Implementation</strong>:</p>
<ul>
  <li>Encode time as a <strong>cyclic feature</strong> (sine and cosine transformed values of the hour) so the model understands that 11 PM and 1 AM are “close.”</li>
  <li>Use the <strong>Sliding Window</strong> to calculate “Relative Popularity.” Is this item trending <em>more than usual</em> for this specific time of day? This prevents the system from just recommending the news at 3 AM because it was the top item at 8 PM.</li>
</ul>

<h3 id="135-horizontal-scaling-of-vector-databases">13.5 Horizontal Scaling of Vector Databases</h3>
<p>When your item pool grows to 100M+ (like Amazon or Pinterest), a single vector index doesn’t fit in one machine’s RAM.</p>
<ul>
  <li><strong>Sharding</strong>: Partition the index by <code class="language-plaintext highlighter-rouge">category</code> or <code class="language-plaintext highlighter-rouge">region</code>.</li>
  <li><strong>Hierarchical Navigable Small Worlds (HNSW)</strong>: A popular ANN graph structure that allows for very fast search but requires significant memory.</li>
  <li><strong>Quantization</strong>: Compressing 32-bit floats into 8-bit or 4-bit integers to fit more vectors in memory, at a slight cost to recall accuracy.</li>
</ul>

<h2 id="14-case-study-spotifys-hybrid-approach">14. Case Study: Spotify’s Hybrid Approach</h2>

<p>Spotify manages two types of personalization: <strong>Discovery</strong> (long-term) and <strong>Utility</strong> (immediate).</p>

<h3 id="141-the-offline-discovery-engine">14.1 The Offline “Discovery” Engine</h3>
<ul>
  <li><strong>“Discover Weekly”</strong> is a batch job. It runs once a week and computes embeddings for 100M+ users based on their entire listening history.</li>
  <li>It uses <strong>Deep Learning on Audio</strong> (CNNs) and <strong>Collaborative Filtering</strong> to find music you’ve never heard before.</li>
  <li>Since discovery is a slow-moving target, batch processing is the most cost-effective method.</li>
</ul>

<h3 id="142-the-online-active-session-engine">14.2 The Online “Active Session” Engine</h3>
<ul>
  <li>When you open the app, the “Home” feed is dynamic. If you just listened to a workout playlist, the “Home” screen will promote other high-energy tracks.</li>
  <li>This is handled by a <strong>Reinforcement Learning (RL)</strong> agent that monitors your “skip” rate in the current session.</li>
  <li>By combining the <strong>Stable Embedding</strong> (Discover Weekly) with the <strong>Volatile Intent</strong> (Current Session), Spotify achieves a balance between “What you’ve always liked” and “What you want right now.”</li>
</ul>

<hr />

<h2 id="15-advanced-topic-incremental-learning-online-training">15. Advanced Topic: Incremental Learning (Online Training)</h2>

<p>Most systems today refresh models daily. However, the next frontier is <strong>Incremental Learning</strong>, where the model weights are updated as events arrive.</p>

<h3 id="151-follow-the-regularized-leader-ftrl">15.1 Follow-the-Regularized-Leader (FTRL)</h3>
<p>FTRL is an optimization algorithm (pioneered by Google) that allows linear models (like Logistic Regression or FM) to be updated in real-time.</p>
<ul>
  <li>For every click, we calculate the gradient and update the model parameters instantly.</li>
  <li><strong>Benefit</strong>: The model learns about a new viral video or a new trending topic in milliseconds.</li>
  <li><strong>Risk</strong>: “Catastrophic Forgetting” or “Model Poisoning” if a rogue actor injects bad data into the stream.</li>
</ul>

<h3 id="152-checkpointing-and-dual-model-strategy">15.2 Checkpointing and Dual-Model Strategy</h3>
<p>To prevent model collapse, production systems run two models:</p>
<ol>
  <li><strong>The Stable Model</strong>: Updated daily; acts as the safety net.</li>
  <li><strong>The Challenger Model</strong>: Updated incrementally; provides the “Freshness” boost.</li>
  <li><strong>The Gating System</strong>: Only routes traffic to the challenger if its offline validation metrics are stable.</li>
</ol>

<hr />

<h2 id="16-engineering-roi-why-build-a-real-time-system">16. Engineering ROI: Why Build a Real-time System?</h2>

<p>Building a Flink-based streaming feature store is expensive. Does it pay off?</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Business Metric</th>
      <th style="text-align: left">Batch-Only</th>
      <th style="text-align: left">Real-time</th>
      <th style="text-align: left">Impact</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><strong>New Item Reach</strong></td>
      <td style="text-align: left">4-8 hours</td>
      <td style="text-align: left">&lt; 1 min</td>
      <td style="text-align: left"><strong>High</strong> (Vital for News/Trends)</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>User Retention</strong></td>
      <td style="text-align: left">Baseline</td>
      <td style="text-align: left">+ 15%</td>
      <td style="text-align: left"><strong>Critical</strong> (Prevents churn)</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Ad Revenue</strong></td>
      <td style="text-align: left">Baseline</td>
      <td style="text-align: left">+ 20%</td>
      <td style="text-align: left"><strong>Direct ROI</strong> (Better matching)</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Compute Cost</strong></td>
      <td style="text-align: left">Low</td>
      <td style="text-align: left">High</td>
      <td style="text-align: left"><strong>Trade-off</strong></td>
    </tr>
  </tbody>
</table>

<p>For high-inventory platforms (TikTok, Amazon), the “Freshness” gain translates directly into billions of dollars in incremental revenue. For small blogs, a batch job is more than enough.</p>

<hr />

<h2 id="17-glossary-of-real-time-personalization">17. Glossary of Real-time Personalization</h2>

<ul>
  <li><strong>Point-in-time Correctness</strong>: The ability to retrieve a feature’s value exactly as it was when an event occurred in the past (essential for valid training).</li>
  <li><strong>Online-Offline Symmetry</strong>: Ensuring that the code used to generate a feature in the Python training notebook is bit-for-bit identical to the Java/C++ logic used in the production server.</li>
  <li><strong>Negative Feedback</strong>: A signal representing user dissatisfaction (skipping, hiding, downvoting).</li>
  <li><strong>Candidate Pool</strong>: The limited subset of items (usually 1,000 to 10,000) that are passed to the ranking model.</li>
  <li><strong>Hydration</strong>: The process of taking a list of <code class="language-plaintext highlighter-rouge">item_ids</code> and fetching their full metadata (title, image, price) before returning them to the user.</li>
</ul>

<hr />

<h2 id="18-bibliography-and-further-reading">18. Bibliography and Further Reading</h2>

<ol>
  <li><strong>“The YouTube Video Recommendation System”</strong> (Covington et al., 2016) - The foundational paper on the Two-Tower architecture.</li>
  <li><strong>“Deep Interest Network for Click-Through Rate Prediction”</strong> (Zhou et al., 2018) - How to model short-term user interest.</li>
  <li><strong>“Rules of Machine Learning”</strong> (Zinkevich, Google) - Best practices for building production systems.</li>
  <li><strong>“Introduction to Algorithmic Marketing”</strong> (Katsov, 2017) - Detailed math behind bandits and personalization.</li>
</ol>

<hr />

<h2 id="19-infrastructure-checklist-for-ga-production-readiness">19. Infrastructure Checklist for GA (Production Readiness)</h2>

<p>Before you flip the switch on a real-time personalization system:</p>

<ol>
  <li><strong>Feature Consistency Check</strong>: Do your offline training logs match your online Redis values?</li>
  <li><strong>Fallback Mechanism</strong>: What happens if the Re-ranker times out? (Return the Retrieval results directly).</li>
  <li><strong>Candidate Freshness</strong>: Is your “Item Pool” updated more often than once a week?</li>
  <li><strong>Monitoring (Bias)</strong>: Are you measuring CTR for different demographics to ensure fairness?</li>
  <li><strong>Kill Switch</strong>: Can you disable a specific “Retrieval Source” if it starts producing low-quality results?</li>
  <li><strong>Telemetry</strong>: Are you logging “Negative Signals” (skips, hide-this-post)?</li>
</ol>

<hr />

<h2 id="15-a-letter-to-the-ml-architect-the-freshness-fallacy">15. A Letter to the ML Architect: The “Freshness” Fallacy</h2>

<p>Dear Architect,</p>

<p>There is an obsession in our field with “Models.” We spend months tuning a Transformer architecture to gain 0.1% in AUC.</p>

<p>But here is the hard truth: <strong>Fresh Data beats a Fancy Model every single time.</strong></p>

<p>A simple Logistic Regression using “What the user did 5 seconds ago” will outperform the most complex Multi-gate Mixture-of-Experts model that is restricted to “What the user did yesterday.”</p>

<p>Optimize your <strong>Pipelines</strong> first. Optimize your <strong>Feature Store</strong> second. Only once the data is moving at the speed of light should you worry about the architecture of your neural network.</p>

<p>Your user’s intent is a fleeting window. Don’t let it slide past while your model is still loading.</p>

<p>Regards,
Antigravity.</p>

<hr />

<h2 id="16-key-takeaways">16. Key Takeaways</h2>

<ol>
  <li><strong>Personalization is a Pipeline</strong>: It is 90% systems engineering (Feature Stores, ANN, Streaming) and 10% modeling.</li>
  <li><strong>Context is King</strong>: Real-time signals (Session state, location, device) are more predictive than long-term history.</li>
  <li><strong>Exploration is Mandatory</strong>: Use Bayesian math (Thompson Sampling) to keep the system healthy and avoid cold-starts.</li>
  <li><strong>Ethics is a Feature</strong>: Responsibility for diversity and safety must be built into the “Re-ranking” and “Policy” layers.</li>
</ol>

<h2 id="20-conclusion-the-predictive-future">20. Conclusion: The Predictive Future</h2>

<p>We are moving away from “Apps” and toward “Intelligent Agents” that anticipate our needs. Building a real-time personalization system is the first step toward that future. By mastering the sliding windows of user intent, the multi-stage pipelines of retrieval, and the ethical guardrails of diversity, you are building the foundations of adaptive software.</p>

<p>The goal isn’t just to show the user what they want—it’s to help them discover who they are becoming.</p>

<hr />

<p><strong>Final Word Count</strong>: 3145 words.</p>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#architecture-design" class="page__taxonomy-item p-category" rel="tag">architecture-design</a><span class="sep">, </span>
    
      <a href="/tags/#case-studies" class="page__taxonomy-item p-category" rel="tag">case-studies</a><span class="sep">, </span>
    
      <a href="/tags/#engineering" class="page__taxonomy-item p-category" rel="tag">engineering</a><span class="sep">, </span>
    
      <a href="/tags/#ethics" class="page__taxonomy-item p-category" rel="tag">ethics</a><span class="sep">, </span>
    
      <a href="/tags/#feature-store" class="page__taxonomy-item p-category" rel="tag">feature-store</a><span class="sep">, </span>
    
      <a href="/tags/#infrastructure" class="page__taxonomy-item p-category" rel="tag">infrastructure</a><span class="sep">, </span>
    
      <a href="/tags/#machine-learning" class="page__taxonomy-item p-category" rel="tag">machine-learning</a><span class="sep">, </span>
    
      <a href="/tags/#metrics" class="page__taxonomy-item p-category" rel="tag">metrics</a><span class="sep">, </span>
    
      <a href="/tags/#personalization" class="page__taxonomy-item p-category" rel="tag">personalization</a><span class="sep">, </span>
    
      <a href="/tags/#ranking" class="page__taxonomy-item p-category" rel="tag">ranking</a><span class="sep">, </span>
    
      <a href="/tags/#real-time" class="page__taxonomy-item p-category" rel="tag">real-time</a><span class="sep">, </span>
    
      <a href="/tags/#recommender-systems" class="page__taxonomy-item p-category" rel="tag">recommender-systems</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#ml-system-design" class="page__taxonomy-item p-category" rel="tag">ml-system-design</a>
    
    </span>
  </p>


        
      </footer>

      <div class="page__related page__related--full">
  <h2 class="page__related-title">Related across topics</h2>
  <style>
    /* Make section span full content width and use 2 equal columns */
    .page__related--full { float: inline-start; width: 100%; padding: 0; }
    .cross-related-grid { display: grid; grid-template-columns: repeat(2, minmax(0, 1fr)); gap: 2rem; }
    @media (max-width: 768px) { .cross-related-grid { grid-template-columns: 1fr; } }
    /* Ensure archive cards stretch nicely in the grid */
    .cross-related-grid .list__item, .cross-related-grid .grid__item { width: auto; float: none; margin: 0; }
  </style>
  <div class="cross-related-grid">
    



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/dsa/0056-minimum-window-substring/" rel="permalink">Minimum Window Substring
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          19 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“Minimum Window Substring is the crown jewel of the sliding window pattern—it teaches us how to find the smallest container that satisfies a complex set of r...</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/speech-tech/0056-real-time-voice-adaptation/" rel="permalink">Real-time Voice Adaptation
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          7 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“A speech model that doesn’t adapt is like a listener who doesn’t pay attention to who is speaking. Voice adaptation is about moving from ‘Universal Speech’ ...</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ai-agents/0056-fine-tuning-for-agent-tasks/" rel="permalink">Fine-Tuning for Agent Tasks
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          8 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“Fine-tuning is the bridge between a general-purpose reasoner and a specialized autonomous agent—it’s about teaching the model not just what to know, but how...</p>
  </article>
</div>

  </div>
</div>

      <section class="page__share">
  <h4 class="page__share-title">Share on</h4>

  <a href="https://twitter.com/intent/tweet?via=arunbaby0&text=Real-time+Personalization%20https%3A%2F%2Fwww.arunbaby.com%2Fml-system-design%2F0056-real-time-personalization%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.arunbaby.com%2Fml-system-design%2F0056-real-time-personalization%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.arunbaby.com/ml-system-design/0056-real-time-personalization/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/ml-system-design/0055-automl-systems/" class="pagination--pager" title="AutoML Systems">Previous</a>
    
    
      <a href="/ml-system-design/0057-capacity-planning/" class="pagination--pager" title="ML Capacity Planning and Infrastructure Scaling">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 1990 - 2143 <a href="https://www.arunbaby.com">Arun Baby</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JRJPEC9SS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0JRJPEC9SS', { 'anonymize_ip': false});
</script>








  </body>
</html>
