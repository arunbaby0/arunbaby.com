<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Online Learning Systems - Arun Baby</title>
<meta name="description" content="Design systems that learn continuously from streaming data, adapting to changing patterns without full retraining.">


  <meta name="author" content="Arun Baby">
  
  <meta property="article:author" content="Arun Baby">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Arun Baby">
<meta property="og:title" content="Online Learning Systems">
<meta property="og:url" content="https://www.arunbaby.com/ml-system-design/0009-online-learning-systems/">


  <meta property="og:description" content="Design systems that learn continuously from streaming data, adapting to changing patterns without full retraining.">



  <meta property="og:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">



  <meta name="twitter:site" content="@arunbaby0">
  <meta name="twitter:title" content="Online Learning Systems">
  <meta name="twitter:description" content="Design systems that learn continuously from streaming data, adapting to changing patterns without full retraining.">
  <meta name="twitter:url" content="https://www.arunbaby.com/ml-system-design/0009-online-learning-systems/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">
    
  

  



  <meta property="article:published_time" content="2025-12-31T10:07:50+05:30">





  

  


<link rel="canonical" href="https://www.arunbaby.com/ml-system-design/0009-online-learning-systems/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Baby Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          <span class="site-subtitle">Arun Baby</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/dsa/"
                
                
              >DSA</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ml-system-design/"
                
                
              >ML Systems</a>
            </li><li class="masthead__menu-item">
              <a
                href="/speech-tech/"
                
                
              >Speech Tech</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ai-agents/"
                
                
              >AI Agents</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li><li class="masthead__menu-item">
              <a
                href="/statuses/"
                
                
              >Statuses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/contact/"
                
                
              >Contact</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main" class="no-author-sidebar">
  
  <div class="sidebar sticky">
  
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Online Learning Systems">
    <meta itemprop="description" content="Design systems that learn continuously from streaming data, adapting to changing patterns without full retraining.">
    <meta itemprop="datePublished" content="2025-12-31T10:07:50+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://www.arunbaby.com/ml-system-design/0009-online-learning-systems/" itemprop="url">Online Learning Systems
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          24 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#introduction">Introduction</a></li><li><a href="#online-vs-batch-learning">Online vs Batch Learning</a><ul><li><a href="#comparison">Comparison</a></li><li><a href="#when-to-use-online-learning">When to Use Online Learning</a></li></ul></li><li><a href="#system-architecture">System Architecture</a></li><li><a href="#core-implementation">Core Implementation</a><ul><li><a href="#basic-online-learning">Basic Online Learning</a></li><li><a href="#mini-batch-online-learning">Mini-Batch Online Learning</a></li></ul></li><li><a href="#handling-concept-drift">Handling Concept Drift</a><ul><li><a href="#detection">Detection</a></li><li><a href="#adaptation-strategies">Adaptation Strategies</a></li></ul></li><li><a href="#production-patterns">Production Patterns</a><ul><li><a href="#pattern-1-multi-model-ensemble">Pattern 1: Multi-Model Ensemble</a></li><li><a href="#pattern-2-warm-start-from-batch-model">Pattern 2: Warm Start from Batch Model</a></li><li><a href="#pattern-3-checkpoint-and-rollback">Pattern 3: Checkpoint and Rollback</a></li></ul></li><li><a href="#streaming-infrastructure">Streaming Infrastructure</a><ul><li><a href="#kafka-integration">Kafka Integration</a></li></ul></li><li><a href="#connection-to-binary-search-dsa">Connection to Binary Search (DSA)</a></li><li><a href="#monitoring--evaluation">Monitoring &amp; Evaluation</a><ul><li><a href="#real-time-metrics-dashboard">Real-time Metrics Dashboard</a></li></ul></li><li><a href="#advanced-techniques">Advanced Techniques</a><ul><li><a href="#1-contextual-bandits">1. Contextual Bandits</a></li><li><a href="#2-bayesian-online-learning">2. Bayesian Online Learning</a></li><li><a href="#3-follow-the-regularized-leader-ftrl">3. Follow-the-Regularized-Leader (FTRL)</a></li></ul></li><li><a href="#real-world-case-studies">Real-World Case Studies</a><ul><li><a href="#case-study-1-netflix-recommendation">Case Study 1: Netflix Recommendation</a></li><li><a href="#case-study-2-twitter-timeline-ranking">Case Study 2: Twitter Timeline Ranking</a></li><li><a href="#case-study-3-fraud-detection">Case Study 3: Fraud Detection</a></li></ul></li><li><a href="#performance-optimization">Performance Optimization</a><ul><li><a href="#gpu-acceleration">GPU Acceleration</a></li></ul></li><li><a href="#key-takeaways">Key Takeaways</a></li></ul>
            </nav>
          </aside>
        
        <p><strong>Design systems that learn continuously from streaming data, adapting to changing patterns without full retraining.</strong></p>

<h2 id="introduction">Introduction</h2>

<p><strong>Online learning</strong> (incremental learning) updates models continuously as new data arrives, without retraining from scratch.</p>

<p><strong>Why online learning?</strong></p>
<ul>
  <li><strong>Concept drift:</strong> User behavior changes over time</li>
  <li><strong>Freshness:</strong> Models stay up-to-date with recent data</li>
  <li><strong>Efficiency:</strong> No need to retrain on entire dataset</li>
  <li><strong>Scalability:</strong> Handle unbounded data streams</li>
</ul>

<p><strong>Key challenges:</strong></p>
<ul>
  <li>Managing model stability vs plasticity</li>
  <li>Handling catastrophic forgetting</li>
  <li>Maintaining low-latency updates</li>
  <li>Ensuring prediction consistency</li>
</ul>

<hr />

<h2 id="online-vs-batch-learning">Online vs Batch Learning</h2>

<h3 id="comparison">Comparison</h3>

<p><code class="language-plaintext highlighter-rouge">
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Aspect â”‚ Batch Learning â”‚ Online Learning â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Data â”‚ Fixed dataset â”‚ Streaming data â”‚
â”‚ Training â”‚ Full retrain â”‚ Incremental updates â”‚
â”‚ Frequency â”‚ Daily/weekly â”‚ Real-time/micro-batchâ”‚
â”‚ Memory â”‚ High (all data) â”‚ Low (current batch) â”‚
â”‚ Adaptability â”‚ Slow â”‚ Fast â”‚
â”‚ Stability â”‚ High â”‚ Requires careful tuningâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></p>

<h3 id="when-to-use-online-learning">When to Use Online Learning</h3>

<p><strong>Good fits:</strong></p>
<ul>
  <li>Recommendation systems (user preferences change)</li>
  <li>Fraud detection (fraud patterns evolve)</li>
  <li>Ad click-through rate prediction</li>
  <li>Search ranking (trending topics)</li>
  <li>Price optimization (market dynamics)</li>
</ul>

<p><strong>Poor fits:</strong></p>
<ul>
  <li>Image classification (static classes)</li>
  <li>Medical diagnosis (stable conditions)</li>
  <li>Sentiment analysis (language changes slowly)</li>
</ul>

<hr />

<h2 id="system-architecture">System Architecture</h2>

<p><code class="language-plaintext highlighter-rouge">
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Sources â”‚
â”‚ (User actions, transactions, events) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Streaming Platform â”‚
â”‚ (Kafka, Kinesis) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â–¼ â–¼ â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Feature â”‚ â”‚ Training â”‚ â”‚ Serving â”‚
 â”‚ Pipeline â”‚ â”‚ Service â”‚ â”‚ Service â”‚
 â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
 â”‚ â”‚ â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Model Registry â”‚
 â”‚ (Versioned) â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></p>

<hr />

<h2 id="core-implementation">Core Implementation</h2>

<h3 id="basic-online-learning">Basic Online Learning</h3>

<p>``python
from river import linear_model, metrics, preprocessing, optim
import numpy as np</p>

<p>class OnlineLearner:
 â€œâ€â€
 Simple online learning system</p>

<p>Updates model with each new example
 â€œâ€â€</p>

<p>def <strong>init</strong>(self, learning_rate=0.01):
 # Standardize features then logistic regression with SGD optimizer
 self.model = (
 preprocessing.StandardScaler() |
 linear_model.LogisticRegression(optimizer=optim.SGD(lr=learning_rate))
 )</p>

<p># Track performance
 self.metric = metrics.Accuracy()
 self.predictions = []</p>

<p>def partial_fit(self, X, y):
 â€œâ€â€
 Update model with new example</p>

<p>Args:
 X: Feature dict
 y: True label</p>

<p>Returns:
 Updated model
 â€œâ€â€
 # Make prediction before updating
 y_pred = self.model.predict_one(X)</p>

<p># Update metric
 self.metric.update(y, y_pred)</p>

<p># Update model with new example
 self.model.learn_one(X, y)</p>

<p>return y_pred</p>

<p>def predict(self, X):
 â€œ"â€Make predictionâ€â€â€
 return self.model.predict_one(X)</p>

<p>def get_metrics(self):
 â€œ"â€Get current performanceâ€â€â€
 return {
 â€˜accuracyâ€™: self.metric.get(),
 â€˜n_samplesâ€™: self.metric.n
 }</p>

<h1 id="usage">Usage</h1>
<p>learner = OnlineLearner()</p>

<h1 id="stream-of-data">Stream of data</h1>
<p>for i in range(1000):
 # Simulate incoming data
 X = {â€˜feature1â€™: np.random.randn(), â€˜feature2â€™: np.random.randn()}
 y = 1 if X[â€˜feature1â€™] + X[â€˜feature2â€™] &gt; 0 else 0</p>

<p># Update model
 pred = learner.partial_fit(X, y)</p>

<p>if i % 100 == 0:
 metrics = learner.get_metrics()
 print(fâ€Step {i}: Accuracy = {metrics[â€˜accuracyâ€™]:.3f}â€)
``</p>

<h3 id="mini-batch-online-learning">Mini-Batch Online Learning</h3>

<p>``python
import torch
import torch.nn as nn
import torch.optim as optim
from collections import deque</p>

<p>class MiniBatchOnlineLearner:
 â€œâ€â€
 Online learning with mini-batches</p>

<p>Accumulates examples and updates in batches
 â€œâ€â€</p>

<p>def <strong>init</strong>(self, input_dim, output_dim, batch_size=32):
 self.batch_size = batch_size</p>

<p># Neural network model
 self.model = nn.Sequential(
 nn.Linear(input_dim, 64),
 nn.ReLU(),
 nn.Linear(64, output_dim)
 )</p>

<p>self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)
 self.criterion = nn.CrossEntropyLoss()</p>

<p># Buffer for accumulating examples
 self.buffer = deque(maxlen=batch_size)</p>

<p>def add_example(self, x, y):
 â€œâ€â€
 Add example to buffer</p>

<p>Triggers update when buffer is full
 â€œâ€â€
 self.buffer.append((x, y))</p>

<p>if len(self.buffer) &gt;= self.batch_size:
 self._update_model()</p>

<p>def _update_model(self):
 â€œ"â€Update model with buffered examplesâ€â€â€
 if not self.buffer:
 return</p>

<p># Extract batch
 X_batch = torch.stack([x for x, y in self.buffer])
 y_batch = torch.tensor([y for x, y in self.buffer], dtype=torch.long)</p>

<p># Forward pass
 outputs = self.model(X_batch)
 loss = self.criterion(outputs, y_batch)</p>

<p># Backward pass
 self.optimizer.zero_grad()
 loss.backward()
 self.optimizer.step()</p>

<p># Clear buffer
 self.buffer.clear()</p>

<p>return loss.item()</p>

<p>def predict(self, x):
 â€œ"â€Make predictionâ€â€â€
 with torch.no_grad():
 output = self.model(x.unsqueeze(0))
 return torch.argmax(output, dim=1).item()</p>

<h1 id="usage-1">Usage</h1>
<p>learner = MiniBatchOnlineLearner(input_dim=10, output_dim=2, batch_size=32)</p>

<h1 id="stream-data">Stream data</h1>
<p>for i in range(1000):
 x = torch.randn(10)
 y = 1 if x.sum() &gt; 0 else 0</p>

<p>learner.add_example(x, y)
``</p>

<hr />

<h2 id="handling-concept-drift">Handling Concept Drift</h2>

<h3 id="detection">Detection</h3>

<p>``python
class DriftDetector:
 â€œâ€â€
 Detect concept drift in online learning</p>

<p>Uses sliding window to track performance
 â€œâ€â€</p>

<p>def <strong>init</strong>(self, window_size=100, threshold=0.05):
 self.window_size = window_size
 self.threshold = threshold</p>

<p>self.recent_errors = deque(maxlen=window_size)
 self.baseline_error = None</p>

<p>def add_prediction(self, y_true, y_pred):
 â€œâ€â€
 Add prediction result</p>

<p>Returns: True if drift detected
 â€œâ€â€
 error = 1 if y_true != y_pred else 0
 self.recent_errors.append(error)</p>

<p># Initialize baseline
 if self.baseline_error is None and len(self.recent_errors) &gt;= self.window_size:
 self.baseline_error = np.mean(self.recent_errors)
 return False</p>

<p># Check for drift
 if self.baseline_error is not None and len(self.recent_errors) &gt;= self.window_size:
 current_error = np.mean(self.recent_errors)</p>

<p># Significant increase in error rate
 if current_error &gt; self.baseline_error + self.threshold:
 print(fâ€âš ï¸ Drift detected! Error: {self.baseline_error:.3f} â†’ {current_error:.3f}â€)
 self.baseline_error = current_error # Update baseline
 return True</p>

<p>return False</p>

<h1 id="usage-2">Usage</h1>
<p>detector = DriftDetector(window_size=100, threshold=0.05)</p>

<p>for i in range(1000):
 # Simulate concept drift at i=500
 if i &lt; 500:
 y_true = 1
 y_pred = np.random.choice([0, 1], p=[0.1, 0.9])
 else:
 # Distribution changes
 y_true = 1
 y_pred = np.random.choice([0, 1], p=[0.4, 0.6])</p>

<p>drift = detector.add_prediction(y_true, y_pred)
``</p>

<h3 id="adaptation-strategies">Adaptation Strategies</h3>

<p>``python
class AdaptiveOnlineLearner:
 â€œâ€â€
 Online learner with adaptive learning rate</p>

<p>Increases learning rate when drift detected
 â€œâ€â€</p>

<p>def <strong>init</strong>(self, base_lr=0.01, drift_lr_multiplier=5.0):
 self.base_lr = base_lr
 self.drift_lr_multiplier = drift_lr_multiplier
 self.current_lr = base_lr</p>

<p>self.model = (
 preprocessing.StandardScaler() |
 linear_model.LogisticRegression(optimizer=optim.SGD(lr=self.base_lr))
 )
 self.drift_detector = DriftDetector()</p>

<p>self.drift_mode = False
 self.drift_countdown = 0</p>

<p>def partial_fit(self, X, y):
 â€œ"â€Update model with drift adaptationâ€â€â€
 # Make prediction
 y_pred = self.model.predict_one(X)</p>

<p># Check for drift
 drift_detected = self.drift_detector.add_prediction(y, y_pred)</p>

<p>if drift_detected:
 # Enter drift mode: increase learning rate
 self.drift_mode = True
 self.drift_countdown = 100 # Stay in drift mode for 100 samples
 self.current_lr = self.base_lr * self.drift_lr_multiplier
 print(fâ€ğŸ“ˆ Increased learning rate to {self.current_lr}â€)</p>

<p># Update model with current learning rate
 # Update with current learning rate by re-wrapping optimizer
 self.model[â€˜LogisticRegressionâ€™].optimizer = optim.SGD(lr=self.current_lr)
 self.model.learn_one(X, y)</p>

<p># Decay drift mode
 if self.drift_mode:
 self.drift_countdown -= 1
 if self.drift_countdown &lt;= 0:
 self.drift_mode = False
 self.current_lr = self.base_lr
 print(fâ€ğŸ“‰ Restored learning rate to {self.current_lr}â€)</p>

<p>return y_pred
``</p>

<hr />

<h2 id="production-patterns">Production Patterns</h2>

<h3 id="pattern-1-multi-model-ensemble">Pattern 1: Multi-Model Ensemble</h3>

<p>``python
class EnsembleOnlineLearner:
 â€œâ€â€
 Maintain ensemble of models with different learning rates</p>

<p>Robust to concept drift
 â€œâ€â€</p>

<p>def <strong>init</strong>(self, n_models=3):
 # Models with different learning rates
 self.models = [
 (
 preprocessing.StandardScaler() |
 linear_model.LogisticRegression(optimizer=optim.SGD(lr=lr))
 )
 for lr in [0.001, 0.01, 0.1]
 ]</p>

<p># Track model weights
 self.model_weights = np.ones(n_models) / n_models
 self.model_errors = [deque(maxlen=100) for _ in range(n_models)]</p>

<p>def partial_fit(self, X, y):
 â€œ"â€Update all modelsâ€â€â€
 predictions = []</p>

<p>for i, model in enumerate(self.models):
 # Predict
 y_pred = model.predict_one(X)
 predictions.append(y_pred)</p>

<p># Track error
 error = 1 if y_pred != y else 0
 self.model_errors[i].append(error)</p>

<p># Update model
 model.learn_one(X, y)</p>

<p># Update model weights based on recent performance
 self._update_weights()</p>

<p># Weighted ensemble prediction
 ensemble_pred = self._ensemble_predict(predictions)</p>

<p>return ensemble_pred</p>

<p>def _update_weights(self):
 â€œ"â€Update model weights based on performanceâ€â€â€
 for i in range(len(self.models)):
 if len(self.model_errors[i]) &gt; 0:
 error_rate = np.mean(self.model_errors[i])
 # Weight inversely proportional to error
 self.model_weights[i] = 1 / (error_rate + 0.01)</p>

<p># Normalize
 self.model_weights /= self.model_weights.sum()</p>

<p>def _ensemble_predict(self, predictions):
 â€œ"â€Weighted votingâ€â€â€
 # For binary classification
 # Convert predictions to 0/1 probabilities if None
 probs = [1.0 if p == 1 else 0.0 for p in predictions]
 weighted_sum = sum(p * w for p, w in zip(probs, self.model_weights))
 return 1 if weighted_sum &gt;= 0.5 else 0</p>

<h1 id="usage-3">Usage</h1>
<p>ensemble = EnsembleOnlineLearner(n_models=3)</p>

<p>for X, y in data_stream:
 pred = ensemble.partial_fit(X, y)
``</p>

<h3 id="pattern-2-warm-start-from-batch-model">Pattern 2: Warm Start from Batch Model</h3>

<p>``python
class HybridLearner:
 â€œâ€â€
 Start with batch-trained model, then update online</p>

<p>Best of both worlds
 â€œâ€â€</p>

<p>def <strong>init</strong>(self, pretrained_model_path):
 # Load pretrained batch model
 self.base_model = self.load_batch_model(pretrained_model_path)</p>

<p># Online learning on top
 self.online_layer = nn.Linear(self.base_model.output_dim, 2)
 self.optimizer = optim.Adam(self.online_layer.parameters(), lr=0.001)</p>

<p># Freeze base model initially
 for param in self.base_model.parameters():
 param.requires_grad = False</p>

<p>self.update_count = 0
 self.unfreeze_after = 1000 # Unfreeze base after 1000 updates</p>

<p>def partial_fit(self, x, y):
 â€œ"â€Update online layer (and optionally base model)â€â€â€
 # Forward pass through frozen base
 with torch.no_grad():
 base_features = self.base_model(x)</p>

<p># Online layer forward pass
 output = self.online_layer(base_features)</p>

<p># Compute loss
 loss = nn.CrossEntropyLoss()(output.unsqueeze(0), torch.tensor([y]))</p>

<p># Backward pass
 self.optimizer.zero_grad()
 loss.backward()
 self.optimizer.step()</p>

<p>self.update_count += 1</p>

<p># Unfreeze base model after warming up
 if self.update_count == self.unfreeze_after:
 print(â€œğŸ”“ Unfreezing base model for fine-tuningâ€)
 for param in self.base_model.parameters():
 param.requires_grad = True</p>

<p># Lower learning rate for base model
 self.optimizer = optim.Adam([
 {â€˜paramsâ€™: self.base_model.parameters(), â€˜lrâ€™: 0.0001},
 {â€˜paramsâ€™: self.online_layer.parameters(), â€˜lrâ€™: 0.001}
 ])</p>

<p>return torch.argmax(output).item()
``</p>

<h3 id="pattern-3-checkpoint-and-rollback">Pattern 3: Checkpoint and Rollback</h3>

<p>``python
class CheckpointedOnlineLearner:
 â€œâ€â€
 Online learner with periodic checkpointing</p>

<p>Allows rollback if performance degrades
 â€œâ€â€</p>

<p>def <strong>init</strong>(self, model, checkpoint_interval=1000):
 self.model = model
 self.checkpoint_interval = checkpoint_interval</p>

<p>self.checkpoints = []
 self.performance_history = []
 self.update_count = 0</p>

<p>def partial_fit(self, X, y):
 â€œ"â€Update with checkpointingâ€â€â€
 # Make prediction
 y_pred = self.model.predict_one(X)</p>

<p># Track performance
 correct = 1 if y_pred == y else 0
 self.performance_history.append(correct)</p>

<p># Update model
 self.model.learn_one(X, y)
 self.update_count += 1</p>

<p># Periodic checkpoint
 if self.update_count % self.checkpoint_interval == 0:
 self._create_checkpoint()</p>

<p>return y_pred</p>

<p>def _create_checkpoint(self):
 â€œ"â€Save model checkpointâ€â€â€
 import copy</p>

<p># Calculate recent performance
 recent_perf = np.mean(self.performance_history[-self.checkpoint_interval:])</p>

<p>checkpoint = {
 â€˜modelâ€™: copy.deepcopy(self.model),
 â€˜update_countâ€™: self.update_count,
 â€˜performanceâ€™: recent_perf
 }</p>

<p>self.checkpoints.append(checkpoint)</p>

<p>print(fâ€ğŸ’¾ Checkpoint {len(self.checkpoints)}: â€œ
 fâ€Performance = {recent_perf:.3f}â€)</p>

<p># Check for degradation
 if len(self.checkpoints) &gt; 1:
 prev_perf = self.checkpoints[-2][â€˜performanceâ€™]
 if recent_perf &lt; prev_perf - 0.1: # Significant drop
 print(â€œâš ï¸ Performance dropped, considering rollbackâ€¦â€)
 self._maybe_rollback()</p>

<p>def _maybe_rollback(self):
 â€œ"â€Rollback to previous checkpoint if neededâ€â€â€
 if len(self.checkpoints) &lt; 2:
 return</p>

<p>current_perf = self.checkpoints[-1][â€˜performanceâ€™]
 best_checkpoint = max(self.checkpoints[:-1], 
 key=lambda x: x[â€˜performanceâ€™])</p>

<p>if best_checkpoint[â€˜performanceâ€™] &gt; current_perf + 0.05:
 print(fâ€ğŸ”„ Rolling back to checkpoint with â€œ
 fâ€performance {best_checkpoint[â€˜performanceâ€™]:.3f}â€)
 self.model = best_checkpoint[â€˜modelâ€™]
``</p>

<hr />

<h2 id="streaming-infrastructure">Streaming Infrastructure</h2>

<h3 id="kafka-integration">Kafka Integration</h3>

<p>``python
from kafka import KafkaConsumer, KafkaProducer
import json</p>

<p>class OnlineLearningService:
 â€œâ€â€
 Online learning service with Kafka</p>

<p>Consumes training data, produces predictions
 â€œâ€â€</p>

<p>def <strong>init</strong>(self, model, kafka_bootstrap_servers):
 self.model = model</p>

<p># Kafka consumer for training data
 self.consumer = KafkaConsumer(
 â€˜training_dataâ€™,
 bootstrap_servers=kafka_bootstrap_servers,
 value_deserializer=lambda m: json.loads(m.decode(â€˜utf-8â€™))
 )</p>

<p># Kafka producer for predictions
 self.producer = KafkaProducer(
 bootstrap_servers=kafka_bootstrap_servers,
 value_serializer=lambda m: json.dumps(m).encode(â€˜utf-8â€™)
 )</p>

<p>self.update_count = 0</p>

<p>def run(self):
 â€œ"â€Main service loopâ€â€â€
 print(â€œğŸš€ Starting online learning serviceâ€¦â€)</p>

<p>for message in self.consumer:
 # Extract training example
 data = message.value
 X = data[â€˜featuresâ€™]
 y = data[â€˜labelâ€™]</p>

<p># Make prediction before update
 y_pred = self.model.predict_one(X)</p>

<p># Update model
 self.model.learn_one(X, y)
 self.update_count += 1</p>

<p># Publish prediction
 result = {
 â€˜idâ€™: data[â€˜idâ€™],
 â€˜predictionâ€™: y_pred,
 â€˜model_versionâ€™: self.update_count
 }
 self.producer.send(â€˜predictionsâ€™, value=result)</p>

<p>if self.update_count % 100 == 0:
 print(fâ€Processed {self.update_count} updatesâ€)</p>

<h1 id="usage-4">Usage</h1>
<p>model = linear_model.LogisticRegression()
service = OnlineLearningService(model, [â€˜localhost:9092â€™])
service.run()
``</p>

<hr />

<h2 id="connection-to-binary-search-dsa">Connection to Binary Search (DSA)</h2>

<p>Online learning uses binary search patterns for hyperparameter optimization:</p>

<p>``python
class OnlineLearningRateOptimizer:
 â€œâ€â€
 Optimize learning rate using binary search</p>

<p>Similar to DSA: binary search on continuous space
 â€œâ€â€</p>

<p>def <strong>init</strong>(self, model, validation_stream):
 self.model = model
 self.validation_stream = validation_stream</p>

<p>def find_optimal_lr(self, min_lr=1e-5, max_lr=1.0, iterations=10):
 â€œâ€â€
 Binary search for optimal learning rate</p>

<p>Args:
 min_lr: Minimum learning rate
 max_lr: Maximum learning rate
 iterations: Number of binary search iterations</p>

<p>Returns:
 Optimal learning rate
 â€œâ€â€
 best_lr = min_lr
 best_score = 0</p>

<p>left, right = min_lr, max_lr</p>

<p>for iteration in range(iterations):
 # Try middle point
 mid_lr = (left + right) / 2</p>

<p># Evaluate this learning rate
 score = self._evaluate_learning_rate(mid_lr)</p>

<p>print(fâ€Iteration {iteration}: lr={mid_lr:.6f}, score={score:.4f}â€)</p>

<p>if score &gt; best_score:
 best_score = score
 best_lr = mid_lr</p>

<p># Adjust search space (simplified heuristic)
 # In practice, use more sophisticated methods
 if score &gt; 0.8:
 # Good performance, try higher learning rate
 left = mid_lr
 else:
 # Poor performance, try lower learning rate
 right = mid_lr</p>

<p>return best_lr, best_score</p>

<p>def _evaluate_learning_rate(self, learning_rate):
 â€œ"â€Evaluate model with given learning rateâ€â€â€
 import copy
 from itertools import islice</p>

<p># Copy and set optimizer lr if available
 temp_model = copy.deepcopy(self.model)
 # Attempt to set lr on inner estimator if present
 try:
 temp_model[â€˜LogisticRegressionâ€™].optimizer = optim.SGD(lr=learning_rate)
 except Exception:
 pass</p>

<p># Train on sample of validation stream
 correct = 0
 total = 0</p>

<p>for X, y in islice(self.validation_stream, 100):
 y_pred = temp_model.predict_one(X)
 correct += (y_pred == y)
 temp_model.learn_one(X, y)
 total += 1</p>

<p>return correct / total if total &gt; 0 else 0</p>

<h1 id="usage-5">Usage</h1>
<p>optimizer = OnlineLearningRateOptimizer(model, validation_data)
optimal_lr, score = optimizer.find_optimal_lr()
print(fâ€Optimal learning rate: {optimal_lr:.6f}â€)
``</p>

<hr />

<h2 id="monitoring--evaluation">Monitoring &amp; Evaluation</h2>

<h3 id="real-time-metrics-dashboard">Real-time Metrics Dashboard</h3>

<p>``python
class OnlineLearningMonitor:
 â€œâ€â€
 Monitor online learning system health</p>

<p>Track multiple metrics in real-time
 â€œâ€â€</p>

<p>def <strong>init</strong>(self, window_size=1000):
 self.window_size = window_size</p>

<p># Metric windows
 self.recent_predictions = deque(maxlen=window_size)
 self.recent_losses = deque(maxlen=window_size)
 self.recent_latencies = deque(maxlen=window_size)</p>

<p># Counters
 self.total_updates = 0
 self.start_time = time.time()</p>

<p>def log_update(self, y_true, y_pred, loss, latency_ms):
 â€œ"â€Log single updateâ€â€â€
 correct = 1 if y_true == y_pred else 0
 self.recent_predictions.append(correct)
 self.recent_losses.append(loss)
 self.recent_latencies.append(latency_ms)</p>

<p>self.total_updates += 1</p>

<p>def get_metrics(self):
 â€œ"â€Get current metricsâ€â€â€
 if not self.recent_predictions:
 return {}</p>

<p>uptime_hours = (time.time() - self.start_time) / 3600</p>

<p>return {
 â€˜accuracyâ€™: np.mean(self.recent_predictions),
 â€˜avg_lossâ€™: np.mean(self.recent_losses),
 â€˜p50_latencyâ€™: np.percentile(self.recent_latencies, 50),
 â€˜p95_latencyâ€™: np.percentile(self.recent_latencies, 95),
 â€˜p99_latencyâ€™: np.percentile(self.recent_latencies, 99),
 â€˜updates_per_secondâ€™: self.total_updates / (uptime_hours * 3600),
 â€˜total_updatesâ€™: self.total_updates,
 â€˜uptime_hoursâ€™: uptime_hours
 }</p>

<p>def print_dashboard(self):
 â€œ"â€Print real-time dashboardâ€â€â€
 metrics = self.get_metrics()</p>

<p>print(â€œ\nâ€ + â€œ=â€<em>50)
 print(â€œOnline Learning Dashboardâ€)
 print(â€œ=â€</em>50)
 print(fâ€Total Updates: {metrics[â€˜total_updatesâ€™]:,}â€)
 print(fâ€Uptime: {metrics[â€˜uptime_hoursâ€™]:.2f} hoursâ€)
 print(fâ€Updates/sec: {metrics[â€˜updates_per_secondâ€™]:.1f}â€)
 print(fâ€Accuracy: {metrics[â€˜accuracyâ€™]:.3f}â€)
 print(fâ€Avg Loss: {metrics[â€˜avg_lossâ€™]:.4f}â€)
 print(fâ€P50 Latency: {metrics[â€˜p50_latencyâ€™]:.2f}msâ€)
 print(fâ€P95 Latency: {metrics[â€˜p95_latencyâ€™]:.2f}msâ€)
 print(fâ€P99 Latency: {metrics[â€˜p99_latencyâ€™]:.2f}msâ€)
 print(â€œ=â€*50 + â€œ\nâ€)</p>

<h1 id="usage-6">Usage</h1>
<p>monitor = OnlineLearningMonitor()</p>

<p>for i in range(10000):
 start = time.time()</p>

<p># Update model
 y_pred = model.partial_fit(X, y)
 loss = compute_loss(y, y_pred)</p>

<p>latency = (time.time() - start) * 1000</p>

<p># Log metrics
 monitor.log_update(y, y_pred, loss, latency)</p>

<p># Print dashboard every 1000 updates
 if i % 1000 == 0:
 monitor.print_dashboard()
``</p>

<hr />

<h2 id="advanced-techniques">Advanced Techniques</h2>

<h3 id="1-contextual-bandits">1. Contextual Bandits</h3>

<p>``python
import numpy as np</p>

<p>class ContextualBandit:
 â€œâ€â€
 Contextual multi-armed bandit for online learning</p>

<p>Learns which model to use based on context
 â€œâ€â€</p>

<p>def <strong>init</strong>(self, n_arms, n_features, epsilon=0.1):
 â€œâ€â€
 Args:
 n_arms: Number of models/actions
 n_features: Number of context features
 epsilon: Exploration rate
 â€œâ€â€
 self.n_arms = n_arms
 self.n_features = n_features
 self.epsilon = epsilon</p>

<p># Linear models for each arm
 self.weights = [np.zeros(n_features) for _ in range(n_arms)]
 self.counts = np.zeros(n_arms)
 self.rewards = [[] for _ in range(n_arms)]</p>

<p>def select_arm(self, context):
 â€œâ€â€
 Select arm (model) based on context</p>

<p>Uses epsilon-greedy with linear reward prediction</p>

<p>Args:
 context: Feature vector [n_features]</p>

<p>Returns:
 Selected arm index
 â€œâ€â€
 if np.random.random() &lt; self.epsilon:
 # Explore: random arm
 return np.random.randint(self.n_arms)</p>

<p># Exploit: arm with highest predicted reward
 predicted_rewards = [
 np.dot(context, weights) 
 for weights in self.weights
 ]
 return np.argmax(predicted_rewards)</p>

<p>def update(self, arm, context, reward):
 â€œâ€â€
 Update armâ€™s model with observed reward</p>

<p>Uses online gradient descent
 â€œâ€â€
 self.counts[arm] += 1
 self.rewards[arm].append(reward)</p>

<p># Online gradient descent update
 prediction = np.dot(context, self.weights[arm])
 error = reward - prediction</p>

<p># Update weights: w = w + alpha * error * context
 learning_rate = 1.0 / (1.0 + self.counts[arm])
 self.weights[arm] += learning_rate * error * context</p>

<p>def get_arm_stats(self):
 â€œ"â€Get statistics for each armâ€â€â€
 return {
 fâ€™arm_{i}â€™: {
 â€˜countâ€™: int(self.counts[i]),
 â€˜avg_rewardâ€™: np.mean(self.rewards[i]) if self.rewards[i] else 0
 }
 for i in range(self.n_arms)
 }</p>

<h1 id="usage-choose-between-models-based-on-user-context">Usage: Choose between models based on user context</h1>
<p>bandit = ContextualBandit(n_arms=3, n_features=5)</p>

<h1 id="simulate-online-serving">Simulate online serving</h1>
<p>for iteration in range(1000):
 # Get user context
 context = np.random.randn(5) # User features</p>

<p># Select model
 model_idx = bandit.select_arm(context)</p>

<p># Get reward (e.g., click-through rate)
 reward = simulate_reward(model_idx, context)</p>

<p># Update
 bandit.update(model_idx, context, reward)</p>

<p>print(bandit.get_arm_stats())
``</p>

<h3 id="2-bayesian-online-learning">2. Bayesian Online Learning</h3>

<p>``python
class BayesianOnlineLearner:
 â€œâ€â€
 Bayesian approach to online learning</p>

<p>Maintains uncertainty estimates
 â€œâ€â€</p>

<p>def <strong>init</strong>(self, n_features, alpha=1.0, beta=1.0):
 â€œâ€â€
 Args:
 n_features: Number of features
 alpha: Prior precision (inverse variance)
 beta: Noise precision
 â€œâ€â€
 self.n_features = n_features
 self.alpha = alpha
 self.beta = beta</p>

<p># Posterior parameters
 self.mean = np.zeros(n_features)
 self.precision = alpha * np.eye(n_features)</p>

<p>self.update_count = 0</p>

<p>def predict(self, X):
 â€œâ€â€
 Predict with uncertainty</p>

<p>Returns: (mean, variance)
 â€œâ€â€
 mean = np.dot(X, self.mean)</p>

<p># Predictive variance
 covariance = np.linalg.inv(self.precision)
 variance = 1.0 / self.beta + np.dot(X, np.dot(covariance, X.T))</p>

<p>return mean, variance</p>

<p>def update(self, X, y):
 â€œâ€â€
 Bayesian online update</p>

<p>Updates posterior distribution
 â€œâ€â€
 # Update precision matrix
 self.precision += self.beta * np.outer(X, X)</p>

<p># Update mean
 covariance = np.linalg.inv(self.precision)
 self.mean = np.dot(
 covariance,
 self.alpha * self.mean + self.beta * y * X
 )</p>

<p>self.update_count += 1</p>

<p>def get_confidence_interval(self, X, confidence=0.95):
 â€œâ€â€
 Get prediction confidence interval</p>

<p>Useful for uncertainty-based exploration
 â€œâ€â€
 mean, variance = self.predict(X)
 std = np.sqrt(variance)</p>

<p># Z-score for confidence level
 from scipy import stats
 z = stats.norm.ppf((1 + confidence) / 2)</p>

<p>return (mean - z * std, mean + z * std)</p>

<h1 id="usage-7">Usage</h1>
<p>learner = BayesianOnlineLearner(n_features=10)</p>

<p>for X, y in data_stream:
 # Predict with uncertainty
 mean, variance = learner.predict(X)</p>

<p>print(fâ€Prediction: {mean:.3f} Â± {np.sqrt(variance):.3f}â€)</p>

<p># Update
 learner.update(X, y)
``</p>

<h3 id="3-follow-the-regularized-leader-ftrl">3. Follow-the-Regularized-Leader (FTRL)</h3>

<p>``python
class FTRLOptimizer:
 â€œâ€â€
 FTRL-Proximal optimizer for online learning</p>

<p>Popular for large-scale online learning (used by Google)
 â€œâ€â€</p>

<p>def <strong>init</strong>(self, n_features, alpha=0.1, beta=1.0, lambda1=0.0, lambda2=1.0):
 â€œâ€â€
 Args:
 alpha: Learning rate
 beta: Smoothing parameter
 lambda1: L1 regularization
 lambda2: L2 regularization
 â€œâ€â€
 self.alpha = alpha
 self.beta = beta
 self.lambda1 = lambda1
 self.lambda2 = lambda2</p>

<p># FTRL parameters
 self.z = np.zeros(n_features) # Accumulated gradient
 self.n = np.zeros(n_features) # Accumulated squared gradient</p>

<p>self.weights = np.zeros(n_features)</p>

<p>def predict(self, x):
 â€œ"â€Make predictionâ€â€â€
 return 1.0 / (1.0 + np.exp(-np.dot(x, self.weights)))</p>

<p>def update(self, x, y):
 â€œâ€â€
 FTRL update step</p>

<p>More stable than standard online gradient descent
 â€œâ€â€
 # Make prediction
 p = self.predict(x)</p>

<p># Compute gradient
 g = (p - y) * x</p>

<p># Update accumulated gradients
 sigma = (np.sqrt(self.n + g * g) - np.sqrt(self.n)) / self.alpha
 self.z += g - sigma * self.weights
 self.n += g * g</p>

<p># Update weights with proximal step
 for i in range(len(self.weights)):
 if abs(self.z[i]) &lt;= self.lambda1:
 self.weights[i] = 0
 else:
 sign = 1 if self.z[i] &gt; 0 else -1
 self.weights[i] = -(self.z[i] - sign * self.lambda1) / (
 (self.beta + np.sqrt(self.n[i])) / self.alpha + self.lambda2
 )</p>

<p>def get_sparsity(self):
 â€œ"â€Get weight sparsity (fraction of zero weights)â€â€â€
 return np.mean(self.weights == 0)</p>

<h1 id="usage-8">Usage</h1>
<p>optimizer = FTRLOptimizer(n_features=100, lambda1=1.0) # L1 for sparsity</p>

<p>for x, y in data_stream:
 pred = optimizer.predict(x)
 optimizer.update(x, y)</p>

<p>print(fâ€Model sparsity: {optimizer.get_sparsity():.1%}â€)
``</p>

<hr />

<h2 id="real-world-case-studies">Real-World Case Studies</h2>

<h3 id="case-study-1-netflix-recommendation">Case Study 1: Netflix Recommendation</h3>

<p>``python
class NetflixOnlineLearning:
 â€œâ€â€
 Simplified Netflix online learning for recommendations</p>

<p>Updates user preferences in real-time based on viewing behavior
 â€œâ€â€</p>

<p>def <strong>init</strong>(self, n_users, n_items, n_factors=50):
 self.n_users = n_users
 self.n_items = n_items
 self.n_factors = n_factors</p>

<p># Matrix factorization embeddings
 self.user_factors = np.random.randn(n_users, n_factors) * 0.01
 self.item_factors = np.random.randn(n_items, n_factors) * 0.01</p>

<p># Learning rates
 self.lr = 0.01
 self.reg = 0.01</p>

<p>def predict(self, user_id, item_id):
 â€œ"â€Predict rating for user-item pairâ€â€â€
 return np.dot(self.user_factors[user_id], self.item_factors[item_id])</p>

<p>def update_from_interaction(self, user_id, item_id, rating):
 â€œâ€â€
 Update embeddings from single interaction</p>

<p>Online matrix factorization
 â€œâ€â€
 # Predict current rating
 pred = self.predict(user_id, item_id)
 error = rating - pred</p>

<p># Gradient updates
 user_grad = error * self.item_factors[item_id] - self.reg * self.user_factors[user_id]
 item_grad = error * self.user_factors[user_id] - self.reg * self.item_factors[item_id]</p>

<p># Update embeddings
 self.user_factors[user_id] += self.lr * user_grad
 self.item_factors[item_id] += self.lr * item_grad</p>

<p>def recommend(self, user_id, n=10):
 â€œ"â€Get top-N recommendations for userâ€â€â€
 scores = np.dot(self.item_factors, self.user_factors[user_id])
 top_items = np.argsort(-scores)[:n]
 return top_items</p>

<h1 id="simulate-netflix-streaming">Simulate Netflix streaming</h1>
<p>recommender = NetflixOnlineLearning(n_users=1000000, n_items=10000)</p>

<h1 id="user-watches-a-movie-and-rates-it">User watches a movie and rates it</h1>
<p>recommender.update_from_interaction(user_id=12345, item_id=567, rating=4.5)</p>

<h1 id="get-real-time-recommendations">Get real-time recommendations</h1>
<p>recommendations = recommender.recommend(user_id=12345, n=10)
``</p>

<h3 id="case-study-2-twitter-timeline-ranking">Case Study 2: Twitter Timeline Ranking</h3>

<p>``python
class TwitterTimelineRanker:
 â€œâ€â€
 Online learning for Twitter timeline ranking</p>

<p>Predicts engagement (clicks, likes, retweets) in real-time
 â€œâ€â€</p>

<p>def <strong>init</strong>(self):
 # Multiple models for different engagement types
 from sklearn.linear_model import SGDClassifier
 self.click_model = SGDClassifier(
 loss=â€™log_lossâ€™,
 learning_rate=â€™optimalâ€™,
 alpha=0.0001
 )
 self.like_model = SGDClassifier(
 loss=â€™log_lossâ€™,
 learning_rate=â€™optimalâ€™,
 alpha=0.0001
 )</p>

<p>self.update_buffer = deque(maxlen=100)
 self.is_initialized = False</p>

<p>def extract_features(self, tweet, user):
 â€œâ€â€
 Extract features for ranking</p>

<p>Features:</p>
<ul>
  <li>Tweet features: author followers, recency, media type</li>
  <li>User features: interests, engagement history</li>
  <li>Interaction features: author-user affinity
 â€œâ€â€
 return {
 â€˜author_followersâ€™: tweet[â€˜author_followersâ€™],
 â€˜tweet_age_minutesâ€™: tweet[â€˜age_minutesâ€™],
 â€˜has_mediaâ€™: int(tweet[â€˜has_mediaâ€™]),
 â€˜user_interest_matchâ€™: user[â€˜interest_similarityâ€™],
 â€˜author_user_affinityâ€™: tweet[â€˜author_affinityâ€™],
 â€˜tweet_lengthâ€™: len(tweet[â€˜textâ€™]),
 }</li>
</ul>

<p>def score_tweet(self, tweet, user):
 â€œâ€â€
 Score tweet for ranking</p>

<p>Combines click and like predictions
 â€œâ€â€
 features = self.extract_features(tweet, user)</p>

<p>if not self.is_initialized:
 return 0.5 # Random score until initialized</p>

<p># Predict engagement probabilities
 click_prob = self.click_model.predict_proba([features])[0][1]
 like_prob = self.like_model.predict_proba([features])[0][1]</p>

<p># Weighted combination
 score = 0.6 * click_prob + 0.4 * like_prob</p>

<p>return score</p>

<p>def update_from_feedback(self, tweet, user, clicked, liked):
 â€œâ€â€
 Update models from user feedback</p>

<p>Called when user interacts (or doesnâ€™t) with tweet
 â€œâ€â€
 features = self.extract_features(tweet, user)</p>

<p># Add to buffer
 self.update_buffer.append((features, clicked, liked))</p>

<p># Batch update when buffer is full
 if len(self.update_buffer) &gt;= 100:
 self._batch_update()</p>

<p>def _batch_update(self):
 â€œ"â€Batch update from bufferâ€â€â€
 features_list = [item[0] for item in self.update_buffer]
 click_labels = [item[1] for item in self.update_buffer]
 like_labels = [item[2] for item in self.update_buffer]</p>

<p># Partial fit (online learning)
 import numpy as np
 X = self._features_to_matrix(features_list)
 y_click = np.array(click_labels)
 y_like = np.array(like_labels)</p>

<p>self.click_model.partial_fit(X, y_click, classes=np.array([0, 1]))
 self.like_model.partial_fit(X, y_like, classes=np.array([0, 1]))</p>

<p>self.is_initialized = True
 self.update_buffer.clear()</p>

<p>def rank_timeline(self, tweets, user):
 â€œ"â€Rank tweets for userâ€™s timelineâ€â€â€
 scored_tweets = []
 for tweet in tweets:
 score = self.score_tweet(tweet, user)
 scored_tweets.append((tweet, score))</p>

<p># Sort by score (descending)
 ranked = sorted(scored_tweets, key=lambda x: x[1], reverse=True)</p>

<p>return [tweet for tweet, score in ranked]</p>

<h1 id="usage-9">Usage</h1>
<p>ranker = TwitterTimelineRanker()</p>

<h1 id="user-views-timeline">User views timeline</h1>
<p>timeline_tweets = fetch_candidate_tweets(user_id)
ranked_timeline = ranker.rank_timeline(timeline_tweets, user)</p>

<h1 id="user-interacts-with-tweets">User interacts with tweets</h1>
<p>for tweet in ranked_timeline[:10]:
 clicked, liked = show_tweet_to_user(tweet)
 ranker.update_from_feedback(tweet, user, clicked, liked)
``</p>

<h3 id="case-study-3-fraud-detection">Case Study 3: Fraud Detection</h3>

<p>``python
class OnlineFraudDetector:
 â€œâ€â€
 Online learning for fraud detection</p>

<p>Adapts to evolving fraud patterns in real-time
 â€œâ€â€</p>

<p>def <strong>init</strong>(self, window_size=10000):
 self.model = linear_model.SGDClassifier(
 loss=â€™logâ€™,
 penalty=â€™l1â€™, # L1 for feature selection
 alpha=0.0001,
 learning_rate=â€™adaptiveâ€™,
 eta0=0.01
 )</p>

<p>self.window_size = window_size
 self.recent_transactions = deque(maxlen=window_size)</p>

<p># Fraud pattern tracking
 self.fraud_patterns = {}
 self.is_initialized = False</p>

<p>def extract_features(self, transaction):
 â€œâ€â€
 Extract fraud detection features</p>

<p>Features:</p>
<ul>
  <li>Transaction amount, location, time</li>
  <li>User behavior patterns</li>
  <li>Merchant risk score
 â€œâ€â€
 return {
 â€˜amountâ€™: transaction[â€˜amountâ€™],
 â€˜amount_z_scoreâ€™: self._get_amount_zscore(transaction),
 â€˜hour_of_dayâ€™: transaction[â€˜timestampâ€™].hour,
 â€˜is_weekendâ€™: int(transaction[â€˜timestampâ€™].weekday() &gt;= 5),
 â€˜distance_from_homeâ€™: transaction[â€˜distance_kmâ€™],
 â€˜merchant_risk_scoreâ€™: self._get_merchant_risk(transaction[â€˜merchantâ€™]),
 â€˜user_velocityâ€™: self._get_user_velocity(transaction[â€˜user_idâ€™]),
 }</li>
</ul>

<p>def predict(self, transaction):
 â€œâ€â€
 Predict if transaction is fraudulent</p>

<p>Returns: (is_fraud, fraud_probability)
 â€œâ€â€
 features = self.extract_features(transaction)</p>

<p>if not self.is_initialized:
 # Cold start: use rule-based system
 return self._rule_based_prediction(transaction)</p>

<p># ML prediction
 features_array = np.array(list(features.values())).reshape(1, -1)
 fraud_prob = self.model.predict_proba(features_array)[0][1]</p>

<p># Threshold
 is_fraud = fraud_prob &gt; 0.9 # High threshold to minimize false positives</p>

<p>return is_fraud, fraud_prob</p>

<p>def update(self, transaction, is_fraud):
 â€œâ€â€
 Update model with labeled transaction</p>

<p>Label comes from:</p>
<ul>
  <li>User confirmation</li>
  <li>Fraud analyst review</li>
  <li>Chargeback
 â€œâ€â€
 features = self.extract_features(transaction)
 features_array = np.array(list(features.values())).reshape(1, -1)</li>
</ul>

<p># Update model
 if self.is_initialized:
 self.model.partial_fit(features_array, [is_fraud])
 else:
 # Initialize on first labeled sample
 self.model.fit(features_array, [is_fraud])
 self.is_initialized = True</p>

<p># Track fraud patterns
 if is_fraud:
 self._update_fraud_patterns(transaction)</p>

<p># Add to recent window
 self.recent_transactions.append((transaction, is_fraud))</p>

<p>def _get_amount_zscore(self, transaction):
 â€œ"â€Z-score of amount compared to userâ€™s historyâ€â€â€
 if not self.recent_transactions:
 return 0.0</p>

<p>user_txns = [
 t[â€˜amountâ€™] for t, _ in self.recent_transactions
 if t[â€˜user_idâ€™] == transaction[â€˜user_idâ€™]
 ]</p>

<p>if len(user_txns) &lt; 2:
 return 0.0</p>

<p>mean = np.mean(user_txns)
 std = np.std(user_txns)</p>

<p>if std == 0:
 return 0.0</p>

<p>return (transaction[â€˜amountâ€™] - mean) / std</p>

<p>def _update_fraud_patterns(self, transaction):
 â€œ"â€Track emerging fraud patternsâ€â€â€
 pattern_key = (transaction[â€˜merchantâ€™], transaction[â€˜locationâ€™])</p>

<p>if pattern_key not in self.fraud_patterns:
 self.fraud_patterns[pattern_key] = {
 â€˜countâ€™: 0,
 â€˜first_seenâ€™: transaction[â€˜timestampâ€™]
 }</p>

<p>self.fraud_patterns[pattern_key][â€˜countâ€™] += 1</p>

<h1 id="usage-10">Usage</h1>
<p>detector = OnlineFraudDetector()</p>

<h1 id="real-time-transaction-processing">Real-time transaction processing</h1>
<p>for transaction in transaction_stream:
 # Predict
 is_fraud, prob = detector.predict(transaction)</p>

<p>if is_fraud:
 # Block transaction
 block_transaction(transaction)</p>

<p># Get analyst review
 analyst_label = request_analyst_review(transaction)
 detector.update(transaction, analyst_label)
 else:
 # Allow transaction
 allow_transaction(transaction)</p>

<p># Update with feedback (if available)
 if has_feedback(transaction):
 label = get_feedback(transaction)
 detector.update(transaction, label)
``</p>

<hr />

<h2 id="performance-optimization">Performance Optimization</h2>

<h3 id="gpu-acceleration">GPU Acceleration</h3>

<p>``python
import torch
import torch.nn as nn</p>

<p>class GPUAcceleratedOnlineLearner:
 â€œâ€â€
 GPU-accelerated online learning</p>

<p>Uses PyTorch for fast batch updates
 â€œâ€â€</p>

<p>def <strong>init</strong>(self, input_dim, hidden_dim=64):
 self.device = torch.device(â€˜cudaâ€™ if torch.cuda.is_available() else â€˜cpuâ€™)</p>

<p># Neural network model
 self.model = nn.Sequential(
 nn.Linear(input_dim, hidden_dim),
 nn.ReLU(),
 nn.Dropout(0.2),
 nn.Linear(hidden_dim, 1),
 nn.Sigmoid()
 ).to(self.device)</p>

<p>self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)
 self.criterion = nn.BCELoss()</p>

<p># Batch buffer for GPU efficiency
 self.batch_buffer = []
 self.batch_size = 128</p>

<p>def add_example(self, x, y):
 â€œâ€â€
 Add example to batch buffer</p>

<p>Triggers GPU update when buffer is full
 â€œâ€â€
 self.batch_buffer.append((x, y))</p>

<p>if len(self.batch_buffer) &gt;= self.batch_size:
 self._update_batch()</p>

<p>def _update_batch(self):
 â€œ"â€Update model with GPU batch processingâ€â€â€
 if not self.batch_buffer:
 return</p>

<p># Prepare batch tensors
 X_batch = torch.tensor(
 [x for x, y in self.batch_buffer],
 dtype=torch.float32,
 device=self.device
 )
 y_batch = torch.tensor(
 [[y] for x, y in self.batch_buffer],
 dtype=torch.float32,
 device=self.device
 )</p>

<p># Forward pass
 self.model.train()
 outputs = self.model(X_batch)
 loss = self.criterion(outputs, y_batch)</p>

<p># Backward pass
 self.optimizer.zero_grad()
 loss.backward()
 self.optimizer.step()</p>

<p># Clear buffer
 self.batch_buffer.clear()</p>

<p>return loss.item()</p>

<p>def predict(self, x):
 â€œ"â€Fast GPU predictionâ€â€â€
 self.model.eval()</p>

<p>x_tensor = torch.tensor(x, dtype=torch.float32, device=self.device)</p>

<p>with torch.no_grad():
 output = self.model(x_tensor.unsqueeze(0))</p>

<p>return output.item()</p>

<h1 id="usage-11">Usage</h1>
<p>learner = GPUAcceleratedOnlineLearner(input_dim=100)</p>

<h1 id="process-stream-with-gpu-acceleration">Process stream with GPU acceleration</h1>
<p>for x, y in data_stream:
 pred = learner.predict(x)
 learner.add_example(x, y)
``</p>

<hr />

<h2 id="key-takeaways">Key Takeaways</h2>

<p>âœ… <strong>Continuous adaptation</strong> - Learn from streaming data without full retraining 
âœ… <strong>Handle concept drift</strong> - Detect and adapt to changing distributions 
âœ… <strong>Memory efficient</strong> - Donâ€™t need to store all historical data 
âœ… <strong>Fast updates</strong> - Incorporate new information in real-time 
âœ… <strong>Stability vs plasticity</strong> - Balance learning new patterns vs retaining knowledge 
âœ… <strong>Production patterns</strong> - Checkpointing, ensembles, warm starts 
âœ… <strong>Binary search optimization</strong> - Find optimal hyperparameters efficiently</p>

<hr />

<p><strong>Originally published at:</strong> <a href="https://www.arunbaby.com/ml-system-design/0009-online-learning-systems/">arunbaby.com/ml-system-design/0009-online-learning-systems</a></p>

<p><em>If you found this helpful, consider sharing it with others who might benefit.</em></p>


        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#incremental-learning" class="page__taxonomy-item p-category" rel="tag">incremental-learning</a><span class="sep">, </span>
    
      <a href="/tags/#model-updates" class="page__taxonomy-item p-category" rel="tag">model-updates</a><span class="sep">, </span>
    
      <a href="/tags/#online-learning" class="page__taxonomy-item p-category" rel="tag">online-learning</a><span class="sep">, </span>
    
      <a href="/tags/#real-time" class="page__taxonomy-item p-category" rel="tag">real-time</a><span class="sep">, </span>
    
      <a href="/tags/#streaming" class="page__taxonomy-item p-category" rel="tag">streaming</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#ml-system-design" class="page__taxonomy-item p-category" rel="tag">ml-system-design</a>
    
    </span>
  </p>


        
      </footer>

      <div class="page__related page__related--full">
  <h2 class="page__related-title">Related across topics</h2>
  <style>
    /* Make section span full content width and use 2 equal columns */
    .page__related--full { float: inline-start; width: 100%; padding: 0; }
    .cross-related-grid { display: grid; grid-template-columns: repeat(2, minmax(0, 1fr)); gap: 2rem; }
    @media (max-width: 768px) { .cross-related-grid { grid-template-columns: 1fr; } }
    /* Ensure archive cards stretch nicely in the grid */
    .cross-related-grid .list__item, .cross-related-grid .grid__item { width: auto; float: none; margin: 0; }
  </style>
  <div class="cross-related-grid">
    



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/dsa/0009-binary-search/" rel="permalink">Binary Search
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          28 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Master binary search to understand logarithmic algorithms and efficient searching, foundational for optimization and search systems.
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/speech-tech/0009-keyword-spotting/" rel="permalink">Real-time Keyword Spotting
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          14 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Build lightweight models that detect specific keywords in audio streams with minimal latency and power consumption for voice interfaces.
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ai-agents/0009-retrieval-augmented-generation/" rel="permalink">Retrieval-Augmented Generation (RAG)
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          7 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">â€œGiving the Brain a Library: The Foundation of Knowledge-Intensive Agents.â€
</p>
  </article>
</div>

  </div>
</div>

      <section class="page__share">
  <h4 class="page__share-title">Share on</h4>

  <a href="https://twitter.com/intent/tweet?via=arunbaby0&text=Online+Learning+Systems%20https%3A%2F%2Fwww.arunbaby.com%2Fml-system-design%2F0009-online-learning-systems%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.arunbaby.com%2Fml-system-design%2F0009-online-learning-systems%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.arunbaby.com/ml-system-design/0009-online-learning-systems/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/ml-system-design/0008-model-serving-architecture/" class="pagination--pager" title="Model Serving Architecture">Previous</a>
    
    
      <a href="/ml-system-design/0010-caching-strategies/" class="pagination--pager" title="Caching Strategies for ML Systems">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 1990 - 2143 <a href="https://www.arunbaby.com">Arun Baby</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JRJPEC9SS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0JRJPEC9SS', { 'anonymize_ip': false});
</script>








  </body>
</html>
