<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Experiment Tracking Systems - Arun Baby</title>
<meta name="description" content="Design robust experiment tracking systems that enable systematic exploration, reproducibility, and collaboration across large ML teams.">


  <meta name="author" content="Arun Baby">
  
  <meta property="article:author" content="Arun Baby">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Arun Baby">
<meta property="og:title" content="Experiment Tracking Systems">
<meta property="og:url" content="https://www.arunbaby.com/ml-system-design/0019-experiment-tracking-systems/">


  <meta property="og:description" content="Design robust experiment tracking systems that enable systematic exploration, reproducibility, and collaboration across large ML teams.">



  <meta property="og:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">



  <meta name="twitter:site" content="@arunbaby0">
  <meta name="twitter:title" content="Experiment Tracking Systems">
  <meta name="twitter:description" content="Design robust experiment tracking systems that enable systematic exploration, reproducibility, and collaboration across large ML teams.">
  <meta name="twitter:url" content="https://www.arunbaby.com/ml-system-design/0019-experiment-tracking-systems/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">
    
  

  



  <meta property="article:published_time" content="2025-12-16T00:19:35+05:30">





  

  


<link rel="canonical" href="https://www.arunbaby.com/ml-system-design/0019-experiment-tracking-systems/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Baby Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          <span class="site-subtitle">Arun Baby</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/dsa/"
                
                
              >DSA</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ml-system-design/"
                
                
              >ML Systems</a>
            </li><li class="masthead__menu-item">
              <a
                href="/speech-tech/"
                
                
              >Speech Tech</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ai-agents/"
                
                
              >AI Agents</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li><li class="masthead__menu-item">
              <a
                href="/statuses/"
                
                
              >Statuses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/contact/"
                
                
              >Contact</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main" class="no-author-sidebar">
  
  <div class="sidebar sticky">
  
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Experiment Tracking Systems">
    <meta itemprop="description" content="Design robust experiment tracking systems that enable systematic exploration, reproducibility, and collaboration across large ML teams.">
    <meta itemprop="datePublished" content="2025-12-16T00:19:35+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://www.arunbaby.com/ml-system-design/0019-experiment-tracking-systems/" itemprop="url">Experiment Tracking Systems
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          13 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#problem-statement">Problem Statement</a><ul><li><a href="#functional-requirements">Functional Requirements</a></li><li><a href="#non-functional-requirements">Non-Functional Requirements</a></li></ul></li><li><a href="#understanding-the-requirements">Understanding the Requirements</a><ul><li><a href="#why-experiment-tracking-matters">Why Experiment Tracking Matters</a></li><li><a href="#the-systematic-iteration-connection">The Systematic Iteration Connection</a></li></ul></li><li><a href="#high-level-architecture">High-Level Architecture</a><ul><li><a href="#key-components">Key Components</a></li></ul></li><li><a href="#component-deep-dive">Component Deep-Dive</a><ul><li><a href="#1-metadata-schema">1. Metadata Schema</a></li><li><a href="#2-python-sdk-client-interface">2. Python SDK (Client Interface)</a></li><li><a href="#3-metric-logging--streaming">3. Metric Logging &amp; Streaming</a></li><li><a href="#4-artifact-storage--deduplication">4. Artifact Storage &amp; Deduplication</a></li><li><a href="#5-query--search">5. Query &amp; Search</a></li></ul></li><li><a href="#scaling-strategies">Scaling Strategies</a><ul><li><a href="#1-sharding-experimentsruns">1. Sharding Experiments/Runs</a></li><li><a href="#2-metric-buffering--batching">2. Metric Buffering &amp; Batching</a></li><li><a href="#3-artifact-caching">3. Artifact Caching</a></li><li><a href="#4-distributed-artifact-storage">4. Distributed Artifact Storage</a></li></ul></li><li><a href="#monitoring--observability">Monitoring &amp; Observability</a><ul><li><a href="#key-metrics">Key Metrics</a></li></ul></li><li><a href="#failure-modes--mitigations">Failure Modes &amp; Mitigations</a></li><li><a href="#real-world-case-study-large-scale-ml-team">Real-World Case Study: Large-Scale ML Team</a></li><li><a href="#cost-analysis">Cost Analysis</a><ul><li><a href="#example-medium-sized-team">Example: Medium-Sized Team</a></li></ul></li><li><a href="#advanced-topics">Advanced Topics</a><ul><li><a href="#1-hyperparameter-sweep-integration">1. Hyperparameter Sweep Integration</a></li><li><a href="#2-model-registry-integration">2. Model Registry Integration</a></li><li><a href="#3-data-versioning">3. Data Versioning</a></li><li><a href="#4-compliance--audit-trails">4. Compliance &amp; Audit Trails</a></li></ul></li><li><a href="#practical-debugging--operations-checklist">Practical Debugging &amp; Operations Checklist</a><ul><li><a href="#for-platform-engineers">For Platform Engineers</a></li><li><a href="#for-ml-engineers">For ML Engineers</a></li></ul></li><li><a href="#key-takeaways">Key Takeaways</a><ul><li><a href="#connection-to-thematic-link-systematic-iteration-and-state-tracking">Connection to Thematic Link: Systematic Iteration and State Tracking</a></li></ul></li></ul>
            </nav>
          </aside>
        
        <p><strong>Design robust experiment tracking systems that enable systematic exploration, reproducibility, and collaboration across large ML teams.</strong></p>

<h2 id="problem-statement">Problem Statement</h2>

<p>Design an <strong>Experiment Tracking System</strong> for ML teams that:</p>

<ol>
  <li><strong>Tracks all experiment metadata</strong>: hyperparameters, metrics, code versions, data versions, artifacts</li>
  <li><strong>Supports large scale</strong>: Thousands of experiments, millions of runs, petabyte-scale model artifacts</li>
  <li><strong>Enables comparison and visualization</strong>: Compare runs, plot learning curves, analyze hyperparameter impact</li>
  <li><strong>Ensures reproducibility</strong>: Any experiment can be re-run from tracked metadata</li>
  <li><strong>Integrates with training pipelines</strong>: Minimal code changes, automatic logging</li>
  <li><strong>Supports collaboration</strong>: Share experiments, notebook integration, API access</li>
</ol>

<h3 id="functional-requirements">Functional Requirements</h3>

<ol>
  <li><strong>Experiment lifecycle management:</strong>
    <ul>
      <li>Create experiments and runs</li>
      <li>Log parameters, metrics, tags, notes</li>
      <li>Upload artifacts (models, plots, datasets)</li>
      <li>Track code versions (Git commit, diff)</li>
      <li>Track data versions (dataset hashes, splits)</li>
      <li>Link parent/child runs (hyperparameter sweeps, ensemble members)</li>
    </ul>
  </li>
  <li><strong>Query and search:</strong>
    <ul>
      <li>Filter by parameters, metrics, tags</li>
      <li>Full-text search over notes and descriptions</li>
      <li>Query by date, user, project</li>
    </ul>
  </li>
  <li><strong>Visualization and comparison:</strong>
    <ul>
      <li>Learning curves (metric vs step/epoch)</li>
      <li>Hyperparameter sweeps (parallel coordinates, scatter)</li>
      <li>Compare multiple runs side-by-side</li>
      <li>Export to notebooks (Jupyter, Colab)</li>
    </ul>
  </li>
  <li><strong>Artifact management:</strong>
    <ul>
      <li>Store and version models, checkpoints, plots</li>
      <li>Efficient storage for large artifacts (deduplication, compression)</li>
      <li>Support for streaming logs (real-time metrics)</li>
    </ul>
  </li>
  <li><strong>Reproducibility:</strong>
    <ul>
      <li>Capture full environment (packages, hardware, Docker image)</li>
      <li>Re-run experiments from tracked metadata</li>
      <li>Audit trail for compliance</li>
    </ul>
  </li>
  <li><strong>Integration:</strong>
    <ul>
      <li>Python SDK (PyTorch, TensorFlow, JAX)</li>
      <li>CLI for automation</li>
      <li>REST API for custom clients</li>
      <li>Webhook/notification support</li>
    </ul>
  </li>
</ol>

<h3 id="non-functional-requirements">Non-Functional Requirements</h3>

<ol>
  <li><strong>Scalability:</strong> Support 10K+ concurrent experiments, 1M+ total runs</li>
  <li><strong>Performance:</strong> Log metrics with &lt;10ms latency, query results in &lt;1s</li>
  <li><strong>Reliability:</strong> 99.9% uptime, no data loss</li>
  <li><strong>Security:</strong> Role-based access control, encryption at rest and in transit</li>
  <li><strong>Cost efficiency:</strong> Optimize storage costs for artifacts (tiered storage, compression)</li>
</ol>

<h2 id="understanding-the-requirements">Understanding the Requirements</h2>

<h3 id="why-experiment-tracking-matters">Why Experiment Tracking Matters</h3>

<p>Without systematic tracking, ML teams face:</p>

<ul>
  <li><strong>Lost experiments:</strong> “Which hyperparameters gave us 92% accuracy last month?”</li>
  <li><strong>Wasted compute:</strong> Re-running experiments accidentally</li>
  <li><strong>Non-reproducibility:</strong> “It worked on my laptop, but we can’t reproduce it”</li>
  <li><strong>Collaboration friction:</strong> Hard to share and compare results</li>
</ul>

<p>A good experiment tracking system is the <strong>foundation of MLOps</strong>—it enables:</p>

<ul>
  <li>Systematic exploration of model/data/hyperparameter spaces</li>
  <li>Clear audit trails for model governance</li>
  <li>Faster iteration through better visibility</li>
</ul>

<h3 id="the-systematic-iteration-connection">The Systematic Iteration Connection</h3>

<p>Just like <strong>Spiral Matrix</strong> systematically traverses a 2D structure layer-by-layer:</p>

<ul>
  <li><strong>Experiment tracking</strong> systematically explores multi-dimensional spaces:
    <ul>
      <li>Hyperparameters × architectures × data configurations × training schedules</li>
    </ul>
  </li>
  <li>Both require <strong>clear state management</strong>:
    <ul>
      <li>Spiral: track boundaries (top, bottom, left, right)</li>
      <li>Experiments: track runs (completed, running, failed), checkpoints, metrics</li>
    </ul>
  </li>
  <li>Both enable <strong>resumability</strong>:
    <ul>
      <li>Spiral: can pause and resume traversal</li>
      <li>Experiments: can restart from checkpoints, resume sweeps</li>
    </ul>
  </li>
</ul>

<h2 id="high-level-architecture">High-Level Architecture</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>┌─────────────────────────────────────────────────────────────────┐
│                  Experiment Tracking System                      │
└─────────────────────────────────────────────────────────────────┘

                            Client Layer
        ┌────────────────────────────────────────────┐
        │  Python SDK  │  CLI  │  Web UI  │  API    │
        └─────────────────────┬──────────────────────┘
                              │
                       API Gateway
                ┌──────────────┴──────────────┐
                │  - Auth &amp; rate limiting      │
                │  - Request routing           │
                │  - Logging &amp; monitoring      │
                └──────────────┬──────────────┘
                               │
              ┌────────────────┼────────────────┐
              │                │                │
      ┌───────▼────────┐ ┌────▼─────┐ ┌───────▼────────┐
      │  Metadata      │ │  Metrics │ │  Artifact      │
      │  Service       │ │  Service │ │  Service       │
      │                │ │          │ │                │
      │ - Experiments  │ │ - Logs   │ │ - Models       │
      │ - Runs         │ │ - Curves │ │ - Plots        │
      │ - Parameters   │ │ - Scalars│ │ - Datasets     │
      │ - Tags         │ │ - Hists  │ │ - Checkpoints  │
      └───────┬────────┘ └────┬─────┘ └───────┬────────┘
              │               │                │
      ┌───────▼────────┐ ┌────▼─────┐ ┌───────▼────────┐
      │  Postgres /    │ │  TimeSeries│ │  Object Store │
      │  MySQL         │ │  DB        │ │  (S3/GCS)     │
      │                │ │  (InfluxDB)│ │                │
      │ - Structured   │ │ - Metrics  │ │ - Large files │
      │   metadata     │ │ - Fast     │ │ - Versioned   │
      └────────────────┘ │   queries  │ │ - Deduped     │
                         └────────────┘ └────────────────┘
</code></pre></div></div>

<h3 id="key-components">Key Components</h3>

<ol>
  <li><strong>Metadata Service:</strong>
    <ul>
      <li>Stores experiment and run metadata (params, tags, code versions, user, etc.)</li>
      <li>Relational DB for structured queries</li>
      <li>Indexes on common query patterns (user, project, date, tags)</li>
    </ul>
  </li>
  <li><strong>Metrics Service:</strong>
    <ul>
      <li>High-throughput metric logging (train loss, val accuracy, etc.)</li>
      <li>Time-series database (InfluxDB, Prometheus, or custom)</li>
      <li>Support for streaming metrics (real-time plots)</li>
    </ul>
  </li>
  <li><strong>Artifact Service:</strong>
    <ul>
      <li>Stores large files (models, checkpoints, plots, datasets)</li>
      <li>Object storage (S3, GCS, Azure Blob)</li>
      <li>Deduplication (hash-based), compression, tiered storage</li>
    </ul>
  </li>
  <li><strong>API Gateway:</strong>
    <ul>
      <li>Authentication &amp; authorization (OAuth, API keys)</li>
      <li>Rate limiting (per user/project)</li>
      <li>Request routing and load balancing</li>
    </ul>
  </li>
  <li><strong>Web UI:</strong>
    <ul>
      <li>Dashboards for experiments, runs, metrics</li>
      <li>Comparison tools (side-by-side, parallel coordinates)</li>
      <li>Notebook integration (export to Jupyter)</li>
    </ul>
  </li>
</ol>

<h2 id="component-deep-dive">Component Deep-Dive</h2>

<h3 id="1-metadata-schema">1. Metadata Schema</h3>

<p><strong>Experiments</strong> group related runs (e.g., “ResNet ablation study”).</p>

<p><strong>Runs</strong> are individual training jobs with:</p>

<ul>
  <li>Unique run ID</li>
  <li>Parameters (hyperparameters, model config)</li>
  <li>Metrics (logged scalars, step-indexed)</li>
  <li>Tags (labels for filtering)</li>
  <li>Code version (Git commit, diff)</li>
  <li>Data version (dataset hash, split config)</li>
  <li>Environment (Python packages, Docker image, hardware)</li>
  <li>Artifacts (model files, plots, logs)</li>
  <li>Status (running, completed, failed)</li>
  <li>Timestamps (start, end)</li>
</ul>

<p><strong>Schema example (simplified):</strong></p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">experiments</span> <span class="p">(</span>
    <span class="n">experiment_id</span> <span class="n">UUID</span> <span class="k">PRIMARY</span> <span class="k">KEY</span><span class="p">,</span>
    <span class="n">name</span> <span class="nb">VARCHAR</span><span class="p">(</span><span class="mi">255</span><span class="p">),</span>
    <span class="n">description</span> <span class="nb">TEXT</span><span class="p">,</span>
    <span class="n">created_at</span> <span class="nb">TIMESTAMP</span><span class="p">,</span>
    <span class="n">user_id</span> <span class="nb">VARCHAR</span><span class="p">(</span><span class="mi">255</span><span class="p">),</span>
    <span class="n">project_id</span> <span class="n">UUID</span>
<span class="p">);</span>

<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">runs</span> <span class="p">(</span>
    <span class="n">run_id</span> <span class="n">UUID</span> <span class="k">PRIMARY</span> <span class="k">KEY</span><span class="p">,</span>
    <span class="n">experiment_id</span> <span class="n">UUID</span> <span class="k">REFERENCES</span> <span class="n">experiments</span><span class="p">(</span><span class="n">experiment_id</span><span class="p">),</span>
    <span class="n">name</span> <span class="nb">VARCHAR</span><span class="p">(</span><span class="mi">255</span><span class="p">),</span>
    <span class="n">status</span> <span class="nb">VARCHAR</span><span class="p">(</span><span class="mi">50</span><span class="p">),</span>  <span class="c1">-- running, completed, failed</span>
    <span class="n">start_time</span> <span class="nb">TIMESTAMP</span><span class="p">,</span>
    <span class="n">end_time</span> <span class="nb">TIMESTAMP</span><span class="p">,</span>
    <span class="n">user_id</span> <span class="nb">VARCHAR</span><span class="p">(</span><span class="mi">255</span><span class="p">),</span>
    <span class="n">git_commit</span> <span class="nb">VARCHAR</span><span class="p">(</span><span class="mi">40</span><span class="p">),</span>
    <span class="n">git_diff</span> <span class="nb">TEXT</span><span class="p">,</span>
    <span class="n">docker_image</span> <span class="nb">VARCHAR</span><span class="p">(</span><span class="mi">255</span><span class="p">),</span>
    <span class="n">environment</span> <span class="n">JSONB</span><span class="p">,</span>  <span class="c1">-- packages, hardware</span>
    <span class="n">notes</span> <span class="nb">TEXT</span>
<span class="p">);</span>

<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">run_params</span> <span class="p">(</span>
    <span class="n">run_id</span> <span class="n">UUID</span> <span class="k">REFERENCES</span> <span class="n">runs</span><span class="p">(</span><span class="n">run_id</span><span class="p">),</span>
    <span class="k">key</span> <span class="nb">VARCHAR</span><span class="p">(</span><span class="mi">255</span><span class="p">),</span>
    <span class="n">value</span> <span class="nb">TEXT</span><span class="p">,</span>  <span class="c1">-- JSON serialized</span>
    <span class="k">PRIMARY</span> <span class="k">KEY</span> <span class="p">(</span><span class="n">run_id</span><span class="p">,</span> <span class="k">key</span><span class="p">)</span>
<span class="p">);</span>

<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">run_metrics</span> <span class="p">(</span>
    <span class="n">run_id</span> <span class="n">UUID</span> <span class="k">REFERENCES</span> <span class="n">runs</span><span class="p">(</span><span class="n">run_id</span><span class="p">),</span>
    <span class="k">key</span> <span class="nb">VARCHAR</span><span class="p">(</span><span class="mi">255</span><span class="p">),</span>  <span class="c1">-- e.g., 'train_loss', 'val_accuracy'</span>
    <span class="n">step</span> <span class="nb">INT</span><span class="p">,</span>
    <span class="n">value</span> <span class="nb">FLOAT</span><span class="p">,</span>
    <span class="nb">timestamp</span> <span class="nb">TIMESTAMP</span><span class="p">,</span>
    <span class="k">PRIMARY</span> <span class="k">KEY</span> <span class="p">(</span><span class="n">run_id</span><span class="p">,</span> <span class="k">key</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
<span class="p">);</span>

<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">run_tags</span> <span class="p">(</span>
    <span class="n">run_id</span> <span class="n">UUID</span> <span class="k">REFERENCES</span> <span class="n">runs</span><span class="p">(</span><span class="n">run_id</span><span class="p">),</span>
    <span class="k">key</span> <span class="nb">VARCHAR</span><span class="p">(</span><span class="mi">255</span><span class="p">),</span>
    <span class="n">value</span> <span class="nb">VARCHAR</span><span class="p">(</span><span class="mi">255</span><span class="p">),</span>
    <span class="k">PRIMARY</span> <span class="k">KEY</span> <span class="p">(</span><span class="n">run_id</span><span class="p">,</span> <span class="k">key</span><span class="p">)</span>
<span class="p">);</span>

<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">run_artifacts</span> <span class="p">(</span>
    <span class="n">artifact_id</span> <span class="n">UUID</span> <span class="k">PRIMARY</span> <span class="k">KEY</span><span class="p">,</span>
    <span class="n">run_id</span> <span class="n">UUID</span> <span class="k">REFERENCES</span> <span class="n">runs</span><span class="p">(</span><span class="n">run_id</span><span class="p">),</span>
    <span class="n">path</span> <span class="nb">VARCHAR</span><span class="p">(</span><span class="mi">1024</span><span class="p">),</span>  <span class="c1">-- e.g., 'model.pt', 'plots/loss.png'</span>
    <span class="n">size_bytes</span> <span class="nb">BIGINT</span><span class="p">,</span>
    <span class="n">content_hash</span> <span class="nb">VARCHAR</span><span class="p">(</span><span class="mi">64</span><span class="p">),</span>  <span class="c1">-- SHA-256</span>
    <span class="n">storage_uri</span> <span class="nb">TEXT</span><span class="p">,</span>  <span class="c1">-- S3 URI</span>
    <span class="n">created_at</span> <span class="nb">TIMESTAMP</span>
<span class="p">);</span>
</code></pre></div></div>

<h3 id="2-python-sdk-client-interface">2. Python SDK (Client Interface)</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">experiment_tracker</span> <span class="k">as</span> <span class="n">et</span>

<span class="c1"># Initialize client
</span><span class="n">client</span> <span class="o">=</span> <span class="n">et</span><span class="p">.</span><span class="nc">Client</span><span class="p">(</span><span class="n">api_url</span><span class="o">=</span><span class="sh">"</span><span class="s">https://tracking.example.com</span><span class="sh">"</span><span class="p">,</span> <span class="n">api_key</span><span class="o">=</span><span class="sh">"</span><span class="s">...</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Create experiment
</span><span class="n">experiment</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="nf">create_experiment</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">ResNet50 ImageNet Ablation</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="sh">"</span><span class="s">Testing different optimizers and learning rates</span><span class="sh">"</span>
<span class="p">)</span>

<span class="c1"># Start a run
</span><span class="n">run</span> <span class="o">=</span> <span class="n">experiment</span><span class="p">.</span><span class="nf">start_run</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">run_adam_lr0.001</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">tags</span><span class="o">=</span><span class="p">{</span><span class="sh">"</span><span class="s">optimizer</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">adam</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">dataset</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">imagenet</span><span class="sh">"</span><span class="p">}</span>
<span class="p">)</span>

<span class="c1"># Log parameters
</span><span class="n">run</span><span class="p">.</span><span class="nf">log_params</span><span class="p">({</span>
    <span class="sh">"</span><span class="s">model</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">resnet50</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">optimizer</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">adam</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">learning_rate</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">batch_size</span><span class="sh">"</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">epochs</span><span class="sh">"</span><span class="p">:</span> <span class="mi">90</span>
<span class="p">})</span>

<span class="c1"># Training loop
</span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">90</span><span class="p">):</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="nf">train_one_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">)</span>
    <span class="n">val_acc</span> <span class="o">=</span> <span class="nf">validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>
    
    <span class="c1"># Log metrics
</span>    <span class="n">run</span><span class="p">.</span><span class="nf">log_metrics</span><span class="p">({</span>
        <span class="sh">"</span><span class="s">train_loss</span><span class="sh">"</span><span class="p">:</span> <span class="n">train_loss</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">val_accuracy</span><span class="sh">"</span><span class="p">:</span> <span class="n">val_acc</span>
    <span class="p">},</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>

<span class="c1"># Save model
</span><span class="n">run</span><span class="p">.</span><span class="nf">log_artifact</span><span class="p">(</span><span class="sh">"</span><span class="s">model.pt</span><span class="sh">"</span><span class="p">,</span> <span class="n">local_path</span><span class="o">=</span><span class="sh">"</span><span class="s">./checkpoints/model_epoch90.pt</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Mark run as complete
</span><span class="n">run</span><span class="p">.</span><span class="nf">finish</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="3-metric-logging--streaming">3. Metric Logging &amp; Streaming</h3>

<p>For real-time metric visualization:</p>

<ul>
  <li>Clients send metrics via WebSocket or HTTP streaming</li>
  <li>Metrics Service buffers and batches writes to time-series DB</li>
  <li>Web UI subscribes to metric streams for live plots</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Streaming metrics example
</span><span class="k">def</span> <span class="nf">train_with_streaming_metrics</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">run</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
        
        <span class="c1"># Log every N steps for live tracking
</span>        <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">run</span><span class="p">.</span><span class="nf">log_metric</span><span class="p">(</span><span class="sh">"</span><span class="s">train_loss</span><span class="sh">"</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">step</span><span class="p">)</span>
            <span class="c1"># Internally: buffered, batched, sent asynchronously
</span></code></pre></div></div>

<h3 id="4-artifact-storage--deduplication">4. Artifact Storage &amp; Deduplication</h3>

<p><strong>Challenge:</strong> Models can be GBs–TBs. Storing every checkpoint is expensive.</p>

<p><strong>Solution:</strong></p>

<ul>
  <li><strong>Content-based deduplication:</strong>
    <ul>
      <li>Hash each artifact (SHA-256).</li>
      <li>If hash exists, create metadata entry but don’t re-upload.</li>
    </ul>
  </li>
  <li><strong>Tiered storage:</strong>
    <ul>
      <li>Hot: Recent artifacts on fast storage (SSD, S3 standard).</li>
      <li>Cold: Old artifacts on cheaper storage (S3 Glacier, tape).</li>
    </ul>
  </li>
  <li><strong>Compression:</strong>
    <ul>
      <li>Compress models before upload (gzip, zstd).</li>
    </ul>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">hashlib</span>
<span class="kn">import</span> <span class="n">gzip</span>

<span class="k">def</span> <span class="nf">upload_artifact</span><span class="p">(</span><span class="n">run_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">local_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="c1"># Compute hash
</span>    <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">local_file</span><span class="p">,</span> <span class="sh">'</span><span class="s">rb</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="nf">read</span><span class="p">()</span>
        <span class="n">content_hash</span> <span class="o">=</span> <span class="n">hashlib</span><span class="p">.</span><span class="nf">sha256</span><span class="p">(</span><span class="n">content</span><span class="p">).</span><span class="nf">hexdigest</span><span class="p">()</span>
    
    <span class="c1"># Check if artifact with this hash exists
</span>    <span class="n">existing</span> <span class="o">=</span> <span class="n">artifact_service</span><span class="p">.</span><span class="nf">get_by_hash</span><span class="p">(</span><span class="n">content_hash</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">existing</span><span class="p">:</span>
        <span class="c1"># Create metadata entry pointing to existing storage
</span>        <span class="n">artifact_service</span><span class="p">.</span><span class="nf">link_artifact</span><span class="p">(</span><span class="n">run_id</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">existing</span><span class="p">.</span><span class="n">storage_uri</span><span class="p">,</span> <span class="n">content_hash</span><span class="p">)</span>
        <span class="k">return</span>
    
    <span class="c1"># Compress and upload
</span>    <span class="n">compressed</span> <span class="o">=</span> <span class="n">gzip</span><span class="p">.</span><span class="nf">compress</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
    <span class="n">storage_uri</span> <span class="o">=</span> <span class="n">object_store</span><span class="p">.</span><span class="nf">upload</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">run_id</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s">.gz</span><span class="sh">"</span><span class="p">,</span> <span class="n">compressed</span><span class="p">)</span>
    
    <span class="c1"># Create metadata entry
</span>    <span class="n">artifact_service</span><span class="p">.</span><span class="nf">create_artifact</span><span class="p">(</span>
        <span class="n">run_id</span><span class="o">=</span><span class="n">run_id</span><span class="p">,</span>
        <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
        <span class="n">size_bytes</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">content</span><span class="p">),</span>
        <span class="n">content_hash</span><span class="o">=</span><span class="n">content_hash</span><span class="p">,</span>
        <span class="n">storage_uri</span><span class="o">=</span><span class="n">storage_uri</span>
    <span class="p">)</span>
</code></pre></div></div>

<h3 id="5-query--search">5. Query &amp; Search</h3>

<p><strong>Common queries:</strong></p>

<ul>
  <li>“Show all runs with learning_rate &gt; 0.01 and val_accuracy &gt; 0.9”</li>
  <li>“Find best run in experiment X by val_accuracy”</li>
  <li>“Show runs created in last 7 days by user Y”</li>
</ul>

<p><strong>Implementation:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Query API example
</span><span class="n">runs</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="nf">search_runs</span><span class="p">(</span>
    <span class="n">experiment_ids</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">exp123</span><span class="sh">"</span><span class="p">],</span>
    <span class="n">filter_string</span><span class="o">=</span><span class="sh">"</span><span class="s">params.learning_rate &gt; 0.01 AND metrics.val_accuracy &gt; 0.9</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">order_by</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">metrics.val_accuracy DESC</span><span class="sh">"</span><span class="p">],</span>
    <span class="n">max_results</span><span class="o">=</span><span class="mi">10</span>
<span class="p">)</span>

<span class="k">for</span> <span class="n">run</span> <span class="ow">in</span> <span class="n">runs</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Run </span><span class="si">{</span><span class="n">run</span><span class="p">.</span><span class="n">run_id</span><span class="si">}</span><span class="s">: LR=</span><span class="si">{</span><span class="n">run</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">learning_rate</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="s">, Acc=</span><span class="si">{</span><span class="n">run</span><span class="p">.</span><span class="n">metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">val_accuracy</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Optimization:</strong></p>

<ul>
  <li>Index on common filter fields (user_id, experiment_id, tags, status, timestamps)</li>
  <li>Cache popular queries (top runs, recent runs)</li>
  <li>Use read replicas for heavy read workloads</li>
</ul>

<h2 id="scaling-strategies">Scaling Strategies</h2>

<h3 id="1-sharding-experimentsruns">1. Sharding Experiments/Runs</h3>

<p>For very large deployments:</p>

<ul>
  <li>Shard metadata DB by experiment_id or user_id</li>
  <li>Each shard handles a subset of experiments</li>
  <li>API Gateway routes requests to correct shard</li>
</ul>

<h3 id="2-metric-buffering--batching">2. Metric Buffering &amp; Batching</h3>

<p>High-throughput training jobs can log metrics at high frequency (100s–1000s/sec):</p>

<ul>
  <li>Client buffers metrics locally</li>
  <li>Batches and sends every N seconds or M metrics</li>
  <li>Server-side ingestion queue (Kafka, SQS) for further buffering</li>
</ul>

<h3 id="3-artifact-caching">3. Artifact Caching</h3>

<p>Frequently accessed artifacts (latest models, popular checkpoints):</p>

<ul>
  <li>Cache in CDN (CloudFront, Fastly)</li>
  <li>Local cache on training nodes (NVMe SSD)</li>
  <li>Lazy loading: download only when accessed</li>
</ul>

<h3 id="4-distributed-artifact-storage">4. Distributed Artifact Storage</h3>

<p>For petabyte-scale artifact storage:</p>

<ul>
  <li>Use distributed object stores (S3, GCS, Ceph)</li>
  <li>Implement multipart upload for large files</li>
  <li>Use pre-signed URLs for direct client-to-storage uploads (bypass API server)</li>
</ul>

<h2 id="monitoring--observability">Monitoring &amp; Observability</h2>

<h3 id="key-metrics">Key Metrics</h3>

<p><strong>System metrics:</strong></p>
<ul>
  <li>Request latency (p50, p95, p99)</li>
  <li>Throughput (requests/sec, metrics logged/sec, artifacts uploaded/sec)</li>
  <li>Error rates (4xx, 5xx)</li>
  <li>Storage usage (DB size, object store size)</li>
</ul>

<p><strong>User metrics:</strong></p>
<ul>
  <li>Active experiments/runs</li>
  <li>Average metrics logged per run</li>
  <li>Average artifact size</li>
  <li>Query response times</li>
</ul>

<p><strong>Dashboards:</strong></p>
<ul>
  <li>Real-time experiment dashboard (running/completed/failed runs)</li>
  <li>System health dashboard (latency, error rates, resource usage)</li>
  <li>Cost dashboard (storage costs, compute costs)</li>
</ul>

<h2 id="failure-modes--mitigations">Failure Modes &amp; Mitigations</h2>

<table>
  <thead>
    <tr>
      <th>Failure Mode</th>
      <th>Impact</th>
      <th>Mitigation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Metadata DB down</strong></td>
      <td>Can’t create/query experiments</td>
      <td>Read replicas, automatic failover, local caching</td>
    </tr>
    <tr>
      <td><strong>Object store unavailable</strong></td>
      <td>Can’t upload/download artifacts</td>
      <td>Retry with exponential backoff, fallback to local storage</td>
    </tr>
    <tr>
      <td><strong>Metric ingestion backlog</strong></td>
      <td>Delayed metric visibility</td>
      <td>Buffering, rate limiting, auto-scaling ingest workers</td>
    </tr>
    <tr>
      <td><strong>Lost run metadata</strong></td>
      <td>Experiment not reproducible</td>
      <td>Periodic backups, transaction logs, write-ahead logs</td>
    </tr>
    <tr>
      <td><strong>Concurrent write conflicts</strong></td>
      <td>Metrics/artifacts overwritten</td>
      <td>Optimistic locking, append-only logs</td>
    </tr>
    <tr>
      <td><strong>API rate limit hit</strong></td>
      <td>Client blocked</td>
      <td>Exponential backoff, client-side buffering, increase limits</td>
    </tr>
  </tbody>
</table>

<h2 id="real-world-case-study-large-scale-ml-team">Real-World Case Study: Large-Scale ML Team</h2>

<p><strong>Scenario:</strong></p>
<ul>
  <li>100+ ML engineers and researchers</li>
  <li>50K+ experiments, 1M+ runs</li>
  <li>10 PB of artifacts (models, datasets, checkpoints)</li>
  <li>Multi-cloud (AWS, GCP)</li>
</ul>

<p><strong>Architecture:</strong></p>
<ul>
  <li>Metadata: PostgreSQL with read replicas, sharded by experiment_id</li>
  <li>Metrics: InfluxDB cluster, 100K metrics/sec write throughput</li>
  <li>Artifacts: S3 + GCS with cross-region replication</li>
  <li>API: Kubernetes cluster with auto-scaling (10–100 pods)</li>
  <li>Web UI: React SPA, served via CDN</li>
</ul>

<p><strong>Key optimizations:</strong></p>
<ul>
  <li>Pre-signed URLs for large artifact uploads (direct to S3/GCS)</li>
  <li>Client-side metric buffering (log every 10 steps, batch send)</li>
  <li>Artifact deduplication (saved ~30% storage cost)</li>
  <li>Tiered storage (hot: S3 Standard, cold: S3 Glacier, ~50% cost reduction)</li>
</ul>

<p><strong>Outcomes:</strong></p>
<ul>
  <li>99.95% uptime</li>
  <li>Median query latency: 120ms</li>
  <li>p99 metric log latency: 8ms</li>
  <li>$200K/year savings from deduplication and tiered storage</li>
</ul>

<h2 id="cost-analysis">Cost Analysis</h2>

<h3 id="example-medium-sized-team">Example: Medium-Sized Team</h3>

<p><strong>Assumptions:</strong></p>
<ul>
  <li>10 researchers</li>
  <li>100 experiments/month, 1000 runs/month</li>
  <li>Average run: 10 GB artifacts, 10K metrics</li>
  <li>Retention: 2 years</li>
</ul>

<table>
  <thead>
    <tr>
      <th>Component</th>
      <th>Cost/Month</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Metadata DB (PostgreSQL RDS, db.r5.large)</td>
      <td>$300</td>
    </tr>
    <tr>
      <td>Metrics DB (InfluxDB Cloud)</td>
      <td>$500</td>
    </tr>
    <tr>
      <td>Object storage (S3, 10 TB)</td>
      <td>$230</td>
    </tr>
    <tr>
      <td>API compute (Kubernetes, 5 nodes)</td>
      <td>$750</td>
    </tr>
    <tr>
      <td>Data transfer</td>
      <td>$100</td>
    </tr>
    <tr>
      <td><strong>Total</strong></td>
      <td><strong>$1,880</strong></td>
    </tr>
  </tbody>
</table>

<p><strong>Optimization levers:</strong></p>
<ul>
  <li>Deduplication: -20–30% storage cost</li>
  <li>Tiered storage: -30–50% storage cost (move old artifacts to Glacier)</li>
  <li>Reserved instances: -30% compute cost</li>
  <li>Compression: -50% storage and transfer cost</li>
</ul>

<h2 id="advanced-topics">Advanced Topics</h2>

<h3 id="1-hyperparameter-sweep-integration">1. Hyperparameter Sweep Integration</h3>

<p>Integrate with hyperparameter tuning libraries (Optuna, Ray Tune):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">optuna</span>
<span class="kn">import</span> <span class="n">experiment_tracker</span> <span class="k">as</span> <span class="n">et</span>

<span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
    <span class="n">run</span> <span class="o">=</span> <span class="n">experiment</span><span class="p">.</span><span class="nf">start_run</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="sh">"</span><span class="s">trial_</span><span class="si">{</span><span class="n">trial</span><span class="p">.</span><span class="n">number</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="c1"># Suggest hyperparameters
</span>    <span class="n">lr</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_loguniform</span><span class="p">(</span><span class="sh">"</span><span class="s">learning_rate</span><span class="sh">"</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">)</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_categorical</span><span class="p">(</span><span class="sh">"</span><span class="s">batch_size</span><span class="sh">"</span><span class="p">,</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">])</span>
    
    <span class="n">run</span><span class="p">.</span><span class="nf">log_params</span><span class="p">({</span><span class="sh">"</span><span class="s">learning_rate</span><span class="sh">"</span><span class="p">:</span> <span class="n">lr</span><span class="p">,</span> <span class="sh">"</span><span class="s">batch_size</span><span class="sh">"</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">})</span>
    
    <span class="c1"># Train and log metrics
</span>    <span class="n">val_acc</span> <span class="o">=</span> <span class="nf">train_and_evaluate</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">run</span><span class="p">)</span>
    
    <span class="n">run</span><span class="p">.</span><span class="nf">finish</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">val_acc</span>

<span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="p">.</span><span class="nf">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="sh">"</span><span class="s">maximize</span><span class="sh">"</span><span class="p">)</span>
<span class="n">study</span><span class="p">.</span><span class="nf">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="2-model-registry-integration">2. Model Registry Integration</h3>

<p>Link experiment tracking with model registry:</p>

<ul>
  <li>Best run → promoted to staging → production</li>
  <li>Track lineage: model → run → experiment → dataset</li>
</ul>

<h3 id="3-data-versioning">3. Data Versioning</h3>

<p>Track data versions alongside experiments:</p>

<ul>
  <li>Dataset hash (content-based)</li>
  <li>Data pipeline version (Git commit)</li>
  <li>Train/val/test split configs</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">run</span><span class="p">.</span><span class="nf">log_dataset</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">imagenet_v2</span><span class="sh">"</span><span class="p">,</span>
    <span class="nb">hash</span><span class="o">=</span><span class="sh">"</span><span class="s">sha256:abc123...</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">split_config</span><span class="o">=</span><span class="p">{</span><span class="sh">"</span><span class="s">train</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span> <span class="sh">"</span><span class="s">val</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span> <span class="sh">"</span><span class="s">test</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">}</span>
<span class="p">)</span>
</code></pre></div></div>

<h3 id="4-compliance--audit-trails">4. Compliance &amp; Audit Trails</h3>

<p>For regulated industries (healthcare, finance):</p>

<ul>
  <li>Immutable experiment logs</li>
  <li>Audit trail for all changes (who, what, when)</li>
  <li>Data lineage tracking</li>
  <li>Access control and encryption</li>
</ul>

<h2 id="practical-debugging--operations-checklist">Practical Debugging &amp; Operations Checklist</h2>

<h3 id="for-platform-engineers">For Platform Engineers</h3>

<ul>
  <li><strong>Monitor ingestion lag:</strong> Metrics should appear in UI within seconds of logging.</li>
  <li><strong>Set up alerts:</strong> DB disk space &gt;80%, API error rate &gt;1%, artifact upload failures.</li>
  <li><strong>Test disaster recovery:</strong> Can you restore from backups? Time to recover?</li>
  <li><strong>Load test:</strong> Can the system handle 10x current load?</li>
</ul>

<h3 id="for-ml-engineers">For ML Engineers</h3>

<ul>
  <li><strong>Always log hyperparameters:</strong> Even “fixed” ones—you’ll want to compare later.</li>
  <li><strong>Use tags liberally:</strong> Makes filtering/searching much easier.</li>
  <li><strong>Log environment:</strong> Git commit, Docker image, package versions—critical for reproducibility.</li>
  <li><strong>Log artifacts incrementally:</strong> Don’t wait until end of training to upload checkpoints.</li>
  <li><strong>Use run names:</strong> Descriptive names make comparison easier (<code class="language-plaintext highlighter-rouge">resnet50_adam_lr0.001</code> vs <code class="language-plaintext highlighter-rouge">run_42</code>).</li>
</ul>

<h2 id="key-takeaways">Key Takeaways</h2>

<p>✅ <strong>Experiment tracking is foundational for MLOps</strong>—enables reproducibility, collaboration, and systematic exploration.</p>

<p>✅ <strong>Scale requires separation of concerns</strong>: metadata, metrics, artifacts each have different storage/query needs.</p>

<p>✅ <strong>Deduplication and tiered storage</strong> are critical for cost efficiency at scale.</p>

<p>✅ <strong>Client-side buffering</strong> avoids overwhelming the backend with high-frequency metric logging.</p>

<p>✅ <strong>Systematic iteration through experiment spaces</strong> mirrors structured traversal patterns (like Spiral Matrix).</p>

<p>✅ <strong>Integration with existing tools</strong> (Git, Docker, hyperparameter tuning) is key for adoption.</p>

<p>✅ <strong>Observability and cost monitoring</strong> are as important as core functionality.</p>

<h3 id="connection-to-thematic-link-systematic-iteration-and-state-tracking">Connection to Thematic Link: Systematic Iteration and State Tracking</h3>

<p>All three Day 19 topics converge on <strong>systematic, stateful exploration</strong>:</p>

<p><strong>DSA (Spiral Matrix):</strong></p>
<ul>
  <li>Layer-by-layer traversal with boundary tracking</li>
  <li>Explicit state management (top, bottom, left, right)</li>
  <li>Resume/pause friendly</li>
</ul>

<p><strong>ML System Design (Experiment Tracking Systems):</strong></p>
<ul>
  <li>Systematic exploration of hyperparameter/architecture spaces</li>
  <li>Track state of experiments (running, completed, failed)</li>
  <li>Resume from checkpoints, recover from failures</li>
</ul>

<p><strong>Speech Tech (Speech Experiment Management):</strong></p>
<ul>
  <li>Organize speech model experiments across multiple dimensions</li>
  <li>Track model versions, data versions, training configs</li>
  <li>Enable reproducibility and comparison</li>
</ul>

<p>The <strong>unifying pattern</strong>: structured iteration through complex spaces, with clear state persistence and recoverability.</p>

<hr />

<p><strong>Originally published at:</strong> <a href="https://www.arunbaby.com/ml-system-design/0019-experiment-tracking-systems/">arunbaby.com/ml-system-design/0019-experiment-tracking-systems</a></p>

<p><em>If you found this helpful, consider sharing it with others who might benefit.</em></p>


        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#experiment-tracking" class="page__taxonomy-item p-category" rel="tag">experiment-tracking</a><span class="sep">, </span>
    
      <a href="/tags/#infrastructure" class="page__taxonomy-item p-category" rel="tag">infrastructure</a><span class="sep">, </span>
    
      <a href="/tags/#metadata" class="page__taxonomy-item p-category" rel="tag">metadata</a><span class="sep">, </span>
    
      <a href="/tags/#mlops" class="page__taxonomy-item p-category" rel="tag">mlops</a><span class="sep">, </span>
    
      <a href="/tags/#reproducibility" class="page__taxonomy-item p-category" rel="tag">reproducibility</a><span class="sep">, </span>
    
      <a href="/tags/#versioning" class="page__taxonomy-item p-category" rel="tag">versioning</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#ml-system-design" class="page__taxonomy-item p-category" rel="tag">ml-system-design</a>
    
    </span>
  </p>


        
      </footer>

      <div class="page__related page__related--full">
  <h2 class="page__related-title">Related across topics</h2>
  <style>
    /* Make section span full content width and use 2 equal columns */
    .page__related--full { float: inline-start; width: 100%; padding: 0; }
    .cross-related-grid { display: grid; grid-template-columns: repeat(2, minmax(0, 1fr)); gap: 2rem; }
    @media (max-width: 768px) { .cross-related-grid { grid-template-columns: 1fr; } }
    /* Ensure archive cards stretch nicely in the grid */
    .cross-related-grid .list__item, .cross-related-grid .grid__item { width: auto; float: none; margin: 0; }
  </style>
  <div class="cross-related-grid">
    



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/dsa/0019-spiral-matrix/" rel="permalink">Spiral Matrix
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          13 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Master systematic matrix traversal—the same pattern used for tracking experiments, processing logs, and managing state in ML systems.
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/speech-tech/0019-speech-experiment-management/" rel="permalink">Speech Experiment Management
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          7 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Design experiment management systems tailored for speech research—tracking audio data, models, metrics, and multi-dimensional experiments at scale.
</p>
  </article>
</div>

  </div>
</div>

      <section class="page__share">
  <h4 class="page__share-title">Share on</h4>

  <a href="https://twitter.com/intent/tweet?via=arunbaby0&text=Experiment+Tracking+Systems%20https%3A%2F%2Fwww.arunbaby.com%2Fml-system-design%2F0019-experiment-tracking-systems%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.arunbaby.com%2Fml-system-design%2F0019-experiment-tracking-systems%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.arunbaby.com/ml-system-design/0019-experiment-tracking-systems/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/ml-system-design/0018-data-augmentation-pipeline/" class="pagination--pager" title="Data Augmentation Pipeline">Previous</a>
    
    
      <a href="/ml-system-design/0020-online-learning-systems/" class="pagination--pager" title="Online Learning Systems">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 1990 - 2143 <a href="https://www.arunbaby.com">Arun Baby</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JRJPEC9SS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0JRJPEC9SS', { 'anonymize_ip': false});
</script>








  </body>
</html>
