<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Model Evaluation Metrics - Arun Baby</title>
<meta name="description" content="How to measure if your ML model is actually good, choosing the right metrics is as important as building the model itself.">


  <meta name="author" content="Arun Baby">
  
  <meta property="article:author" content="Arun Baby">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Arun Baby">
<meta property="og:title" content="Model Evaluation Metrics">
<meta property="og:url" content="https://www.arunbaby.com/ml-system-design/0006-model-evaluation-metrics/">


  <meta property="og:description" content="How to measure if your ML model is actually good, choosing the right metrics is as important as building the model itself.">



  <meta property="og:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">



  <meta name="twitter:site" content="@arunbaby0">
  <meta name="twitter:title" content="Model Evaluation Metrics">
  <meta name="twitter:description" content="How to measure if your ML model is actually good, choosing the right metrics is as important as building the model itself.">
  <meta name="twitter:url" content="https://www.arunbaby.com/ml-system-design/0006-model-evaluation-metrics/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">
    
  

  



  <meta property="article:published_time" content="2025-12-13T22:45:49+05:30">





  

  


<link rel="canonical" href="https://www.arunbaby.com/ml-system-design/0006-model-evaluation-metrics/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Baby Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          <span class="site-subtitle">Arun Baby</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/dsa/"
                
                
              >DSA</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ml-system-design/"
                
                
              >ML Systems</a>
            </li><li class="masthead__menu-item">
              <a
                href="/speech-tech/"
                
                
              >Speech Tech</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li><li class="masthead__menu-item">
              <a
                href="/statuses/"
                
                
              >Statuses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/contact/"
                
                
              >Contact</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main" class="no-author-sidebar">
  
  <div class="sidebar sticky">
  
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Model Evaluation Metrics">
    <meta itemprop="description" content="How to measure if your ML model is actually good, choosing the right metrics is as important as building the model itself.">
    <meta itemprop="datePublished" content="2025-12-13T22:45:49+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://www.arunbaby.com/ml-system-design/0006-model-evaluation-metrics/" itemprop="url">Model Evaluation Metrics
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          24 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#introduction">Introduction</a></li><li><a href="#classification-metrics">Classification Metrics</a><ul><li><a href="#binary-classification">Binary Classification</a><ul><li><a href="#accuracy">Accuracy</a></li><li><a href="#precision">Precision</a></li><li><a href="#recall-sensitivity-true-positive-rate">Recall (Sensitivity, True Positive Rate)</a></li><li><a href="#f1-score">F1 Score</a></li><li><a href="#roc-curve--auc">ROC Curve &amp; AUC</a></li><li><a href="#precision-recall-curve">Precision-Recall Curve</a></li></ul></li><li><a href="#multi-class-classification">Multi-Class Classification</a></li></ul></li><li><a href="#regression-metrics">Regression Metrics</a><ul><li><a href="#mean-squared-error-mse">Mean Squared Error (MSE)</a></li><li><a href="#root-mean-squared-error-rmse">Root Mean Squared Error (RMSE)</a></li><li><a href="#mean-absolute-error-mae">Mean Absolute Error (MAE)</a></li><li><a href="#r-score-coefficient-of-determination">R² Score (Coefficient of Determination)</a></li><li><a href="#mean-absolute-percentage-error-mape">Mean Absolute Percentage Error (MAPE)</a></li></ul></li><li><a href="#ranking-metrics">Ranking Metrics</a><ul><li><a href="#normalized-discounted-cumulative-gain-ndcg">Normalized Discounted Cumulative Gain (NDCG)</a></li><li><a href="#mean-average-precision-map">Mean Average Precision (MAP)</a></li><li><a href="#mean-reciprocal-rank-mrr">Mean Reciprocal Rank (MRR)</a></li></ul></li><li><a href="#choosing-the-right-metric">Choosing the Right Metric</a><ul><li><a href="#decision-framework">Decision Framework</a></li></ul></li><li><a href="#production-monitoring">Production Monitoring</a><ul><li><a href="#metric-tracking-system">Metric Tracking System</a></li></ul></li><li><a href="#model-calibration">Model Calibration</a><ul><li><a href="#calibration-plot">Calibration Plot</a></li><li><a href="#calibrating-models">Calibrating Models</a></li></ul></li><li><a href="#threshold-tuning">Threshold Tuning</a><ul><li><a href="#finding-optimal-threshold">Finding Optimal Threshold</a></li><li><a href="#threshold-selection-strategies">Threshold Selection Strategies</a></li></ul></li><li><a href="#handling-imbalanced-datasets">Handling Imbalanced Datasets</a><ul><li><a href="#why-standard-metrics-fail">Why Standard Metrics Fail</a></li><li><a href="#better-metrics-for-imbalanced-data">Better Metrics for Imbalanced Data</a></li><li><a href="#sampling-strategies">Sampling Strategies</a></li></ul></li><li><a href="#aligning-ml-metrics-with-business-kpis">Aligning ML Metrics with Business KPIs</a><ul><li><a href="#example-1-e-commerce-recommendation-system">Example 1: E-commerce Recommendation System</a></li><li><a href="#example-2-content-moderation">Example 2: Content Moderation</a></li></ul></li><li><a href="#common-pitfalls">Common Pitfalls</a><ul><li><a href="#pitfall-1-data-leakage-in-evaluation">Pitfall 1: Data Leakage in Evaluation</a></li><li><a href="#pitfall-2-using-wrong-metric-for-problem">Pitfall 2: Using Wrong Metric for Problem</a></li><li><a href="#pitfall-3-ignoring-confidence-intervals">Pitfall 3: Ignoring Confidence Intervals</a></li><li><a href="#pitfall-4-overfitting-to-validation-set">Pitfall 4: Overfitting to Validation Set</a></li></ul></li><li><a href="#connection-to-speech-systems">Connection to Speech Systems</a><ul><li><a href="#tts-quality-metrics">TTS Quality Metrics</a></li><li><a href="#asr-error-metrics">ASR Error Metrics</a></li><li><a href="#speaker-verification">Speaker Verification</a></li></ul></li><li><a href="#key-takeaways">Key Takeaways</a></li></ul>
            </nav>
          </aside>
        
        <p><strong>How to measure if your ML model is actually good, choosing the right metrics is as important as building the model itself.</strong></p>

<h2 id="introduction">Introduction</h2>

<p><strong>Model evaluation metrics</strong> are quantitative measures of model performance. Choosing the wrong metric can lead to models that optimize for the wrong objective.</p>

<p><strong>Why metrics matter:</strong></p>
<ul>
  <li><strong>Define success:</strong> What does “good” mean for your model?</li>
  <li><strong>Compare models:</strong> Which of 10 models should you deploy?</li>
  <li><strong>Monitor production:</strong> Detect when model degrades</li>
  <li><strong>Align with business:</strong> ML metrics must connect to business KPIs</li>
</ul>

<p><strong>What you’ll learn:</strong></p>
<ul>
  <li>Classification metrics (accuracy, precision, recall, F1, ROC-AUC)</li>
  <li>Regression metrics (MSE, MAE, R²)</li>
  <li>Ranking metrics (NDCG, MAP, MRR)</li>
  <li>Choosing the right metric for your problem</li>
  <li>Production monitoring strategies</li>
</ul>

<hr />

<h2 id="classification-metrics">Classification Metrics</h2>

<h3 id="binary-classification">Binary Classification</h3>

<p><strong>Confusion Matrix:</strong> Foundation of all classification metrics.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                 Predicted
                 Pos   Neg
Actual  Pos      TP    FN
        Neg      FP    TN

TP: True Positive  - Correctly predicted positive
TN: True Negative  - Correctly predicted negative
FP: False Positive - Incorrectly predicted positive (Type I error)
FN: False Negative - Incorrectly predicted negative (Type II error)
</code></pre></div></div>

<h4 id="accuracy">Accuracy</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Accuracy = (TP + TN) / (TP + TN + FP + FN)
</code></pre></div></div>

<p><strong>When to use:</strong> Balanced datasets<br />
<strong>When NOT to use:</strong> Imbalanced datasets</p>

<p><strong>Example:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="n">accuracy</span> <span class="o">=</span> <span class="nf">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="o">%</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>  <span class="c1"># 75.00%
</span></code></pre></div></div>

<p><strong>Accuracy Paradox:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Dataset: 95% negative, 5% positive (highly imbalanced)
# Model always predicts negative → 95% accurate!
# But useless for detecting positive class
</span></code></pre></div></div>

<h4 id="precision">Precision</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Precision = TP / (TP + FP)
</code></pre></div></div>

<p><strong>Interpretation:</strong> Of all positive predictions, how many were actually positive?</p>

<p><strong>When to use:</strong> Cost of false positives is high<br />
<strong>Example:</strong> Email spam detection (don’t mark legitimate emails as spam)</p>

<h4 id="recall-sensitivity-true-positive-rate">Recall (Sensitivity, True Positive Rate)</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Recall = TP / (TP + FN)
</code></pre></div></div>

<p><strong>Interpretation:</strong> Of all actual positives, how many did we detect?</p>

<p><strong>When to use:</strong> Cost of false negatives is high<br />
<strong>Example:</strong> Cancer detection (don’t miss actual cases)</p>

<h4 id="f1-score">F1 Score</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>F1 = 2 * (Precision * Recall) / (Precision + Recall)
</code></pre></div></div>

<p><strong>Interpretation:</strong> Harmonic mean of precision and recall</p>

<p><strong>When to use:</strong> Need balance between precision and recall</p>

<p><strong>Implementation:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>

<span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

<span class="c1"># Compute metrics
</span><span class="n">precision</span> <span class="o">=</span> <span class="nf">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">recall</span> <span class="o">=</span> <span class="nf">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">f1</span> <span class="o">=</span> <span class="nf">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Precision: </span><span class="si">{</span><span class="n">precision</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="o">%</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Recall: </span><span class="si">{</span><span class="n">recall</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="o">%</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">F1 Score: </span><span class="si">{</span><span class="n">f1</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="o">%</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Confusion matrix
</span><span class="n">cm</span> <span class="o">=</span> <span class="nf">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Confusion Matrix:</span><span class="se">\n</span><span class="si">{</span><span class="n">cm</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="roc-curve--auc">ROC Curve &amp; AUC</h4>

<p><strong>ROC (Receiver Operating Characteristic):</strong> Plot of True Positive Rate vs False Positive Rate at different thresholds.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">roc_auc_score</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># Predicted probabilities
</span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">y_scores</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]</span>

<span class="c1"># Compute ROC curve
</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="nf">roc_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>

<span class="c1"># Compute AUC
</span><span class="n">auc</span> <span class="o">=</span> <span class="nf">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>

<span class="c1"># Plot
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="sh">'</span><span class="s">ROC Curve (AUC = </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="sh">'</span><span class="s">k--</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Random Classifier</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">False Positive Rate</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">True Positive Rate</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">ROC Curve</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">AUC: </span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>AUC Interpretation:</strong></p>
<ul>
  <li>1.0: Perfect classifier</li>
  <li>0.5: Random classifier</li>
  <li>&lt; 0.5: Worse than random (inverted predictions)</li>
</ul>

<p><strong>When to use AUC:</strong> When you want threshold-independent performance measure</p>

<h4 id="precision-recall-curve">Precision-Recall Curve</h4>

<p>Better than ROC for imbalanced datasets.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_curve</span><span class="p">,</span> <span class="n">average_precision_score</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># Compute precision-recall curve
</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="nf">precision_recall_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>

<span class="c1"># Average precision
</span><span class="n">avg_precision</span> <span class="o">=</span> <span class="nf">average_precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>

<span class="c1"># Plot
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">recall</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="sh">'</span><span class="s">PR Curve (AP = </span><span class="si">{</span><span class="n">avg_precision</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Recall</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Precision</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Precision-Recall Curve</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<hr />

<h3 id="multi-class-classification">Multi-Class Classification</h3>

<p><strong>Macro vs Micro Averaging:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>

<span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>

<span class="c1"># Classification report
</span><span class="n">report</span> <span class="o">=</span> <span class="nf">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">Class A</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Class B</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Class C</span><span class="sh">'</span><span class="p">])</span>
<span class="nf">print</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Macro Average:</strong> Average of per-class metrics (treats all classes equally)<br />
<strong>Micro Average:</strong> Aggregate TP, FP, FN across all classes (favors frequent classes)<br />
<strong>Weighted Average:</strong> Weighted by class frequency</p>

<p><strong>When to use which:</strong></p>
<ul>
  <li><strong>Macro:</strong> All classes equally important</li>
  <li><strong>Micro:</strong> Overall performance across all predictions</li>
  <li><strong>Weighted:</strong> Account for class imbalance</li>
</ul>

<hr />

<h2 id="regression-metrics">Regression Metrics</h2>

<h3 id="mean-squared-error-mse">Mean Squared Error (MSE)</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>MSE = (1/n) * Σ(y_true - y_pred)²
</code></pre></div></div>

<p><strong>Properties:</strong></p>
<ul>
  <li>Penalizes large errors heavily (squared term)</li>
  <li>Always non-negative</li>
  <li>Same units as y²</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">]</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">]</span>

<span class="n">mse</span> <span class="o">=</span> <span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">MSE: </span><span class="si">{</span><span class="n">mse</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="root-mean-squared-error-rmse">Root Mean Squared Error (RMSE)</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>RMSE = √MSE
</code></pre></div></div>

<p><strong>Properties:</strong></p>
<ul>
  <li>Same units as y (interpretable)</li>
  <li>Sensitive to outliers</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rmse</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">RMSE: </span><span class="si">{</span><span class="n">rmse</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="mean-absolute-error-mae">Mean Absolute Error (MAE)</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>MAE = (1/n) * Σ|y_true - y_pred|
</code></pre></div></div>

<p><strong>Properties:</strong></p>
<ul>
  <li>Linear penalty (all errors weighted equally)</li>
  <li>More robust to outliers than MSE</li>
  <li>Same units as y</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>

<span class="n">mae</span> <span class="o">=</span> <span class="nf">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">MAE: </span><span class="si">{</span><span class="n">mae</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>MSE vs MAE:</strong></p>
<ul>
  <li>Use <strong>MSE</strong> when large errors are especially bad</li>
  <li>Use <strong>MAE</strong> when all errors have equal weight</li>
</ul>

<h3 id="r-score-coefficient-of-determination">R² Score (Coefficient of Determination)</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>R² = 1 - (SS_res / SS_tot)

where:
  SS_res = Σ(y_true - y_pred)²  (residual sum of squares)
  SS_tot = Σ(y_true - y_mean)²  (total sum of squares)
</code></pre></div></div>

<p><strong>Interpretation:</strong></p>
<ul>
  <li>1.0: Perfect predictions</li>
  <li>0.0: Model performs as well as predicting mean</li>
  <li>&lt; 0.0: Model worse than predicting mean</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">r2</span> <span class="o">=</span> <span class="nf">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">R²: </span><span class="si">{</span><span class="n">r2</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="mean-absolute-percentage-error-mape">Mean Absolute Percentage Error (MAPE)</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>MAPE = (100/n) * Σ|((y_true - y_pred) / y_true)|
</code></pre></div></div>

<p><strong>When to use:</strong> When relative error matters more than absolute error</p>

<p><strong>Caveat:</strong> Undefined when y_true = 0</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">mean_absolute_percentage_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    MAPE implementation
    
    Warning: Undefined when y_true contains zeros
    </span><span class="sh">"""</span>
    <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">y_true</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
    
    <span class="c1"># Avoid division by zero
</span>    <span class="n">non_zero_mask</span> <span class="o">=</span> <span class="n">y_true</span> <span class="o">!=</span> <span class="mi">0</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="p">.</span><span class="nf">any</span><span class="p">(</span><span class="n">non_zero_mask</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">inf</span>
    
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">((</span><span class="n">y_true</span><span class="p">[</span><span class="n">non_zero_mask</span><span class="p">]</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">non_zero_mask</span><span class="p">])</span> <span class="o">/</span> <span class="n">y_true</span><span class="p">[</span><span class="n">non_zero_mask</span><span class="p">]))</span> <span class="o">*</span> <span class="mi">100</span>

<span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">300</span><span class="p">]</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">110</span><span class="p">,</span> <span class="mi">190</span><span class="p">,</span> <span class="mi">160</span><span class="p">,</span> <span class="mi">280</span><span class="p">]</span>

<span class="n">mape</span> <span class="o">=</span> <span class="nf">mean_absolute_percentage_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">MAPE: </span><span class="si">{</span><span class="n">mape</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">%</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<hr />

<h2 id="ranking-metrics">Ranking Metrics</h2>

<p>For recommendation systems, search engines, etc.</p>

<h3 id="normalized-discounted-cumulative-gain-ndcg">Normalized Discounted Cumulative Gain (NDCG)</h3>

<p>Measures quality of ranking where position matters.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">ndcg_score</span>

<span class="c1"># Relevance scores for each item (higher = more relevant)
# Order matters: first item is ranked first, etc.
</span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>  <span class="c1"># True relevance
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">2.8</span><span class="p">,</span> <span class="mf">1.9</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="mf">1.8</span><span class="p">]]</span>  <span class="c1"># Predicted scores
</span>
<span class="c1"># NDCG@k for different k values
</span><span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="bp">None</span><span class="p">]:</span>  <span class="c1"># None means all items
</span>    <span class="n">ndcg</span> <span class="o">=</span> <span class="nf">ndcg_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">label</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">NDCG@</span><span class="si">{</span><span class="n">k</span> <span class="k">if</span> <span class="n">k</span> <span class="k">else</span> <span class="sh">'</span><span class="s">all</span><span class="sh">'</span><span class="si">}</span><span class="sh">"</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">ndcg</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Interpretation:</strong></p>
<ul>
  <li>1.0: Perfect ranking</li>
  <li>0.0: Worst possible ranking</li>
</ul>

<p><strong>When to use:</strong> Position-aware ranking (search, recommendations)</p>

<h3 id="mean-average-precision-map">Mean Average Precision (MAP)</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">average_precision</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Compute Average Precision
    
    Args:
        y_true: Binary relevance (1 = relevant, 0 = not relevant)
        y_scores: Predicted scores
    
    Returns:
        Average precision
    </span><span class="sh">"""</span>
    <span class="c1"># Sort by scores (descending)
</span>    <span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argsort</span><span class="p">(</span><span class="n">y_scores</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">y_true_sorted</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">y_true</span><span class="p">)[</span><span class="n">sorted_indices</span><span class="p">]</span>
    
    <span class="c1"># Compute precision at each relevant item
</span>    <span class="n">precisions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">num_relevant</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">is_relevant</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">y_true_sorted</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">is_relevant</span><span class="p">:</span>
            <span class="n">num_relevant</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">precision_at_i</span> <span class="o">=</span> <span class="n">num_relevant</span> <span class="o">/</span> <span class="n">i</span>
            <span class="n">precisions</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">precision_at_i</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">precisions</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span>
    
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">precisions</span><span class="p">)</span>

<span class="c1"># Example
</span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">y_scores</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]</span>

<span class="n">ap</span> <span class="o">=</span> <span class="nf">average_precision</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Average Precision: </span><span class="si">{</span><span class="n">ap</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="mean-reciprocal-rank-mrr">Mean Reciprocal Rank (MRR)</h3>

<p>Measures where the first relevant item appears.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>MRR = (1/|Q|) * Σ(1 / rank_i)

where rank_i is the rank of first relevant item for query i
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">mean_reciprocal_rank</span><span class="p">(</span><span class="n">y_true_queries</span><span class="p">,</span> <span class="n">y_pred_queries</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Compute MRR across multiple queries
    
    Args:
        y_true_queries: List of relevance lists (one per query)
        y_pred_queries: List of score lists (one per query)
    
    Returns:
        MRR score
    </span><span class="sh">"""</span>
    <span class="n">reciprocal_ranks</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">y_true_queries</span><span class="p">,</span> <span class="n">y_pred_queries</span><span class="p">):</span>
        <span class="c1"># Sort by scores
</span>        <span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argsort</span><span class="p">(</span><span class="n">y_scores</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">y_true_sorted</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">y_true</span><span class="p">)[</span><span class="n">sorted_indices</span><span class="p">]</span>
        
        <span class="c1"># Find first relevant item
</span>        <span class="k">for</span> <span class="n">rank</span><span class="p">,</span> <span class="n">is_relevant</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">y_true_sorted</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">is_relevant</span><span class="p">:</span>
                <span class="n">reciprocal_ranks</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">rank</span><span class="p">)</span>
                <span class="k">break</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># No relevant item found
</span>            <span class="n">reciprocal_ranks</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">reciprocal_ranks</span><span class="p">)</span>

<span class="c1"># Example: 3 queries
</span><span class="n">y_true_queries</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>  <span class="c1"># Query 1: first relevant at position 2
</span>    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>  <span class="c1"># Query 2: first relevant at position 1
</span>    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>  <span class="c1"># Query 3: first relevant at position 3
</span><span class="p">]</span>

<span class="n">y_pred_queries</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
<span class="p">]</span>

<span class="n">mrr</span> <span class="o">=</span> <span class="nf">mean_reciprocal_rank</span><span class="p">(</span><span class="n">y_true_queries</span><span class="p">,</span> <span class="n">y_pred_queries</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">MRR: </span><span class="si">{</span><span class="n">mrr</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<hr />

<h2 id="choosing-the-right-metric">Choosing the Right Metric</h2>

<h3 id="decision-framework">Decision Framework</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MetricSelector</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Help choose appropriate metric based on problem characteristics
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">recommend_metric</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">task_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">class_balance</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">'</span><span class="s">balanced</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">business_priority</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">
        Recommend metrics based on problem characteristics
        
        Args:
            task_type: </span><span class="sh">'</span><span class="s">binary_classification</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">multiclass</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">regression</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">ranking</span><span class="sh">'</span><span class="s">
            class_balance: </span><span class="sh">'</span><span class="s">balanced</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">imbalanced</span><span class="sh">'</span><span class="s">
            business_priority: </span><span class="sh">'</span><span class="s">precision</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">recall</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">both</span><span class="sh">'</span><span class="s">, None
        
        Returns:
            List of recommended metrics
        </span><span class="sh">"""</span>
        <span class="n">recommendations</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">if</span> <span class="n">task_type</span> <span class="o">==</span> <span class="sh">'</span><span class="s">binary_classification</span><span class="sh">'</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">class_balance</span> <span class="o">==</span> <span class="sh">'</span><span class="s">balanced</span><span class="sh">'</span><span class="p">:</span>
                <span class="n">recommendations</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">Accuracy</span><span class="sh">'</span><span class="p">)</span>
                <span class="n">recommendations</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">ROC-AUC</span><span class="sh">'</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">recommendations</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">Precision-Recall AUC</span><span class="sh">'</span><span class="p">)</span>
                <span class="n">recommendations</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">F1 Score</span><span class="sh">'</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">business_priority</span> <span class="o">==</span> <span class="sh">'</span><span class="s">precision</span><span class="sh">'</span><span class="p">:</span>
                <span class="n">recommendations</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">Precision (optimize threshold)</span><span class="sh">'</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">business_priority</span> <span class="o">==</span> <span class="sh">'</span><span class="s">recall</span><span class="sh">'</span><span class="p">:</span>
                <span class="n">recommendations</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">Recall (optimize threshold)</span><span class="sh">'</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">business_priority</span> <span class="o">==</span> <span class="sh">'</span><span class="s">both</span><span class="sh">'</span><span class="p">:</span>
                <span class="n">recommendations</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">F1 Score</span><span class="sh">'</span><span class="p">)</span>
        
        <span class="k">elif</span> <span class="n">task_type</span> <span class="o">==</span> <span class="sh">'</span><span class="s">multiclass</span><span class="sh">'</span><span class="p">:</span>
            <span class="n">recommendations</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">Macro F1 (if classes equally important)</span><span class="sh">'</span><span class="p">)</span>
            <span class="n">recommendations</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">Weighted F1 (if accounting for imbalance)</span><span class="sh">'</span><span class="p">)</span>
            <span class="n">recommendations</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">Confusion Matrix (for detailed analysis)</span><span class="sh">'</span><span class="p">)</span>
        
        <span class="k">elif</span> <span class="n">task_type</span> <span class="o">==</span> <span class="sh">'</span><span class="s">regression</span><span class="sh">'</span><span class="p">:</span>
            <span class="n">recommendations</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">RMSE (if penalizing large errors)</span><span class="sh">'</span><span class="p">)</span>
            <span class="n">recommendations</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">MAE (if robust to outliers)</span><span class="sh">'</span><span class="p">)</span>
            <span class="n">recommendations</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">R² (for explained variance)</span><span class="sh">'</span><span class="p">)</span>
        
        <span class="k">elif</span> <span class="n">task_type</span> <span class="o">==</span> <span class="sh">'</span><span class="s">ranking</span><span class="sh">'</span><span class="p">:</span>
            <span class="n">recommendations</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">NDCG (for position-aware ranking)</span><span class="sh">'</span><span class="p">)</span>
            <span class="n">recommendations</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">MAP (for information retrieval)</span><span class="sh">'</span><span class="p">)</span>
            <span class="n">recommendations</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">MRR (for first relevant item)</span><span class="sh">'</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">recommendations</span>

<span class="c1"># Usage
</span><span class="n">selector</span> <span class="o">=</span> <span class="nc">MetricSelector</span><span class="p">()</span>

<span class="c1"># Example 1: Fraud detection (imbalanced, recall critical)
</span><span class="n">metrics</span> <span class="o">=</span> <span class="n">selector</span><span class="p">.</span><span class="nf">recommend_metric</span><span class="p">(</span>
    <span class="n">task_type</span><span class="o">=</span><span class="sh">'</span><span class="s">binary_classification</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">class_balance</span><span class="o">=</span><span class="sh">'</span><span class="s">imbalanced</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">business_priority</span><span class="o">=</span><span class="sh">'</span><span class="s">recall</span><span class="sh">'</span>
<span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Fraud detection metrics:</span><span class="sh">"</span><span class="p">,</span> <span class="n">metrics</span><span class="p">)</span>

<span class="c1"># Example 2: Search ranking
</span><span class="n">metrics</span> <span class="o">=</span> <span class="n">selector</span><span class="p">.</span><span class="nf">recommend_metric</span><span class="p">(</span>
    <span class="n">task_type</span><span class="o">=</span><span class="sh">'</span><span class="s">ranking</span><span class="sh">'</span>
<span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Search ranking metrics:</span><span class="sh">"</span><span class="p">,</span> <span class="n">metrics</span><span class="p">)</span>
</code></pre></div></div>

<hr />

<h2 id="production-monitoring">Production Monitoring</h2>

<h3 id="metric-tracking-system">Metric Tracking System</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">time</span>
<span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span>

<span class="k">class</span> <span class="nc">MetricTracker</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Track metrics over time in production
    
    Use case: Monitor model performance degradation
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">window_size</span> <span class="o">=</span> <span class="n">window_size</span>
        
        <span class="c1"># Sliding windows for predictions and actuals
</span>        <span class="n">self</span><span class="p">.</span><span class="n">predictions</span> <span class="o">=</span> <span class="nf">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">window_size</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">actuals</span> <span class="o">=</span> <span class="nf">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">window_size</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">timestamps</span> <span class="o">=</span> <span class="nf">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">window_size</span><span class="p">)</span>
        
        <span class="c1"># Historical metrics
</span>        <span class="n">self</span><span class="p">.</span><span class="n">metric_history</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">:</span> <span class="p">[],</span>
            <span class="sh">'</span><span class="s">precision</span><span class="sh">'</span><span class="p">:</span> <span class="p">[],</span>
            <span class="sh">'</span><span class="s">recall</span><span class="sh">'</span><span class="p">:</span> <span class="p">[],</span>
            <span class="sh">'</span><span class="s">f1</span><span class="sh">'</span><span class="p">:</span> <span class="p">[],</span>
            <span class="sh">'</span><span class="s">timestamp</span><span class="sh">'</span><span class="p">:</span> <span class="p">[]</span>
        <span class="p">}</span>
    
    <span class="k">def</span> <span class="nf">log_prediction</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Log a prediction and its actual outcome
        </span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="n">predictions</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">actuals</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">timestamps</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">())</span>
    
    <span class="k">def</span> <span class="nf">compute_current_metrics</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Compute metrics over current window
        </span><span class="sh">"""</span>
        <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">predictions</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{}</span>
        
        <span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">f1_score</span>
        
        <span class="k">try</span><span class="p">:</span>
            <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span>
                <span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">:</span> <span class="nf">accuracy_score</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">actuals</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">predictions</span><span class="p">),</span>
                <span class="sh">'</span><span class="s">precision</span><span class="sh">'</span><span class="p">:</span> <span class="nf">precision_score</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">actuals</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">predictions</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                <span class="sh">'</span><span class="s">recall</span><span class="sh">'</span><span class="p">:</span> <span class="nf">recall_score</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">actuals</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">predictions</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                <span class="sh">'</span><span class="s">f1</span><span class="sh">'</span><span class="p">:</span> <span class="nf">f1_score</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">actuals</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">predictions</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                <span class="sh">'</span><span class="s">sample_count</span><span class="sh">'</span><span class="p">:</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">predictions</span><span class="p">)</span>
            <span class="p">}</span>
            
            <span class="c1"># Save to history
</span>            <span class="k">for</span> <span class="n">metric_name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">metrics</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">metric_name</span> <span class="o">!=</span> <span class="sh">'</span><span class="s">sample_count</span><span class="sh">'</span><span class="p">:</span>
                    <span class="n">self</span><span class="p">.</span><span class="n">metric_history</span><span class="p">[</span><span class="n">metric_name</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
            
            <span class="n">self</span><span class="p">.</span><span class="n">metric_history</span><span class="p">[</span><span class="sh">'</span><span class="s">timestamp</span><span class="sh">'</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">())</span>
            
            <span class="k">return</span> <span class="n">metrics</span>
        
        <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Error computing metrics: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">{}</span>
    
    <span class="k">def</span> <span class="nf">detect_degradation</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">baseline_metric</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">'</span><span class="s">f1</span><span class="sh">'</span><span class="p">,</span> <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Detect if model performance has degraded
        
        Args:
            baseline_metric: Metric to monitor
            threshold: Alert if metric drops by this much from baseline
        
        Returns:
            True if degradation detected
        </span><span class="sh">"""</span>
        <span class="n">history</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">metric_history</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">baseline_metric</span><span class="p">,</span> <span class="p">[])</span>
        
        <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">history</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">False</span>
        
        <span class="c1"># Compare recent average to baseline (first 10% of history)
</span>        <span class="n">baseline_size</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">history</span><span class="p">)</span> <span class="o">//</span> <span class="mi">10</span><span class="p">)</span>
        <span class="n">baseline_avg</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">history</span><span class="p">[:</span><span class="n">baseline_size</span><span class="p">])</span>
        <span class="n">recent_avg</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="o">-</span><span class="n">baseline_size</span><span class="p">:])</span>
        
        <span class="n">degradation</span> <span class="o">=</span> <span class="n">baseline_avg</span> <span class="o">-</span> <span class="n">recent_avg</span>
        
        <span class="k">return</span> <span class="n">degradation</span> <span class="o">&gt;</span> <span class="n">threshold</span>

<span class="c1"># Usage
</span><span class="n">tracker</span> <span class="o">=</span> <span class="nc">MetricTracker</span><span class="p">(</span><span class="n">window_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>

<span class="c1"># Simulate predictions over time
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1500</span><span class="p">):</span>
    <span class="c1"># Simulate ground truth and prediction
</span>    <span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">p</span><span class="o">=</span><span class="p">[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">])</span>
    
    <span class="c1"># Simulate model getting worse over time
</span>    <span class="n">accuracy_degradation</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">i</span> <span class="o">/</span> <span class="mi">10000</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="p">(</span><span class="mf">0.8</span> <span class="o">-</span> <span class="n">accuracy_degradation</span><span class="p">):</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_true</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">y_true</span>
    
    <span class="n">tracker</span><span class="p">.</span><span class="nf">log_prediction</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    
    <span class="c1"># Compute metrics every 100 predictions
</span>    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="n">tracker</span><span class="p">.</span><span class="nf">compute_current_metrics</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">metrics</span><span class="p">:</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Step </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">: F1 = </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">f1</span><span class="sh">'</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">tracker</span><span class="p">.</span><span class="nf">detect_degradation</span><span class="p">():</span>
                <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">⚠️ WARNING: Model degradation detected at step </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<hr />

<h2 id="model-calibration">Model Calibration</h2>

<p><strong>Calibration:</strong> How well predicted probabilities match actual outcomes.</p>

<p><strong>Example of poor calibration:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Model predicts 80% probability for 100 samples
# Only 40 of them are actually positive
# Model is overconfident! (80% predicted vs 40% actual)
</span></code></pre></div></div>

<h3 id="calibration-plot">Calibration Plot</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.calibration</span> <span class="kn">import</span> <span class="n">calibration_curve</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="k">def</span> <span class="nf">plot_calibration_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_prob</span><span class="p">,</span> <span class="n">n_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Plot calibration curve
    
    A well-calibrated model</span><span class="sh">'</span><span class="s">s curve follows the diagonal
    </span><span class="sh">"""</span>
    <span class="n">prob_true</span><span class="p">,</span> <span class="n">prob_pred</span> <span class="o">=</span> <span class="nf">calibration_curve</span><span class="p">(</span>
        <span class="n">y_true</span><span class="p">,</span>
        <span class="n">y_prob</span><span class="p">,</span>
        <span class="n">n_bins</span><span class="o">=</span><span class="n">n_bins</span><span class="p">,</span>
        <span class="n">strategy</span><span class="o">=</span><span class="sh">'</span><span class="s">uniform</span><span class="sh">'</span>
    <span class="p">)</span>
    
    <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">prob_pred</span><span class="p">,</span> <span class="n">prob_true</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="sh">'</span><span class="s">o</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Model</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="sh">'</span><span class="s">k--</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Perfect Calibration</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Mean Predicted Probability</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Fraction of Positives</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Calibration Plot</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="c1"># Example
</span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span>  <span class="c1"># 100 samples
</span><span class="n">y_prob</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.85</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span>

<span class="nf">plot_calibration_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_prob</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="calibrating-models">Calibrating Models</h3>

<p>Some models (e.g., SVMs, tree ensembles) output poorly calibrated probabilities.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.calibration</span> <span class="kn">import</span> <span class="n">CalibratedClassifierCV</span>
<span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="c1"># Train base model
</span><span class="n">base_model</span> <span class="o">=</span> <span class="nc">RandomForestClassifier</span><span class="p">()</span>
<span class="n">base_model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Calibrate predictions
</span><span class="n">calibrated_model</span> <span class="o">=</span> <span class="nc">CalibratedClassifierCV</span><span class="p">(</span>
    <span class="n">base_model</span><span class="p">,</span>
    <span class="n">method</span><span class="o">=</span><span class="sh">'</span><span class="s">sigmoid</span><span class="sh">'</span><span class="p">,</span>  <span class="c1"># or 'isotonic'
</span>    <span class="n">cv</span><span class="o">=</span><span class="mi">5</span>
<span class="p">)</span>
<span class="n">calibrated_model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Now probabilities are better calibrated
</span><span class="n">y_prob_calibrated</span> <span class="o">=</span> <span class="n">calibrated_model</span><span class="p">.</span><span class="nf">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
</code></pre></div></div>

<p><strong>Calibration methods:</strong></p>
<ul>
  <li><strong>Platt scaling (sigmoid):</strong> Fits logistic regression on predictions</li>
  <li><strong>Isotonic regression:</strong> Non-parametric, more flexible but needs more data</li>
</ul>

<hr />

<h2 id="threshold-tuning">Threshold Tuning</h2>

<p>Classification models output probabilities. Choosing the decision threshold impacts precision/recall trade-off.</p>

<h3 id="finding-optimal-threshold">Finding Optimal Threshold</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_curve</span><span class="p">,</span> <span class="n">f1_score</span>

<span class="k">def</span> <span class="nf">find_optimal_threshold</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_prob</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="sh">'</span><span class="s">f1</span><span class="sh">'</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Find threshold that maximizes a metric
    
    Args:
        y_true: True labels
        y_prob: Predicted probabilities
        metric: </span><span class="sh">'</span><span class="s">f1</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">precision</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">recall</span><span class="sh">'</span><span class="s">, or custom function
    
    Returns:
        optimal_threshold, best_score
    </span><span class="sh">"""</span>
    <span class="k">if</span> <span class="n">metric</span> <span class="o">==</span> <span class="sh">'</span><span class="s">f1</span><span class="sh">'</span><span class="p">:</span>
        <span class="c1"># Compute F1 at different thresholds
</span>        <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="nf">precision_recall_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_prob</span><span class="p">)</span>
        <span class="n">f1_scores</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">precision</span> <span class="o">*</span> <span class="n">recall</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">precision</span> <span class="o">+</span> <span class="n">recall</span> <span class="o">+</span> <span class="mf">1e-10</span><span class="p">)</span>
        
        <span class="n">best_idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">f1_scores</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">thresholds</span><span class="p">[</span><span class="n">best_idx</span><span class="p">]</span> <span class="k">if</span> <span class="n">best_idx</span> <span class="o">&lt;</span> <span class="nf">len</span><span class="p">(</span><span class="n">thresholds</span><span class="p">)</span> <span class="k">else</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">f1_scores</span><span class="p">[</span><span class="n">best_idx</span><span class="p">]</span>
    
    <span class="k">elif</span> <span class="n">metric</span> <span class="o">==</span> <span class="sh">'</span><span class="s">precision</span><span class="sh">'</span><span class="p">:</span>
        <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="nf">precision_recall_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_prob</span><span class="p">)</span>
        <span class="c1"># Find threshold for minimum acceptable recall (e.g., 0.8)
</span>        <span class="n">min_recall</span> <span class="o">=</span> <span class="mf">0.8</span>
        <span class="n">valid_idx</span> <span class="o">=</span> <span class="n">recall</span> <span class="o">&gt;=</span> <span class="n">min_recall</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nf">any</span><span class="p">(</span><span class="n">valid_idx</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">None</span><span class="p">,</span> <span class="mi">0</span>
        <span class="n">best_idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">precision</span><span class="p">[</span><span class="n">valid_idx</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">thresholds</span><span class="p">[</span><span class="n">valid_idx</span><span class="p">][</span><span class="n">best_idx</span><span class="p">],</span> <span class="n">precision</span><span class="p">[</span><span class="n">valid_idx</span><span class="p">][</span><span class="n">best_idx</span><span class="p">]</span>
    
    <span class="k">elif</span> <span class="n">metric</span> <span class="o">==</span> <span class="sh">'</span><span class="s">recall</span><span class="sh">'</span><span class="p">:</span>
        <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="nf">precision_recall_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_prob</span><span class="p">)</span>
        <span class="c1"># Find threshold for minimum acceptable precision (e.g., 0.9)
</span>        <span class="n">min_precision</span> <span class="o">=</span> <span class="mf">0.9</span>
        <span class="n">valid_idx</span> <span class="o">=</span> <span class="n">precision</span> <span class="o">&gt;=</span> <span class="n">min_precision</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nf">any</span><span class="p">(</span><span class="n">valid_idx</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">None</span><span class="p">,</span> <span class="mi">0</span>
        <span class="n">best_idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">recall</span><span class="p">[</span><span class="n">valid_idx</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">thresholds</span><span class="p">[</span><span class="n">valid_idx</span><span class="p">][</span><span class="n">best_idx</span><span class="p">],</span> <span class="n">recall</span><span class="p">[</span><span class="n">valid_idx</span><span class="p">][</span><span class="n">best_idx</span><span class="p">]</span>

<span class="c1"># Example
</span><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">y_prob</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.85</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">])</span>

<span class="n">optimal_threshold</span><span class="p">,</span> <span class="n">best_f1</span> <span class="o">=</span> <span class="nf">find_optimal_threshold</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_prob</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="sh">'</span><span class="s">f1</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Optimal threshold: </span><span class="si">{</span><span class="n">optimal_threshold</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">, Best F1: </span><span class="si">{</span><span class="n">best_f1</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="threshold-selection-strategies">Threshold Selection Strategies</h3>

<p><strong>1. Maximize F1 Score</strong></p>
<ul>
  <li>Balanced precision and recall</li>
  <li>Good default choice</li>
</ul>

<p><strong>2. Business-Driven</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Example: Fraud detection
# False negative (missed fraud) costs $500
# False positive (declined legit transaction) costs $10
</span>
<span class="k">def</span> <span class="nf">business_value_threshold</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_prob</span><span class="p">,</span> <span class="n">fn_cost</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">fp_cost</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Find threshold that maximizes business value
    </span><span class="sh">"""</span>
    <span class="n">best_threshold</span> <span class="o">=</span> <span class="mf">0.5</span>
    <span class="n">best_value</span> <span class="o">=</span> <span class="nf">float</span><span class="p">(</span><span class="sh">'</span><span class="s">-inf</span><span class="sh">'</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">threshold</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">):</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_prob</span> <span class="o">&gt;=</span> <span class="n">threshold</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        
        <span class="c1"># Compute confusion matrix
</span>        <span class="n">tn</span> <span class="o">=</span> <span class="p">((</span><span class="n">y_true</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)).</span><span class="nf">sum</span><span class="p">()</span>
        <span class="n">fp</span> <span class="o">=</span> <span class="p">((</span><span class="n">y_true</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)).</span><span class="nf">sum</span><span class="p">()</span>
        <span class="n">fn</span> <span class="o">=</span> <span class="p">((</span><span class="n">y_true</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)).</span><span class="nf">sum</span><span class="p">()</span>
        <span class="n">tp</span> <span class="o">=</span> <span class="p">((</span><span class="n">y_true</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)).</span><span class="nf">sum</span><span class="p">()</span>
        
        <span class="c1"># Business value = savings from catching fraud - cost of false alarms
</span>        <span class="n">value</span> <span class="o">=</span> <span class="n">tp</span> <span class="o">*</span> <span class="n">fn_cost</span> <span class="o">-</span> <span class="n">fp</span> <span class="o">*</span> <span class="n">fp_cost</span>
        
        <span class="k">if</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="n">best_value</span><span class="p">:</span>
            <span class="n">best_value</span> <span class="o">=</span> <span class="n">value</span>
            <span class="n">best_threshold</span> <span class="o">=</span> <span class="n">threshold</span>
    
    <span class="k">return</span> <span class="n">best_threshold</span><span class="p">,</span> <span class="n">best_value</span>

<span class="n">threshold</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="nf">business_value_threshold</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_prob</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Best threshold: </span><span class="si">{</span><span class="n">threshold</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">, Business value: $</span><span class="si">{</span><span class="n">value</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>3. Operating Point Selection</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Healthcare: Prioritize recall (don't miss diseases)
# Set minimum recall = 0.95, maximize precision subject to that
</span>
<span class="k">def</span> <span class="nf">threshold_for_min_recall</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_prob</span><span class="p">,</span> <span class="n">min_recall</span><span class="o">=</span><span class="mf">0.95</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Find threshold that achieves minimum recall while maximizing precision</span><span class="sh">"""</span>
    <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="nf">precision_recall_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_prob</span><span class="p">)</span>
    
    <span class="n">valid_indices</span> <span class="o">=</span> <span class="n">recall</span> <span class="o">&gt;=</span> <span class="n">min_recall</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nf">any</span><span class="p">(</span><span class="n">valid_indices</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">None</span>
    
    <span class="n">best_precision_idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">precision</span><span class="p">[</span><span class="n">valid_indices</span><span class="p">])</span>
    <span class="n">threshold_idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="n">valid_indices</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="n">best_precision_idx</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="n">thresholds</span><span class="p">[</span><span class="n">threshold_idx</span><span class="p">]</span> <span class="k">if</span> <span class="n">threshold_idx</span> <span class="o">&lt;</span> <span class="nf">len</span><span class="p">(</span><span class="n">thresholds</span><span class="p">)</span> <span class="k">else</span> <span class="mf">0.0</span>
</code></pre></div></div>

<hr />

<h2 id="handling-imbalanced-datasets">Handling Imbalanced Datasets</h2>

<h3 id="why-standard-metrics-fail">Why Standard Metrics Fail</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Dataset: 99% negative, 1% positive
</span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">990</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span>
<span class="n">y_pred_dummy</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">1000</span>  <span class="c1"># Always predict negative
</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Accuracy: </span><span class="si">{</span><span class="nf">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_dummy</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="o">%</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>  <span class="c1"># 99%!
</span><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Precision: </span><span class="si">{</span><span class="nf">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_dummy</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="o">%</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>  <span class="c1"># Undefined (0/0)
</span><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Recall: </span><span class="si">{</span><span class="nf">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred_dummy</span><span class="p">)</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="o">%</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>  <span class="c1"># 0%
</span></code></pre></div></div>

<p><strong>Accuracy is 99%</strong> but model is useless!</p>

<h3 id="better-metrics-for-imbalanced-data">Better Metrics for Imbalanced Data</h3>

<p><strong>1. Precision-Recall AUC</strong></p>

<p>Better than ROC-AUC for imbalanced data because it doesn’t include TN (which dominates in imbalanced datasets).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">average_precision_score</span>

<span class="n">ap</span> <span class="o">=</span> <span class="nf">average_precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Average Precision: </span><span class="si">{</span><span class="n">ap</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>2. Cohen’s Kappa</strong></p>

<p>Measures agreement between predicted and actual, adjusted for chance.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">cohen_kappa_score</span>

<span class="n">kappa</span> <span class="o">=</span> <span class="nf">cohen_kappa_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Cohen</span><span class="sh">'</span><span class="s">s Kappa: </span><span class="si">{</span><span class="n">kappa</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Interpretation:
# &lt; 0: No agreement
# 0-0.20: Slight
# 0.21-0.40: Fair
# 0.41-0.60: Moderate
# 0.61-0.80: Substantial
# 0.81-1.0: Almost perfect
</span></code></pre></div></div>

<p><strong>3. Matthews Correlation Coefficient (MCC)</strong></p>

<p>Takes all four confusion matrix values into account. Ranges from -1 to +1.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">matthews_corrcoef</span>

<span class="n">mcc</span> <span class="o">=</span> <span class="nf">matthews_corrcoef</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">MCC: </span><span class="si">{</span><span class="n">mcc</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Interpretation:
# +1: Perfect prediction
# 0: Random prediction
# -1: Perfect inverse prediction
</span></code></pre></div></div>

<p><strong>4. Class-Weighted Metrics</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">fbeta_score</span>

<span class="c1"># Emphasize recall (beta &gt; 1) for imbalanced positive class
</span><span class="n">f2</span> <span class="o">=</span> <span class="nf">fbeta_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># Recall weighted 2x more than precision
</span><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">F2 Score: </span><span class="si">{</span><span class="n">f2</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="sampling-strategies">Sampling Strategies</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">SMOTE</span>
<span class="kn">from</span> <span class="n">imblearn.under_sampling</span> <span class="kn">import</span> <span class="n">RandomUnderSampler</span>
<span class="kn">from</span> <span class="n">imblearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span> <span class="k">as</span> <span class="n">ImbPipeline</span>

<span class="c1"># Combine over-sampling and under-sampling
</span><span class="n">pipeline</span> <span class="o">=</span> <span class="nc">ImbPipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">oversample</span><span class="sh">'</span><span class="p">,</span> <span class="nc">SMOTE</span><span class="p">(</span><span class="n">sampling_strategy</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)),</span>  <span class="c1"># Increase minority to 50% of majority
</span>    <span class="p">(</span><span class="sh">'</span><span class="s">undersample</span><span class="sh">'</span><span class="p">,</span> <span class="nc">RandomUnderSampler</span><span class="p">(</span><span class="n">sampling_strategy</span><span class="o">=</span><span class="mf">1.0</span><span class="p">))</span>  <span class="c1"># Balance classes
</span><span class="p">])</span>

<span class="n">X_resampled</span><span class="p">,</span> <span class="n">y_resampled</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="nf">fit_resample</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<hr />

<h2 id="aligning-ml-metrics-with-business-kpis">Aligning ML Metrics with Business KPIs</h2>

<h3 id="example-1-e-commerce-recommendation-system">Example 1: E-commerce Recommendation System</h3>

<p><strong>ML Metrics:</strong></p>
<ul>
  <li>Precision@10: 0.65</li>
  <li>Recall@10: 0.45</li>
  <li>NDCG@10: 0.72</li>
</ul>

<p><strong>Business KPIs:</strong></p>
<ul>
  <li>Click-through rate (CTR): 3.5%</li>
  <li>Conversion rate: 1.2%</li>
  <li>Revenue per user: $45</li>
</ul>

<p><strong>Alignment:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">BusinessMetricTracker</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Track both ML and business metrics
    
    Use case: Connect model performance to business impact
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">ml_metrics</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">self</span><span class="p">.</span><span class="n">business_metrics</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">self</span><span class="p">.</span><span class="n">correlations</span> <span class="o">=</span> <span class="p">{}</span>
    
    <span class="k">def</span> <span class="nf">log_session</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">ml_metrics</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
        <span class="n">business_metrics</span><span class="p">:</span> <span class="nb">dict</span>
    <span class="p">):</span>
        <span class="sh">"""</span><span class="s">Log metrics for a user session</span><span class="sh">"""</span>
        <span class="k">for</span> <span class="n">metric</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">ml_metrics</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">metric</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">ml_metrics</span><span class="p">:</span>
                <span class="n">self</span><span class="p">.</span><span class="n">ml_metrics</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">self</span><span class="p">.</span><span class="n">ml_metrics</span><span class="p">[</span><span class="n">metric</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">metric</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">business_metrics</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">metric</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">business_metrics</span><span class="p">:</span>
                <span class="n">self</span><span class="p">.</span><span class="n">business_metrics</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">self</span><span class="p">.</span><span class="n">business_metrics</span><span class="p">[</span><span class="n">metric</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">compute_correlations</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Compute correlation between ML and business metrics</span><span class="sh">"""</span>
        <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
        <span class="kn">from</span> <span class="n">scipy.stats</span> <span class="kn">import</span> <span class="n">pearsonr</span>
        
        <span class="k">for</span> <span class="n">ml_metric</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">ml_metrics</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">biz_metric</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">business_metrics</span><span class="p">:</span>
                <span class="n">ml_values</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">ml_metrics</span><span class="p">[</span><span class="n">ml_metric</span><span class="p">])</span>
                <span class="n">biz_values</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">business_metrics</span><span class="p">[</span><span class="n">biz_metric</span><span class="p">])</span>
                
                <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">ml_values</span><span class="p">)</span> <span class="o">==</span> <span class="nf">len</span><span class="p">(</span><span class="n">biz_values</span><span class="p">):</span>
                    <span class="n">corr</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="nf">pearsonr</span><span class="p">(</span><span class="n">ml_values</span><span class="p">,</span> <span class="n">biz_values</span><span class="p">)</span>
                    <span class="n">self</span><span class="p">.</span><span class="n">correlations</span><span class="p">[(</span><span class="n">ml_metric</span><span class="p">,</span> <span class="n">biz_metric</span><span class="p">)]</span> <span class="o">=</span> <span class="p">{</span>
                        <span class="sh">'</span><span class="s">correlation</span><span class="sh">'</span><span class="p">:</span> <span class="n">corr</span><span class="p">,</span>
                        <span class="sh">'</span><span class="s">p_value</span><span class="sh">'</span><span class="p">:</span> <span class="n">p_value</span>
                    <span class="p">}</span>
        
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">correlations</span>

<span class="c1"># Usage
</span><span class="n">tracker</span> <span class="o">=</span> <span class="nc">BusinessMetricTracker</span><span class="p">()</span>

<span class="c1"># Log multiple sessions
</span><span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">tracker</span><span class="p">.</span><span class="nf">log_session</span><span class="p">(</span>
        <span class="n">ml_metrics</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">precision</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">)},</span>
        <span class="n">business_metrics</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">ctr</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">)}</span>
    <span class="p">)</span>

<span class="n">correlations</span> <span class="o">=</span> <span class="n">tracker</span><span class="p">.</span><span class="nf">compute_correlations</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">ML Metric ↔ Business KPI Correlations:</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">for </span><span class="p">(</span><span class="n">ml</span><span class="p">,</span> <span class="n">biz</span><span class="p">),</span> <span class="n">stats</span> <span class="ow">in</span> <span class="n">correlations</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">ml</span><span class="si">}</span><span class="s"> ↔ </span><span class="si">{</span><span class="n">biz</span><span class="si">}</span><span class="s">: r=</span><span class="si">{</span><span class="n">stats</span><span class="p">[</span><span class="sh">'</span><span class="s">correlation</span><span class="sh">'</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">, p=</span><span class="si">{</span><span class="n">stats</span><span class="p">[</span><span class="sh">'</span><span class="s">p_value</span><span class="sh">'</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="example-2-content-moderation">Example 2: Content Moderation</h3>

<p><strong>ML Metrics:</strong></p>
<ul>
  <li>Precision: 0.92 (92% of flagged content is actually bad)</li>
  <li>Recall: 0.78 (catch 78% of bad content)</li>
</ul>

<p><strong>Business KPIs:</strong></p>
<ul>
  <li>User reports: How many users still report bad content?</li>
  <li>User retention: Are false positives causing users to leave?</li>
  <li>Moderator workload: Hours spent reviewing flagged content</li>
</ul>

<p><strong>Trade-off:</strong></p>
<ul>
  <li>High recall → More bad content caught → Fewer user reports ✓</li>
  <li>But also → More false positives → Higher moderator workload ✗</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">estimate_moderator_cost</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">daily_content</span><span class="p">,</span> <span class="n">hourly_rate</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Estimate cost of content moderation
    
    Args:
        precision: Model precision
        recall: Model recall
        daily_content: Number of content items per day
        hourly_rate: Cost per moderator hour
    
    Returns:
        Daily moderation cost
    </span><span class="sh">"""</span>
    <span class="c1"># Assume 1% of content is actually bad
</span>    <span class="n">bad_content</span> <span class="o">=</span> <span class="n">daily_content</span> <span class="o">*</span> <span class="mf">0.01</span>
    
    <span class="c1"># Content flagged by model
</span>    <span class="n">flagged</span> <span class="o">=</span> <span class="p">(</span><span class="n">bad_content</span> <span class="o">*</span> <span class="n">recall</span><span class="p">)</span> <span class="o">/</span> <span class="n">precision</span>
    
    <span class="c1"># Time to review (assume 30 seconds per item)
</span>    <span class="n">review_hours</span> <span class="o">=</span> <span class="p">(</span><span class="n">flagged</span> <span class="o">*</span> <span class="mi">30</span><span class="p">)</span> <span class="o">/</span> <span class="mi">3600</span>
    
    <span class="c1"># Cost
</span>    <span class="n">cost</span> <span class="o">=</span> <span class="n">review_hours</span> <span class="o">*</span> <span class="n">hourly_rate</span>
    
    <span class="k">return</span> <span class="n">cost</span><span class="p">,</span> <span class="n">review_hours</span>

<span class="c1"># Compare different models
</span><span class="n">models</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">Conservative</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">precision</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.95</span><span class="p">,</span> <span class="sh">'</span><span class="s">recall</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.70</span><span class="p">},</span>
    <span class="p">{</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">Balanced</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">precision</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.90</span><span class="p">,</span> <span class="sh">'</span><span class="s">recall</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.80</span><span class="p">},</span>
    <span class="p">{</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">Aggressive</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">precision</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.85</span><span class="p">,</span> <span class="sh">'</span><span class="s">recall</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.90</span><span class="p">}</span>
<span class="p">]</span>

<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
    <span class="n">cost</span><span class="p">,</span> <span class="n">hours</span> <span class="o">=</span> <span class="nf">estimate_moderator_cost</span><span class="p">(</span>
        <span class="n">model</span><span class="p">[</span><span class="sh">'</span><span class="s">precision</span><span class="sh">'</span><span class="p">],</span>
        <span class="n">model</span><span class="p">[</span><span class="sh">'</span><span class="s">recall</span><span class="sh">'</span><span class="p">],</span>
        <span class="n">daily_content</span><span class="o">=</span><span class="mi">100000</span>
    <span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">model</span><span class="p">[</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="s">: $</span><span class="si">{</span><span class="n">cost</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">/day, </span><span class="si">{</span><span class="n">hours</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s"> hours/day</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<hr />

<h2 id="common-pitfalls">Common Pitfalls</h2>

<h3 id="pitfall-1-data-leakage-in-evaluation">Pitfall 1: Data Leakage in Evaluation</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># WRONG: Fit preprocessing on entire dataset
</span><span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="nc">StandardScaler</span><span class="p">()</span>
<span class="n">X_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>  <span class="c1"># Leakage! Test data info leaks into training
</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># CORRECT: Fit only on training data
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="nc">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>  <span class="c1"># Fit on train only
</span><span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>  <span class="c1"># Transform test
</span></code></pre></div></div>

<h3 id="pitfall-2-using-wrong-metric-for-problem">Pitfall 2: Using Wrong Metric for Problem</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Wrong: Using accuracy for imbalanced fraud detection
# Fraud rate: 0.1%, model always predicts "not fraud"
# Accuracy: 99.9% ✓ (misleading!)
# Recall: 0% ✗ (useless!)
</span>
<span class="c1"># Right: Use precision-recall, F1, or PR-AUC
</span></code></pre></div></div>

<h3 id="pitfall-3-ignoring-confidence-intervals">Pitfall 3: Ignoring Confidence Intervals</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Model A: Accuracy = 85.2%
# Model B: Accuracy = 85.5%
</span>
<span class="c1"># Is B really better? Need confidence intervals!
</span>
<span class="kn">from</span> <span class="n">scipy</span> <span class="kn">import</span> <span class="n">stats</span>

<span class="k">def</span> <span class="nf">accuracy_confidence_interval</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">confidence</span><span class="o">=</span><span class="mf">0.95</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Compute confidence interval for accuracy</span><span class="sh">"""</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_true</span> <span class="o">==</span> <span class="n">y_pred</span><span class="p">).</span><span class="nf">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">n</span>
    
    <span class="c1"># Wilson score interval
</span>    <span class="n">z</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="n">norm</span><span class="p">.</span><span class="nf">ppf</span><span class="p">((</span><span class="mi">1</span> <span class="o">+</span> <span class="n">confidence</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">denominator</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">z</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="n">n</span>
    <span class="n">center</span> <span class="o">=</span> <span class="p">(</span><span class="n">accuracy</span> <span class="o">+</span> <span class="n">z</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">n</span><span class="p">))</span> <span class="o">/</span> <span class="n">denominator</span>
    <span class="n">margin</span> <span class="o">=</span> <span class="n">z</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">accuracy</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">accuracy</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span> <span class="o">+</span> <span class="n">z</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">n</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="n">denominator</span>
    
    <span class="k">return</span> <span class="n">center</span> <span class="o">-</span> <span class="n">margin</span><span class="p">,</span> <span class="n">center</span> <span class="o">+</span> <span class="n">margin</span>

<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># Example toy predictions for illustration
</span><span class="n">y_true_a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">y_pred_a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">y_true_b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">y_pred_b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>

<span class="n">ci_a</span> <span class="o">=</span> <span class="nf">accuracy_confidence_interval</span><span class="p">(</span><span class="n">y_true_a</span><span class="p">,</span> <span class="n">y_pred_a</span><span class="p">)</span>
<span class="n">acc_a</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_true_a</span> <span class="o">==</span> <span class="n">y_pred_a</span><span class="p">).</span><span class="nf">mean</span><span class="p">()</span> <span class="o">*</span> <span class="mi">100</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Model A: </span><span class="si">{</span><span class="n">acc_a</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s">% [</span><span class="si">{</span><span class="n">ci_a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s">%, </span><span class="si">{</span><span class="n">ci_a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s">%]</span><span class="sh">"</span><span class="p">)</span>

<span class="n">ci_b</span> <span class="o">=</span> <span class="nf">accuracy_confidence_interval</span><span class="p">(</span><span class="n">y_true_b</span><span class="p">,</span> <span class="n">y_pred_b</span><span class="p">)</span>
<span class="n">acc_b</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_true_b</span> <span class="o">==</span> <span class="n">y_pred_b</span><span class="p">).</span><span class="nf">mean</span><span class="p">()</span> <span class="o">*</span> <span class="mi">100</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Model B: </span><span class="si">{</span><span class="n">acc_b</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s">% [</span><span class="si">{</span><span class="n">ci_b</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s">%, </span><span class="si">{</span><span class="n">ci_b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s">%]</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># If intervals overlap significantly, difference may not be meaningful
</span></code></pre></div></div>

<h3 id="pitfall-4-overfitting-to-validation-set">Pitfall 4: Overfitting to Validation Set</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># WRONG: Repeatedly tuning on same validation set
</span><span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>  <span class="c1"># Many iterations
</span>    <span class="n">model</span> <span class="o">=</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">hyperparams</span><span class="p">)</span>
    <span class="n">val_score</span> <span class="o">=</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>
    <span class="n">hyperparams</span> <span class="o">=</span> <span class="nf">adjust_based_on_score</span><span class="p">(</span><span class="n">val_score</span><span class="p">)</span>  <span class="c1"># Overfitting to val!
</span>
<span class="c1"># CORRECT: Use nested cross-validation or holdout test set
</span><span class="n">X_train_full</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train_full</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="c1"># Tune on train_full (with inner CV)
</span><span class="n">best_model</span> <span class="o">=</span> <span class="nf">grid_search_cv</span><span class="p">(</span><span class="n">X_train_full</span><span class="p">,</span> <span class="n">y_train_full</span><span class="p">)</span>

<span class="c1"># Evaluate ONCE on test set
</span><span class="n">final_score</span> <span class="o">=</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">best_model</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div></div>

<hr />

<h2 id="connection-to-speech-systems">Connection to Speech Systems</h2>

<p>Model evaluation principles apply directly to speech/audio ML systems:</p>

<h3 id="tts-quality-metrics">TTS Quality Metrics</h3>

<p><strong>Objective Metrics:</strong></p>
<ul>
  <li><strong>Mel Cepstral Distortion (MCD):</strong> Similar to MSE for regression</li>
  <li><strong>F0 RMSE:</strong> Pitch prediction error</li>
  <li><strong>Duration Accuracy:</strong> Similar to classification metrics for boundary detection</li>
</ul>

<p><strong>Subjective Metrics:</strong></p>
<ul>
  <li><strong>Mean Opinion Score (MOS):</strong> Like human evaluation for content moderation</li>
  <li><strong>Must have confidence intervals:</strong> Just like accuracy CIs above</li>
</ul>

<h3 id="asr-error-metrics">ASR Error Metrics</h3>

<p><strong>Word Error Rate (WER):</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>WER = (S + D + I) / N

S: Substitutions
D: Deletions
I: Insertions
N: Total words in reference
</code></pre></div></div>

<p>Similar to precision/recall trade-off:</p>
<ul>
  <li>High substitutions → Low precision (predicting wrong words)</li>
  <li>High deletions → Low recall (missing words)</li>
</ul>

<h3 id="speaker-verification">Speaker Verification</h3>

<p>Uses same binary classification metrics:</p>
<ul>
  <li><strong>EER (Equal Error Rate):</strong> Point where FPR = FNR</li>
  <li><strong>DCF (Detection Cost Function):</strong> Business-driven threshold (like threshold tuning above)</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">compute_eer</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Compute Equal Error Rate for speaker verification
    
    Similar to finding optimal threshold
    </span><span class="sh">"""</span>
    <span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span>
    
    <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="nf">roc_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>
    <span class="n">fnr</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">tpr</span>
    
    <span class="c1"># Find where FPR ≈ FNR
</span>    <span class="n">eer_idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmin</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">fpr</span> <span class="o">-</span> <span class="n">fnr</span><span class="p">))</span>
    <span class="n">eer</span> <span class="o">=</span> <span class="p">(</span><span class="n">fpr</span><span class="p">[</span><span class="n">eer_idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">fnr</span><span class="p">[</span><span class="n">eer_idx</span><span class="p">])</span> <span class="o">/</span> <span class="mi">2</span>
    
    <span class="k">return</span> <span class="n">eer</span><span class="p">,</span> <span class="n">thresholds</span><span class="p">[</span><span class="n">eer_idx</span><span class="p">]</span>

<span class="c1"># Example: Speaker verification scores
</span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">y_scores</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.85</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">]</span>

<span class="n">eer</span><span class="p">,</span> <span class="n">eer_threshold</span> <span class="o">=</span> <span class="nf">compute_eer</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">EER: </span><span class="si">{</span><span class="n">eer</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="o">%</span><span class="si">}</span><span class="s"> at threshold </span><span class="si">{</span><span class="n">eer_threshold</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<hr />

<h2 id="key-takeaways">Key Takeaways</h2>

<p>✅ <strong>No single best metric</strong> - choice depends on problem and business context<br />
✅ <strong>Accuracy misleading</strong> for imbalanced datasets - use precision/recall/F1<br />
✅ <strong>ROC-AUC</strong> good for threshold-independent evaluation<br />
✅ <strong>Precision-Recall</strong> better than ROC for imbalanced data<br />
✅ <strong>Regression metrics</strong> - MSE for outlier sensitivity, MAE for robustness<br />
✅ <strong>Ranking metrics</strong> - NDCG for position-aware, MRR for first relevant item<br />
✅ <strong>Production monitoring</strong> - track metrics over time to detect degradation<br />
✅ <strong>Align with business</strong> - metrics must connect to business KPIs</p>

<hr />

<p><strong>Originally published at:</strong> <a href="https://www.arunbaby.com/ml-system-design/0006-model-evaluation-metrics/">arunbaby.com/ml-system-design/0006-model-evaluation-metrics</a></p>

<p><em>If you found this helpful, consider sharing it with others who might benefit.</em></p>


        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#evaluation" class="page__taxonomy-item p-category" rel="tag">evaluation</a><span class="sep">, </span>
    
      <a href="/tags/#metrics" class="page__taxonomy-item p-category" rel="tag">metrics</a><span class="sep">, </span>
    
      <a href="/tags/#model-performance" class="page__taxonomy-item p-category" rel="tag">model-performance</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#ml-system-design" class="page__taxonomy-item p-category" rel="tag">ml-system-design</a>
    
    </span>
  </p>


        
      </footer>

      <div class="page__related page__related--full">
  <h2 class="page__related-title">Related across topics</h2>
  <style>
    /* Make section span full content width and use 2 equal columns */
    .page__related--full { float: inline-start; width: 100%; padding: 0; }
    .cross-related-grid { display: grid; grid-template-columns: repeat(2, minmax(0, 1fr)); gap: 2rem; }
    @media (max-width: 768px) { .cross-related-grid { grid-template-columns: 1fr; } }
    /* Ensure archive cards stretch nicely in the grid */
    .cross-related-grid .list__item, .cross-related-grid .grid__item { width: auto; float: none; margin: 0; }
  </style>
  <div class="cross-related-grid">
    



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/dsa/0006-climbing-stairs/" rel="permalink">Climbing Stairs
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          25 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">The Fibonacci problem in disguise, teaching the fundamental transition from recursion to dynamic programming to space optimization.
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/speech-tech/0006-text-to-speech-basics/" rel="permalink">Text-to-Speech (TTS) System Fundamentals
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          18 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">From text to natural speech: understanding modern neural TTS architectures that power Alexa, Google Assistant, and Siri.
</p>
  </article>
</div>

  </div>
</div>

      <section class="page__share">
  <h4 class="page__share-title">Share on</h4>

  <a href="https://twitter.com/intent/tweet?via=arunbaby0&text=Model+Evaluation+Metrics%20https%3A%2F%2Fwww.arunbaby.com%2Fml-system-design%2F0006-model-evaluation-metrics%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.arunbaby.com%2Fml-system-design%2F0006-model-evaluation-metrics%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.arunbaby.com/ml-system-design/0006-model-evaluation-metrics/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/ml-system-design/0005-batch-realtime-inference/" class="pagination--pager" title="Batch vs Real-Time Inference">Previous</a>
    
    
      <a href="/ml-system-design/0007-feature-engineering/" class="pagination--pager" title="Feature Engineering at Scale">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 1990 - 2143 <a href="https://www.arunbaby.com">Arun Baby</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JRJPEC9SS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0JRJPEC9SS', { 'anonymize_ip': false});
</script>








  </body>
</html>
