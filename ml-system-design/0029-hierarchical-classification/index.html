<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Hierarchical Classification Systems - Arun Baby</title>
<meta name="description" content="“Organizing the world’s information into a structured hierarchy.”">


  <meta name="author" content="Arun Baby">
  
  <meta property="article:author" content="Arun Baby">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Arun Baby">
<meta property="og:title" content="Hierarchical Classification Systems">
<meta property="og:url" content="https://www.arunbaby.com/ml-system-design/0029-hierarchical-classification/">


  <meta property="og:description" content="“Organizing the world’s information into a structured hierarchy.”">



  <meta property="og:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">



  <meta name="twitter:site" content="@arunbaby0">
  <meta name="twitter:title" content="Hierarchical Classification Systems">
  <meta name="twitter:description" content="“Organizing the world’s information into a structured hierarchy.”">
  <meta name="twitter:url" content="https://www.arunbaby.com/ml-system-design/0029-hierarchical-classification/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">
    
  

  



  <meta property="article:published_time" content="2025-12-05T18:49:37+05:30">





  

  


<link rel="canonical" href="https://www.arunbaby.com/ml-system-design/0029-hierarchical-classification/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Baby Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          <span class="site-subtitle">Arun Baby</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/dsa/"
                
                
              >DSA</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ml-system-design/"
                
                
              >ML Systems</a>
            </li><li class="masthead__menu-item">
              <a
                href="/speech-tech/"
                
                
              >Speech Tech</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li><li class="masthead__menu-item">
              <a
                href="/statuses/"
                
                
              >Statuses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/contact/"
                
                
              >Contact</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main" class="no-author-sidebar">
  
  <div class="sidebar sticky">
  
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Hierarchical Classification Systems">
    <meta itemprop="description" content="“Organizing the world’s information into a structured hierarchy.”">
    <meta itemprop="datePublished" content="2025-12-05T18:49:37+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://www.arunbaby.com/ml-system-design/0029-hierarchical-classification/" itemprop="url">Hierarchical Classification Systems
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          11 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#1-what-is-hierarchical-classification">1. What is Hierarchical Classification?</a></li><li><a href="#2-flat-vs-hierarchical-classification">2. Flat vs. Hierarchical Classification</a></li><li><a href="#3-hierarchical-classification-approaches">3. Hierarchical Classification Approaches</a><ul><li><a href="#approach-1-global-classifier-flat-with-post-processing">Approach 1: Global Classifier (Flat with Post-Processing)</a></li><li><a href="#approach-2-local-classifiers-per-node-lcn">Approach 2: Local Classifiers Per Node (LCN)</a></li><li><a href="#approach-3-end-to-end-hierarchical-model">Approach 3: End-to-End Hierarchical Model</a></li></ul></li><li><a href="#4-handling-multi-label-hierarchy">4. Handling Multi-Label Hierarchy</a></li><li><a href="#5-hierarchy-aware-loss-functions">5. Hierarchy-Aware Loss Functions</a><ul><li><a href="#loss-1-hierarchical-softmax">Loss 1: Hierarchical Softmax</a></li><li><a href="#loss-2-hierarchical-cross-entropy-h-loss">Loss 2: Hierarchical Cross-Entropy (H-Loss)</a></li><li><a href="#loss-3-symmetric-kl-divergence">Loss 3: Symmetric KL Divergence</a></li></ul></li><li><a href="#deep-dive-amazons-product-taxonomy">Deep Dive: Amazon’s Product Taxonomy</a></li><li><a href="#deep-dive-extreme-multi-label-classification-xml">Deep Dive: Extreme Multi-Label Classification (XML)</a></li><li><a href="#deep-dive-googles-knowledge-graph-categories">Deep Dive: Google’s Knowledge Graph Categories</a></li><li><a href="#deep-dive-hierarchical-multi-task-learning-hmtl">Deep Dive: Hierarchical Multi-Task Learning (HMTL)</a></li><li><a href="#deep-dive-taxonomy-expansion-adding-new-categories">Deep Dive: Taxonomy Expansion (Adding New Categories)</a></li><li><a href="#deep-dive-handling-imbalanced-hierarchies">Deep Dive: Handling Imbalanced Hierarchies</a></li><li><a href="#deep-dive-evaluation-metrics">Deep Dive: Evaluation Metrics</a><ul><li><a href="#metric-1-hierarchical-precision-and-recall">Metric 1: Hierarchical Precision and Recall</a></li><li><a href="#metric-2-tree-induced-distance">Metric 2: Tree-Induced Distance</a></li><li><a href="#metric-3-f1-at-different-levels">Metric 3: F1 at Different Levels</a></li></ul></li><li><a href="#deep-dive-active-learning-for-taxonomy-labeling">Deep Dive: Active Learning for Taxonomy Labeling</a></li><li><a href="#deep-dive-hierarchical-attention-networks-han">Deep Dive: Hierarchical Attention Networks (HAN)</a></li><li><a href="#deep-dive-label-embedding-and-matching">Deep Dive: Label Embedding and Matching</a></li><li><a href="#deep-dive-hierarchical-reinforcement-learning-hrl-for-sequential-classification">Deep Dive: Hierarchical Reinforcement Learning (HRL) for Sequential Classification</a></li><li><a href="#implementation-example-pytorch-hierarchical-classifier">Implementation Example: PyTorch Hierarchical Classifier</a></li><li><a href="#top-interview-questions">Top Interview Questions</a></li><li><a href="#key-takeaways">Key Takeaways</a></li><li><a href="#summary">Summary</a></li></ul>
            </nav>
          </aside>
        
        <p><strong>“Organizing the world’s information into a structured hierarchy.”</strong></p>

<h2 id="1-what-is-hierarchical-classification">1. What is Hierarchical Classification?</h2>

<p>Hierarchical classification is the task of assigning an item to one or more nodes in a <strong>taxonomy tree</strong>.</p>

<p><strong>Example: Product Categorization</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Electronics
├── Computers
│   ├── Laptops
│   │   ├── Gaming Laptops
│   │   └── Business Laptops
│   └── Desktops
└── Mobile Devices
    ├── Smartphones
    └── Tablets
</code></pre></div></div>

<p><strong>Problem:</strong> Given a product description “Dell XPS 15 with RTX 3050”, classify it into:</p>
<ul>
  <li>Electronics &gt; Computers &gt; Laptops &gt; Business Laptops (or Gaming Laptops?)</li>
</ul>

<p><strong>Challenges:</strong></p>
<ol>
  <li><strong>Large Taxonomies:</strong> Amazon has 30,000+ categories.</li>
  <li><strong>Multi-path:</strong> An item can belong to multiple leaf nodes (e.g., “Wireless Gaming Mouse” → Computers/Accessories AND Gaming/Peripherals).</li>
  <li><strong>Imbalanced Data:</strong> “Electronics” has millions of items, “Vintage Typewriters” has 100.</li>
  <li><strong>Hierarchy Violations:</strong> A model might predict “Gaming Laptop” without predicting “Laptop” (parent).</li>
</ol>

<h2 id="2-flat-vs-hierarchical-classification">2. Flat vs. Hierarchical Classification</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Aspect</th>
      <th style="text-align: left">Flat Classification</th>
      <th style="text-align: left">Hierarchical Classification</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><strong>Model</strong></td>
      <td style="text-align: left">Single multi-class classifier</td>
      <td style="text-align: left">Tree-structured classifiers</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Predictions</strong></td>
      <td style="text-align: left">One label</td>
      <td style="text-align: left">Path in tree</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Training</strong></td>
      <td style="text-align: left">One model</td>
      <td style="text-align: left">Multiple models (global or local)</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Hierarchy</strong></td>
      <td style="text-align: left">Ignored</td>
      <td style="text-align: left">Exploited</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Example</strong></td>
      <td style="text-align: left">CIFAR-10 (10 classes)</td>
      <td style="text-align: left">ImageNet (1000 classes in hierarchy)</td>
    </tr>
  </tbody>
</table>

<p><strong>Why Hierarchical?</strong></p>
<ul>
  <li><strong>Scalability:</strong> Training a single model with 30,000 classes is intractable.</li>
  <li><strong>Interpretability:</strong> Users navigate taxonomies (“Show me all Electronics &gt; Computers”).</li>
  <li><strong>Zero-shot:</strong> New subcategories can be added without retraining the entire model.</li>
</ul>

<h2 id="3-hierarchical-classification-approaches">3. Hierarchical Classification Approaches</h2>

<h3 id="approach-1-global-classifier-flat-with-post-processing">Approach 1: Global Classifier (Flat with Post-Processing)</h3>

<p>Train a <strong>single multi-class classifier</strong> predicting all leaf nodes, then use the hierarchy to ensure consistency.</p>

<p><strong>Model:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Predict all 30,000 leaf categories
</span><span class="n">logits</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>  <span class="c1"># Shape: [batch, 30000]
</span><span class="n">probs</span> <span class="o">=</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>

<span class="c1"># Post-process: ensure parent probabilities &gt;= child probabilities
</span><span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">taxonomy</span><span class="p">.</span><span class="nf">postorder</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">node</span><span class="p">.</span><span class="n">children</span><span class="p">:</span>
        <span class="n">node</span><span class="p">.</span><span class="n">prob</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">node</span><span class="p">.</span><span class="n">prob</span><span class="p">,</span> <span class="nf">max</span><span class="p">(</span><span class="n">child</span><span class="p">.</span><span class="n">prob</span> <span class="k">for</span> <span class="n">child</span> <span class="ow">in</span> <span class="n">node</span><span class="p">.</span><span class="n">children</span><span class="p">))</span>
</code></pre></div></div>

<p><strong>Pros:</strong></p>
<ul>
  <li>Simple: One model.</li>
  <li>High accuracy if data is sufficient.</li>
</ul>

<p><strong>Cons:</strong></p>
<ul>
  <li><strong>Class Imbalance:</strong> Popular categories dominate.</li>
  <li><strong>No hierarchy exploitation during training.</strong></li>
</ul>

<h3 id="approach-2-local-classifiers-per-node-lcn">Approach 2: Local Classifiers Per Node (LCN)</h3>

<p>Train a <strong>separate classifier at each internal node</strong> to choose among its children.</p>

<p><strong>Example:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Root Classifier: Electronics vs. Clothing vs. Books
  ├─ Electronics Classifier: Computers vs. Mobile Devices
  │   ├─ Computers Classifier: Laptops vs. Desktops
</code></pre></div></div>

<p><strong>Inference:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">node</span> <span class="o">=</span> <span class="n">root</span>
<span class="k">while</span> <span class="ow">not</span> <span class="n">node</span><span class="p">.</span><span class="nf">is_leaf</span><span class="p">():</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">node</span><span class="p">.</span><span class="nf">classifier</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
    <span class="n">node</span> <span class="o">=</span> <span class="n">node</span><span class="p">.</span><span class="n">children</span><span class="p">[</span><span class="nf">argmax</span><span class="p">(</span><span class="n">probs</span><span class="p">)]</span>
<span class="k">return</span> <span class="n">node</span>
</code></pre></div></div>

<p><strong>Pros:</strong></p>
<ul>
  <li><strong>Balanced:</strong> Each classifier handles a small, focused problem.</li>
  <li><strong>Modular:</strong> Can update one classifier without retraining others.</li>
</ul>

<p><strong>Cons:</strong></p>
<ul>
  <li><strong>Error Propagation:</strong> If the root classifier is wrong, the entire path is wrong.</li>
  <li><strong>Many Models:</strong> Need to train and deploy K models (where K = number of internal nodes).</li>
</ul>

<h3 id="approach-3-end-to-end-hierarchical-model">Approach 3: End-to-End Hierarchical Model</h3>

<p>Use a <strong>shared encoder</strong> with <strong>hierarchical output heads</strong>.</p>

<p><strong>Architecture:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">HierarchicalClassifier</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">taxonomy</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="nc">ResNet</span><span class="p">()</span>  <span class="c1"># Shared
</span>        <span class="n">self</span><span class="p">.</span><span class="n">heads</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ModuleDict</span><span class="p">({</span>
            <span class="n">node</span><span class="p">.</span><span class="nb">id</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">2048</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">node</span><span class="p">.</span><span class="n">children</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">taxonomy</span><span class="p">.</span><span class="nf">internal_nodes</span><span class="p">()</span>
        <span class="p">})</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">node_id</span><span class="p">,</span> <span class="n">head</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">heads</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
            <span class="n">outputs</span><span class="p">[</span><span class="n">node_id</span><span class="p">]</span> <span class="o">=</span> <span class="nf">head</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">outputs</span>
</code></pre></div></div>

<p><strong>Loss:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">taxonomy</span><span class="p">.</span><span class="nf">internal_nodes</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">ground_truth_path</span><span class="p">:</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">ground_truth_path</span><span class="p">[</span><span class="n">node</span><span class="p">].</span><span class="n">child_index</span>
        <span class="n">total_loss</span> <span class="o">+=</span> <span class="nf">cross_entropy</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="n">node</span><span class="p">.</span><span class="nb">id</span><span class="p">],</span> <span class="n">target</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Pros:</strong></p>
<ul>
  <li><strong>Shared Representations:</strong> Lower layers learn general features.</li>
  <li><strong>End-to-End Training:</strong> Optimizes the entire path jointly.</li>
</ul>

<p><strong>Cons:</strong></p>
<ul>
  <li><strong>Complex:</strong> Harder to debug and tune.</li>
  <li><strong>Memory:</strong> All heads must fit in GPU memory.</li>
</ul>

<h2 id="4-handling-multi-label-hierarchy">4. Handling Multi-Label Hierarchy</h2>

<p>Some items belong to <strong>multiple paths</strong> in the tree.</p>

<p><strong>Example:</strong>
“Logitech Wireless Gaming Mouse”</p>
<ul>
  <li>Path 1: Electronics &gt; Computers &gt; Accessories &gt; Mouse</li>
  <li>Path 2: Electronics &gt; Gaming &gt; Peripherals &gt; Mouse</li>
</ul>

<p><strong>Approach: Multi-Task Learning</strong></p>
<ul>
  <li>Treat each path as a separate task.</li>
  <li>Loss = Sum of losses for all valid paths.
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">loss</span> <span class="o">=</span> <span class="nf">sum</span><span class="p">(</span><span class="nf">path_loss</span><span class="p">(</span><span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">path</span><span class="p">)</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">ground_truth_paths</span><span class="p">)</span>
</code></pre></div>    </div>
  </li>
</ul>

<h2 id="5-hierarchy-aware-loss-functions">5. Hierarchy-Aware Loss Functions</h2>

<h3 id="loss-1-hierarchical-softmax">Loss 1: Hierarchical Softmax</h3>

<p>Instead of standard softmax over 30,000 classes, factorize:
\[
P(\text{Leaf} | x) = P(\text{Root} \to \text{Child}_1 | x) \times P(\text{Child}_1 \to \text{Child}_2 | x) \times \ldots
\]</p>

<p><strong>Benefit:</strong> Reduces computation from \(O(K)\) to \(O(\log K)\) where K is number of classes.</p>

<h3 id="loss-2-hierarchical-cross-entropy-h-loss">Loss 2: Hierarchical Cross-Entropy (H-Loss)</h3>

<p>Penalize mistakes based on the distance in the tree.
\[
\mathcal{L} = \sum_{i=1}^{D} \alpha_i \cdot \text{CE}(\text{pred}_i, \text{true}_i)
\]
where \(D\) is the depth and \(\alpha_i\) increases with depth (leaf nodes weighted more).</p>

<p><strong>Intuition:</strong> Mistaking “Gaming Laptop” for “Business Laptop” (siblings) is less bad than mistaking it for “Tablet” (cousin).</p>

<h3 id="loss-3-symmetric-kl-divergence">Loss 3: Symmetric KL Divergence</h3>

<p>Encourage the model to predict <strong>ancestor probabilities &gt;= descendant probabilities</strong>.
\[
\mathcal{L}<em>{\text{consistency}} = \sum</em>{\text{parent, child}} \max(0, P(\text{child}) - P(\text{parent}))
\]</p>

<h2 id="deep-dive-amazons-product-taxonomy">Deep Dive: Amazon’s Product Taxonomy</h2>

<p>Amazon has a <strong>forest of taxonomies</strong> (one per marketplace).
<strong>Challenge:</strong> Items listed in multiple marketplaces need consistent categorization.</p>

<p><strong>Solution: Transfer Learning</strong></p>
<ol>
  <li>Train a base model on US taxonomy (most data).</li>
  <li>Fine-tune on UK, Japan, India taxonomies.</li>
  <li>Use <strong>adapter layers</strong> to handle marketplace-specific categories.</li>
</ol>

<p><strong>Scale:</strong></p>
<ul>
  <li><strong>Items:</strong> 350M+</li>
  <li><strong>Categories:</strong> 30,000+</li>
  <li><strong>Languages:</strong> 15+</li>
</ul>

<h2 id="deep-dive-extreme-multi-label-classification-xml">Deep Dive: Extreme Multi-Label Classification (XML)</h2>

<p>When the number of labels is in the millions (e.g., Wikipedia categories), standard approaches fail.</p>

<p><strong>Approaches:</strong></p>
<ol>
  <li><strong>Embedding-Based (AnnexML, Bonsai, Parabel):</strong>
    <ul>
      <li>Embed labels and inputs into the same space.</li>
      <li>Use ANN (Approximate Nearest Neighbors) to retrieve top-K labels.</li>
    </ul>
  </li>
  <li><strong>Attention Mechanisms:</strong>
    <ul>
      <li>Label-Attention: Attend to label descriptions during encoding.</li>
    </ul>
  </li>
  <li><strong>Tree Pruning:</strong>
    <ul>
      <li>Prune unlikely branches early using a lightweight model.</li>
    </ul>
  </li>
</ol>

<p><strong>Parabel Architecture:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1. Build a label tree (clustering similar labels).
2. Train classifiers at each node (like LCN).
3. Beam search during inference to explore top-K branches.
</code></pre></div></div>

<h2 id="deep-dive-googles-knowledge-graph-categories">Deep Dive: Google’s Knowledge Graph Categories</h2>

<p>Google Search uses a hierarchical taxonomy for entities.
<strong>Example:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Thing
├── Creative Work
│   └── Movie
└── Person
    └── Actor
</code></pre></div></div>

<p><strong>Challenge:</strong> New entities appear daily (new movies, new people).
<strong>Solution:</strong></p>
<ul>
  <li><strong>Zero-Shot Classification:</strong> Use a text encoder (BERT) to embed the entity description.</li>
  <li><strong>Nearest Ancestor:</strong> Find the closest category in the embedding space.</li>
</ul>

<h2 id="deep-dive-hierarchical-multi-task-learning-hmtl">Deep Dive: Hierarchical Multi-Task Learning (HMTL)</h2>

<p>In HMTL, tasks are organized in a hierarchy where:</p>
<ul>
  <li><strong>Lower tasks</strong> are easier (e.g., “Is this electronics?”).</li>
  <li><strong>Higher tasks</strong> are harder (e.g., “Is this a gaming laptop?”).</li>
</ul>

<p><strong>Architecture:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Input → Shared Encoder → Task 1 (Electronics?) ──┐
                         ├→ Task 2 (Computers?)   │
                         └→ Task 3 (Laptops?)     │
                                                   ├→ Final Prediction
</code></pre></div></div>

<p><strong>Loss:</strong>
\[
\mathcal{L} = \lambda_1 \mathcal{L}_1 + \lambda_2 \mathcal{L}_2 + \lambda_3 \mathcal{L}_3
\]
where \(\lambda_i\) are learned or hand-tuned.</p>

<h2 id="deep-dive-taxonomy-expansion-adding-new-categories">Deep Dive: Taxonomy Expansion (Adding New Categories)</h2>

<p><strong>Problem:</strong> A new category “Foldable Smartphones” needs to be added.</p>

<p><strong>Approach 1: Retrain from Scratch</strong></p>
<ul>
  <li>Expensive and slow.</li>
</ul>

<p><strong>Approach 2: Continual Learning</strong></p>
<ul>
  <li>Fine-tune the model on new data while preserving old knowledge.</li>
  <li><strong>Challenge:</strong> Catastrophic forgetting.</li>
  <li><strong>Solution:</strong> Elastic Weight Consolidation (EWC) or rehearsal buffers.</li>
</ul>

<p><strong>Approach 3: Few-Shot Learning</strong></p>
<ul>
  <li>Train a meta-learner that can adapt to new categories with &lt; 100 examples.</li>
  <li>Use <strong>Prototypical Networks</strong> or <strong>MAML</strong>.</li>
</ul>

<h2 id="deep-dive-handling-imbalanced-hierarchies">Deep Dive: Handling Imbalanced Hierarchies</h2>

<p><strong>Problem:</strong> “Laptops” has 1M examples, “Typewriters” has 50.</p>

<p><strong>Solutions:</strong></p>
<ol>
  <li><strong>Class Weighting:</strong>
\[
w_i = \frac{\text{total samples}}{\text{samples in class } i}
\]</li>
  <li><strong>Focal Loss:</strong>
\[
\mathcal{L} = -\alpha (1 - p_t)^\gamma \log(p_t)
\]
Focuses on hard-to-classify examples.</li>
  <li><strong>Oversampling:</strong>
    <ul>
      <li>Augment rare classes.</li>
    </ul>
  </li>
  <li><strong>Hierarchical Sampling:</strong>
    <ul>
      <li>Sample uniformly at each <strong>level</strong> of the tree, not uniformly across all leaves.</li>
    </ul>
  </li>
</ol>

<h2 id="deep-dive-evaluation-metrics">Deep Dive: Evaluation Metrics</h2>

<h3 id="metric-1-hierarchical-precision-and-recall">Metric 1: Hierarchical Precision and Recall</h3>

<p>Standard precision/recall don’t account for hierarchy.
<strong>Hierarchical Precision:</strong>
\[
hP = \frac{|\text{predicted path} \cap \text{true path}|}{|\text{predicted path}|}
\]</p>

<p><strong>Example:</strong></p>
<ul>
  <li>True: Electronics &gt; Computers &gt; Laptops</li>
  <li>Predicted: Electronics &gt; Computers &gt; Desktops</li>
  <li>\( hP = \frac{2}{3} \) (got Electronics and Computers right, but wrong at Laptops level).</li>
</ul>

<h3 id="metric-2-tree-induced-distance">Metric 2: Tree-Induced Distance</h3>

<p>Measure the shortest path between predicted and true leaf in the tree.
\[
d(\text{pred}, \text{true}) = \text{depth}(\text{LCA}(\text{pred}, \text{true}))
\]</p>

<p><strong>Example:</strong></p>
<ul>
  <li>pred = Gaming Laptop, true = Business Laptop</li>
  <li>LCA = Laptop</li>
  <li>Distance = depth(Laptop) = 2 (smaller is better)</li>
</ul>

<h3 id="metric-3-f1-at-different-levels">Metric 3: F1 at Different Levels</h3>

<p>Compute F1 separately at each level of the hierarchy.</p>
<ul>
  <li><strong>Level 0 (Root):</strong> F1 = 100% (trivial).</li>
  <li><strong>Level 1:</strong> F1 on {Electronics, Clothing, Books}.</li>
  <li><strong>Level 2:</strong> F1 on {Computers, Mobile, etc.}.</li>
</ul>

<h2 id="deep-dive-active-learning-for-taxonomy-labeling">Deep Dive: Active Learning for Taxonomy Labeling</h2>

<p><strong>Problem:</strong> Labeling 10M products manually is expensive.</p>

<p><strong>Solution: Active Learning</strong></p>
<ol>
  <li>Train initial model on small labeled set.</li>
  <li><strong>Query:</strong> Find the most uncertain samples.
    <ul>
      <li>Entropy: \( H = -\sum_i p_i \log p_i \)</li>
      <li>Least Confident: \( 1 - \max_i p_i \)</li>
    </ul>
  </li>
  <li>Human labels the queried samples.</li>
  <li>Retrain and repeat.</li>
</ol>

<p><strong>Hierarchical Active Learning:</strong></p>
<ul>
  <li>Prioritize samples where the model is uncertain <strong>at multiple levels</strong> of the tree.</li>
</ul>

<h2 id="deep-dive-hierarchical-attention-networks-han">Deep Dive: Hierarchical Attention Networks (HAN)</h2>

<p><strong>Idea:</strong> Use attention at each level of the hierarchy to focus on relevant features.</p>

<p><strong>Architecture:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">HierarchicalAttention</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">word_attention</span> <span class="o">=</span> <span class="nc">Attention</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">sentence_attention</span> <span class="o">=</span> <span class="nc">Attention</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">document_attention</span> <span class="o">=</span> <span class="nc">Attention</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">document</span><span class="p">):</span>
        <span class="c1"># Level 1: Words → Sentence Representation
</span>        <span class="n">sentence_reps</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">document</span><span class="p">:</span>
            <span class="n">word_reps</span> <span class="o">=</span> <span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="nf">embed</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="p">]</span>
            <span class="n">sentence_rep</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">word_attention</span><span class="p">(</span><span class="n">word_reps</span><span class="p">)</span>
            <span class="n">sentence_reps</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">sentence_rep</span><span class="p">)</span>
        
        <span class="c1"># Level 2: Sentences → Document Representation
</span>        <span class="n">doc_rep</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">sentence_attention</span><span class="p">(</span><span class="n">sentence_reps</span><span class="p">)</span>
        
        <span class="c1"># Level 3: Document → Category
</span>        <span class="n">category</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">document_attention</span><span class="p">(</span><span class="n">doc_rep</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">category</span>
</code></pre></div></div>

<h2 id="deep-dive-label-embedding-and-matching">Deep Dive: Label Embedding and Matching</h2>

<p><strong>Idea:</strong> Embed both inputs and labels into the same space.</p>

<p><strong>Training:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">input_emb</span> <span class="o">=</span> <span class="nf">encoder</span><span class="p">(</span><span class="n">product_description</span><span class="p">)</span>  <span class="c1"># [batch, 512]
</span><span class="n">label_embs</span> <span class="o">=</span> <span class="nf">label_encoder</span><span class="p">(</span><span class="n">all_labels</span><span class="p">)</span>     <span class="c1"># [30000, 512]
</span>
<span class="c1"># Dot product similarity
</span><span class="n">scores</span> <span class="o">=</span> <span class="n">input_emb</span> <span class="o">@</span> <span class="n">label_embs</span><span class="p">.</span><span class="n">T</span>  <span class="c1"># [batch, 30000]
</span><span class="n">loss</span> <span class="o">=</span> <span class="nf">cross_entropy</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Inference:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Use FAISS for fast top-K retrieval
</span><span class="n">top_k_labels</span> <span class="o">=</span> <span class="n">faiss_index</span><span class="p">.</span><span class="nf">search</span><span class="p">(</span><span class="n">input_emb</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Benefit:</strong> Decouples the number of labels from model size. Can add new labels without retraining.</p>

<h2 id="deep-dive-hierarchical-reinforcement-learning-hrl-for-sequential-classification">Deep Dive: Hierarchical Reinforcement Learning (HRL) for Sequential Classification</h2>

<p><strong>Problem:</strong> Some taxonomies require a sequence of decisions.</p>

<p><strong>Example:</strong>
“Classify this support ticket”</p>
<ol>
  <li>Department? (Sales, Support, Engineering)</li>
  <li>If Support, Priority? (Low, Medium, High)</li>
  <li>If High, Assign to? (Agent 1, Agent 2, Agent 3)</li>
</ol>

<p><strong>Approach: Hierarchical RL</strong></p>
<ul>
  <li><strong>High-Level Policy:</strong> Chooses department.</li>
  <li><strong>Low-Level Policies:</strong> Choose priority, assign agent.</li>
  <li><strong>Reward:</strong> +1 if ticket is resolved quickly.</li>
</ul>

<h2 id="implementation-example-pytorch-hierarchical-classifier">Implementation Example: PyTorch Hierarchical Classifier</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">HierarchicalModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">taxonomy</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">768</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">taxonomy</span> <span class="o">=</span> <span class="n">taxonomy</span>
        <span class="n">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
        <span class="p">)</span>
        
        <span class="c1"># One classifier per internal node
</span>        <span class="n">self</span><span class="p">.</span><span class="n">classifiers</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ModuleDict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">taxonomy</span><span class="p">.</span><span class="nf">internal_nodes</span><span class="p">():</span>
            <span class="n">self</span><span class="p">.</span><span class="n">classifiers</span><span class="p">[</span><span class="nf">str</span><span class="p">(</span><span class="n">node</span><span class="p">.</span><span class="nb">id</span><span class="p">)]</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">node</span><span class="p">.</span><span class="n">children</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">return_all</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">return_all</span><span class="p">:</span>
            <span class="c1"># Return logits for all nodes (for training)
</span>            <span class="n">outputs</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">node_id</span><span class="p">,</span> <span class="n">classifier</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">classifiers</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
                <span class="n">outputs</span><span class="p">[</span><span class="n">node_id</span><span class="p">]</span> <span class="o">=</span> <span class="nf">classifier</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">outputs</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Greedy path prediction (for inference)
</span>            <span class="n">node</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">taxonomy</span><span class="p">.</span><span class="n">root</span>
            <span class="n">path</span> <span class="o">=</span> <span class="p">[</span><span class="n">node</span><span class="p">]</span>
            
            <span class="k">while</span> <span class="ow">not</span> <span class="n">node</span><span class="p">.</span><span class="nf">is_leaf</span><span class="p">():</span>
                <span class="n">logits</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">classifiers</span><span class="p">[</span><span class="nf">str</span><span class="p">(</span><span class="n">node</span><span class="p">.</span><span class="nb">id</span><span class="p">)](</span><span class="n">features</span><span class="p">)</span>
                <span class="n">child_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">node</span> <span class="o">=</span> <span class="n">node</span><span class="p">.</span><span class="n">children</span><span class="p">[</span><span class="n">child_idx</span><span class="p">.</span><span class="nf">item</span><span class="p">()]</span>
                <span class="n">path</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
            
            <span class="k">return</span> <span class="n">path</span>

<span class="k">def</span> <span class="nf">hierarchical_loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">true_path</span><span class="p">):</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">true_path</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">node</span><span class="p">.</span><span class="nf">is_leaf</span><span class="p">():</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="nf">str</span><span class="p">(</span><span class="n">node</span><span class="p">.</span><span class="nb">id</span><span class="p">)]</span>
            <span class="n">target</span> <span class="o">=</span> <span class="n">true_path</span><span class="p">.</span><span class="nf">index</span><span class="p">(</span><span class="n">node</span><span class="p">.</span><span class="nf">get_child_on_path</span><span class="p">(</span><span class="n">true_path</span><span class="p">))</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">()(</span><span class="n">logits</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="n">target</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">loss</span>
</code></pre></div></div>

<h2 id="top-interview-questions">Top Interview Questions</h2>

<p><strong>Q1: How do you handle products that fit multiple categories?</strong>
<em>Answer:</em>
Use <strong>multi-label classification</strong>. Train the model to predict multiple paths. At inference, use a threshold (e.g., predict all paths with confidence &gt; 0.3).</p>

<p><strong>Q2: What if the taxonomy is updated (categories added/removed)?</strong>
<em>Answer:</em>
Use <strong>modular design</strong> (local classifiers) so you can retrain only affected nodes. Or use <strong>label embeddings</strong> which allow adding new categories without retraining.</p>

<p><strong>Q3: How do you ensure hierarchy consistency?</strong>
<em>Answer:</em>
Post-process predictions to ensure \(P(\text{child}) \leq P(\text{parent})\). During training, add a <strong>consistency loss</strong> term.</p>

<p><strong>Q4: How do you deal with extreme imbalance (popular vs. rare categories)?</strong>
<em>Answer:</em></p>
<ul>
  <li>Focal loss to focus on hard examples.</li>
  <li>Hierarchical sampling (sample uniformly at each level).</li>
  <li>Data augmentation for rare categories.</li>
</ul>

<h2 id="key-takeaways">Key Takeaways</h2>

<ol>
  <li><strong>Hierarchy Exploitation:</strong> Use the tree structure during both training and inference.</li>
  <li><strong>Local vs. Global:</strong> Trade-off between modular (easy to update) and end-to-end (higher accuracy).</li>
  <li><strong>Multi-Label:</strong> Real-world taxonomies often have overlapping categories.</li>
  <li><strong>Scalability:</strong> For millions of classes, use embedding-based retrieval (ANN).</li>
  <li><strong>Evaluation:</strong> Standard metrics don’t account for hierarchy; use hierarchical precision/recall.</li>
</ol>

<h2 id="summary">Summary</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Aspect</th>
      <th style="text-align: left">Insight</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><strong>Approaches</strong></td>
      <td style="text-align: left">Global, Local (LCN), End-to-End Hierarchical</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Loss Functions</strong></td>
      <td style="text-align: left">Hierarchical Softmax, H-Loss, Consistency Loss</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Scalability</strong></td>
      <td style="text-align: left">Label embeddings + FAISS for extreme multi-label</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Evaluation</strong></td>
      <td style="text-align: left">Hierarchical precision, tree-induced distance</td>
    </tr>
  </tbody>
</table>

<hr />

<p><strong>Originally published at:</strong> <a href="https://www.arunbaby.com/ml-system-design/0029-hierarchical-classification/">arunbaby.com/ml-system-design/0029-hierarchical-classification</a></p>

<p><em>If you found this helpful, consider sharing it with others who might benefit.</em></p>


        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#classification" class="page__taxonomy-item p-category" rel="tag">classification</a><span class="sep">, </span>
    
      <a href="/tags/#hierarchical" class="page__taxonomy-item p-category" rel="tag">hierarchical</a><span class="sep">, </span>
    
      <a href="/tags/#multi-label" class="page__taxonomy-item p-category" rel="tag">multi-label</a><span class="sep">, </span>
    
      <a href="/tags/#taxonomy" class="page__taxonomy-item p-category" rel="tag">taxonomy</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#ml-system-design" class="page__taxonomy-item p-category" rel="tag">ml_system_design</a>
    
    </span>
  </p>


        
      </footer>

      <div class="page__related page__related--full">
  <h2 class="page__related-title">Related across topics</h2>
  <style>
    /* Make section span full content width and use 2 equal columns */
    .page__related--full { float: inline-start; width: 100%; padding: 0; }
    .cross-related-grid { display: grid; grid-template-columns: repeat(2, minmax(0, 1fr)); gap: 2rem; }
    @media (max-width: 768px) { .cross-related-grid { grid-template-columns: 1fr; } }
    /* Ensure archive cards stretch nicely in the grid */
    .cross-related-grid .list__item, .cross-related-grid .grid__item { width: auto; float: none; margin: 0; }
  </style>
  <div class="cross-related-grid">
    



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/dsa/0029-lowest-common-ancestor/" rel="permalink">Lowest Common Ancestor of a Binary Tree
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          12 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“Find the point where two paths in a tree first meet.”
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/speech-tech/0029-hierarchical-speech-classification/" rel="permalink">Hierarchical Speech Classification
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          12 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“From broad categories to fine-grained speech understanding.”
</p>
  </article>
</div>

  </div>
</div>

      <section class="page__share">
  <h4 class="page__share-title">Share on</h4>

  <a href="https://twitter.com/intent/tweet?via=arunbaby0&text=Hierarchical+Classification+Systems%20https%3A%2F%2Fwww.arunbaby.com%2Fml-system-design%2F0029-hierarchical-classification%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.arunbaby.com%2Fml-system-design%2F0029-hierarchical-classification%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.arunbaby.com/ml-system-design/0029-hierarchical-classification/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/ml-system-design/0028-ranking-systems-at-scale/" class="pagination--pager" title="Ranking Systems at Scale">Previous</a>
    
    
      <a href="/ml-system-design/0030-graph-based-recommendations/" class="pagination--pager" title="Graph-based Recommendation Systems">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 1990 - 2143 <a href="https://www.arunbaby.com">Arun Baby</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JRJPEC9SS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0JRJPEC9SS', { 'anonymize_ip': false});
</script>








  </body>
</html>
