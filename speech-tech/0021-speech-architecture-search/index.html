<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Speech Architecture Search - Arun Baby</title>
<meta name="description" content="Design neural architecture search systems for speech models that automatically discover optimal ASR/TTS architectures—using dynamic programming and path optimization to navigate exponential search spaces.">


  <meta name="author" content="Arun Baby">
  
  <meta property="article:author" content="Arun Baby">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Arun Baby">
<meta property="og:title" content="Speech Architecture Search">
<meta property="og:url" content="https://www.arunbaby.com/speech-tech/0021-speech-architecture-search/">


  <meta property="og:description" content="Design neural architecture search systems for speech models that automatically discover optimal ASR/TTS architectures—using dynamic programming and path optimization to navigate exponential search spaces.">



  <meta property="og:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">



  <meta name="twitter:site" content="@arunbaby0">
  <meta name="twitter:title" content="Speech Architecture Search">
  <meta name="twitter:description" content="Design neural architecture search systems for speech models that automatically discover optimal ASR/TTS architectures—using dynamic programming and path optimization to navigate exponential search spaces.">
  <meta name="twitter:url" content="https://www.arunbaby.com/speech-tech/0021-speech-architecture-search/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">
    
  

  



  <meta property="article:published_time" content="2025-11-24T23:16:44+05:30">





  

  


<link rel="canonical" href="https://www.arunbaby.com/speech-tech/0021-speech-architecture-search/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Baby Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          <span class="site-subtitle">Arun Baby</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/dsa/"
                
                
              >DSA</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ml-system-design/"
                
                
              >ML Systems</a>
            </li><li class="masthead__menu-item">
              <a
                href="/speech-tech/"
                
                
              >Speech Tech</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li><li class="masthead__menu-item">
              <a
                href="/statuses/"
                
                
              >Statuses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/contact/"
                
                
              >Contact</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main" class="no-author-sidebar">
  
  <div class="sidebar sticky">
  
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Speech Architecture Search">
    <meta itemprop="description" content="Design neural architecture search systems for speech models that automatically discover optimal ASR/TTS architectures—using dynamic programming and path optimization to navigate exponential search spaces.">
    <meta itemprop="datePublished" content="2025-11-24T23:16:44+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://www.arunbaby.com/speech-tech/0021-speech-architecture-search/" itemprop="url">Speech Architecture Search
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          17 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#problem-statement">Problem Statement</a><ul><li><a href="#functional-requirements">Functional Requirements</a></li><li><a href="#non-functional-requirements">Non-Functional Requirements</a></li></ul></li><li><a href="#understanding-the-requirements">Understanding the Requirements</a><ul><li><a href="#why-speech-architecture-search">Why Speech Architecture Search?</a></li><li><a href="#speech-architecture-challenges">Speech Architecture Challenges</a></li><li><a href="#the-path-optimization-connection">The Path Optimization Connection</a></li></ul></li><li><a href="#high-level-architecture">High-Level Architecture</a><ul><li><a href="#key-components">Key Components</a></li></ul></li><li><a href="#component-deep-dives">Component Deep-Dives</a><ul><li><a href="#1-speech-specific-search-space">1. Speech-Specific Search Space</a></li><li><a href="#2-architecture-evaluation">2. Architecture Evaluation</a></li><li><a href="#3-search-strategy-for-speech">3. Search Strategy for Speech</a></li><li><a href="#4-multi-objective-optimization">4. Multi-Objective Optimization</a></li></ul></li><li><a href="#scaling-strategies">Scaling Strategies</a><ul><li><a href="#efficient-evaluation">Efficient Evaluation</a></li></ul></li><li><a href="#real-world-case-study-googles-speech-nas">Real-World Case Study: Google’s Speech NAS</a><ul><li><a href="#googles-approach-for-mobile-asr">Google’s Approach for Mobile ASR</a></li><li><a href="#lessons-learned">Lessons Learned</a></li></ul></li><li><a href="#cost-analysis">Cost Analysis</a><ul><li><a href="#nas-vs-manual-design">NAS vs Manual Design</a></li></ul></li><li><a href="#advanced-topics">Advanced Topics</a><ul><li><a href="#1-multi-lingual-nas">1. Multi-Lingual NAS</a></li><li><a href="#2-streaming-aware-nas">2. Streaming-Aware NAS</a></li><li><a href="#3-transfer-from-vision-nas">3. Transfer from Vision NAS</a></li></ul></li><li><a href="#monitoring--debugging">Monitoring &amp; Debugging</a><ul><li><a href="#key-metrics">Key Metrics</a></li><li><a href="#debugging-tools">Debugging Tools</a></li></ul></li><li><a href="#key-takeaways">Key Takeaways</a><ul><li><a href="#connection-to-thematic-link-dynamic-programming-and-path-optimization">Connection to Thematic Link: Dynamic Programming and Path Optimization</a></li></ul></li></ul>
            </nav>
          </aside>
        
        <p><strong>Design neural architecture search systems for speech models that automatically discover optimal ASR/TTS architectures—using dynamic programming and path optimization to navigate exponential search spaces.</strong></p>

<h2 id="problem-statement">Problem Statement</h2>

<p>Design a <strong>Speech Architecture Search System</strong> that:</p>

<ol>
  <li><strong>Automatically discovers</strong> ASR/TTS architectures optimized for accuracy, latency, and size</li>
  <li><strong>Searches efficiently</strong> through speech-specific architecture spaces (encoders, decoders, attention)</li>
  <li><strong>Handles speech constraints</strong> (streaming, long sequences, variable-length inputs)</li>
  <li><strong>Optimizes for deployment</strong> (mobile, edge, server, different hardware)</li>
  <li><strong>Supports multi-objective</strong> optimization (WER, latency, params, multilingual capability)</li>
</ol>

<h3 id="functional-requirements">Functional Requirements</h3>

<ol>
  <li><strong>Speech-specific search spaces:</strong>
    <ul>
      <li>Encoder architectures (Conformer, Transformer, RNN, CNN)</li>
      <li>Decoder types (CTC, RNN-T, attention-based)</li>
      <li>Attention mechanisms (self-attention, cross-attention, relative positional)</li>
      <li>Feature extraction configs (mel-spec, MFCC, learnable features)</li>
    </ul>
  </li>
  <li><strong>Search strategies:</strong>
    <ul>
      <li>Reinforcement learning</li>
      <li>Evolutionary algorithms</li>
      <li>Differentiable NAS (DARTS for speech)</li>
      <li>Bayesian optimization</li>
      <li>Transfer from vision NAS results</li>
    </ul>
  </li>
  <li><strong>Performance estimation:</strong>
    <ul>
      <li>Train on subset of data (LibriSpeech-100h vs 960h)</li>
      <li>Early stopping based on validation WER</li>
      <li>Weight sharing across architectures</li>
      <li>WER prediction from architecture features</li>
    </ul>
  </li>
  <li><strong>Multi-objective optimization:</strong>
    <ul>
      <li>WER vs latency (for real-time ASR)</li>
      <li>WER vs model size (for on-device)</li>
      <li>WER vs RTF (real-time factor)</li>
      <li>Multi-lingual capability vs params</li>
    </ul>
  </li>
  <li><strong>Streaming-aware search:</strong>
    <ul>
      <li>Architectures must support chunk-wise processing</li>
      <li>Latency measured per chunk, not full utterance</li>
      <li>Look-ahead constraints (for causal models)</li>
    </ul>
  </li>
  <li><strong>Evaluation:</strong>
    <ul>
      <li>WER/CER on multiple test sets</li>
      <li>Latency measurement on target hardware</li>
      <li>Parameter count and memory footprint</li>
      <li>Multi-lingual evaluation</li>
    </ul>
  </li>
</ol>

<h3 id="non-functional-requirements">Non-Functional Requirements</h3>

<ol>
  <li><strong>Efficiency:</strong> Find good architecture in &lt;50 GPU days</li>
  <li><strong>Quality:</strong> WER competitive with hand-designed models</li>
  <li><strong>Generalizability:</strong> Transfer across languages and domains</li>
  <li><strong>Reproducibility:</strong> Same search produces same results</li>
  <li><strong>Practicality:</strong> Discovered models deployable in production</li>
</ol>

<h2 id="understanding-the-requirements">Understanding the Requirements</h2>

<h3 id="why-speech-architecture-search">Why Speech Architecture Search?</h3>

<p><strong>Manual speech model design challenges:</strong></p>
<ul>
  <li>Requires domain expertise (speech signal processing + deep learning)</li>
  <li>Hard to balance accuracy, latency, and size</li>
  <li>Difficult to optimize for specific hardware (mobile, server)</li>
  <li>Time-consuming to explore alternative designs</li>
</ul>

<p><strong>Speech NAS enables:</strong></p>
<ul>
  <li>Automated discovery of novel architectures</li>
  <li>Hardware-specific optimization (mobile, edge TPU, server GPU)</li>
  <li>Multi-lingual model optimization</li>
  <li>Systematic exploration of design space</li>
</ul>

<h3 id="speech-architecture-challenges">Speech Architecture Challenges</h3>

<ol>
  <li><strong>Long sequences:</strong> Audio is 100s-1000s of frames (vs images ~224×224)</li>
  <li><strong>Temporal modeling:</strong> Need strong sequential modeling (RNNs, Transformers)</li>
  <li><strong>Streaming requirements:</strong> Many applications need real-time processing</li>
  <li><strong>Variable length:</strong> Utterances vary from 1s to 60s+</li>
  <li><strong>Multi-lingual:</strong> Same architecture should work across languages</li>
</ol>

<h3 id="the-path-optimization-connection">The Path Optimization Connection</h3>

<p>Just like <strong>Unique Paths</strong> uses DP to count paths through a grid:</p>

<table>
  <thead>
    <tr>
      <th>Unique Paths</th>
      <th>Neural Arch Search</th>
      <th>Speech Arch Search</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>m×n grid</td>
      <td>General model space</td>
      <td>Speech-specific space</td>
    </tr>
    <tr>
      <td>Count paths</td>
      <td>Evaluate architectures</td>
      <td>Evaluate speech models</td>
    </tr>
    <tr>
      <td>DP: paths(i,j) = paths(i-1,j) + paths(i,j-1)</td>
      <td>DP: Build from sub-architectures</td>
      <td>DP: Build from encoder/decoder blocks</td>
    </tr>
    <tr>
      <td>O(m×n) from O(2^(m+n))</td>
      <td>Polynomial from exponential</td>
      <td>Efficient from exhaustive</td>
    </tr>
    <tr>
      <td>Reconstruct optimal path</td>
      <td>Extract best architecture</td>
      <td>Extract best speech model</td>
    </tr>
  </tbody>
</table>

<p>Both use <strong>DP and path optimization</strong> to navigate exponentially large spaces.</p>

<h2 id="high-level-architecture">High-Level Architecture</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>┌─────────────────────────────────────────────────────────────────┐
│                Speech Architecture Search System                 │
└─────────────────────────────────────────────────────────────────┘

                    Search Controller
        ┌────────────────────────────────────┐
        │  Strategy: RL / EA / DARTS         │
        │  - Propose speech architectures    │
        │  - Encoder + Decoder + Attention   │
        └──────────────┬─────────────────────┘
                       │
                ┌──────▼──────┐
                │ Speech      │
                │ Search      │
                │ Space       │
                │             │
                │ - Encoder   │
                │ - Decoder   │
                │ - Attention │
                │ - Features  │
                └──────┬──────┘
                       │
        ┌──────────────┼──────────────┐
        │              │              │
┌───────▼────────┐ ┌──▼────┐ ┌──────▼──────┐
│ Architecture   │ │  WER  │ │ Latency     │
│ Evaluator      │ │Predict│ │ Predictor   │
│                │ │       │ │             │
│ - Train ASR/TTS│ │ - Skip│ │ - Hardware  │
│ - Measure WER  │ │   bad │ │   profile   │
│ - Measure RTF  │ │  archs│ │ - RTF est   │
└───────┬────────┘ └───────┘ └──────┬──────┘
        │                           │
        └─────────────┬─────────────┘
                      │
            ┌─────────▼────────┐
            │ Distributed      │
            │ Training         │
            │ - Worker pool    │
            │ - GPU cluster    │
            │ - Multi-task eval│
            └─────────┬────────┘
                      │
            ┌─────────▼────────┐
            │ Results Database │
            │ - Architectures  │
            │ - WER scores     │
            │ - Latency        │
            │ - Pareto front   │
            └──────────────────┘
</code></pre></div></div>

<h3 id="key-components">Key Components</h3>

<ol>
  <li><strong>Search Controller:</strong> Proposes speech architectures</li>
  <li><strong>Speech Search Space:</strong> Defines encoder/decoder/attention options</li>
  <li><strong>Architecture Evaluator:</strong> Trains and measures WER/latency</li>
  <li><strong>Performance Predictors:</strong> Estimate WER and latency without full training</li>
  <li><strong>Distributed Training:</strong> Parallel architecture evaluation</li>
  <li><strong>Results Database:</strong> Track all evaluated architectures</li>
</ol>

<h2 id="component-deep-dives">Component Deep-Dives</h2>

<h3 id="1-speech-specific-search-space">1. Speech-Specific Search Space</h3>

<p>Define search space for ASR models:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="kn">from</span> <span class="n">enum</span> <span class="kn">import</span> <span class="n">Enum</span>

<span class="k">class</span> <span class="nc">EncoderType</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Encoder architecture options.</span><span class="sh">"""</span>
    <span class="n">CONFORMER</span> <span class="o">=</span> <span class="sh">"</span><span class="s">conformer</span><span class="sh">"</span>
    <span class="n">TRANSFORMER</span> <span class="o">=</span> <span class="sh">"</span><span class="s">transformer</span><span class="sh">"</span>
    <span class="n">LSTM</span> <span class="o">=</span> <span class="sh">"</span><span class="s">lstm</span><span class="sh">"</span>
    <span class="n">BLSTM</span> <span class="o">=</span> <span class="sh">"</span><span class="s">blstm</span><span class="sh">"</span>
    <span class="n">CNN_LSTM</span> <span class="o">=</span> <span class="sh">"</span><span class="s">cnn_lstm</span><span class="sh">"</span>
    <span class="n">CONTEXTNET</span> <span class="o">=</span> <span class="sh">"</span><span class="s">contextnet</span><span class="sh">"</span>

<span class="k">class</span> <span class="nc">DecoderType</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Decoder architecture options.</span><span class="sh">"""</span>
    <span class="n">CTC</span> <span class="o">=</span> <span class="sh">"</span><span class="s">ctc</span><span class="sh">"</span>
    <span class="n">RNN_T</span> <span class="o">=</span> <span class="sh">"</span><span class="s">rnn_t</span><span class="sh">"</span>
    <span class="n">ATTENTION</span> <span class="o">=</span> <span class="sh">"</span><span class="s">attention</span><span class="sh">"</span>
    <span class="n">TRANSFORMER_DECODER</span> <span class="o">=</span> <span class="sh">"</span><span class="s">transformer_decoder</span><span class="sh">"</span>

<span class="k">class</span> <span class="nc">AttentionType</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Attention mechanism options.</span><span class="sh">"""</span>
    <span class="n">MULTI_HEAD</span> <span class="o">=</span> <span class="sh">"</span><span class="s">multi_head</span><span class="sh">"</span>
    <span class="n">RELATIVE</span> <span class="o">=</span> <span class="sh">"</span><span class="s">relative</span><span class="sh">"</span>
    <span class="n">LOCAL</span> <span class="o">=</span> <span class="sh">"</span><span class="s">local</span><span class="sh">"</span>
    <span class="n">EFFICIENT</span> <span class="o">=</span> <span class="sh">"</span><span class="s">efficient_attention</span><span class="sh">"</span>

<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">SpeechArchConfig</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Speech model architecture configuration.
    
    Similar to choosing path in Unique Paths:
    - Each choice (encoder, decoder, etc.) is like a move
    - Combination forms complete architecture (path)
    </span><span class="sh">"""</span>
    <span class="c1"># Encoder config
</span>    <span class="n">encoder_type</span><span class="p">:</span> <span class="n">EncoderType</span>
    <span class="n">encoder_layers</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">encoder_dim</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">encoder_heads</span><span class="p">:</span> <span class="nb">int</span>  <span class="c1"># For attention-based encoders
</span>    
    <span class="c1"># Decoder config
</span>    <span class="n">decoder_type</span><span class="p">:</span> <span class="n">DecoderType</span>
    <span class="n">decoder_layers</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">decoder_dim</span><span class="p">:</span> <span class="nb">int</span>
    
    <span class="c1"># Attention config
</span>    <span class="n">attention_type</span><span class="p">:</span> <span class="n">AttentionType</span>
    <span class="n">attention_dim</span><span class="p">:</span> <span class="nb">int</span>
    
    <span class="c1"># Feature extraction
</span>    <span class="n">n_mels</span><span class="p">:</span> <span class="nb">int</span>
    
    <span class="k">def</span> <span class="nf">count_parameters</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Estimate parameter count.</span><span class="sh">"""</span>
        <span class="c1"># Simplified estimation
</span>        <span class="n">encoder_params</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">encoder_layers</span> <span class="o">*</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">encoder_dim</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">4</span>
        <span class="n">decoder_params</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">decoder_layers</span> <span class="o">*</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">decoder_dim</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">4</span>
        <span class="k">return</span> <span class="n">encoder_params</span> <span class="o">+</span> <span class="n">decoder_params</span>
    
    <span class="k">def</span> <span class="nf">estimate_flops</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Estimate FLOPs for sequence of given length.</span><span class="sh">"""</span>
        <span class="c1"># Encoder (attention is O(L^2 * D))
</span>        <span class="n">encoder_flops</span> <span class="o">=</span> <span class="n">sequence_length</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">encoder_dim</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">encoder_layers</span>
        
        <span class="c1"># Decoder
</span>        <span class="n">decoder_flops</span> <span class="o">=</span> <span class="n">sequence_length</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">decoder_dim</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">decoder_layers</span>
        
        <span class="k">return</span> <span class="n">encoder_flops</span> <span class="o">+</span> <span class="n">decoder_flops</span>


<span class="k">class</span> <span class="nc">SpeechSearchSpace</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Search space for speech architectures.
    
    Similar to grid in Unique Paths:
    - Dimensions: encoder × decoder × attention × features
    - Each dimension has multiple choices
    - Total space is exponential
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="c1"># Define choices
</span>        <span class="n">self</span><span class="p">.</span><span class="n">encoder_types</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">EncoderType</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">decoder_types</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">DecoderType</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">encoder_layer_options</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">12</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">encoder_dim_options</span> <span class="o">=</span> <span class="p">[</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">768</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">decoder_layer_options</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
        
    <span class="k">def</span> <span class="nf">count_total_architectures</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Count total architectures (like counting paths).
        </span><span class="sh">"""</span>
        <span class="n">count</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">encoder_types</span><span class="p">)</span> <span class="o">*</span>
            <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">encoder_layer_options</span><span class="p">)</span> <span class="o">*</span>
            <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">encoder_dim_options</span><span class="p">)</span> <span class="o">*</span>
            <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">decoder_types</span><span class="p">)</span> <span class="o">*</span>
            <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">decoder_layer_options</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">count</span>
    
    <span class="k">def</span> <span class="nf">sample_random_architecture</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SpeechArchConfig</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Sample random architecture from space.</span><span class="sh">"""</span>
        <span class="kn">import</span> <span class="n">random</span>
        
        <span class="k">return</span> <span class="nc">SpeechArchConfig</span><span class="p">(</span>
            <span class="n">encoder_type</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">encoder_types</span><span class="p">),</span>
            <span class="n">encoder_layers</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">encoder_layer_options</span><span class="p">),</span>
            <span class="n">encoder_dim</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">encoder_dim_options</span><span class="p">),</span>
            <span class="n">encoder_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>  <span class="c1"># Fixed for simplicity
</span>            <span class="n">decoder_type</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">decoder_types</span><span class="p">),</span>
            <span class="n">decoder_layers</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">decoder_layer_options</span><span class="p">),</span>
            <span class="n">decoder_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>  <span class="c1"># Fixed
</span>            <span class="n">attention_type</span><span class="o">=</span><span class="n">AttentionType</span><span class="p">.</span><span class="n">MULTI_HEAD</span><span class="p">,</span>
            <span class="n">attention_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
            <span class="n">n_mels</span><span class="o">=</span><span class="mi">80</span>
        <span class="p">)</span>
</code></pre></div></div>

<h3 id="2-architecture-evaluation">2. Architecture Evaluation</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="k">def</span> <span class="nf">build_speech_model</span><span class="p">(</span><span class="n">config</span><span class="p">:</span> <span class="n">SpeechArchConfig</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Build speech model from configuration.
    
    Args:
        config: Architecture configuration
        
    Returns:
        PyTorch model
    </span><span class="sh">"""</span>
    <span class="c1"># This would integrate with ESPnet or custom implementation
</span>    <span class="c1"># Simplified example:
</span>    
    <span class="k">if</span> <span class="n">config</span><span class="p">.</span><span class="n">encoder_type</span> <span class="o">==</span> <span class="n">EncoderType</span><span class="p">.</span><span class="n">CONFORMER</span><span class="p">:</span>
        <span class="kn">from</span> <span class="n">espnet.nets.pytorch_backend.conformer.encoder</span> <span class="kn">import</span> <span class="n">Encoder</span>
        <span class="n">encoder</span> <span class="o">=</span> <span class="nc">Encoder</span><span class="p">(</span>
            <span class="n">idim</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">n_mels</span><span class="p">,</span>
            <span class="n">attention_dim</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">encoder_dim</span><span class="p">,</span>
            <span class="n">attention_heads</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">encoder_heads</span><span class="p">,</span>
            <span class="n">linear_units</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">encoder_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span>
            <span class="n">num_blocks</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">encoder_layers</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">config</span><span class="p">.</span><span class="n">encoder_type</span> <span class="o">==</span> <span class="n">EncoderType</span><span class="p">.</span><span class="n">TRANSFORMER</span><span class="p">:</span>
        <span class="kn">from</span> <span class="n">espnet.nets.pytorch_backend.transformer.encoder</span> <span class="kn">import</span> <span class="n">Encoder</span>
        <span class="n">encoder</span> <span class="o">=</span> <span class="nc">Encoder</span><span class="p">(</span>
            <span class="n">idim</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">n_mels</span><span class="p">,</span>
            <span class="n">attention_dim</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">encoder_dim</span><span class="p">,</span>
            <span class="n">attention_heads</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">encoder_heads</span><span class="p">,</span>
            <span class="n">linear_units</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">encoder_dim</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span>
            <span class="n">num_blocks</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">encoder_layers</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># LSTM, CNN-LSTM, etc.
</span>        <span class="n">encoder</span> <span class="o">=</span> <span class="nf">create_encoder</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    
    <span class="c1"># Build decoder
</span>    <span class="k">if</span> <span class="n">config</span><span class="p">.</span><span class="n">decoder_type</span> <span class="o">==</span> <span class="n">DecoderType</span><span class="p">.</span><span class="n">CTC</span><span class="p">:</span>
        <span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">encoder_dim</span><span class="p">,</span> <span class="n">num_tokens</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">config</span><span class="p">.</span><span class="n">decoder_type</span> <span class="o">==</span> <span class="n">DecoderType</span><span class="p">.</span><span class="n">RNN_T</span><span class="p">:</span>
        <span class="n">decoder</span> <span class="o">=</span> <span class="nf">create_rnnt_decoder</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">decoder</span> <span class="o">=</span> <span class="nf">create_attention_decoder</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    
    <span class="c1"># Combine into full model
</span>    <span class="n">model</span> <span class="o">=</span> <span class="nc">SpeechModel</span><span class="p">(</span><span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="o">=</span><span class="n">decoder</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">model</span>


<span class="k">def</span> <span class="nf">evaluate_speech_architecture</span><span class="p">(</span>
    <span class="n">config</span><span class="p">:</span> <span class="n">SpeechArchConfig</span><span class="p">,</span>
    <span class="n">train_subset</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">"</span><span class="s">librispeech-100h</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">val_subset</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">"</span><span class="s">librispeech-dev</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">max_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Evaluate speech architecture.
    
    Args:
        config: Architecture to evaluate
        train_subset: Training data subset
        val_subset: Validation data
        max_epochs: Max training epochs
        
    Returns:
        Dictionary with WER, latency, params, etc.
    </span><span class="sh">"""</span>
    <span class="c1"># Build model
</span>    <span class="n">model</span> <span class="o">=</span> <span class="nf">build_speech_model</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    
    <span class="c1"># Count parameters
</span>    <span class="n">num_params</span> <span class="o">=</span> <span class="nf">sum</span><span class="p">(</span><span class="n">p</span><span class="p">.</span><span class="nf">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">())</span>
    
    <span class="c1"># Train
</span>    <span class="n">best_wer</span> <span class="o">=</span> <span class="nf">train_and_evaluate</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">train_data</span><span class="o">=</span><span class="n">train_subset</span><span class="p">,</span>
        <span class="n">val_data</span><span class="o">=</span><span class="n">val_subset</span><span class="p">,</span>
        <span class="n">max_epochs</span><span class="o">=</span><span class="n">max_epochs</span>
    <span class="p">)</span>
    
    <span class="c1"># Measure latency
</span>    <span class="n">latency_ms</span> <span class="o">=</span> <span class="nf">measure_inference_latency</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    
    <span class="c1"># Measure RTF (real-time factor)
</span>    <span class="n">rtf</span> <span class="o">=</span> <span class="nf">measure_rtf</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="p">{</span>
        <span class="sh">"</span><span class="s">config</span><span class="sh">"</span><span class="p">:</span> <span class="n">config</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">wer</span><span class="sh">"</span><span class="p">:</span> <span class="n">best_wer</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">latency_ms</span><span class="sh">"</span><span class="p">:</span> <span class="n">latency_ms</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">rtf</span><span class="sh">"</span><span class="p">:</span> <span class="n">rtf</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">params</span><span class="sh">"</span><span class="p">:</span> <span class="n">num_params</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">flops</span><span class="sh">"</span><span class="p">:</span> <span class="n">config</span><span class="p">.</span><span class="nf">estimate_flops</span><span class="p">()</span>
    <span class="p">}</span>
</code></pre></div></div>

<h3 id="3-search-strategy-for-speech">3. Search Strategy for Speech</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SpeechNASController</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    NAS controller for speech architectures.
    
    Uses DP-like building:
    - Build encoder → choose decoder → optimize jointly
    - Like building path: choose direction at each step
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">search_space</span><span class="p">:</span> <span class="n">SpeechSearchSpace</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">search_space</span> <span class="o">=</span> <span class="n">search_space</span>
        <span class="n">self</span><span class="p">.</span><span class="n">evaluated_archs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">self</span><span class="p">.</span><span class="n">best_archs</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">def</span> <span class="nf">search_with_evolutionary</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">population_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">generations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Evolutionary search for speech architectures.
        
        Similar to exploring paths in Unique Paths:
        - Generate population (multiple paths)
        - Evaluate fitness (WER)
        - Mutate and crossover (create new paths)
        - Select best (optimal paths)
        </span><span class="sh">"""</span>
        <span class="c1"># Initialize population
</span>        <span class="n">population</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">self</span><span class="p">.</span><span class="n">search_space</span><span class="p">.</span><span class="nf">sample_random_architecture</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">population_size</span><span class="p">)</span>
        <span class="p">]</span>
        
        <span class="k">for</span> <span class="n">generation</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">generations</span><span class="p">):</span>
            <span class="c1"># Evaluate all architectures
</span>            <span class="n">fitness_scores</span> <span class="o">=</span> <span class="p">[]</span>
            
            <span class="k">for</span> <span class="n">arch</span> <span class="ow">in</span> <span class="n">population</span><span class="p">:</span>
                <span class="k">if</span> <span class="nf">encode_architecture</span><span class="p">(</span><span class="n">arch</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">evaluated_archs</span><span class="p">:</span>
                    <span class="n">result</span> <span class="o">=</span> <span class="nf">evaluate_speech_architecture</span><span class="p">(</span><span class="n">arch</span><span class="p">)</span>
                    <span class="n">self</span><span class="p">.</span><span class="n">evaluated_archs</span><span class="p">[</span><span class="nf">encode_architecture</span><span class="p">(</span><span class="n">arch</span><span class="p">)]</span> <span class="o">=</span> <span class="n">result</span>
                    <span class="n">fitness</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="sh">'</span><span class="s">wer</span><span class="sh">'</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.01</span><span class="p">)</span>  <span class="c1"># Lower WER = higher fitness
</span>                <span class="k">else</span><span class="p">:</span>
                    <span class="n">result</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">evaluated_archs</span><span class="p">[</span><span class="nf">encode_architecture</span><span class="p">(</span><span class="n">arch</span><span class="p">)]</span>
                    <span class="n">fitness</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="sh">'</span><span class="s">wer</span><span class="sh">'</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.01</span><span class="p">)</span>
                
                <span class="n">fitness_scores</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">arch</span><span class="p">,</span> <span class="n">fitness</span><span class="p">,</span> <span class="n">result</span><span class="p">))</span>
            
            <span class="c1"># Sort by fitness
</span>            <span class="n">fitness_scores</span><span class="p">.</span><span class="nf">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            
            <span class="c1"># Track best
</span>            <span class="n">self</span><span class="p">.</span><span class="n">best_archs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">fitness_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            
            <span class="c1"># Selection: keep top 50%
</span>            <span class="n">survivors</span> <span class="o">=</span> <span class="p">[</span><span class="n">arch</span> <span class="k">for</span> <span class="n">arch</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">fitness_scores</span><span class="p">[:</span><span class="n">population_size</span> <span class="o">//</span> <span class="mi">2</span><span class="p">]]</span>
            
            <span class="c1"># Mutation and crossover to create next generation
</span>            <span class="n">offspring</span> <span class="o">=</span> <span class="p">[]</span>
            
            <span class="k">while</span> <span class="nf">len</span><span class="p">(</span><span class="n">offspring</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">population_size</span> <span class="o">//</span> <span class="mi">2</span><span class="p">:</span>
                <span class="c1"># Select parents
</span>                <span class="n">parent1</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">survivors</span><span class="p">)</span>
                <span class="n">parent2</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">survivors</span><span class="p">)</span>
                
                <span class="c1"># Crossover
</span>                <span class="n">child</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_crossover</span><span class="p">(</span><span class="n">parent1</span><span class="p">,</span> <span class="n">parent2</span><span class="p">)</span>
                
                <span class="c1"># Mutation
</span>                <span class="k">if</span> <span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.3</span><span class="p">:</span>
                    <span class="n">child</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_mutate</span><span class="p">(</span><span class="n">child</span><span class="p">)</span>
                
                <span class="n">offspring</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">child</span><span class="p">)</span>
            
            <span class="c1"># New population
</span>            <span class="n">population</span> <span class="o">=</span> <span class="n">survivors</span> <span class="o">+</span> <span class="n">offspring</span>
        
        <span class="c1"># Return best architecture found
</span>        <span class="n">best</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">best_archs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">best</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">best</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    
    <span class="k">def</span> <span class="nf">_crossover</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">arch1</span><span class="p">:</span> <span class="n">SpeechArchConfig</span><span class="p">,</span> <span class="n">arch2</span><span class="p">:</span> <span class="n">SpeechArchConfig</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SpeechArchConfig</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Crossover two architectures.
        
        Randomly inherit components from parents.
        </span><span class="sh">"""</span>
        <span class="k">return</span> <span class="nc">SpeechArchConfig</span><span class="p">(</span>
            <span class="n">encoder_type</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">([</span><span class="n">arch1</span><span class="p">.</span><span class="n">encoder_type</span><span class="p">,</span> <span class="n">arch2</span><span class="p">.</span><span class="n">encoder_type</span><span class="p">]),</span>
            <span class="n">encoder_layers</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">([</span><span class="n">arch1</span><span class="p">.</span><span class="n">encoder_layers</span><span class="p">,</span> <span class="n">arch2</span><span class="p">.</span><span class="n">encoder_layers</span><span class="p">]),</span>
            <span class="n">encoder_dim</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">([</span><span class="n">arch1</span><span class="p">.</span><span class="n">encoder_dim</span><span class="p">,</span> <span class="n">arch2</span><span class="p">.</span><span class="n">encoder_dim</span><span class="p">]),</span>
            <span class="n">encoder_heads</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">([</span><span class="n">arch1</span><span class="p">.</span><span class="n">encoder_heads</span><span class="p">,</span> <span class="n">arch2</span><span class="p">.</span><span class="n">encoder_heads</span><span class="p">]),</span>
            <span class="n">decoder_type</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">([</span><span class="n">arch1</span><span class="p">.</span><span class="n">decoder_type</span><span class="p">,</span> <span class="n">arch2</span><span class="p">.</span><span class="n">decoder_type</span><span class="p">]),</span>
            <span class="n">decoder_layers</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">([</span><span class="n">arch1</span><span class="p">.</span><span class="n">decoder_layers</span><span class="p">,</span> <span class="n">arch2</span><span class="p">.</span><span class="n">decoder_layers</span><span class="p">]),</span>
            <span class="n">decoder_dim</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">([</span><span class="n">arch1</span><span class="p">.</span><span class="n">decoder_dim</span><span class="p">,</span> <span class="n">arch2</span><span class="p">.</span><span class="n">decoder_dim</span><span class="p">]),</span>
            <span class="n">attention_type</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">([</span><span class="n">arch1</span><span class="p">.</span><span class="n">attention_type</span><span class="p">,</span> <span class="n">arch2</span><span class="p">.</span><span class="n">attention_type</span><span class="p">]),</span>
            <span class="n">attention_dim</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">([</span><span class="n">arch1</span><span class="p">.</span><span class="n">attention_dim</span><span class="p">,</span> <span class="n">arch2</span><span class="p">.</span><span class="n">attention_dim</span><span class="p">]),</span>
            <span class="n">n_mels</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">([</span><span class="n">arch1</span><span class="p">.</span><span class="n">n_mels</span><span class="p">,</span> <span class="n">arch2</span><span class="p">.</span><span class="n">n_mels</span><span class="p">])</span>
        <span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_mutate</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">arch</span><span class="p">:</span> <span class="n">SpeechArchConfig</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SpeechArchConfig</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Mutate architecture.
        
        Randomly change one component.
        </span><span class="sh">"""</span>
        <span class="n">mutation_choice</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        
        <span class="n">new_arch</span> <span class="o">=</span> <span class="nc">SpeechArchConfig</span><span class="p">(</span><span class="o">**</span><span class="n">arch</span><span class="p">.</span><span class="n">__dict__</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">mutation_choice</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Mutate encoder
</span>            <span class="n">new_arch</span><span class="p">.</span><span class="n">encoder_layers</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">search_space</span><span class="p">.</span><span class="n">encoder_layer_options</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mutation_choice</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Mutate encoder dim
</span>            <span class="n">new_arch</span><span class="p">.</span><span class="n">encoder_dim</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">search_space</span><span class="p">.</span><span class="n">encoder_dim_options</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mutation_choice</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="c1"># Mutate decoder
</span>            <span class="n">new_arch</span><span class="p">.</span><span class="n">decoder_layers</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">search_space</span><span class="p">.</span><span class="n">decoder_layer_options</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Mutate encoder type
</span>            <span class="n">new_arch</span><span class="p">.</span><span class="n">encoder_type</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">search_space</span><span class="p">.</span><span class="n">encoder_types</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">new_arch</span>
</code></pre></div></div>

<h3 id="4-multi-objective-optimization">4. Multi-Objective Optimization</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MultiObjectiveSpeechNAS</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Multi-objective NAS for speech.
    
    Optimize for:
    - WER (minimize)
    - Latency (minimize)
    - Model size (minimize)
    
    Find Pareto frontier of optimal trade-offs.
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">search_space</span><span class="p">:</span> <span class="n">SpeechSearchSpace</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">search_space</span> <span class="o">=</span> <span class="n">search_space</span>
        <span class="n">self</span><span class="p">.</span><span class="n">pareto_front</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">def</span> <span class="nf">search</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">num_candidates</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Search for Pareto-optimal architectures.</span><span class="sh">"""</span>
        <span class="n">evaluated</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_candidates</span><span class="p">):</span>
            <span class="c1"># Sample architecture
</span>            <span class="n">arch</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">search_space</span><span class="p">.</span><span class="nf">sample_random_architecture</span><span class="p">()</span>
            
            <span class="c1"># Evaluate
</span>            <span class="n">result</span> <span class="o">=</span> <span class="nf">evaluate_speech_architecture</span><span class="p">(</span><span class="n">arch</span><span class="p">)</span>
            
            <span class="n">evaluated</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span>
                <span class="sh">"</span><span class="s">arch</span><span class="sh">"</span><span class="p">:</span> <span class="n">arch</span><span class="p">,</span>
                <span class="sh">"</span><span class="s">wer</span><span class="sh">"</span><span class="p">:</span> <span class="n">result</span><span class="p">[</span><span class="sh">'</span><span class="s">wer</span><span class="sh">'</span><span class="p">],</span>
                <span class="sh">"</span><span class="s">latency</span><span class="sh">"</span><span class="p">:</span> <span class="n">result</span><span class="p">[</span><span class="sh">'</span><span class="s">latency_ms</span><span class="sh">'</span><span class="p">],</span>
                <span class="sh">"</span><span class="s">params</span><span class="sh">"</span><span class="p">:</span> <span class="n">result</span><span class="p">[</span><span class="sh">'</span><span class="s">params</span><span class="sh">'</span><span class="p">]</span>
            <span class="p">})</span>
        
        <span class="c1"># Find Pareto frontier
</span>        <span class="n">self</span><span class="p">.</span><span class="n">pareto_front</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_compute_pareto_front</span><span class="p">(</span><span class="n">evaluated</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">pareto_front</span>
    
    <span class="k">def</span> <span class="nf">_compute_pareto_front</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">candidates</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">
        Compute Pareto frontier.
        
        An architecture is Pareto-optimal if no other architecture
        is better in all objectives.
        </span><span class="sh">"""</span>
        <span class="n">pareto</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">cand1</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">candidates</span><span class="p">):</span>
            <span class="n">is_dominated</span> <span class="o">=</span> <span class="bp">False</span>
            
            <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">cand2</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">candidates</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">j</span><span class="p">:</span>
                    <span class="k">continue</span>
                
                <span class="c1"># Check if cand2 dominates cand1
</span>                <span class="c1"># (better or equal in all objectives, strictly better in at least one)
</span>                <span class="nf">if </span><span class="p">(</span><span class="n">cand2</span><span class="p">[</span><span class="sh">'</span><span class="s">wer</span><span class="sh">'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">cand1</span><span class="p">[</span><span class="sh">'</span><span class="s">wer</span><span class="sh">'</span><span class="p">]</span> <span class="ow">and</span>
                    <span class="n">cand2</span><span class="p">[</span><span class="sh">'</span><span class="s">latency</span><span class="sh">'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">cand1</span><span class="p">[</span><span class="sh">'</span><span class="s">latency</span><span class="sh">'</span><span class="p">]</span> <span class="ow">and</span>
                    <span class="n">cand2</span><span class="p">[</span><span class="sh">'</span><span class="s">params</span><span class="sh">'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">cand1</span><span class="p">[</span><span class="sh">'</span><span class="s">params</span><span class="sh">'</span><span class="p">]</span> <span class="ow">and</span>
                    <span class="p">(</span><span class="n">cand2</span><span class="p">[</span><span class="sh">'</span><span class="s">wer</span><span class="sh">'</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">cand1</span><span class="p">[</span><span class="sh">'</span><span class="s">wer</span><span class="sh">'</span><span class="p">]</span> <span class="ow">or</span>
                     <span class="n">cand2</span><span class="p">[</span><span class="sh">'</span><span class="s">latency</span><span class="sh">'</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">cand1</span><span class="p">[</span><span class="sh">'</span><span class="s">latency</span><span class="sh">'</span><span class="p">]</span> <span class="ow">or</span>
                     <span class="n">cand2</span><span class="p">[</span><span class="sh">'</span><span class="s">params</span><span class="sh">'</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">cand1</span><span class="p">[</span><span class="sh">'</span><span class="s">params</span><span class="sh">'</span><span class="p">])):</span>
                    <span class="n">is_dominated</span> <span class="o">=</span> <span class="bp">True</span>
                    <span class="k">break</span>
            
            <span class="k">if</span> <span class="ow">not</span> <span class="n">is_dominated</span><span class="p">:</span>
                <span class="n">pareto</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">cand1</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">pareto</span>
    
    <span class="k">def</span> <span class="nf">select_for_target</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">max_latency_ms</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">max_params</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">
        Select best architecture meeting constraints.
        
        Args:
            max_latency_ms: Maximum acceptable latency
            max_params: Maximum model size
            
        Returns:
            Best architecture meeting constraints, or None
        </span><span class="sh">"""</span>
        <span class="n">candidates</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">arch</span> <span class="k">for</span> <span class="n">arch</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">pareto_front</span>
            <span class="k">if</span> <span class="n">arch</span><span class="p">[</span><span class="sh">'</span><span class="s">latency</span><span class="sh">'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">max_latency_ms</span> <span class="ow">and</span> <span class="n">arch</span><span class="p">[</span><span class="sh">'</span><span class="s">params</span><span class="sh">'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">max_params</span>
        <span class="p">]</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="n">candidates</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">None</span>
        
        <span class="c1"># Return lowest WER among candidates
</span>        <span class="k">return</span> <span class="nf">min</span><span class="p">(</span><span class="n">candidates</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="sh">'</span><span class="s">wer</span><span class="sh">'</span><span class="p">])</span>
</code></pre></div></div>

<h2 id="scaling-strategies">Scaling Strategies</h2>

<h3 id="efficient-evaluation">Efficient Evaluation</h3>

<p><strong>1. Progressive training:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">progressive_evaluation</span><span class="p">(</span><span class="n">arch</span><span class="p">:</span> <span class="n">SpeechArchConfig</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Evaluate architecture progressively.
    
    Start with small dataset/short training.
    Only continue if promising.
    </span><span class="sh">"""</span>
    <span class="c1"># Stage 1: Train on LibriSpeech-100h for 5 epochs
</span>    <span class="n">wer_stage1</span> <span class="o">=</span> <span class="nf">quick_train</span><span class="p">(</span><span class="n">arch</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="sh">"</span><span class="s">librispeech-100h</span><span class="sh">"</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">wer_stage1</span> <span class="o">&gt;</span> <span class="mf">0.20</span><span class="p">:</span>  <span class="c1"># 20% WER threshold
</span>        <span class="k">return</span> <span class="p">{</span><span class="sh">"</span><span class="s">wer</span><span class="sh">"</span><span class="p">:</span> <span class="n">wer_stage1</span><span class="p">,</span> <span class="sh">"</span><span class="s">early_stopped</span><span class="sh">"</span><span class="p">:</span> <span class="bp">True</span><span class="p">}</span>
    
    <span class="c1"># Stage 2: Train on LibriSpeech-100h for 20 epochs
</span>    <span class="n">wer_stage2</span> <span class="o">=</span> <span class="nf">quick_train</span><span class="p">(</span><span class="n">arch</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="sh">"</span><span class="s">librispeech-100h</span><span class="sh">"</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">wer_stage2</span> <span class="o">&gt;</span> <span class="mf">0.10</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span><span class="sh">"</span><span class="s">wer</span><span class="sh">"</span><span class="p">:</span> <span class="n">wer_stage2</span><span class="p">,</span> <span class="sh">"</span><span class="s">early_stopped</span><span class="sh">"</span><span class="p">:</span> <span class="bp">True</span><span class="p">}</span>
    
    <span class="c1"># Stage 3: Full training on LibriSpeech-960h
</span>    <span class="n">wer_final</span> <span class="o">=</span> <span class="nf">full_train</span><span class="p">(</span><span class="n">arch</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="sh">"</span><span class="s">librispeech-960h</span><span class="sh">"</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="p">{</span><span class="sh">"</span><span class="s">wer</span><span class="sh">"</span><span class="p">:</span> <span class="n">wer_final</span><span class="p">,</span> <span class="sh">"</span><span class="s">early_stopped</span><span class="sh">"</span><span class="p">:</span> <span class="bp">False</span><span class="p">}</span>
</code></pre></div></div>

<p><strong>2. Weight sharing (supernet for speech):</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SpeechSuperNet</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Super-network for speech NAS.
    
    Contains all possible operations.
    Different architectures share weights.
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">search_space</span><span class="p">:</span> <span class="n">SpeechSearchSpace</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="c1"># Create all encoder options
</span>        <span class="n">self</span><span class="p">.</span><span class="n">encoders</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ModuleDict</span><span class="p">({</span>
            <span class="n">enc_type</span><span class="p">.</span><span class="n">value</span><span class="p">:</span> <span class="nf">create_encoder</span><span class="p">(</span><span class="n">enc_type</span><span class="p">,</span> <span class="n">max_layers</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">max_dim</span><span class="o">=</span><span class="mi">768</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">enc_type</span> <span class="ow">in</span> <span class="n">EncoderType</span>
        <span class="p">})</span>
        
        <span class="c1"># Create all decoder options
</span>        <span class="n">self</span><span class="p">.</span><span class="n">decoders</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ModuleDict</span><span class="p">({</span>
            <span class="n">dec_type</span><span class="p">.</span><span class="n">value</span><span class="p">:</span> <span class="nf">create_decoder</span><span class="p">(</span><span class="n">dec_type</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">dec_type</span> <span class="ow">in</span> <span class="n">DecoderType</span>
        <span class="p">})</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio_features</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">arch</span><span class="p">:</span> <span class="n">SpeechArchConfig</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Forward with specific architecture.</span><span class="sh">"""</span>
        <span class="c1"># Select encoder
</span>        <span class="n">encoder</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">encoders</span><span class="p">[</span><span class="n">arch</span><span class="p">.</span><span class="n">encoder_type</span><span class="p">.</span><span class="n">value</span><span class="p">]</span>
        
        <span class="c1"># Select decoder
</span>        <span class="n">decoder</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">decoders</span><span class="p">[</span><span class="n">arch</span><span class="p">.</span><span class="n">decoder_type</span><span class="p">.</span><span class="n">value</span><span class="p">]</span>
        
        <span class="c1"># Forward pass
</span>        <span class="n">encoder_out</span> <span class="o">=</span> <span class="nf">encoder</span><span class="p">(</span><span class="n">audio_features</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="nf">decoder</span><span class="p">(</span><span class="n">encoder_out</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">output</span>
</code></pre></div></div>

<h2 id="real-world-case-study-googles-speech-nas">Real-World Case Study: Google’s Speech NAS</h2>

<h3 id="googles-approach-for-mobile-asr">Google’s Approach for Mobile ASR</h3>

<p><strong>Goal:</strong> Find ASR architecture for on-device deployment with &lt;100ms latency.</p>

<p><strong>Search space:</strong></p>
<ul>
  <li>Encoder: RNN, LSTM, GRU, Conformer variants</li>
  <li>Layers: 2-8</li>
  <li>Hidden dim: 128-512</li>
  <li>Decoder: CTC, RNN-T</li>
</ul>

<p><strong>Search strategy:</strong></p>
<ul>
  <li>Reinforcement learning controller</li>
  <li>Multi-objective: WER + latency + model size</li>
  <li>Progressive training (100h → 960h dataset)</li>
</ul>

<p><strong>Results:</strong></p>
<ul>
  <li><strong>Discovered architecture:</strong> 4-layer Conformer + RNN-T</li>
  <li><strong>WER:</strong> 5.2% on LibriSpeech test-clean (vs 6.1% baseline)</li>
  <li><strong>Latency:</strong> 85ms on Pixel 6 (vs 120ms baseline)</li>
  <li><strong>Size:</strong> 45M params (vs 80M baseline LSTM)</li>
  <li><strong>Search cost:</strong> 80 GPU days (vs months of manual tuning)</li>
</ul>

<p><strong>Key insights:</strong></p>
<ul>
  <li>Conformer with fewer layers beats deep LSTM</li>
  <li>RNN-T decoder better latency than attention for streaming</li>
  <li>Smaller models with better architecture beat larger hand-designed ones</li>
</ul>

<h3 id="lessons-learned">Lessons Learned</h3>

<ol>
  <li><strong>Speech-specific constraints matter:</strong> Streaming, variable length, long sequences</li>
  <li><strong>Multi-objective is essential:</strong> Can’t just optimize WER</li>
  <li><strong>Progressive evaluation saves compute:</strong> 80% of candidates filtered early</li>
  <li><strong>Transfer works:</strong> ImageNet NAS insights transfer to speech (depth vs width)</li>
  <li><strong>Hardware-in-the-loop:</strong> Measure latency on actual target device</li>
</ol>

<h2 id="cost-analysis">Cost Analysis</h2>

<h3 id="nas-vs-manual-design">NAS vs Manual Design</h3>

<table>
  <thead>
    <tr>
      <th>Approach</th>
      <th>Time</th>
      <th>GPU Cost</th>
      <th>Quality (WER)</th>
      <th>Notes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Manual design</td>
      <td>6 months</td>
      <td>50 GPU days</td>
      <td>6.5%</td>
      <td>Expert-dependent</td>
    </tr>
    <tr>
      <td>Random search</td>
      <td>N/A</td>
      <td>500 GPU days</td>
      <td>7.0%</td>
      <td>Baseline</td>
    </tr>
    <tr>
      <td>Evolutionary NAS</td>
      <td>2 months</td>
      <td>100 GPU days</td>
      <td>5.8%</td>
      <td>Robust</td>
    </tr>
    <tr>
      <td>RL-based NAS</td>
      <td>1 month</td>
      <td>80 GPU days</td>
      <td>5.2%</td>
      <td>Google’s approach</td>
    </tr>
    <tr>
      <td>DARTS for speech</td>
      <td>2 weeks</td>
      <td>10 GPU days</td>
      <td>6.0%</td>
      <td>Fast but less stable</td>
    </tr>
    <tr>
      <td>Transfer + fine-tune</td>
      <td>1 week</td>
      <td>5 GPU days</td>
      <td>5.5%</td>
      <td>Use vision NAS results</td>
    </tr>
  </tbody>
</table>

<p><strong>ROI:</strong></p>
<ul>
  <li>Manual: $120K (engineer time) + $15K (GPUs) = $135K</li>
  <li>NAS: $40K (engineer time) + $24K (GPUs) = $64K</li>
  <li><strong>Savings:</strong> $71K + better model + faster iteration</li>
</ul>

<h2 id="advanced-topics">Advanced Topics</h2>

<h3 id="1-multi-lingual-nas">1. Multi-Lingual NAS</h3>

<p>Search for architectures that work across languages:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">multi_lingual_nas</span><span class="p">(</span><span class="n">languages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">en</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">zh</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">es</span><span class="sh">"</span><span class="p">]):</span>
    <span class="sh">"""</span><span class="s">
    Search for architecture that works well across languages.
    
    Fitness = average WER across all languages.
    </span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">evaluate_multilingual</span><span class="p">(</span><span class="n">arch</span><span class="p">:</span> <span class="n">SpeechArchConfig</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="n">wers</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">lang</span> <span class="ow">in</span> <span class="n">languages</span><span class="p">:</span>
            <span class="n">wer</span> <span class="o">=</span> <span class="nf">train_and_evaluate</span><span class="p">(</span>
                <span class="n">arch</span><span class="p">,</span>
                <span class="n">train_data</span><span class="o">=</span><span class="sa">f</span><span class="sh">"</span><span class="s">common_voice_</span><span class="si">{</span><span class="n">lang</span><span class="si">}</span><span class="sh">"</span><span class="p">,</span>
                <span class="n">val_data</span><span class="o">=</span><span class="sa">f</span><span class="sh">"</span><span class="s">common_voice_</span><span class="si">{</span><span class="n">lang</span><span class="si">}</span><span class="s">_dev</span><span class="sh">"</span>
            <span class="p">)</span>
            <span class="n">wers</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">wer</span><span class="p">)</span>
        
        <span class="c1"># Average WER across languages
</span>        <span class="k">return</span> <span class="nf">sum</span><span class="p">(</span><span class="n">wers</span><span class="p">)</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">wers</span><span class="p">)</span>
    
    <span class="c1"># Search with multi-lingual fitness
</span>    <span class="c1"># ... (use evolutionary or RL search)
</span></code></pre></div></div>

<h3 id="2-streaming-aware-nas">2. Streaming-Aware NAS</h3>

<p>Optimize for streaming ASR:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">streaming_aware_evaluation</span><span class="p">(</span><span class="n">arch</span><span class="p">:</span> <span class="n">SpeechArchConfig</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Evaluate architecture for streaming capability.
    
    Metrics:
    - Per-chunk latency (not full utterance)
    - Look-ahead requirement
    - Chunk size vs WER trade-off
    </span><span class="sh">"""</span>
    <span class="n">model</span> <span class="o">=</span> <span class="nf">build_speech_model</span><span class="p">(</span><span class="n">arch</span><span class="p">)</span>
    
    <span class="c1"># Test streaming performance
</span>    <span class="n">chunk_size_ms</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># 100ms chunks
</span>    
    <span class="n">chunk_latency</span> <span class="o">=</span> <span class="nf">measure_chunk_latency</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">chunk_size_ms</span><span class="p">)</span>
    <span class="n">streaming_wer</span> <span class="o">=</span> <span class="nf">evaluate_streaming_wer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">chunk_size_ms</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="p">{</span>
        <span class="sh">"</span><span class="s">chunk_latency_ms</span><span class="sh">"</span><span class="p">:</span> <span class="n">chunk_latency</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">streaming_wer</span><span class="sh">"</span><span class="p">:</span> <span class="n">streaming_wer</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">supports_streaming</span><span class="sh">"</span><span class="p">:</span> <span class="n">chunk_latency</span> <span class="o">&lt;</span> <span class="n">chunk_size_ms</span>
    <span class="p">}</span>
</code></pre></div></div>

<h3 id="3-transfer-from-vision-nas">3. Transfer from Vision NAS</h3>

<p>Leverage insights from ImageNet NAS:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">transfer_vision_to_speech</span><span class="p">(</span><span class="n">vision_arch_config</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Transfer successful vision architectures to speech.
    
    Example: EfficientNet principles → EfficientConformer
    - Depth scaling
    - Width scaling
    - Compound scaling
    </span><span class="sh">"""</span>
    <span class="c1"># Extract architectural principles
</span>    <span class="n">depth_factor</span> <span class="o">=</span> <span class="n">vision_arch_config</span><span class="p">.</span><span class="n">depth_coefficient</span>
    <span class="n">width_factor</span> <span class="o">=</span> <span class="n">vision_arch_config</span><span class="p">.</span><span class="n">width_coefficient</span>
    
    <span class="c1"># Apply to speech
</span>    <span class="n">speech_config</span> <span class="o">=</span> <span class="nc">SpeechArchConfig</span><span class="p">(</span>
        <span class="n">encoder_type</span><span class="o">=</span><span class="n">EncoderType</span><span class="p">.</span><span class="n">CONFORMER</span><span class="p">,</span>
        <span class="n">encoder_layers</span><span class="o">=</span><span class="nf">int</span><span class="p">(</span><span class="mi">6</span> <span class="o">*</span> <span class="n">depth_factor</span><span class="p">),</span>
        <span class="n">encoder_dim</span><span class="o">=</span><span class="nf">int</span><span class="p">(</span><span class="mi">256</span> <span class="o">*</span> <span class="n">width_factor</span><span class="p">),</span>
        <span class="n">encoder_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">decoder_type</span><span class="o">=</span><span class="n">DecoderType</span><span class="p">.</span><span class="n">RNN_T</span><span class="p">,</span>
        <span class="n">decoder_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">decoder_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
        <span class="n">attention_type</span><span class="o">=</span><span class="n">AttentionType</span><span class="p">.</span><span class="n">RELATIVE</span><span class="p">,</span>
        <span class="n">attention_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
        <span class="n">n_mels</span><span class="o">=</span><span class="mi">80</span>
    <span class="p">)</span>
    
    <span class="k">return</span> <span class="n">speech_config</span>
</code></pre></div></div>

<h2 id="monitoring--debugging">Monitoring &amp; Debugging</h2>

<h3 id="key-metrics">Key Metrics</h3>

<p><strong>Search Progress:</strong></p>
<ul>
  <li>Best WER found so far vs iterations</li>
  <li>Pareto frontier evolution</li>
  <li>Architecture diversity (entropy of designs explored)</li>
  <li>GPU utilization during search</li>
</ul>

<p><strong>Architecture Analysis:</strong></p>
<ul>
  <li>Most common encoder/decoder types in top performers</li>
  <li>Depth vs width trade-offs</li>
  <li>Correlation between architecture features and WER</li>
</ul>

<p><strong>Resource Tracking:</strong></p>
<ul>
  <li>Total GPU hours consumed</li>
  <li>Average training time per architecture</li>
  <li>Early stopping rate (% of archs stopped early)</li>
</ul>

<h3 id="debugging-tools">Debugging Tools</h3>

<ul>
  <li>Visualize architecture graphs</li>
  <li>Compare top-N architectures side-by-side</li>
  <li>Ablation studies (which components matter most?)</li>
  <li>Error analysis (where do discovered archs fail?)</li>
</ul>

<h2 id="key-takeaways">Key Takeaways</h2>

<p>✅ <strong>Speech NAS automates</strong> architecture design for ASR/TTS models</p>

<p>✅ <strong>Search space is exponential</strong> - like paths in a grid, need smart search</p>

<p>✅ <strong>DP and smart search</strong> make NAS practical - from infeasible to 50-100 GPU days</p>

<p>✅ <strong>Multi-objective optimization</strong> essential - WER, latency, size must be balanced</p>

<p>✅ <strong>Progressive evaluation</strong> saves compute - filter bad candidates early</p>

<p>✅ <strong>Weight sharing</strong> (supernet) enables evaluating 1000s of architectures</p>

<p>✅ <strong>Speech-specific constraints</strong> - streaming, variable length, multi-lingual</p>

<p>✅ <strong>Transfer from vision</strong> accelerates speech NAS</p>

<p>✅ <strong>Hardware-aware search</strong> critical for deployment</p>

<p>✅ <strong>Same DP pattern</strong> as Unique Paths - build optimal solution from sub-solutions</p>

<h3 id="connection-to-thematic-link-dynamic-programming-and-path-optimization">Connection to Thematic Link: Dynamic Programming and Path Optimization</h3>

<p>All three Day 21 topics use <strong>DP to optimize paths through exponential spaces</strong>:</p>

<p><strong>DSA (Unique Paths):</strong></p>
<ul>
  <li>Navigate m×n grid using DP</li>
  <li>Recurrence: paths(i,j) = paths(i-1,j) + paths(i,j-1)</li>
  <li>Build solution from optimal sub-solutions</li>
</ul>

<p><strong>ML System Design (Neural Architecture Search):</strong></p>
<ul>
  <li>Navigate exponential architecture space</li>
  <li>Use DP/RL/gradient methods to find optimal</li>
  <li>Build full model from optimal components</li>
</ul>

<p><strong>Speech Tech (Speech Architecture Search):</strong></p>
<ul>
  <li>Navigate encoder×decoder×attention space</li>
  <li>Use DP-inspired search to find optimal speech models</li>
  <li>Build ASR/TTS from optimal sub-architectures</li>
</ul>

<p>The <strong>unifying principle</strong>: decompose exponentially large search spaces into manageable subproblems, solve optimally using DP or DP-inspired methods, and construct the best overall solution.</p>

<hr />

<p><strong>Originally published at:</strong> <a href="https://www.arunbaby.com/speech-tech/0021-speech-architecture-search/">arunbaby.com/speech-tech/0021-speech-architecture-search</a></p>

<p><em>If you found this helpful, consider sharing it with others who might benefit.</em></p>


        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#asr" class="page__taxonomy-item p-category" rel="tag">asr</a><span class="sep">, </span>
    
      <a href="/tags/#automl" class="page__taxonomy-item p-category" rel="tag">automl</a><span class="sep">, </span>
    
      <a href="/tags/#model-optimization" class="page__taxonomy-item p-category" rel="tag">model-optimization</a><span class="sep">, </span>
    
      <a href="/tags/#nas" class="page__taxonomy-item p-category" rel="tag">nas</a><span class="sep">, </span>
    
      <a href="/tags/#neural-architecture-search" class="page__taxonomy-item p-category" rel="tag">neural-architecture-search</a><span class="sep">, </span>
    
      <a href="/tags/#speech-recognition" class="page__taxonomy-item p-category" rel="tag">speech-recognition</a><span class="sep">, </span>
    
      <a href="/tags/#tts" class="page__taxonomy-item p-category" rel="tag">tts</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#speech-tech" class="page__taxonomy-item p-category" rel="tag">speech-tech</a>
    
    </span>
  </p>


        
      </footer>

      <div class="page__related page__related--full">
  <h2 class="page__related-title">Related across topics</h2>
  <style>
    /* Make section span full content width and use 2 equal columns */
    .page__related--full { float: inline-start; width: 100%; padding: 0; }
    .cross-related-grid { display: grid; grid-template-columns: repeat(2, minmax(0, 1fr)); gap: 2rem; }
    @media (max-width: 768px) { .cross-related-grid { grid-template-columns: 1fr; } }
    /* Ensure archive cards stretch nicely in the grid */
    .cross-related-grid .list__item, .cross-related-grid .grid__item { width: auto; float: none; margin: 0; }
  </style>
  <div class="cross-related-grid">
    



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/dsa/0021-unique-paths/" rel="permalink">Unique Paths
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          23 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Master grid path counting with dynamic programming—the same optimization technique used in neural architecture search and speech model design.
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ml-system-design/0021-neural-architecture-search/" rel="permalink">Neural Architecture Search
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          18 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Design neural architecture search systems that automatically discover optimal model architectures using dynamic programming and path optimization—the same pr...</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/speech-tech/0021-speech-architecture-search/" rel="permalink">Speech Architecture Search
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          17 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Design neural architecture search systems for speech models that automatically discover optimal ASR/TTS architectures—using dynamic programming and path opti...</p>
  </article>
</div>

  </div>
</div>

      <section class="page__share">
  <h4 class="page__share-title">Share on</h4>

  <a href="https://twitter.com/intent/tweet?via=arunbaby0&text=Speech+Architecture+Search%20https%3A%2F%2Fwww.arunbaby.com%2Fspeech-tech%2F0021-speech-architecture-search%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.arunbaby.com%2Fspeech-tech%2F0021-speech-architecture-search%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.arunbaby.com/speech-tech/0021-speech-architecture-search/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/speech-tech/0020-adaptive-speech-models/" class="pagination--pager" title="Adaptive Speech Models">Previous</a>
    
    
      <a href="/speech-tech/0022-cost-efficient-speech-systems/" class="pagination--pager" title="Cost-efficient Speech Systems">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 1990 - 2143 <a href="https://www.arunbaby.com">Arun Baby</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JRJPEC9SS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0JRJPEC9SS', { 'anonymize_ip': false});
</script>








  </body>
</html>
