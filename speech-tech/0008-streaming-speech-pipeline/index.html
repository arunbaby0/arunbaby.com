<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Streaming Speech Processing Pipeline - Arun Baby</title>
<meta name="description" content="Build real-time speech processing pipelines that handle audio streams with minimal latency for live transcription and voice interfaces.">


  <meta name="author" content="Arun Baby">
  
  <meta property="article:author" content="Arun Baby">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Arun Baby">
<meta property="og:title" content="Streaming Speech Processing Pipeline">
<meta property="og:url" content="https://www.arunbaby.com/speech-tech/0008-streaming-speech-pipeline/">


  <meta property="og:description" content="Build real-time speech processing pipelines that handle audio streams with minimal latency for live transcription and voice interfaces.">



  <meta property="og:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">



  <meta name="twitter:site" content="@arunbaby0">
  <meta name="twitter:title" content="Streaming Speech Processing Pipeline">
  <meta name="twitter:description" content="Build real-time speech processing pipelines that handle audio streams with minimal latency for live transcription and voice interfaces.">
  <meta name="twitter:url" content="https://www.arunbaby.com/speech-tech/0008-streaming-speech-pipeline/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">
    
  

  



  <meta property="article:published_time" content="2025-10-27T23:15:41+05:30">





  

  


<link rel="canonical" href="https://www.arunbaby.com/speech-tech/0008-streaming-speech-pipeline/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Baby Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          <span class="site-subtitle">Arun Baby</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/dsa/"
                
                
              >DSA</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ml-system-design/"
                
                
              >ML Systems</a>
            </li><li class="masthead__menu-item">
              <a
                href="/speech-tech/"
                
                
              >Speech Tech</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li><li class="masthead__menu-item">
              <a
                href="/statuses/"
                
                
              >Statuses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/contact/"
                
                
              >Contact</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main" class="no-author-sidebar">
  
  <div class="sidebar sticky">
  
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Streaming Speech Processing Pipeline">
    <meta itemprop="description" content="Build real-time speech processing pipelines that handle audio streams with minimal latency for live transcription and voice interfaces.">
    <meta itemprop="datePublished" content="2025-10-27T23:15:41+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://www.arunbaby.com/speech-tech/0008-streaming-speech-pipeline/" itemprop="url">Streaming Speech Processing Pipeline
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          24 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#introduction">Introduction</a></li><li><a href="#streaming-pipeline-architecture">Streaming Pipeline Architecture</a></li><li><a href="#audio-capture--chunking">Audio Capture &amp; Chunking</a><ul><li><a href="#real-time-audio-capture">Real-time Audio Capture</a></li><li><a href="#chunk-buffering-strategy">Chunk Buffering Strategy</a></li></ul></li><li><a href="#websocket-based-streaming">WebSocket-Based Streaming</a><ul><li><a href="#server-side">Server Side</a></li><li><a href="#client-side">Client Side</a></li></ul></li><li><a href="#latency-optimization">Latency Optimization</a><ul><li><a href="#latency-breakdown">Latency Breakdown</a></li><li><a href="#optimization-strategies">Optimization Strategies</a></li></ul></li><li><a href="#state-management">State Management</a><ul><li><a href="#stateful-streaming">Stateful Streaming</a></li></ul></li><li><a href="#error-handling--recovery">Error Handling &amp; Recovery</a><ul><li><a href="#robust-streaming">Robust Streaming</a></li></ul></li><li><a href="#connection-to-model-serving-day-8-ml">Connection to Model Serving (Day 8 ML)</a></li><li><a href="#production-patterns">Production Patterns</a><ul><li><a href="#1-multi-channel-audio-streaming">1. Multi-Channel Audio Streaming</a></li><li><a href="#2-adaptive-chunk-size">2. Adaptive Chunk Size</a></li><li><a href="#3-buffering-strategy-for-unreliable-networks">3. Buffering Strategy for Unreliable Networks</a></li></ul></li><li><a href="#advanced-optimization-techniques">Advanced Optimization Techniques</a><ul><li><a href="#1-model-warm-up">1. Model Warm-Up</a></li><li><a href="#2-gpu-batching-for-throughput">2. GPU Batching for Throughput</a></li><li><a href="#3-quantized-models-for-edge-devices">3. Quantized Models for Edge Devices</a></li></ul></li><li><a href="#real-world-integration-examples">Real-World Integration Examples</a><ul><li><a href="#1-zoom-like-meeting-transcription">1. Zoom-like Meeting Transcription</a></li><li><a href="#2-voice-assistant-backend">2. Voice Assistant Backend</a></li></ul></li><li><a href="#performance-metrics--slas">Performance Metrics &amp; SLAs</a><ul><li><a href="#latency-tracking">Latency Tracking</a></li></ul></li><li><a href="#key-takeaways">Key Takeaways</a></li></ul>
            </nav>
          </aside>
        
        <p><strong>Build real-time speech processing pipelines that handle audio streams with minimal latency for live transcription and voice interfaces.</strong></p>

<h2 id="introduction">Introduction</h2>

<p><strong>Streaming speech processing</strong> handles audio in real-time as it’s captured, without waiting for the entire recording.</p>

<p><strong>Why streaming matters:</strong></p>
<ul>
  <li><strong>Low latency:</strong> Start processing immediately (&lt; 100ms)</li>
  <li><strong>Live applications:</strong> Transcription, translation, voice assistants</li>
  <li><strong>Memory efficiency:</strong> Process chunks, not entire recordings</li>
  <li><strong>Better UX:</strong> Instant feedback to users</li>
</ul>

<p><strong>Challenges:</strong></p>
<ul>
  <li>Chunking audio correctly</li>
  <li>Managing state across chunks</li>
  <li>Handling network delays</li>
  <li>Synchronization issues</li>
</ul>

<hr />

<h2 id="streaming-pipeline-architecture">Streaming Pipeline Architecture</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>┌─────────────┐
│  Microphone │
└──────┬──────┘
       │ Audio stream (PCM)
       ▼
┌──────────────────┐
│  Audio Chunker   │  ← Split into chunks (e.g., 100ms)
└──────┬───────────┘
       │ Chunks
       ▼
┌──────────────────┐
│   Preprocessor   │  ← Normalize, filter
└──────┬───────────┘
       │
       ▼
┌──────────────────┐
│  Feature Extract │  ← MFCC, Mel-spec
└──────┬───────────┘
       │
       ▼
┌──────────────────┐
│   ML Model       │  ← ASR, classification
└──────┬───────────┘
       │
       ▼
┌──────────────────┐
│ Post-processing  │  ← Smoothing, formatting
└──────┬───────────┘
       │
       ▼
┌──────────────────┐
│     Output       │  ← Transcription, action
└──────────────────┘
</code></pre></div></div>

<hr />

<h2 id="audio-capture--chunking">Audio Capture &amp; Chunking</h2>

<h3 id="real-time-audio-capture">Real-time Audio Capture</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pyaudio</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">queue</span> <span class="kn">import</span> <span class="n">Queue</span>
<span class="kn">import</span> <span class="n">threading</span>

<span class="k">class</span> <span class="nc">AudioStreamer</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Capture audio from microphone in real-time
    
    Buffers chunks for processing
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="o">=</span><span class="mi">16000</span><span class="p">,</span> <span class="n">chunk_duration_ms</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
        <span class="n">self</span><span class="p">.</span><span class="n">chunk_duration_ms</span> <span class="o">=</span> <span class="n">chunk_duration_ms</span>
        <span class="n">self</span><span class="p">.</span><span class="n">chunk_size</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">sample_rate</span> <span class="o">*</span> <span class="n">chunk_duration_ms</span> <span class="o">/</span> <span class="mi">1000</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">audio_queue</span> <span class="o">=</span> <span class="nc">Queue</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">stream</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="n">self</span><span class="p">.</span><span class="n">running</span> <span class="o">=</span> <span class="bp">False</span>
    
    <span class="k">def</span> <span class="nf">_audio_callback</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">in_data</span><span class="p">,</span> <span class="n">frame_count</span><span class="p">,</span> <span class="n">time_info</span><span class="p">,</span> <span class="n">status</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Callback called by PyAudio for each audio chunk
        
        Runs in separate thread
        </span><span class="sh">"""</span>
        <span class="k">if</span> <span class="n">status</span><span class="p">:</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Audio status: </span><span class="si">{</span><span class="n">status</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="c1"># Convert bytes to numpy array
</span>        <span class="n">audio_data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">frombuffer</span><span class="p">(</span><span class="n">in_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">int16</span><span class="p">)</span>
        
        <span class="c1"># Normalize to [-1, 1]
</span>        <span class="n">audio_data</span> <span class="o">=</span> <span class="n">audio_data</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="mf">32768.0</span>
        
        <span class="c1"># Add to queue
</span>        <span class="n">self</span><span class="p">.</span><span class="n">audio_queue</span><span class="p">.</span><span class="nf">put</span><span class="p">(</span><span class="n">audio_data</span><span class="p">)</span>
        
        <span class="nf">return </span><span class="p">(</span><span class="n">in_data</span><span class="p">,</span> <span class="n">pyaudio</span><span class="p">.</span><span class="n">paContinue</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">start</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Start capturing audio</span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="n">running</span> <span class="o">=</span> <span class="bp">True</span>
        
        <span class="n">p</span> <span class="o">=</span> <span class="n">pyaudio</span><span class="p">.</span><span class="nc">PyAudio</span><span class="p">()</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">stream</span> <span class="o">=</span> <span class="n">p</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span>
            <span class="nb">format</span><span class="o">=</span><span class="n">pyaudio</span><span class="p">.</span><span class="n">paInt16</span><span class="p">,</span>
            <span class="n">channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">rate</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">sample_rate</span><span class="p">,</span>
            <span class="nb">input</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">frames_per_buffer</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">chunk_size</span><span class="p">,</span>
            <span class="n">stream_callback</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">_audio_callback</span>
        <span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">stream</span><span class="p">.</span><span class="nf">start_stream</span><span class="p">()</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Started audio capture (chunk=</span><span class="si">{</span><span class="n">self</span><span class="p">.</span><span class="n">chunk_duration_ms</span><span class="si">}</span><span class="s">ms)</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">stop</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Stop capturing audio</span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="n">running</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">stream</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">stream</span><span class="p">.</span><span class="nf">stop_stream</span><span class="p">()</span>
            <span class="n">self</span><span class="p">.</span><span class="n">stream</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Stopped audio capture</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">get_chunk</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Get next audio chunk
        
        Returns: numpy array of audio samples
        </span><span class="sh">"""</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">audio_queue</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">None</span>

<span class="c1"># Usage
</span><span class="n">streamer</span> <span class="o">=</span> <span class="nc">AudioStreamer</span><span class="p">(</span><span class="n">sample_rate</span><span class="o">=</span><span class="mi">16000</span><span class="p">,</span> <span class="n">chunk_duration_ms</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">streamer</span><span class="p">.</span><span class="nf">start</span><span class="p">()</span>

<span class="c1"># Process chunks in real-time
</span><span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
    <span class="n">chunk</span> <span class="o">=</span> <span class="n">streamer</span><span class="p">.</span><span class="nf">get_chunk</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">chunk</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="c1"># Process chunk
</span>        <span class="nf">process_audio_chunk</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="chunk-buffering-strategy">Chunk Buffering Strategy</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ChunkBuffer</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Buffer audio chunks with overlap
    
    Helps models that need context from previous chunks
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">buffer_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">overlap_size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Args:
            buffer_size: Number of chunks to keep
            overlap_size: Number of chunks to overlap
        </span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="n">buffer_size</span> <span class="o">=</span> <span class="n">buffer_size</span>
        <span class="n">self</span><span class="p">.</span><span class="n">overlap_size</span> <span class="o">=</span> <span class="n">overlap_size</span>
        <span class="n">self</span><span class="p">.</span><span class="n">chunks</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">def</span> <span class="nf">add_chunk</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">chunk</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Add new chunk to buffer</span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="n">chunks</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
        
        <span class="c1"># Keep only recent chunks
</span>        <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">chunks</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">self</span><span class="p">.</span><span class="n">buffer_size</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">chunks</span><span class="p">.</span><span class="nf">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">get_buffered_audio</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Get concatenated audio with overlap
        
        Returns: numpy array
        </span><span class="sh">"""</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">self</span><span class="p">.</span><span class="n">chunks</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">None</span>
        
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">chunks</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">get_latest_with_context</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Get latest chunk with context from previous chunks
        
        Useful for models that need history
        </span><span class="sh">"""</span>
        <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">chunks</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">chunks</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">chunks</span> <span class="k">else</span> <span class="bp">None</span>
        
        <span class="c1"># Return last 'overlap_size + 1' chunks
</span>        <span class="n">context_chunks</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">chunks</span><span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">overlap_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):]</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">(</span><span class="n">context_chunks</span><span class="p">)</span>

<span class="c1"># Usage
</span><span class="nb">buffer</span> <span class="o">=</span> <span class="nc">ChunkBuffer</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">overlap_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">audio_chunks</span><span class="p">:</span>
    <span class="nb">buffer</span><span class="p">.</span><span class="nf">add_chunk</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
    <span class="n">audio_with_context</span> <span class="o">=</span> <span class="nb">buffer</span><span class="p">.</span><span class="nf">get_latest_with_context</span><span class="p">()</span>
    <span class="c1"># Process audio with context
</span></code></pre></div></div>

<hr />

<h2 id="websocket-based-streaming">WebSocket-Based Streaming</h2>

<h3 id="server-side">Server Side</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">asyncio</span>
<span class="kn">import</span> <span class="n">websockets</span>
<span class="kn">import</span> <span class="n">json</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">time</span>

<span class="k">class</span> <span class="nc">StreamingASRServer</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    WebSocket server for streaming ASR
    
    Clients send audio chunks, server returns transcriptions
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="mi">8765</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="n">self</span><span class="p">.</span><span class="n">port</span> <span class="o">=</span> <span class="n">port</span>
        <span class="n">self</span><span class="p">.</span><span class="n">active_connections</span> <span class="o">=</span> <span class="nf">set</span><span class="p">()</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">handle_client</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">websocket</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Handle single client connection</span><span class="sh">"""</span>
        <span class="n">client_id</span> <span class="o">=</span> <span class="nf">id</span><span class="p">(</span><span class="n">websocket</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">active_connections</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="n">websocket</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Client </span><span class="si">{</span><span class="n">client_id</span><span class="si">}</span><span class="s"> connected</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="k">try</span><span class="p">:</span>
            <span class="k">async</span> <span class="k">for</span> <span class="n">message</span> <span class="ow">in</span> <span class="n">websocket</span><span class="p">:</span>
                <span class="c1"># Decode message
</span>                <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="nf">loads</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>
                
                <span class="k">if</span> <span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">type</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="sh">'</span><span class="s">audio</span><span class="sh">'</span><span class="p">:</span>
                    <span class="c1"># Process audio chunk
</span>                    <span class="n">audio_bytes</span> <span class="o">=</span> <span class="nb">bytes</span><span class="p">.</span><span class="nf">fromhex</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">audio</span><span class="sh">'</span><span class="p">])</span>
                    <span class="n">audio_chunk</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">frombuffer</span><span class="p">(</span><span class="n">audio_bytes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
                    
                    <span class="c1"># Run inference
</span>                    <span class="n">transcription</span> <span class="o">=</span> <span class="k">await</span> <span class="n">self</span><span class="p">.</span><span class="nf">process_chunk</span><span class="p">(</span><span class="n">audio_chunk</span><span class="p">)</span>
                    
                    <span class="c1"># Send result
</span>                    <span class="n">response</span> <span class="o">=</span> <span class="p">{</span>
                        <span class="sh">'</span><span class="s">type</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">transcription</span><span class="sh">'</span><span class="p">,</span>
                        <span class="sh">'</span><span class="s">text</span><span class="sh">'</span><span class="p">:</span> <span class="n">transcription</span><span class="p">,</span>
                        <span class="sh">'</span><span class="s">is_final</span><span class="sh">'</span><span class="p">:</span> <span class="n">data</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">is_final</span><span class="sh">'</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>
                    <span class="p">}</span>
                    <span class="k">await</span> <span class="n">websocket</span><span class="p">.</span><span class="nf">send</span><span class="p">(</span><span class="n">json</span><span class="p">.</span><span class="nf">dumps</span><span class="p">(</span><span class="n">response</span><span class="p">))</span>
                
                <span class="k">elif</span> <span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">type</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="sh">'</span><span class="s">end</span><span class="sh">'</span><span class="p">:</span>
                    <span class="c1"># Session ended
</span>                    <span class="k">break</span>
        
        <span class="k">except</span> <span class="n">websockets</span><span class="p">.</span><span class="n">exceptions</span><span class="p">.</span><span class="n">ConnectionClosed</span><span class="p">:</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Client </span><span class="si">{</span><span class="n">client_id</span><span class="si">}</span><span class="s"> disconnected</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">active_connections</span><span class="p">.</span><span class="nf">remove</span><span class="p">(</span><span class="n">websocket</span><span class="p">)</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">process_chunk</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio_chunk</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Process audio chunk
        
        Returns: Transcription text
        </span><span class="sh">"""</span>
        <span class="c1"># Extract features
</span>        <span class="c1"># Placeholder feature extractor (should match your model's expected input)
</span>        <span class="n">features</span> <span class="o">=</span> <span class="nf">extract_features</span><span class="p">(</span><span class="n">audio_chunk</span><span class="p">)</span>
        
        <span class="c1"># Run model inference
</span>        <span class="n">transcription</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">transcription</span>
    
    <span class="k">def</span> <span class="nf">start</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Start WebSocket server</span><span class="sh">"""</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Starting ASR server on port </span><span class="si">{</span><span class="n">self</span><span class="p">.</span><span class="n">port</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="n">start_server</span> <span class="o">=</span> <span class="n">websockets</span><span class="p">.</span><span class="nf">serve</span><span class="p">(</span>
            <span class="n">self</span><span class="p">.</span><span class="n">handle_client</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">localhost</span><span class="sh">'</span><span class="p">,</span>
            <span class="n">self</span><span class="p">.</span><span class="n">port</span>
        <span class="p">)</span>
        
        <span class="n">asyncio</span><span class="p">.</span><span class="nf">get_event_loop</span><span class="p">().</span><span class="nf">run_until_complete</span><span class="p">(</span><span class="n">start_server</span><span class="p">)</span>
        <span class="n">asyncio</span><span class="p">.</span><span class="nf">get_event_loop</span><span class="p">().</span><span class="nf">run_forever</span><span class="p">()</span>

<span class="c1"># Usage
</span><span class="n">server</span> <span class="o">=</span> <span class="nc">StreamingASRServer</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">asr_model</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="mi">8765</span><span class="p">)</span>
<span class="n">server</span><span class="p">.</span><span class="nf">start</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="client-side">Client Side</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">asyncio</span>
<span class="kn">import</span> <span class="n">websockets</span>
<span class="kn">import</span> <span class="n">json</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">class</span> <span class="nc">StreamingASRClient</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    WebSocket client for streaming ASR
    
    Sends audio chunks and receives transcriptions
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">server_url</span><span class="o">=</span><span class="sh">'</span><span class="s">ws://localhost:8765</span><span class="sh">'</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">server_url</span> <span class="o">=</span> <span class="n">server_url</span>
        <span class="n">self</span><span class="p">.</span><span class="n">websocket</span> <span class="o">=</span> <span class="bp">None</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">connect</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Connect to server</span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="n">websocket</span> <span class="o">=</span> <span class="k">await</span> <span class="n">websockets</span><span class="p">.</span><span class="nf">connect</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">server_url</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Connected to </span><span class="si">{</span><span class="n">self</span><span class="p">.</span><span class="n">server_url</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">send_audio_chunk</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio_chunk</span><span class="p">,</span> <span class="n">is_final</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Send audio chunk to server
        
        Args:
            audio_chunk: numpy array
            is_final: Whether this is the last chunk
        </span><span class="sh">"""</span>
        <span class="c1"># Convert to bytes
</span>        <span class="n">audio_bytes</span> <span class="o">=</span> <span class="n">audio_chunk</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">).</span><span class="nf">tobytes</span><span class="p">()</span>
        <span class="n">audio_hex</span> <span class="o">=</span> <span class="n">audio_bytes</span><span class="p">.</span><span class="nf">hex</span><span class="p">()</span>
        
        <span class="c1"># Create message
</span>        <span class="n">message</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">type</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">audio</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">audio</span><span class="sh">'</span><span class="p">:</span> <span class="n">audio_hex</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">is_final</span><span class="sh">'</span><span class="p">:</span> <span class="n">is_final</span>
        <span class="p">}</span>
        
        <span class="c1"># Send
</span>        <span class="k">await</span> <span class="n">self</span><span class="p">.</span><span class="n">websocket</span><span class="p">.</span><span class="nf">send</span><span class="p">(</span><span class="n">json</span><span class="p">.</span><span class="nf">dumps</span><span class="p">(</span><span class="n">message</span><span class="p">))</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">receive_transcription</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Receive transcription from server
        
        Returns: Dict with transcription
        </span><span class="sh">"""</span>
        <span class="n">response</span> <span class="o">=</span> <span class="k">await</span> <span class="n">self</span><span class="p">.</span><span class="n">websocket</span><span class="p">.</span><span class="nf">recv</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">json</span><span class="p">.</span><span class="nf">loads</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">close</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Close connection</span><span class="sh">"""</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">websocket</span><span class="p">:</span>
            <span class="k">await</span> <span class="n">self</span><span class="p">.</span><span class="n">websocket</span><span class="p">.</span><span class="nf">send</span><span class="p">(</span><span class="n">json</span><span class="p">.</span><span class="nf">dumps</span><span class="p">({</span><span class="sh">'</span><span class="s">type</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">end</span><span class="sh">'</span><span class="p">}))</span>
            <span class="k">await</span> <span class="n">self</span><span class="p">.</span><span class="n">websocket</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>

<span class="c1"># Usage
</span><span class="k">async</span> <span class="k">def</span> <span class="nf">stream_audio</span><span class="p">():</span>
    <span class="n">client</span> <span class="o">=</span> <span class="nc">StreamingASRClient</span><span class="p">()</span>
    <span class="k">await</span> <span class="n">client</span><span class="p">.</span><span class="nf">connect</span><span class="p">()</span>
    
    <span class="c1"># Stream audio chunks
</span>    <span class="n">streamer</span> <span class="o">=</span> <span class="nc">AudioStreamer</span><span class="p">()</span>
    <span class="n">streamer</span><span class="p">.</span><span class="nf">start</span><span class="p">()</span>
    
    <span class="k">try</span><span class="p">:</span>
        <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
            <span class="n">chunk</span> <span class="o">=</span> <span class="n">streamer</span><span class="p">.</span><span class="nf">get_chunk</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">chunk</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="k">break</span>
            
            <span class="c1"># Send chunk
</span>            <span class="k">await</span> <span class="n">client</span><span class="p">.</span><span class="nf">send_audio_chunk</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
            
            <span class="c1"># Receive transcription
</span>            <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">client</span><span class="p">.</span><span class="nf">receive_transcription</span><span class="p">()</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Transcription: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="sh">'</span><span class="s">text</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="k">finally</span><span class="p">:</span>
        <span class="n">streamer</span><span class="p">.</span><span class="nf">stop</span><span class="p">()</span>
        <span class="k">await</span> <span class="n">client</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>

<span class="c1"># Run
</span><span class="n">asyncio</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="nf">stream_audio</span><span class="p">())</span>
</code></pre></div></div>

<hr />

<h2 id="latency-optimization">Latency Optimization</h2>

<h3 id="latency-breakdown">Latency Breakdown</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Total Latency = Audio Capture + Network + Processing + Network + Display

Typical values:
- Audio capture: 10-50ms (chunk duration)
- Network (client → server): 10-30ms
- Feature extraction: 5-10ms
- Model inference: 20-100ms (depends on model)
- Network (server → client): 10-30ms
- Display: 1-5ms

Total: 56-225ms (aim for &lt; 100ms)
</code></pre></div></div>

<h3 id="optimization-strategies">Optimization Strategies</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">OptimizedStreamingPipeline</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Optimized streaming pipeline
    
    Techniques:
    - Smaller chunks
    - Model quantization
    - Batch processing
    - Prefetching
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">chunk_duration_ms</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Args:
            chunk_duration_ms: Smaller chunks = lower latency
        </span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="n">self</span><span class="p">.</span><span class="n">chunk_duration_ms</span> <span class="o">=</span> <span class="n">chunk_duration_ms</span>
        
        <span class="c1"># Prefetch buffer
</span>        <span class="n">self</span><span class="p">.</span><span class="n">prefetch_buffer</span> <span class="o">=</span> <span class="n">asyncio</span><span class="p">.</span><span class="nc">Queue</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
        
        <span class="c1"># Start prefetching thread
</span>        <span class="n">self</span><span class="p">.</span><span class="n">prefetch_task</span> <span class="o">=</span> <span class="bp">None</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">start_prefetching</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio_source</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Prefetch audio chunks
        
        Reduces waiting time
        </span><span class="sh">"""</span>
        <span class="k">async</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">audio_source</span><span class="p">:</span>
            <span class="k">await</span> <span class="n">self</span><span class="p">.</span><span class="n">prefetch_buffer</span><span class="p">.</span><span class="nf">put</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">process_stream</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio_source</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Process audio stream with optimizations
        </span><span class="sh">"""</span>
        <span class="c1"># Start prefetching
</span>        <span class="n">self</span><span class="p">.</span><span class="n">prefetch_task</span> <span class="o">=</span> <span class="n">asyncio</span><span class="p">.</span><span class="nf">create_task</span><span class="p">(</span>
            <span class="n">self</span><span class="p">.</span><span class="nf">start_prefetching</span><span class="p">(</span><span class="n">audio_source</span><span class="p">)</span>
        <span class="p">)</span>
        
        <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
            <span class="c1"># Get prefetched chunk (zero wait!)
</span>            <span class="n">chunk</span> <span class="o">=</span> <span class="k">await</span> <span class="n">self</span><span class="p">.</span><span class="n">prefetch_buffer</span><span class="p">.</span><span class="nf">get</span><span class="p">()</span>
            
            <span class="k">if</span> <span class="n">chunk</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="k">break</span>
            
            <span class="c1"># Process chunk
</span>            <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">self</span><span class="p">.</span><span class="nf">process_chunk_optimized</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
            
            <span class="k">yield</span> <span class="n">result</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">process_chunk_optimized</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">chunk</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Optimized chunk processing
        
        Uses quantized model for faster inference
        </span><span class="sh">"""</span>
        <span class="c1"># Extract features (optimized)
</span>        <span class="n">features</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">extract_features_fast</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
        
        <span class="c1"># Run inference (quantized model)
</span>        <span class="n">result</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">result</span>
    
    <span class="k">def</span> <span class="nf">extract_features_fast</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Fast feature extraction
        
        Uses caching and vectorization
        </span><span class="sh">"""</span>
        <span class="c1"># Vectorized operations are faster
</span>        <span class="n">mfcc</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="n">feature</span><span class="p">.</span><span class="nf">mfcc</span><span class="p">(</span>
            <span class="n">y</span><span class="o">=</span><span class="n">audio</span><span class="p">,</span>
            <span class="n">sr</span><span class="o">=</span><span class="mi">16000</span><span class="p">,</span>
            <span class="n">n_mfcc</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span>
            <span class="n">hop_length</span><span class="o">=</span><span class="mi">160</span>  <span class="c1"># Smaller hop = more features
</span>        <span class="p">)</span>
        
        <span class="k">return</span> <span class="n">mfcc</span>
</code></pre></div></div>

<hr />

<h2 id="state-management">State Management</h2>

<h3 id="stateful-streaming">Stateful Streaming</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">StatefulStreamingProcessor</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Maintain state across chunks
    
    Important for context-dependent models
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="n">self</span><span class="p">.</span><span class="n">state</span> <span class="o">=</span> <span class="bp">None</span>  <span class="c1"># Hidden state for RNN/LSTM models
</span>        <span class="n">self</span><span class="p">.</span><span class="n">previous_chunks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">partial_results</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">def</span> <span class="nf">process_chunk</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio_chunk</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Process chunk with state
        
        Returns: (result, is_complete)
        </span><span class="sh">"""</span>
        <span class="c1"># Extract features
</span>        <span class="n">features</span> <span class="o">=</span> <span class="nf">extract_features</span><span class="p">(</span><span class="n">audio_chunk</span><span class="p">)</span>
        
        <span class="c1"># Run model with state
</span>        <span class="k">if</span> <span class="nf">hasattr</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">,</span> <span class="sh">'</span><span class="s">predict_stateful</span><span class="sh">'</span><span class="p">):</span>
            <span class="n">result</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">predict_stateful</span><span class="p">(</span>
                <span class="n">features</span><span class="p">,</span>
                <span class="n">previous_state</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">state</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Fallback: concatenate with previous chunks
</span>            <span class="n">self</span><span class="p">.</span><span class="n">previous_chunks</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">audio_chunk</span><span class="p">)</span>
            <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">previous_chunks</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">5</span><span class="p">:</span>
                <span class="n">self</span><span class="p">.</span><span class="n">previous_chunks</span><span class="p">.</span><span class="nf">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            
            <span class="n">combined_audio</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">previous_chunks</span><span class="p">)</span>
            <span class="n">combined_features</span> <span class="o">=</span> <span class="nf">extract_features</span><span class="p">(</span><span class="n">combined_audio</span><span class="p">)</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">combined_features</span><span class="p">)</span>
        
        <span class="c1"># Determine if result is complete
</span>        <span class="n">is_complete</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">check_completeness</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">is_complete</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">partial_results</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">result</span><span class="p">,</span> <span class="n">is_complete</span>
    
    <span class="k">def</span> <span class="nf">check_completeness</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">result</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Check if result is a complete utterance
        
        Uses heuristics:
        - Pause detection
        - Confidence threshold
        - Length limits
        </span><span class="sh">"""</span>
        <span class="c1"># Simple heuristic: check for pause
</span>        <span class="c1"># (In practice, use more sophisticated methods)
</span>        <span class="k">if</span> <span class="nf">hasattr</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="sh">'</span><span class="s">confidence</span><span class="sh">'</span><span class="p">)</span> <span class="ow">and</span> <span class="n">result</span><span class="p">.</span><span class="n">confidence</span> <span class="o">&gt;</span> <span class="mf">0.9</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">True</span>
        
        <span class="k">return</span> <span class="bp">False</span>
    
    <span class="k">def</span> <span class="nf">reset_state</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Reset state (e.g., after complete utterance)</span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="n">state</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="n">self</span><span class="p">.</span><span class="n">previous_chunks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">partial_results</span> <span class="o">=</span> <span class="p">[]</span>
</code></pre></div></div>

<hr />

<h2 id="error-handling--recovery">Error Handling &amp; Recovery</h2>

<h3 id="robust-streaming">Robust Streaming</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">RobustStreamingPipeline</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Streaming pipeline with error handling
    
    Handles:
    - Network failures
    - Audio glitches
    - Model errors
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="n">self</span><span class="p">.</span><span class="n">error_count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">self</span><span class="p">.</span><span class="n">max_errors</span> <span class="o">=</span> <span class="mi">10</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">process_stream_robust</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio_source</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Process stream with error recovery
        </span><span class="sh">"""</span>
        <span class="n">retry_count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">max_retries</span> <span class="o">=</span> <span class="mi">3</span>
        
        <span class="k">async</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">audio_source</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># Process chunk
</span>                <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">self</span><span class="p">.</span><span class="nf">process_chunk_safe</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
                
                <span class="c1"># Reset retry count on success
</span>                <span class="n">retry_count</span> <span class="o">=</span> <span class="mi">0</span>
                
                <span class="k">yield</span> <span class="n">result</span>
            
            <span class="k">except</span> <span class="n">AudioGlitchError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="c1"># Audio glitch: skip chunk
</span>                <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Audio glitch detected: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
                <span class="n">self</span><span class="p">.</span><span class="n">error_count</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">continue</span>
            
            <span class="k">except</span> <span class="n">ModelInferenceError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="c1"># Model error: retry with fallback
</span>                <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Model inference failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
                
                <span class="k">if</span> <span class="n">retry_count</span> <span class="o">&lt;</span> <span class="n">max_retries</span><span class="p">:</span>
                    <span class="n">retry_count</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="c1"># Use simpler fallback model
</span>                    <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">self</span><span class="p">.</span><span class="nf">fallback_inference</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
                    <span class="k">yield</span> <span class="n">result</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Give up after max retries
</span>                    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Max retries exceeded, skipping chunk</span><span class="sh">"</span><span class="p">)</span>
                    <span class="n">retry_count</span> <span class="o">=</span> <span class="mi">0</span>
            
            <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="c1"># Unexpected error
</span>                <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Unexpected error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
                <span class="n">self</span><span class="p">.</span><span class="n">error_count</span> <span class="o">+=</span> <span class="mi">1</span>
                
                <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">error_count</span> <span class="o">&gt;</span> <span class="n">self</span><span class="p">.</span><span class="n">max_errors</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="nc">RuntimeError</span><span class="p">(</span><span class="sh">"</span><span class="s">Too many errors, stopping stream</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">process_chunk_safe</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">chunk</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Process chunk with validation
        </span><span class="sh">"""</span>
        <span class="c1"># Validate chunk
</span>        <span class="k">if</span> <span class="ow">not</span> <span class="n">self</span><span class="p">.</span><span class="nf">validate_chunk</span><span class="p">(</span><span class="n">chunk</span><span class="p">):</span>
            <span class="k">raise</span> <span class="nc">AudioGlitchError</span><span class="p">(</span><span class="sh">"</span><span class="s">Invalid audio chunk</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="c1"># Process
</span>        <span class="k">try</span><span class="p">:</span>
            <span class="n">features</span> <span class="o">=</span> <span class="nf">extract_features</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">result</span>
        <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="nc">ModelInferenceError</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Inference failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">validate_chunk</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">chunk</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Validate audio chunk
        
        Checks for:
        - Correct length
        - Valid range
        - No NaN values
        </span><span class="sh">"""</span>
        <span class="k">if</span> <span class="n">chunk</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">or</span> <span class="nf">len</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">False</span>
        
        <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="nf">any</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">isnan</span><span class="p">(</span><span class="n">chunk</span><span class="p">)):</span>
            <span class="k">return</span> <span class="bp">False</span>
        
        <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">chunk</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">:</span>  <span class="c1"># Suspiciously large
</span>            <span class="k">return</span> <span class="bp">False</span>
        
        <span class="k">return</span> <span class="bp">True</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">fallback_inference</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">chunk</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Fallback inference with simpler model
        
        Trades accuracy for reliability
        </span><span class="sh">"""</span>
        <span class="c1"># Use cached results or simple heuristics
</span>        <span class="k">return</span> <span class="p">{</span><span class="sh">"</span><span class="s">text</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">[processing...]</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">confidence</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">}</span>

<span class="k">class</span> <span class="nc">AudioGlitchError</span><span class="p">(</span><span class="nb">Exception</span><span class="p">):</span>
    <span class="k">pass</span>

<span class="k">class</span> <span class="nc">ModelInferenceError</span><span class="p">(</span><span class="nb">Exception</span><span class="p">):</span>
    <span class="k">pass</span>
</code></pre></div></div>

<hr />

<h2 id="connection-to-model-serving-day-8-ml">Connection to Model Serving (Day 8 ML)</h2>

<p>Streaming speech pipelines use model serving patterns:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">StreamingSpeechServer</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Streaming speech server with model serving best practices
    
    Combines:
    - Model serving (Day 8 ML)
    - Streaming audio (Day 8 Speech)
    - Validation (Day 8 DSA)
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model_path</span><span class="p">):</span>
        <span class="c1"># Load model (model serving pattern)
</span>        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">load_model</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
        
        <span class="c1"># Validation (BST-like range checking)
</span>        <span class="n">self</span><span class="p">.</span><span class="n">validator</span> <span class="o">=</span> <span class="nc">AudioValidator</span><span class="p">()</span>
        
        <span class="c1"># Monitoring
</span>        <span class="n">self</span><span class="p">.</span><span class="n">metrics</span> <span class="o">=</span> <span class="nc">StreamingMetrics</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model_path</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Load model with caching (from model serving)</span><span class="sh">"""</span>
        <span class="kn">import</span> <span class="n">joblib</span>
        <span class="k">return</span> <span class="n">joblib</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">process_audio_stream</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio_chunks</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Process streaming audio
        
        Uses patterns from all Day 8 topics
        </span><span class="sh">"""</span>
        <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">audio_chunks</span><span class="p">:</span>
            <span class="c1"># Validate input (BST validation pattern)
</span>            <span class="n">is_valid</span><span class="p">,</span> <span class="n">violations</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">validator</span><span class="p">.</span><span class="nf">validate</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="ow">not</span> <span class="n">is_valid</span><span class="p">:</span>
                <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Invalid chunk: </span><span class="si">{</span><span class="n">violations</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
                <span class="k">continue</span>
            
            <span class="c1"># Process chunk (model serving)
</span>            <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
            <span class="n">latency</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
            
            <span class="c1"># Monitor (model serving)
</span>            <span class="n">self</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="nf">record_prediction</span><span class="p">(</span><span class="n">latency</span><span class="p">)</span>
            
            <span class="k">yield</span> <span class="n">result</span>

<span class="k">class</span> <span class="nc">AudioValidator</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">Validate audio chunks (similar to BST validation)</span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="c1"># Define valid ranges (like BST min/max)
</span>        <span class="n">self</span><span class="p">.</span><span class="n">amplitude_range</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">length_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>  <span class="c1"># samples
</span>    
    <span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">chunk</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Validate chunk falls within ranges
        
        Like BST validation with [min, max] bounds
        </span><span class="sh">"""</span>
        <span class="n">violations</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="c1"># Check amplitude range
</span>        <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="nf">min</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">self</span><span class="p">.</span><span class="n">amplitude_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="n">violations</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">"</span><span class="s">Amplitude too low</span><span class="sh">"</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">self</span><span class="p">.</span><span class="n">amplitude_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">violations</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">"</span><span class="s">Amplitude too high</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="c1"># Check length range
</span>        <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">self</span><span class="p">.</span><span class="n">length_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="n">violations</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">"</span><span class="s">Chunk too short</span><span class="sh">"</span><span class="p">)</span>
        <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">self</span><span class="p">.</span><span class="n">length_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">violations</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">"</span><span class="s">Chunk too long</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="nf">len</span><span class="p">(</span><span class="n">violations</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="n">violations</span>
</code></pre></div></div>

<hr />

<h2 id="production-patterns">Production Patterns</h2>

<h3 id="1-multi-channel-audio-streaming">1. Multi-Channel Audio Streaming</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MultiChannelStreamingProcessor</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Process multiple audio streams simultaneously
    
    Use case: Conference calls, multi-mic arrays
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">num_channels</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">num_channels</span> <span class="o">=</span> <span class="n">num_channels</span>
        <span class="n">self</span><span class="p">.</span><span class="n">channel_buffers</span> <span class="o">=</span> <span class="p">[</span><span class="nc">ChunkBuffer</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_channels</span><span class="p">)]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">processors</span> <span class="o">=</span> <span class="p">[</span><span class="nc">StreamingProcessor</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_channels</span><span class="p">)]</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">process_multi_channel</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">channel_chunks</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Process multiple channels in parallel
        
        Args:
            channel_chunks: Dict {channel_id: audio_chunk}
        
        Returns: Dict {channel_id: result}
        </span><span class="sh">"""</span>
        <span class="kn">import</span> <span class="n">asyncio</span>
        
        <span class="c1"># Process channels in parallel
</span>        <span class="n">tasks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">channel_id</span><span class="p">,</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">channel_chunks</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
            <span class="n">task</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">processors</span><span class="p">[</span><span class="n">channel_id</span><span class="p">].</span><span class="nf">process_chunk_async</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
            <span class="n">tasks</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">channel_id</span><span class="p">,</span> <span class="n">task</span><span class="p">))</span>
        
        <span class="c1"># Wait for all results
</span>        <span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">channel_id</span><span class="p">,</span> <span class="n">task</span> <span class="ow">in</span> <span class="n">tasks</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">task</span>
            <span class="n">results</span><span class="p">[</span><span class="n">channel_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span>
        
        <span class="k">return</span> <span class="n">results</span>
    
    <span class="k">def</span> <span class="nf">merge_results</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">channel_results</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Merge results from multiple channels
        
        E.g., speaker diarization, beam forming
        </span><span class="sh">"""</span>
        <span class="c1"># Simple merging: concatenate transcriptions
</span>        <span class="n">merged_text</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">channel_id</span> <span class="ow">in</span> <span class="nf">sorted</span><span class="p">(</span><span class="n">channel_results</span><span class="p">.</span><span class="nf">keys</span><span class="p">()):</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">channel_results</span><span class="p">[</span><span class="n">channel_id</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">result</span><span class="p">:</span>
                <span class="n">merged_text</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">[Channel </span><span class="si">{</span><span class="n">channel_id</span><span class="si">}</span><span class="s">]: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="sh">'</span><span class="s">text</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="sh">'</span><span class="se">\n</span><span class="sh">'</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">merged_text</span><span class="p">)</span>

<span class="c1"># Usage
</span><span class="n">multi_processor</span> <span class="o">=</span> <span class="nc">MultiChannelStreamingProcessor</span><span class="p">(</span><span class="n">num_channels</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="c1"># Stream audio from 4 microphones
</span><span class="k">async</span> <span class="k">def</span> <span class="nf">process_meeting</span><span class="p">():</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="c1"># Get chunks from all channels
</span>        <span class="n">chunks</span> <span class="o">=</span> <span class="p">{</span>
            <span class="mi">0</span><span class="p">:</span> <span class="n">mic1</span><span class="p">.</span><span class="nf">get_chunk</span><span class="p">(),</span>
            <span class="mi">1</span><span class="p">:</span> <span class="n">mic2</span><span class="p">.</span><span class="nf">get_chunk</span><span class="p">(),</span>
            <span class="mi">2</span><span class="p">:</span> <span class="n">mic3</span><span class="p">.</span><span class="nf">get_chunk</span><span class="p">(),</span>
            <span class="mi">3</span><span class="p">:</span> <span class="n">mic4</span><span class="p">.</span><span class="nf">get_chunk</span><span class="p">()</span>
        <span class="p">}</span>
        
        <span class="c1"># Process in parallel
</span>        <span class="n">results</span> <span class="o">=</span> <span class="k">await</span> <span class="n">multi_processor</span><span class="p">.</span><span class="nf">process_multi_channel</span><span class="p">(</span><span class="n">chunks</span><span class="p">)</span>
        
        <span class="c1"># Merge and display
</span>        <span class="n">merged</span> <span class="o">=</span> <span class="n">multi_processor</span><span class="p">.</span><span class="nf">merge_results</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">merged</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="2-adaptive-chunk-size">2. Adaptive Chunk Size</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">AdaptiveChunkingProcessor</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Dynamically adjust chunk size based on network/compute conditions
    
    Smaller chunks: Lower latency but higher overhead
    Larger chunks: Higher latency but more efficient
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">min_chunk_ms</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">max_chunk_ms</span><span class="o">=</span><span class="mi">200</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">min_chunk_ms</span> <span class="o">=</span> <span class="n">min_chunk_ms</span>
        <span class="n">self</span><span class="p">.</span><span class="n">max_chunk_ms</span> <span class="o">=</span> <span class="n">max_chunk_ms</span>
        <span class="n">self</span><span class="p">.</span><span class="n">current_chunk_ms</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># Start with middle value
</span>        <span class="n">self</span><span class="p">.</span><span class="n">latency_history</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">def</span> <span class="nf">adjust_chunk_size</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">recent_latency_ms</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Adjust chunk size based on latency
        
        High latency → smaller chunks (more responsive)
        Low latency → larger chunks (more efficient)
        </span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="n">latency_history</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">recent_latency_ms</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">latency_history</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">current_chunk_ms</span>
        
        <span class="c1"># Calculate average latency
</span>        <span class="n">avg_latency</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">latency_history</span><span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">:])</span>
        
        <span class="c1"># Adjust chunk size
</span>        <span class="k">if</span> <span class="n">avg_latency</span> <span class="o">&gt;</span> <span class="mi">150</span><span class="p">:</span>  <span class="c1"># High latency
</span>            <span class="c1"># Reduce chunk size for better responsiveness
</span>            <span class="n">self</span><span class="p">.</span><span class="n">current_chunk_ms</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span>
                <span class="n">self</span><span class="p">.</span><span class="n">min_chunk_ms</span><span class="p">,</span>
                <span class="n">self</span><span class="p">.</span><span class="n">current_chunk_ms</span> <span class="o">-</span> <span class="mi">10</span>
            <span class="p">)</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">↓ Reducing chunk size to </span><span class="si">{</span><span class="n">self</span><span class="p">.</span><span class="n">current_chunk_ms</span><span class="si">}</span><span class="s">ms</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="k">elif</span> <span class="n">avg_latency</span> <span class="o">&lt;</span> <span class="mi">50</span><span class="p">:</span>  <span class="c1"># Very low latency
</span>            <span class="c1"># Increase chunk size for efficiency
</span>            <span class="n">self</span><span class="p">.</span><span class="n">current_chunk_ms</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span>
                <span class="n">self</span><span class="p">.</span><span class="n">max_chunk_ms</span><span class="p">,</span>
                <span class="n">self</span><span class="p">.</span><span class="n">current_chunk_ms</span> <span class="o">+</span> <span class="mi">10</span>
            <span class="p">)</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">↑ Increasing chunk size to </span><span class="si">{</span><span class="n">self</span><span class="p">.</span><span class="n">current_chunk_ms</span><span class="si">}</span><span class="s">ms</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">current_chunk_ms</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">process_with_adaptive_chunking</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio_stream</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Process stream with adaptive chunk sizing</span><span class="sh">"""</span>
        <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">audio_stream</span><span class="p">:</span>
            <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
            
            <span class="c1"># Process chunk
</span>            <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">self</span><span class="p">.</span><span class="nf">process_chunk</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
            
            <span class="c1"># Calculate latency
</span>            <span class="n">latency_ms</span> <span class="o">=</span> <span class="p">(</span><span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span>
            
            <span class="c1"># Adjust chunk size for next iteration
</span>            <span class="n">next_chunk_ms</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">adjust_chunk_size</span><span class="p">(</span><span class="n">latency_ms</span><span class="p">)</span>
            
            <span class="k">yield</span> <span class="n">result</span><span class="p">,</span> <span class="n">next_chunk_ms</span>
</code></pre></div></div>

<h3 id="3-buffering-strategy-for-unreliable-networks">3. Buffering Strategy for Unreliable Networks</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">NetworkAwareStreamingBuffer</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Buffer audio to handle network issues
    
    Maintains smooth playback despite packet loss
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">buffer_size_seconds</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">sample_rate</span><span class="o">=</span><span class="mi">16000</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">buffer_size</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">buffer_size_seconds</span> <span class="o">*</span> <span class="n">sample_rate</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="nb">buffer</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">buffer_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">write_pos</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">self</span><span class="p">.</span><span class="n">read_pos</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">self</span><span class="p">.</span><span class="n">underrun_count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">self</span><span class="p">.</span><span class="n">overrun_count</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">def</span> <span class="nf">write_chunk</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">chunk</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Write audio chunk to buffer
        
        Returns: Success status
        </span><span class="sh">"""</span>
        <span class="n">chunk_size</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
        
        <span class="c1"># Check for buffer overrun
</span>        <span class="n">available_space</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">buffer_size</span> <span class="o">-</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">write_pos</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">read_pos</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">chunk_size</span> <span class="o">&gt;</span> <span class="n">available_space</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">overrun_count</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">⚠️ Buffer overrun - dropping oldest data</span><span class="sh">"</span><span class="p">)</span>
            <span class="c1"># Drop oldest data
</span>            <span class="n">self</span><span class="p">.</span><span class="n">read_pos</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">write_pos</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">buffer_size</span> <span class="o">+</span> <span class="n">chunk_size</span>
        
        <span class="c1"># Write to circular buffer
</span>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sample</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">chunk</span><span class="p">):</span>
            <span class="n">pos</span> <span class="o">=</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">write_pos</span> <span class="o">+</span> <span class="n">i</span><span class="p">)</span> <span class="o">%</span> <span class="n">self</span><span class="p">.</span><span class="n">buffer_size</span>
            <span class="n">self</span><span class="p">.</span><span class="nb">buffer</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">write_pos</span> <span class="o">+=</span> <span class="n">chunk_size</span>
        <span class="k">return</span> <span class="bp">True</span>
    
    <span class="k">def</span> <span class="nf">read_chunk</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Read audio chunk from buffer
        
        Returns: Audio chunk or None if underrun
        </span><span class="sh">"""</span>
        <span class="c1"># Check for buffer underrun
</span>        <span class="n">available_data</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">write_pos</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">read_pos</span>
        <span class="k">if</span> <span class="n">available_data</span> <span class="o">&lt;</span> <span class="n">chunk_size</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">underrun_count</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">⚠️ Buffer underrun - not enough data</span><span class="sh">"</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">None</span>
        
        <span class="c1"># Read from circular buffer
</span>        <span class="n">chunk</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">chunk_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">chunk_size</span><span class="p">):</span>
            <span class="n">pos</span> <span class="o">=</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">read_pos</span> <span class="o">+</span> <span class="n">i</span><span class="p">)</span> <span class="o">%</span> <span class="n">self</span><span class="p">.</span><span class="n">buffer_size</span>
            <span class="n">chunk</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nb">buffer</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">read_pos</span> <span class="o">+=</span> <span class="n">chunk_size</span>
        <span class="k">return</span> <span class="n">chunk</span>
    
    <span class="k">def</span> <span class="nf">get_buffer_level</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Get current buffer fill level (0-1)</span><span class="sh">"""</span>
        <span class="n">available</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">write_pos</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">read_pos</span>
        <span class="k">return</span> <span class="n">available</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">buffer_size</span>
    
    <span class="k">def</span> <span class="nf">get_stats</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Get buffer statistics</span><span class="sh">"""</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">buffer_level</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="nf">get_buffer_level</span><span class="p">(),</span>
            <span class="sh">'</span><span class="s">underruns</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">underrun_count</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">overruns</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">overrun_count</span>
        <span class="p">}</span>

<span class="c1"># Usage
</span><span class="nb">buffer</span> <span class="o">=</span> <span class="nc">NetworkAwareStreamingBuffer</span><span class="p">(</span><span class="n">buffer_size_seconds</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>

<span class="c1"># Writer thread (receiving from network)
</span><span class="k">async</span> <span class="k">def</span> <span class="nf">receive_audio</span><span class="p">():</span>
    <span class="k">async</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">network_stream</span><span class="p">:</span>
        <span class="nb">buffer</span><span class="p">.</span><span class="nf">write_chunk</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
        
        <span class="c1"># Adaptive buffering
</span>        <span class="n">level</span> <span class="o">=</span> <span class="nb">buffer</span><span class="p">.</span><span class="nf">get_buffer_level</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">level</span> <span class="o">&lt;</span> <span class="mf">0.2</span><span class="p">:</span>
            <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">⚠️ Low buffer, may need to increase</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Reader thread (processing)
</span><span class="k">async</span> <span class="k">def</span> <span class="nf">process_audio</span><span class="p">():</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">chunk</span> <span class="o">=</span> <span class="nb">buffer</span><span class="p">.</span><span class="nf">read_chunk</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">1600</span><span class="p">)</span>  <span class="c1"># 100ms at 16kHz
</span>        <span class="k">if</span> <span class="n">chunk</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="nf">process_chunk</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">result</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">await</span> <span class="n">asyncio</span><span class="p">.</span><span class="nf">sleep</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>  <span class="c1"># Wait for more data
</span></code></pre></div></div>

<hr />

<h2 id="advanced-optimization-techniques">Advanced Optimization Techniques</h2>

<h3 id="1-model-warm-up">1. Model Warm-Up</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">WarmUpStreamingProcessor</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Pre-warm model for lower latency on first request
    
    Cold start can add 100-500ms latency
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="n">self</span><span class="p">.</span><span class="n">is_warm</span> <span class="o">=</span> <span class="bp">False</span>
    
    <span class="k">def</span> <span class="nf">warm_up</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="o">=</span><span class="mi">16000</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Warm up model with dummy input
        
        Call during initialization
        </span><span class="sh">"""</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Warming up model...</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="c1"># Create dummy audio chunk
</span>        <span class="n">dummy_chunk</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="nf">int</span><span class="p">(</span><span class="n">sample_rate</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">))</span>  <span class="c1"># 100ms
</span>        
        <span class="c1"># Run inference to warm up
</span>        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
            <span class="n">_</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">dummy_chunk</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">is_warm</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Model warm-up complete</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">process_chunk</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">chunk</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Process with warm-up check</span><span class="sh">"""</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">self</span><span class="p">.</span><span class="n">is_warm</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="nf">warm_up</span><span class="p">()</span>
        
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>

<span class="c1"># Usage
</span><span class="n">processor</span> <span class="o">=</span> <span class="nc">WarmUpStreamingProcessor</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">processor</span><span class="p">.</span><span class="nf">warm_up</span><span class="p">()</span>  <span class="c1"># Do this during server startup
</span></code></pre></div></div>

<h3 id="2-gpu-batching-for-throughput">2. GPU Batching for Throughput</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">GPUBatchProcessor</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Batch multiple streams for GPU efficiency
    
    GPUs are most efficient with batch processing
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">max_batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">max_wait_ms</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="n">self</span><span class="p">.</span><span class="n">max_batch_size</span> <span class="o">=</span> <span class="n">max_batch_size</span>
        <span class="n">self</span><span class="p">.</span><span class="n">max_wait_ms</span> <span class="o">=</span> <span class="n">max_wait_ms</span>
        <span class="n">self</span><span class="p">.</span><span class="n">pending_batches</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">process_chunk_batched</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">chunk</span><span class="p">,</span> <span class="n">stream_id</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Add chunk to batch and process when ready
        
        Returns: Future that resolves with result
        </span><span class="sh">"""</span>
        <span class="n">future</span> <span class="o">=</span> <span class="n">asyncio</span><span class="p">.</span><span class="nc">Future</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">pending_batches</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">chunk</span><span class="p">,</span> <span class="n">stream_id</span><span class="p">,</span> <span class="n">future</span><span class="p">))</span>
        
        <span class="c1"># Process batch if ready
</span>        <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">pending_batches</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">self</span><span class="p">.</span><span class="n">max_batch_size</span><span class="p">:</span>
            <span class="k">await</span> <span class="n">self</span><span class="p">.</span><span class="nf">_process_batch</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Wait for more requests or timeout
</span>            <span class="n">asyncio</span><span class="p">.</span><span class="nf">create_task</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">_process_batch_after_delay</span><span class="p">())</span>
        
        <span class="k">return</span> <span class="k">await</span> <span class="n">future</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">_process_batch</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Process accumulated batch on GPU</span><span class="sh">"""</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">self</span><span class="p">.</span><span class="n">pending_batches</span><span class="p">:</span>
            <span class="k">return</span>
        
        <span class="c1"># Extract batch
</span>        <span class="n">chunks</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">pending_batches</span><span class="p">]</span>
        <span class="n">stream_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">pending_batches</span><span class="p">]</span>
        <span class="n">futures</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">pending_batches</span><span class="p">]</span>
        
        <span class="c1"># Pad to same length
</span>        <span class="n">max_len</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">chunks</span><span class="p">)</span>
        <span class="n">padded_chunks</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">np</span><span class="p">.</span><span class="nf">pad</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_len</span> <span class="o">-</span> <span class="nf">len</span><span class="p">(</span><span class="n">c</span><span class="p">)),</span> <span class="n">mode</span><span class="o">=</span><span class="sh">'</span><span class="s">constant</span><span class="sh">'</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">chunks</span>
        <span class="p">]</span>
        
        <span class="c1"># Stack into batch
</span>        <span class="n">batch</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span><span class="n">padded_chunks</span><span class="p">)</span>
        
        <span class="c1"># Run batch inference on GPU
</span>        <span class="n">results</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">predict_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        
        <span class="c1"># Distribute results
</span>        <span class="k">for</span> <span class="n">result</span><span class="p">,</span> <span class="n">future</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">futures</span><span class="p">):</span>
            <span class="n">future</span><span class="p">.</span><span class="nf">set_result</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
        
        <span class="c1"># Clear batch
</span>        <span class="n">self</span><span class="p">.</span><span class="n">pending_batches</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">_process_batch_after_delay</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Process batch after timeout</span><span class="sh">"""</span>
        <span class="k">await</span> <span class="n">asyncio</span><span class="p">.</span><span class="nf">sleep</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">max_wait_ms</span> <span class="o">/</span> <span class="mf">1000.0</span><span class="p">)</span>
        <span class="k">await</span> <span class="n">self</span><span class="p">.</span><span class="nf">_process_batch</span><span class="p">()</span>

<span class="c1"># Usage
</span><span class="n">gpu_processor</span> <span class="o">=</span> <span class="nc">GPUBatchProcessor</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">max_batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

<span class="c1"># Multiple concurrent streams
</span><span class="k">async</span> <span class="k">def</span> <span class="nf">process_stream</span><span class="p">(</span><span class="n">stream_id</span><span class="p">):</span>
    <span class="k">async</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">audio_streams</span><span class="p">[</span><span class="n">stream_id</span><span class="p">]:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">gpu_processor</span><span class="p">.</span><span class="nf">process_chunk_batched</span><span class="p">(</span><span class="n">chunk</span><span class="p">,</span> <span class="n">stream_id</span><span class="p">)</span>
        <span class="k">yield</span> <span class="n">result</span>

<span class="c1"># Run multiple streams in parallel
</span><span class="k">await</span> <span class="n">asyncio</span><span class="p">.</span><span class="nf">gather</span><span class="p">(</span><span class="o">*</span><span class="p">[</span>
    <span class="nf">process_stream</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="p">])</span>
</code></pre></div></div>

<h3 id="3-quantized-models-for-edge-devices">3. Quantized Models for Edge Devices</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torchaudio</span>

<span class="k">class</span> <span class="nc">EdgeOptimizedStreamingASR</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Streaming ASR optimized for edge devices
    
    Uses INT8 quantization for faster inference
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model_path</span><span class="p">):</span>
        <span class="c1"># Load and quantize model
</span>        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">quantization</span><span class="p">.</span><span class="nf">quantize_dynamic</span><span class="p">(</span>
            <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">,</span>
            <span class="p">{</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">LSTM</span><span class="p">},</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">qint8</span>
        <span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">process_chunk_optimized</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio_chunk</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Process chunk with optimizations
        
        - INT8 quantization: 4x faster
        - No gradient computation
        - Minimal memory allocation
        </span><span class="sh">"""</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="c1"># Convert to tensor
</span>            <span class="n">audio_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">from_numpy</span><span class="p">(</span><span class="n">audio_chunk</span><span class="p">).</span><span class="nf">float</span><span class="p">()</span>
            <span class="n">audio_tensor</span> <span class="o">=</span> <span class="n">audio_tensor</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Add batch dim
</span>            
            <span class="c1"># Extract features (optimized)
</span>            <span class="n">features</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="p">.</span><span class="n">compliance</span><span class="p">.</span><span class="n">kaldi</span><span class="p">.</span><span class="nf">mfcc</span><span class="p">(</span>
                <span class="n">audio_tensor</span><span class="p">,</span>
                <span class="n">sample_frequency</span><span class="o">=</span><span class="mi">16000</span><span class="p">,</span>
                <span class="n">num_ceps</span><span class="o">=</span><span class="mi">13</span>
            <span class="p">)</span>
            
            <span class="c1"># Run inference
</span>            <span class="n">output</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
            
            <span class="c1"># Decode
</span>            <span class="n">transcription</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">decode</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
            
            <span class="k">return</span> <span class="n">transcription</span>
    
    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">output</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Simple greedy decoding</span><span class="sh">"""</span>
        <span class="c1"># Get most likely tokens
</span>        <span class="n">tokens</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># Convert to text (simplified)
</span>        <span class="n">transcription</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">tokens_to_text</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">transcription</span>

<span class="c1"># Benchmark: Quantized vs Full Precision
</span><span class="k">def</span> <span class="nf">benchmark_models</span><span class="p">():</span>
    <span class="sh">"""</span><span class="s">Compare quantized vs full precision</span><span class="sh">"""</span>
    <span class="n">full_model</span> <span class="o">=</span> <span class="nf">load_model</span><span class="p">(</span><span class="sh">'</span><span class="s">model_fp32.pt</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">quant_model</span> <span class="o">=</span> <span class="nc">EdgeOptimizedStreamingASR</span><span class="p">(</span><span class="sh">'</span><span class="s">model_int8.pt</span><span class="sh">'</span><span class="p">)</span>
    
    <span class="n">audio_chunk</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">1600</span><span class="p">)</span>  <span class="c1"># 100ms at 16kHz
</span>    
    <span class="c1"># Full precision
</span>    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">full_model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">audio_chunk</span><span class="p">)</span>
    <span class="n">fp32_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>
    
    <span class="c1"># Quantized
</span>    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">quant_model</span><span class="p">.</span><span class="nf">process_chunk_optimized</span><span class="p">(</span><span class="n">audio_chunk</span><span class="p">)</span>
    <span class="n">int8_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>
    
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">FP32: </span><span class="si">{</span><span class="n">fp32_time</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">s</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">INT8: </span><span class="si">{</span><span class="n">int8_time</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">s</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Speedup: </span><span class="si">{</span><span class="n">fp32_time</span> <span class="o">/</span> <span class="n">int8_time</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s">x</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<hr />

<h2 id="real-world-integration-examples">Real-World Integration Examples</h2>

<h3 id="1-zoom-like-meeting-transcription">1. Zoom-like Meeting Transcription</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MeetingTranscriptionService</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Real-time meeting transcription
    
    Similar to Zoom</span><span class="sh">'</span><span class="s">s live transcription
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">asr_model</span> <span class="o">=</span> <span class="nf">load_asr_model</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">active_sessions</span> <span class="o">=</span> <span class="p">{}</span>
    
    <span class="k">def</span> <span class="nf">start_session</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">meeting_id</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Start transcription session</span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="n">active_sessions</span><span class="p">[</span><span class="n">meeting_id</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">participants</span><span class="sh">'</span><span class="p">:</span> <span class="p">{},</span>
            <span class="sh">'</span><span class="s">transcript</span><span class="sh">'</span><span class="p">:</span> <span class="p">[],</span>
            <span class="sh">'</span><span class="s">start_time</span><span class="sh">'</span><span class="p">:</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
        <span class="p">}</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">process_participant_audio</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">meeting_id</span><span class="p">,</span> <span class="n">participant_id</span><span class="p">,</span> <span class="n">audio_stream</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Process audio from single participant
        
        Returns: Real-time transcription
        </span><span class="sh">"""</span>
        <span class="n">session</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">active_sessions</span><span class="p">[</span><span class="n">meeting_id</span><span class="p">]</span>
        
        <span class="c1"># Initialize participant
</span>        <span class="k">if</span> <span class="n">participant_id</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">session</span><span class="p">[</span><span class="sh">'</span><span class="s">participants</span><span class="sh">'</span><span class="p">]:</span>
            <span class="n">session</span><span class="p">[</span><span class="sh">'</span><span class="s">participants</span><span class="sh">'</span><span class="p">][</span><span class="n">participant_id</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                <span class="sh">'</span><span class="s">processor</span><span class="sh">'</span><span class="p">:</span> <span class="nc">StatefulStreamingProcessor</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">asr_model</span><span class="p">),</span>
                <span class="sh">'</span><span class="s">transcript_buffer</span><span class="sh">'</span><span class="p">:</span> <span class="p">[]</span>
            <span class="p">}</span>
        
        <span class="n">participant</span> <span class="o">=</span> <span class="n">session</span><span class="p">[</span><span class="sh">'</span><span class="s">participants</span><span class="sh">'</span><span class="p">][</span><span class="n">participant_id</span><span class="p">]</span>
        <span class="n">processor</span> <span class="o">=</span> <span class="n">participant</span><span class="p">[</span><span class="sh">'</span><span class="s">processor</span><span class="sh">'</span><span class="p">]</span>
        
        <span class="k">async</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">audio_stream</span><span class="p">:</span>
            <span class="c1"># Process chunk
</span>            <span class="n">result</span><span class="p">,</span> <span class="n">is_complete</span> <span class="o">=</span> <span class="n">processor</span><span class="p">.</span><span class="nf">process_chunk</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">is_complete</span><span class="p">:</span>
                <span class="c1"># Add to transcript
</span>                <span class="n">timestamp</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">session</span><span class="p">[</span><span class="sh">'</span><span class="s">start_time</span><span class="sh">'</span><span class="p">]</span>
                <span class="n">transcript_entry</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="sh">'</span><span class="s">participant_id</span><span class="sh">'</span><span class="p">:</span> <span class="n">participant_id</span><span class="p">,</span>
                    <span class="sh">'</span><span class="s">text</span><span class="sh">'</span><span class="p">:</span> <span class="n">result</span><span class="p">[</span><span class="sh">'</span><span class="s">text</span><span class="sh">'</span><span class="p">],</span>
                    <span class="sh">'</span><span class="s">timestamp</span><span class="sh">'</span><span class="p">:</span> <span class="n">timestamp</span><span class="p">,</span>
                    <span class="sh">'</span><span class="s">confidence</span><span class="sh">'</span><span class="p">:</span> <span class="n">result</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">confidence</span><span class="sh">'</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
                <span class="p">}</span>
                
                <span class="n">session</span><span class="p">[</span><span class="sh">'</span><span class="s">transcript</span><span class="sh">'</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="n">transcript_entry</span><span class="p">)</span>
                
                <span class="k">yield</span> <span class="n">transcript_entry</span>
    
    <span class="k">def</span> <span class="nf">get_full_transcript</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">meeting_id</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Get complete meeting transcript</span><span class="sh">"""</span>
        <span class="k">if</span> <span class="n">meeting_id</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">active_sessions</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>
        
        <span class="n">transcript</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">active_sessions</span><span class="p">[</span><span class="n">meeting_id</span><span class="p">][</span><span class="sh">'</span><span class="s">transcript</span><span class="sh">'</span><span class="p">]</span>
        
        <span class="c1"># Format as readable text
</span>        <span class="n">formatted</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">transcript</span><span class="p">:</span>
            <span class="n">time_str</span> <span class="o">=</span> <span class="nf">format_timestamp</span><span class="p">(</span><span class="n">entry</span><span class="p">[</span><span class="sh">'</span><span class="s">timestamp</span><span class="sh">'</span><span class="p">])</span>
            <span class="n">formatted</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span>
                <span class="sa">f</span><span class="sh">"</span><span class="s">[</span><span class="si">{</span><span class="n">time_str</span><span class="si">}</span><span class="s">] Participant </span><span class="si">{</span><span class="n">entry</span><span class="p">[</span><span class="sh">'</span><span class="s">participant_id</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">entry</span><span class="p">[</span><span class="sh">'</span><span class="s">text</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="sh">"</span>
            <span class="p">)</span>
        
        <span class="k">return</span> <span class="sh">'</span><span class="se">\n</span><span class="sh">'</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">formatted</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">format_timestamp</span><span class="p">(</span><span class="n">seconds</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Format seconds as MM:SS</span><span class="sh">"""</span>
    <span class="n">minutes</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">seconds</span> <span class="o">//</span> <span class="mi">60</span><span class="p">)</span>
    <span class="n">secs</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">seconds</span> <span class="o">%</span> <span class="mi">60</span><span class="p">)</span>
    <span class="k">return</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">minutes</span><span class="si">:</span><span class="mi">02</span><span class="n">d</span><span class="si">}</span><span class="s">:</span><span class="si">{</span><span class="n">secs</span><span class="si">:</span><span class="mi">02</span><span class="n">d</span><span class="si">}</span><span class="sh">"</span>

<span class="c1"># Usage
</span><span class="n">service</span> <span class="o">=</span> <span class="nc">MeetingTranscriptionService</span><span class="p">()</span>
<span class="n">service</span><span class="p">.</span><span class="nf">start_session</span><span class="p">(</span><span class="sh">'</span><span class="s">meeting-123</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Process audio from multiple participants
</span><span class="k">async</span> <span class="k">def</span> <span class="nf">transcribe_meeting</span><span class="p">():</span>
    <span class="n">participants</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">user1</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">user2</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">user3</span><span class="sh">'</span><span class="p">]</span>
    
    <span class="c1"># Process all participants in parallel
</span>    <span class="n">tasks</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">service</span><span class="p">.</span><span class="nf">process_participant_audio</span><span class="p">(</span>
            <span class="sh">'</span><span class="s">meeting-123</span><span class="sh">'</span><span class="p">,</span>
            <span class="n">participant_id</span><span class="p">,</span>
            <span class="nf">get_audio_stream</span><span class="p">(</span><span class="n">participant_id</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">participant_id</span> <span class="ow">in</span> <span class="n">participants</span>
    <span class="p">]</span>
    
    <span class="c1"># Collect transcriptions
</span>    <span class="c1"># Collect tasks concurrently
</span>    <span class="n">results</span> <span class="o">=</span> <span class="k">await</span> <span class="n">asyncio</span><span class="p">.</span><span class="nf">gather</span><span class="p">(</span><span class="o">*</span><span class="n">tasks</span><span class="p">,</span> <span class="n">return_exceptions</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">res</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
        <span class="k">if</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="nb">Exception</span><span class="p">):</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Stream error: </span><span class="si">{</span><span class="n">res</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">res</span><span class="p">:</span>
                <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">[</span><span class="si">{</span><span class="n">entry</span><span class="p">[</span><span class="sh">'</span><span class="s">timestamp</span><span class="sh">'</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s">s] </span><span class="si">{</span><span class="n">entry</span><span class="p">[</span><span class="sh">'</span><span class="s">participant_id</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">entry</span><span class="p">[</span><span class="sh">'</span><span class="s">text</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="2-voice-assistant-backend">2. Voice Assistant Backend</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">VoiceAssistantPipeline</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Complete voice assistant pipeline
    
    ASR → NLU → Action → TTS
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">asr</span> <span class="o">=</span> <span class="nc">StreamingASR</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">nlu</span> <span class="o">=</span> <span class="nc">IntentClassifier</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">action_executor</span> <span class="o">=</span> <span class="nc">ActionExecutor</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">tts</span> <span class="o">=</span> <span class="nc">TextToSpeech</span><span class="p">()</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">process_voice_command</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio_stream</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Process voice command end-to-end
        
        Returns: Audio response
        </span><span class="sh">"""</span>
        <span class="c1"># 1. Speech Recognition
</span>        <span class="n">transcription</span> <span class="o">=</span> <span class="k">await</span> <span class="n">self</span><span class="p">.</span><span class="n">asr</span><span class="p">.</span><span class="nf">transcribe_stream</span><span class="p">(</span><span class="n">audio_stream</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">User said: </span><span class="si">{</span><span class="n">transcription</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="c1"># 2. Natural Language Understanding
</span>        <span class="n">intent</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">nlu</span><span class="p">.</span><span class="nf">classify</span><span class="p">(</span><span class="n">transcription</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Intent: </span><span class="si">{</span><span class="n">intent</span><span class="p">[</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="s"> (confidence: </span><span class="si">{</span><span class="n">intent</span><span class="p">[</span><span class="sh">'</span><span class="s">confidence</span><span class="sh">'</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">)</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="c1"># 3. Execute Action
</span>        <span class="k">if</span> <span class="n">intent</span><span class="p">[</span><span class="sh">'</span><span class="s">confidence</span><span class="sh">'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.7</span><span class="p">:</span>
            <span class="n">response_text</span> <span class="o">=</span> <span class="k">await</span> <span class="n">self</span><span class="p">.</span><span class="n">action_executor</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="n">intent</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">response_text</span> <span class="o">=</span> <span class="sh">"</span><span class="s">I</span><span class="sh">'</span><span class="s">m not sure what you mean. Could you rephrase that?</span><span class="sh">"</span>
        
        <span class="c1"># 4. Text-to-Speech
</span>        <span class="n">response_audio</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">tts</span><span class="p">.</span><span class="nf">synthesize</span><span class="p">(</span><span class="n">response_text</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">transcription</span><span class="sh">'</span><span class="p">:</span> <span class="n">transcription</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">intent</span><span class="sh">'</span><span class="p">:</span> <span class="n">intent</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">response_text</span><span class="sh">'</span><span class="p">:</span> <span class="n">response_text</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">response_audio</span><span class="sh">'</span><span class="p">:</span> <span class="n">response_audio</span>
        <span class="p">}</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">continuous_listening</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio_source</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Continuously listen for wake word + command
        
        Efficient always-on listening
        </span><span class="sh">"""</span>
        <span class="n">wake_word_detector</span> <span class="o">=</span> <span class="nc">WakeWordDetector</span><span class="p">(</span><span class="sh">'</span><span class="s">hey assistant</span><span class="sh">'</span><span class="p">)</span>
        
        <span class="k">async</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">audio_source</span><span class="p">:</span>
            <span class="c1"># Check for wake word (lightweight model)
</span>            <span class="k">if</span> <span class="n">wake_word_detector</span><span class="p">.</span><span class="nf">detect</span><span class="p">(</span><span class="n">chunk</span><span class="p">):</span>
                <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">🎤 Wake word detected!</span><span class="sh">"</span><span class="p">)</span>
                
                <span class="c1"># Start full ASR
</span>                <span class="n">command_audio</span> <span class="o">=</span> <span class="k">await</span> <span class="n">self</span><span class="p">.</span><span class="nf">capture_command</span><span class="p">(</span><span class="n">audio_source</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mf">5.0</span><span class="p">)</span>
                
                <span class="c1"># Process command
</span>                <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">self</span><span class="p">.</span><span class="nf">process_voice_command</span><span class="p">(</span><span class="n">command_audio</span><span class="p">)</span>
                
                <span class="c1"># Play response
</span>                <span class="nf">play_audio</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="sh">'</span><span class="s">response_audio</span><span class="sh">'</span><span class="p">])</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">capture_command</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio_source</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mf">5.0</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Capture audio command after wake word</span><span class="sh">"""</span>
        <span class="n">command_chunks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
        
        <span class="k">async</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">audio_source</span><span class="p">:</span>
            <span class="n">command_chunks</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
            
            <span class="c1"># Check timeout
</span>            <span class="k">if</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span> <span class="o">&gt;</span> <span class="n">timeout</span><span class="p">:</span>
                <span class="k">break</span>
            
            <span class="c1"># Check for end of speech (silence)
</span>            <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="nf">is_silence</span><span class="p">(</span><span class="n">chunk</span><span class="p">):</span>
                <span class="k">break</span>
        
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">(</span><span class="n">command_chunks</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">is_silence</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">chunk</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Detect if chunk is silence</span><span class="sh">"""</span>
        <span class="n">energy</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">chunk</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">energy</span> <span class="o">&lt;</span> <span class="n">threshold</span>

<span class="c1"># Usage
</span><span class="n">assistant</span> <span class="o">=</span> <span class="nc">VoiceAssistantPipeline</span><span class="p">()</span>

<span class="c1"># Continuous listening
</span><span class="k">await</span> <span class="n">assistant</span><span class="p">.</span><span class="nf">continuous_listening</span><span class="p">(</span><span class="n">microphone_stream</span><span class="p">)</span>
</code></pre></div></div>

<hr />

<h2 id="performance-metrics--slas">Performance Metrics &amp; SLAs</h2>

<h3 id="latency-tracking">Latency Tracking</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">StreamingLatencyTracker</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Track end-to-end latency for streaming pipeline
    
    Measures:
    - Audio capture latency
    - Network latency
    - Processing latency
    - Total latency
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">capture_latency</span><span class="sh">'</span><span class="p">:</span> <span class="p">[],</span>
            <span class="sh">'</span><span class="s">network_latency</span><span class="sh">'</span><span class="p">:</span> <span class="p">[],</span>
            <span class="sh">'</span><span class="s">processing_latency</span><span class="sh">'</span><span class="p">:</span> <span class="p">[],</span>
            <span class="sh">'</span><span class="s">total_latency</span><span class="sh">'</span><span class="p">:</span> <span class="p">[]</span>
        <span class="p">}</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">process_with_tracking</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio_chunk</span><span class="p">,</span> <span class="n">capture_timestamp</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Process chunk with latency tracking
        
        Args:
            audio_chunk: Audio data
            capture_timestamp: When audio was captured
        
        Returns: (result, latency_breakdown)
        </span><span class="sh">"""</span>
        <span class="c1"># Network latency (time from capture to arrival)
</span>        <span class="n">network_start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
        <span class="n">network_latency</span> <span class="o">=</span> <span class="p">(</span><span class="n">network_start</span> <span class="o">-</span> <span class="n">capture_timestamp</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span>
        <span class="n">self</span><span class="p">.</span><span class="n">metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">network_latency</span><span class="sh">'</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="n">network_latency</span><span class="p">)</span>
        
        <span class="c1"># Processing latency
</span>        <span class="n">processing_start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
        <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">self</span><span class="p">.</span><span class="nf">process_chunk</span><span class="p">(</span><span class="n">audio_chunk</span><span class="p">)</span>
        <span class="n">processing_end</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
        <span class="n">processing_latency</span> <span class="o">=</span> <span class="p">(</span><span class="n">processing_end</span> <span class="o">-</span> <span class="n">processing_start</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span>
        <span class="n">self</span><span class="p">.</span><span class="n">metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">processing_latency</span><span class="sh">'</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="n">processing_latency</span><span class="p">)</span>
        
        <span class="c1"># Total latency
</span>        <span class="n">total_latency</span> <span class="o">=</span> <span class="p">(</span><span class="n">processing_end</span> <span class="o">-</span> <span class="n">capture_timestamp</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span>
        <span class="n">self</span><span class="p">.</span><span class="n">metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">total_latency</span><span class="sh">'</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="n">total_latency</span><span class="p">)</span>
        
        <span class="n">latency_breakdown</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">network_ms</span><span class="sh">'</span><span class="p">:</span> <span class="n">network_latency</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">processing_ms</span><span class="sh">'</span><span class="p">:</span> <span class="n">processing_latency</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">total_ms</span><span class="sh">'</span><span class="p">:</span> <span class="n">total_latency</span>
        <span class="p">}</span>
        
        <span class="k">return</span> <span class="n">result</span><span class="p">,</span> <span class="n">latency_breakdown</span>
    
    <span class="k">def</span> <span class="nf">get_latency_stats</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Get latency statistics</span><span class="sh">"""</span>
        <span class="n">stats</span> <span class="o">=</span> <span class="p">{}</span>
        
        <span class="k">for</span> <span class="n">metric_name</span><span class="p">,</span> <span class="n">values</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">values</span><span class="p">:</span>
                <span class="n">stats</span><span class="p">[</span><span class="n">metric_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="sh">'</span><span class="s">p50</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
                    <span class="sh">'</span><span class="s">p95</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="mi">95</span><span class="p">),</span>
                    <span class="sh">'</span><span class="s">p99</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="mi">99</span><span class="p">),</span>
                    <span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">values</span><span class="p">),</span>
                    <span class="sh">'</span><span class="s">max</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
                <span class="p">}</span>
        
        <span class="k">return</span> <span class="n">stats</span>
    
    <span class="k">def</span> <span class="nf">check_sla</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">sla_ms</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Check if meeting SLA
        
        Returns: (is_meeting_sla, violation_rate)
        </span><span class="sh">"""</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">self</span><span class="p">.</span><span class="n">metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">total_latency</span><span class="sh">'</span><span class="p">]:</span>
            <span class="k">return</span> <span class="bp">True</span><span class="p">,</span> <span class="mf">0.0</span>
        
        <span class="n">violations</span> <span class="o">=</span> <span class="nf">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">lat</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">total_latency</span><span class="sh">'</span><span class="p">]</span> <span class="k">if</span> <span class="n">lat</span> <span class="o">&gt;</span> <span class="n">sla_ms</span><span class="p">)</span>
        <span class="n">violation_rate</span> <span class="o">=</span> <span class="n">violations</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">total_latency</span><span class="sh">'</span><span class="p">])</span>
        
        <span class="n">is_meeting_sla</span> <span class="o">=</span> <span class="n">violation_rate</span> <span class="o">&lt;</span> <span class="mf">0.01</span>  <span class="c1"># &lt; 1% violations
</span>        
        <span class="k">return</span> <span class="n">is_meeting_sla</span><span class="p">,</span> <span class="n">violation_rate</span>

<span class="c1"># Usage
</span><span class="n">tracker</span> <span class="o">=</span> <span class="nc">StreamingLatencyTracker</span><span class="p">()</span>

<span class="c1"># Process with tracking
</span><span class="n">result</span><span class="p">,</span> <span class="n">latency</span> <span class="o">=</span> <span class="k">await</span> <span class="n">tracker</span><span class="p">.</span><span class="nf">process_with_tracking</span><span class="p">(</span><span class="n">chunk</span><span class="p">,</span> <span class="n">capture_time</span><span class="p">)</span>

<span class="c1"># Check SLA
</span><span class="n">is_ok</span><span class="p">,</span> <span class="n">violation_rate</span> <span class="o">=</span> <span class="n">tracker</span><span class="p">.</span><span class="nf">check_sla</span><span class="p">(</span><span class="n">sla_ms</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">is_ok</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">⚠️ SLA violation rate: </span><span class="si">{</span><span class="n">violation_rate</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="o">%</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Get detailed stats
</span><span class="n">stats</span> <span class="o">=</span> <span class="n">tracker</span><span class="p">.</span><span class="nf">get_latency_stats</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">P95 latency: </span><span class="si">{</span><span class="n">stats</span><span class="p">[</span><span class="sh">'</span><span class="s">total_latency</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">p95</span><span class="sh">'</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s">ms</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<hr />

<h2 id="key-takeaways">Key Takeaways</h2>

<p>✅ <strong>Chunk audio correctly</strong> - Balance latency vs context<br />
✅ <strong>Manage state</strong> - RNN/LSTM models need previous chunks<br />
✅ <strong>Optimize latency</strong> - Smaller chunks, quantization, prefetching<br />
✅ <strong>Handle errors gracefully</strong> - Network failures, audio glitches<br />
✅ <strong>Validate inputs</strong> - Like BST range checking<br />
✅ <strong>Monitor performance</strong> - Latency, error rate, throughput<br />
✅ <strong>WebSocket for streaming</strong> - Bidirectional, low-latency</p>

<hr />

<p><strong>Originally published at:</strong> <a href="https://www.arunbaby.com/speech-tech/0008-streaming-speech-pipeline/">arunbaby.com/speech-tech/0008-streaming-speech-pipeline</a></p>

<p><em>If you found this helpful, consider sharing it with others who might benefit.</em></p>


        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#latency" class="page__taxonomy-item p-category" rel="tag">latency</a><span class="sep">, </span>
    
      <a href="/tags/#pipeline" class="page__taxonomy-item p-category" rel="tag">pipeline</a><span class="sep">, </span>
    
      <a href="/tags/#real-time" class="page__taxonomy-item p-category" rel="tag">real-time</a><span class="sep">, </span>
    
      <a href="/tags/#streaming" class="page__taxonomy-item p-category" rel="tag">streaming</a><span class="sep">, </span>
    
      <a href="/tags/#websockets" class="page__taxonomy-item p-category" rel="tag">websockets</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#speech-tech" class="page__taxonomy-item p-category" rel="tag">speech-tech</a>
    
    </span>
  </p>


        
      </footer>

      <div class="page__related page__related--full">
  <h2 class="page__related-title">Related across topics</h2>
  <style>
    /* Make section span full content width and use 2 equal columns */
    .page__related--full { float: inline-start; width: 100%; padding: 0; }
    .cross-related-grid { display: grid; grid-template-columns: repeat(2, minmax(0, 1fr)); gap: 2rem; }
    @media (max-width: 768px) { .cross-related-grid { grid-template-columns: 1fr; } }
    /* Ensure archive cards stretch nicely in the grid */
    .cross-related-grid .list__item, .cross-related-grid .grid__item { width: auto; float: none; margin: 0; }
  </style>
  <div class="cross-related-grid">
    



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/dsa/0008-validate-binary-search-tree/" rel="permalink">Validate Binary Search Tree
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          23 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Master BST validation to understand data integrity in tree structures, critical for indexing and search systems.
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ml-system-design/0008-model-serving-architecture/" rel="permalink">Model Serving Architecture
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          22 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Design production-grade model serving systems that deliver predictions at scale with low latency and high reliability.
</p>
  </article>
</div>

  </div>
</div>

      <section class="page__share">
  <h4 class="page__share-title">Share on</h4>

  <a href="https://twitter.com/intent/tweet?via=arunbaby0&text=Streaming+Speech+Processing+Pipeline%20https%3A%2F%2Fwww.arunbaby.com%2Fspeech-tech%2F0008-streaming-speech-pipeline%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.arunbaby.com%2Fspeech-tech%2F0008-streaming-speech-pipeline%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.arunbaby.com/speech-tech/0008-streaming-speech-pipeline/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/speech-tech/0007-audio-preprocessing/" class="pagination--pager" title="Audio Preprocessing &amp; Signal Processing">Previous</a>
    
    
      <a href="/speech-tech/0009-keyword-spotting/" class="pagination--pager" title="Real-time Keyword Spotting">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 1990 - 2143 <a href="https://www.arunbaby.com">Arun Baby</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JRJPEC9SS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0JRJPEC9SS', { 'anonymize_ip': false});
</script>








  </body>
</html>
