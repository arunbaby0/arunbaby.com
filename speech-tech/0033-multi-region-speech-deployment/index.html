<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Multi-region Speech Deployment - Arun Baby</title>
<meta name="description" content="“Deploying speech models close to users for low-latency voice experiences.”">


  <meta name="author" content="Arun Baby">
  
  <meta property="article:author" content="Arun Baby">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Arun Baby">
<meta property="og:title" content="Multi-region Speech Deployment">
<meta property="og:url" content="https://www.arunbaby.com/speech-tech/0033-multi-region-speech-deployment/">


  <meta property="og:description" content="“Deploying speech models close to users for low-latency voice experiences.”">



  <meta property="og:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">



  <meta name="twitter:site" content="@arunbaby0">
  <meta name="twitter:title" content="Multi-region Speech Deployment">
  <meta name="twitter:description" content="“Deploying speech models close to users for low-latency voice experiences.”">
  <meta name="twitter:url" content="https://www.arunbaby.com/speech-tech/0033-multi-region-speech-deployment/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">
    
  

  



  <meta property="article:published_time" content="2025-12-14T12:09:57+05:30">





  

  


<link rel="canonical" href="https://www.arunbaby.com/speech-tech/0033-multi-region-speech-deployment/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Baby Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          <span class="site-subtitle">Arun Baby</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/dsa/"
                
                
              >DSA</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ml-system-design/"
                
                
              >ML Systems</a>
            </li><li class="masthead__menu-item">
              <a
                href="/speech-tech/"
                
                
              >Speech Tech</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li><li class="masthead__menu-item">
              <a
                href="/statuses/"
                
                
              >Statuses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/contact/"
                
                
              >Contact</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main" class="no-author-sidebar">
  
  <div class="sidebar sticky">
  
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Multi-region Speech Deployment">
    <meta itemprop="description" content="“Deploying speech models close to users for low-latency voice experiences.”">
    <meta itemprop="datePublished" content="2025-12-14T12:09:57+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://www.arunbaby.com/speech-tech/0033-multi-region-speech-deployment/" itemprop="url">Multi-region Speech Deployment
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          20 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#1-the-challenge-speech-requires-real-time-performance">1. The Challenge: Speech Requires Real-Time Performance</a></li><li><a href="#2-multi-region-architecture-overview">2. Multi-Region Architecture Overview</a></li><li><a href="#3-geodns-routing">3. GeoDNS Routing</a></li><li><a href="#4-edge-deployment-for-ultra-low-latency">4. Edge Deployment for Ultra-Low Latency</a></li><li><a href="#5-deep-dive-model-synchronization-across-regions">5. Deep Dive: Model Synchronization Across Regions</a><ul><li><a href="#strategy-1-centralized-model-registry">Strategy 1: Centralized Model Registry</a></li><li><a href="#strategy-2-regional-model-stores">Strategy 2: Regional Model Stores</a></li></ul></li><li><a href="#6-deep-dive-handling-regional-data-compliance-gdpr">6. Deep Dive: Handling Regional Data Compliance (GDPR)</a></li><li><a href="#7-deep-dive-canary-deployment-in-multi-region">7. Deep Dive: Canary Deployment in Multi-Region</a></li><li><a href="#8-deep-dive-fallback-and-disaster-recovery">8. Deep Dive: Fallback and Disaster Recovery</a><ul><li><a href="#fallback-strategy-1-route-to-nearest-healthy-region">Fallback Strategy 1: Route to Nearest Healthy Region</a></li><li><a href="#fallback-strategy-2-multi-region-active-active">Fallback Strategy 2: Multi-Region Active-Active</a></li></ul></li><li><a href="#9-deep-dive-caching-at-edge-and-regional-layers">9. Deep Dive: Caching at Edge and Regional Layers</a></li><li><a href="#10-deep-dive-model-compression-for-edge-deployment">10. Deep Dive: Model Compression for Edge Deployment</a></li><li><a href="#11-deep-dive-monitoring-multi-region-deployments">11. Deep Dive: Monitoring Multi-Region Deployments</a></li><li><a href="#12-real-world-case-studies">12. Real-World Case Studies</a><ul><li><a href="#case-study-1-google-assistant-multi-region">Case Study 1: Google Assistant Multi-Region</a></li><li><a href="#case-study-2-amazon-alexa-edge-deployment">Case Study 2: Amazon Alexa Edge Deployment</a></li><li><a href="#case-study-3-zooms-real-time-transcription">Case Study 3: Zoom’s Real-Time Transcription</a></li></ul></li><li><a href="#implementation-multi-region-speech-api">Implementation: Multi-Region Speech API</a></li><li><a href="#top-interview-questions">Top Interview Questions</a></li><li><a href="#13-deep-dive-streaming-asr-with-webrtc">13. Deep Dive: Streaming ASR with WebRTC</a></li><li><a href="#14-deep-dive-voice-quality-monitoring">14. Deep Dive: Voice Quality Monitoring</a></li><li><a href="#15-deep-dive-bandwidth-management">15. Deep Dive: Bandwidth Management</a></li><li><a href="#16-deep-dive-cost-optimization-for-global-speech">16. Deep Dive: Cost Optimization for Global Speech</a></li><li><a href="#17-deep-dive-multi-language-support">17. Deep Dive: Multi-Language Support</a></li><li><a href="#18-deep-dive-failover-testing-and-chaos-engineering">18. Deep Dive: Failover Testing and Chaos Engineering</a></li><li><a href="#19-deep-dive-shadow-traffic-for-model-validation">19. Deep Dive: Shadow Traffic for Model Validation</a></li><li><a href="#20-production-war-stories">20. Production War Stories</a></li><li><a href="#21-deep-dive-network-optimization-for-speech">21. Deep Dive: Network Optimization for Speech</a></li><li><a href="#22-deep-dive-latency-slas-and-penalties">22. Deep Dive: Latency SLAs and Penalties</a></li><li><a href="#23-production-deployment-checklist">23. Production Deployment Checklist</a></li><li><a href="#24-future-trends-serverless-speech">24. Future Trends: Serverless Speech</a></li><li><a href="#key-takeaways">Key Takeaways</a></li><li><a href="#summary">Summary</a></li></ul>
            </nav>
          </aside>
        
        <p><strong>“Deploying speech models close to users for low-latency voice experiences.”</strong></p>

<h2 id="1-the-challenge-speech-requires-real-time-performance">1. The Challenge: Speech Requires Real-Time Performance</h2>

<p>Speech applications have <strong>strict latency requirements</strong>:</p>
<ul>
  <li><strong>Voice Assistants:</strong> Users expect responses in &lt; 300ms.</li>
  <li><strong>Live Captioning:</strong> Must transcribe as the speaker talks (&lt; 100ms lag).</li>
  <li><strong>Voice Calls:</strong> Any delay &gt; 150ms is noticeable and disruptive.</li>
</ul>

<p><strong>Why Multi-Region Deployment?</strong></p>
<ul>
  <li>A single data center in Virginia serves users in Tokyo with 250ms network latency.</li>
  <li>Deploying ASR models in Tokyo reduces latency to 20ms.</li>
</ul>

<h2 id="2-multi-region-architecture-overview">2. Multi-Region Architecture Overview</h2>

<p><strong>Architecture:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        Global Load Balancer (AWS Route 53, Cloudflare)
                    |
    ---------------------------------
    |               |               |
  US-West         EU-West        Asia-Pacific
  (Oregon)        (Frankfurt)     (Tokyo)
    |               |               |
  ASR Model       ASR Model       ASR Model
  TTS Model       TTS Model       TTS Model
  Speaker ID      Speaker ID      Speaker ID
</code></pre></div></div>

<p><strong>Key Components:</strong></p>
<ol>
  <li><strong>Global Load Balancer:</strong> Routes users to the nearest region (GeoDNS).</li>
  <li><strong>Regional Clusters:</strong> Each region has a full stack of speech models.</li>
  <li><strong>Model Sync:</strong> Ensures all regions serve the same model version.</li>
</ol>

<h2 id="3-geodns-routing">3. GeoDNS Routing</h2>

<p><strong>Concept:</strong> Direct users to the closest data center based on their geographic location.</p>

<p><strong>Implementation:</strong></p>
<ul>
  <li><strong>AWS Route 53:</strong> Geolocation routing policy.</li>
  <li><strong>Cloudflare:</strong> Automatic geo-routing via Anycast.</li>
</ul>

<p><strong>Example (Route 53):</strong></p>
<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"Name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"speech-api.example.com"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"Type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"A"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"GeoLocation"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"ContinentCode"</span><span class="p">:</span><span class="w"> </span><span class="s2">"NA"</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"ResourceRecords"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="p">{</span><span class="nl">"Value"</span><span class="p">:</span><span class="w"> </span><span class="s2">"3.12.45.67"</span><span class="p">}</span><span class="w">  </span><span class="err">//</span><span class="w"> </span><span class="err">US-West</span><span class="w"> </span><span class="err">IP</span><span class="w">
  </span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>Users in North America get routed to <code class="language-plaintext highlighter-rouge">3.12.45.67</code> (US-West).
Users in Europe get routed to EU-West.</p>

<p><strong>Pros:</strong></p>
<ul>
  <li>Reduces latency by 80%+.</li>
  <li>Automatic failover (if a region goes down, route to the next closest).</li>
</ul>

<p><strong>Cons:</strong></p>
<ul>
  <li>DNS caching (TTL = 60s) can delay failover.</li>
</ul>

<h2 id="4-edge-deployment-for-ultra-low-latency">4. Edge Deployment for Ultra-Low Latency</h2>

<p>For applications like voice calls or gaming, even 50ms is too much. Deploy models at the <strong>edge</strong> (CDN points of presence).</p>

<p><strong>Edge Locations:</strong></p>
<ul>
  <li>AWS has 400+ edge locations.</li>
  <li>Cloudflare has 300+ PoPs.</li>
</ul>

<p><strong>Architecture:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>User in Berlin → Cloudflare PoP (Berlin) → ASR Model (Frankfurt)
                       ↑
                  Model cached at edge
</code></pre></div></div>

<p><strong>Implementation (AWS Lambda@Edge):</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">json</span>

<span class="k">def</span> <span class="nf">lambda_handler</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
    <span class="c1"># Run lightweight ASR model at edge
</span>    <span class="n">audio_data</span> <span class="o">=</span> <span class="n">event</span><span class="p">[</span><span class="sh">'</span><span class="s">body</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">transcript</span> <span class="o">=</span> <span class="n">edge_asr_model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">audio_data</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="p">{</span>
        <span class="sh">'</span><span class="s">statusCode</span><span class="sh">'</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">body</span><span class="sh">'</span><span class="p">:</span> <span class="n">json</span><span class="p">.</span><span class="nf">dumps</span><span class="p">({</span><span class="sh">'</span><span class="s">transcript</span><span class="sh">'</span><span class="p">:</span> <span class="n">transcript</span><span class="p">})</span>
    <span class="p">}</span>
</code></pre></div></div>

<p><strong>Trade-offs:</strong></p>
<ul>
  <li><strong>Pros:</strong> &lt; 10ms latency.</li>
  <li><strong>Cons:</strong> Edge environments have limited compute (no GPU). Must use quantized/lightweight models.</li>
</ul>

<h2 id="5-deep-dive-model-synchronization-across-regions">5. Deep Dive: Model Synchronization Across Regions</h2>

<p><strong>Challenge:</strong> You train a new ASR model in US-West. How do you deploy it to 10 regions?</p>

<h3 id="strategy-1-centralized-model-registry">Strategy 1: Centralized Model Registry</h3>
<p>A single S3 bucket (replicated globally) stores all model versions.</p>

<p><strong>Flow:</strong></p>
<ol>
  <li>Upload model to <code class="language-plaintext highlighter-rouge">s3://global-models/asr-v100.pt</code>.</li>
  <li>S3 replicates to all regions (automated cross-region replication).</li>
  <li>Each regional cluster pulls the latest model.</li>
</ol>

<p><strong>AWS S3 Cross-Region Replication:</strong></p>
<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"Role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"arn:aws:iam::123456789:role/s3-replication"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"Rules"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"Status"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Enabled"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"Priority"</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w">
      </span><span class="nl">"Filter"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nl">"Prefix"</span><span class="p">:</span><span class="w"> </span><span class="s2">"models/"</span><span class="p">},</span><span class="w">
      </span><span class="nl">"Destination"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"Bucket"</span><span class="p">:</span><span class="w"> </span><span class="s2">"arn:aws:s3:::models-eu-west"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"ReplicationTime"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nl">"Status"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Enabled"</span><span class="p">,</span><span class="w"> </span><span class="nl">"Time"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nl">"Minutes"</span><span class="p">:</span><span class="w"> </span><span class="mi">15</span><span class="p">}}</span><span class="w">
      </span><span class="p">}</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>Models replicate within 15 minutes.</p>

<h3 id="strategy-2-regional-model-stores">Strategy 2: Regional Model Stores</h3>
<p>Each region has its own S3 bucket. A deployment pipeline copies models to all buckets.</p>

<p><strong>Terraform Script:</strong></p>
<div class="language-hcl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">resource</span> <span class="s2">"aws_s3_bucket"</span> <span class="s2">"model_store"</span> <span class="p">{</span>
  <span class="nx">for_each</span> <span class="o">=</span> <span class="nx">toset</span><span class="p">([</span><span class="s2">"us-west-2"</span><span class="p">,</span> <span class="s2">"eu-west-1"</span><span class="p">,</span> <span class="s2">"ap-southeast-1"</span><span class="p">])</span>
  <span class="nx">bucket</span>   <span class="o">=</span> <span class="s2">"speech-models-${each.value}"</span>
  <span class="nx">region</span>   <span class="o">=</span> <span class="nx">each</span><span class="p">.</span><span class="nx">value</span>
<span class="p">}</span>

<span class="nx">resource</span> <span class="s2">"aws_s3_bucket_object"</span> <span class="s2">"model"</span> <span class="p">{</span>
  <span class="nx">for_each</span> <span class="o">=</span> <span class="nx">aws_s3_bucket</span><span class="p">.</span><span class="nx">model_store</span>
  <span class="nx">bucket</span>   <span class="o">=</span> <span class="nx">each</span><span class="p">.</span><span class="nx">value</span><span class="p">.</span><span class="nx">id</span>
  <span class="nx">key</span>      <span class="o">=</span> <span class="s2">"asr-v100.pt"</span>
  <span class="nx">source</span>   <span class="o">=</span> <span class="s2">"models/asr-v100.pt"</span>
<span class="p">}</span>
</code></pre></div></div>

<p><strong>Pros:</strong> Independent regions (failure in one doesn’t affect others).
<strong>Cons:</strong> Deployment latency (sequential uploads).</p>

<h2 id="6-deep-dive-handling-regional-data-compliance-gdpr">6. Deep Dive: Handling Regional Data Compliance (GDPR)</h2>

<p><strong>Problem:</strong> EU regulations (GDPR) require that user audio data stays in the EU.</p>

<p><strong>Architecture:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>EU User → EU Load Balancer → EU ASR Model → EU Storage
   ↓
Audio NEVER leaves EU
</code></pre></div></div>

<p><strong>Implementation:</strong></p>
<ul>
  <li><strong>Network Policies:</strong> Block cross-region traffic from EU to US.</li>
  <li><strong>IAM Roles:</strong> EU instances can only access EU S3 buckets.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># In EU region only
</span><span class="n">AWS_REGION</span> <span class="o">=</span> <span class="sh">"</span><span class="s">eu-west-1</span><span class="sh">"</span>
<span class="n">s3_client</span> <span class="o">=</span> <span class="n">boto3</span><span class="p">.</span><span class="nf">client</span><span class="p">(</span><span class="sh">'</span><span class="s">s3</span><span class="sh">'</span><span class="p">,</span> <span class="n">region_name</span><span class="o">=</span><span class="n">AWS_REGION</span><span class="p">)</span>

<span class="c1"># This will fail if model is in US bucket
</span><span class="n">model</span> <span class="o">=</span> <span class="n">s3_client</span><span class="p">.</span><span class="nf">get_object</span><span class="p">(</span><span class="n">Bucket</span><span class="o">=</span><span class="sh">'</span><span class="s">models-us-west</span><span class="sh">'</span><span class="p">,</span> <span class="n">Key</span><span class="o">=</span><span class="sh">'</span><span class="s">asr.pt</span><span class="sh">'</span><span class="p">)</span>
<span class="c1"># Error: Access Denied
</span></code></pre></div></div>

<p><strong>Separate Training Pipelines:</strong></p>
<ul>
  <li><strong>EU Model:</strong> Trained only on EU user data.</li>
  <li><strong>US Model:</strong> Trained only on US user data.</li>
  <li>Models may have different vocabularies (accents, slang).</li>
</ul>

<h2 id="7-deep-dive-canary-deployment-in-multi-region">7. Deep Dive: Canary Deployment in Multi-Region</h2>

<p><strong>Scenario:</strong> Deploy a new TTS model to 5 regions.</p>

<p><strong>Strategy:</strong></p>
<ol>
  <li><strong>Deploy to 1% of servers in US-West</strong> (canary).</li>
  <li>Monitor for 24 hours (latency, error rate, voice quality scores).</li>
  <li>If healthy, roll out to <strong>all servers in US-West</strong>.</li>
  <li>If still healthy, roll out to <strong>EU-West</strong>, then <strong>Asia-Pacific</strong>.</li>
</ol>

<p><strong>Kubernetes Deployment:</strong></p>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">tts-v2-canary</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">us-west</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">1</span>  <span class="c1"># 1% of 100 total replicas</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">tts</span>
      <span class="na">version</span><span class="pi">:</span> <span class="s">v2</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">tts</span>
        <span class="na">image</span><span class="pi">:</span> <span class="s">tts:v2</span>
</code></pre></div></div>

<p><strong>Traffic Split (Istio):</strong></p>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">networking.istio.io/v1beta1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">VirtualService</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">tts-service</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">hosts</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">tts.example.com</span>
  <span class="na">http</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">match</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">headers</span><span class="pi">:</span>
        <span class="na">canary</span><span class="pi">:</span>
          <span class="na">exact</span><span class="pi">:</span> <span class="s2">"</span><span class="s">true"</span>
    <span class="na">route</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">destination</span><span class="pi">:</span>
        <span class="na">host</span><span class="pi">:</span> <span class="s">tts</span>
        <span class="na">subset</span><span class="pi">:</span> <span class="s">v2</span>
  <span class="pi">-</span> <span class="na">route</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">destination</span><span class="pi">:</span>
        <span class="na">host</span><span class="pi">:</span> <span class="s">tts</span>
        <span class="na">subset</span><span class="pi">:</span> <span class="s">v1</span>
      <span class="na">weight</span><span class="pi">:</span> <span class="m">99</span>
    <span class="pi">-</span> <span class="na">destination</span><span class="pi">:</span>
        <span class="na">host</span><span class="pi">:</span> <span class="s">tts</span>
        <span class="na">subset</span><span class="pi">:</span> <span class="s">v2</span>
      <span class="na">weight</span><span class="pi">:</span> <span class="m">1</span>
</code></pre></div></div>

<h2 id="8-deep-dive-fallback-and-disaster-recovery">8. Deep Dive: Fallback and Disaster Recovery</h2>

<p><strong>Scenario:</strong> The EU-West data center goes offline (power outage).</p>

<h3 id="fallback-strategy-1-route-to-nearest-healthy-region">Fallback Strategy 1: Route to Nearest Healthy Region</h3>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>EU User → (EU-West DOWN) → GeoDNS → US-East
</code></pre></div></div>

<p><strong>Cons:</strong> Increased latency (50ms → 150ms).</p>

<h3 id="fallback-strategy-2-multi-region-active-active">Fallback Strategy 2: Multi-Region Active-Active</h3>
<p>Deploy to <strong>2 regions per continent</strong>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>EU User → EU-West (Primary) + EU-Central (Backup)
</code></pre></div></div>

<p>If EU-West fails, EU-Central takes over instantly.</p>

<p><strong>Cost:</strong> 2x infrastructure in each continent.</p>

<h2 id="9-deep-dive-caching-at-edge-and-regional-layers">9. Deep Dive: Caching at Edge and Regional Layers</h2>

<p>Speech models are compute-intensive. Caching can reduce load.</p>

<p><strong>What to Cache:</strong></p>
<ol>
  <li><strong>TTS Output:</strong> User says “What’s the weather?” every morning.
    <ul>
      <li>Cache the audio file for “It’s 72°F and sunny” for that user.</li>
    </ul>
  </li>
  <li><strong>Common Queries:</strong> “Set a timer for 10 minutes” is a frequent request.
    <ul>
      <li>Precompute ASR + NLU results.</li>
    </ul>
  </li>
</ol>

<p><strong>Redis Caching:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">redis</span>
<span class="kn">import</span> <span class="n">hashlib</span>

<span class="n">redis_client</span> <span class="o">=</span> <span class="n">redis</span><span class="p">.</span><span class="nc">Redis</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">tts_with_cache</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">cache_key</span> <span class="o">=</span> <span class="n">hashlib</span><span class="p">.</span><span class="nf">md5</span><span class="p">(</span><span class="n">text</span><span class="p">.</span><span class="nf">encode</span><span class="p">()).</span><span class="nf">hexdigest</span><span class="p">()</span>
    
    <span class="c1"># Check cache
</span>    <span class="n">cached_audio</span> <span class="o">=</span> <span class="n">redis_client</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">cache_key</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">cached_audio</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">cached_audio</span>
    
    <span class="c1"># Generate TTS
</span>    <span class="n">audio</span> <span class="o">=</span> <span class="n">tts_model</span><span class="p">.</span><span class="nf">synthesize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    
    <span class="c1"># Store in cache (TTL = 1 hour)
</span>    <span class="n">redis_client</span><span class="p">.</span><span class="nf">setex</span><span class="p">(</span><span class="n">cache_key</span><span class="p">,</span> <span class="mi">3600</span><span class="p">,</span> <span class="n">audio</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">audio</span>
</code></pre></div></div>

<p><strong>Pros:</strong> Reduces TTS latency from 200ms to 5ms (cache hit).
<strong>Cons:</strong> Stale data (if model updates, cache must be invalidated).</p>

<h2 id="10-deep-dive-model-compression-for-edge-deployment">10. Deep Dive: Model Compression for Edge Deployment</h2>

<p>Edge devices (smartphones, smart speakers) have limited compute. Deploy <strong>quantized models</strong>.</p>

<p><strong>Quantization:</strong></p>
<ul>
  <li>Convert FP32 weights to INT8.</li>
  <li>Model size: 500 MB → 125 MB.</li>
  <li>Inference speed: 2x faster.</li>
</ul>

<p><strong>PyTorch Quantization:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>

<span class="c1"># Load original model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">'</span><span class="s">asr_fp32.pt</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Quantize to INT8
</span><span class="n">quantized_model</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">quantization</span><span class="p">.</span><span class="nf">quantize_dynamic</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="p">{</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">},</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">qint8</span>
<span class="p">)</span>

<span class="c1"># Save
</span><span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">quantized_model</span><span class="p">,</span> <span class="sh">'</span><span class="s">asr_int8.pt</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Accuracy Drop:</strong> Typically &lt; 1% WER increase.</p>

<h2 id="11-deep-dive-monitoring-multi-region-deployments">11. Deep Dive: Monitoring Multi-Region Deployments</h2>

<p><strong>Metrics to Track:</strong></p>
<ol>
  <li><strong>Latency per Region:</strong> P50, P99 latency for ASR inference.</li>
  <li><strong>Error Rate per Region:</strong> % of failed requests.</li>
  <li><strong>Model Version:</strong> Which version is running in each region?</li>
  <li><strong>Traffic Distribution:</strong> % of traffic per region.</li>
</ol>

<p><strong>Prometheus Metrics:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">prometheus_client</span> <span class="kn">import</span> <span class="n">Counter</span><span class="p">,</span> <span class="n">Histogram</span>

<span class="n">asr_requests</span> <span class="o">=</span> <span class="nc">Counter</span><span class="p">(</span><span class="sh">'</span><span class="s">asr_requests_total</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Total ASR requests</span><span class="sh">'</span><span class="p">,</span> <span class="p">[</span><span class="sh">'</span><span class="s">region</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">model_version</span><span class="sh">'</span><span class="p">])</span>
<span class="n">asr_latency</span> <span class="o">=</span> <span class="nc">Histogram</span><span class="p">(</span><span class="sh">'</span><span class="s">asr_latency_seconds</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">ASR latency</span><span class="sh">'</span><span class="p">,</span> <span class="p">[</span><span class="sh">'</span><span class="s">region</span><span class="sh">'</span><span class="p">])</span>

<span class="nd">@app.post</span><span class="p">(</span><span class="sh">"</span><span class="s">/asr</span><span class="sh">"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">transcribe</span><span class="p">(</span><span class="n">audio</span><span class="p">:</span> <span class="nb">bytes</span><span class="p">):</span>
    <span class="n">region</span> <span class="o">=</span> <span class="nf">get_region</span><span class="p">()</span>
    <span class="n">model_version</span> <span class="o">=</span> <span class="nf">get_model_version</span><span class="p">()</span>
    
    <span class="n">asr_requests</span><span class="p">.</span><span class="nf">labels</span><span class="p">(</span><span class="n">region</span><span class="o">=</span><span class="n">region</span><span class="p">,</span> <span class="n">model_version</span><span class="o">=</span><span class="n">model_version</span><span class="p">).</span><span class="nf">inc</span><span class="p">()</span>
    
    <span class="k">with</span> <span class="n">asr_latency</span><span class="p">.</span><span class="nf">labels</span><span class="p">(</span><span class="n">region</span><span class="o">=</span><span class="n">region</span><span class="p">).</span><span class="nf">time</span><span class="p">():</span>
        <span class="n">transcript</span> <span class="o">=</span> <span class="n">asr_model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="p">{</span><span class="sh">"</span><span class="s">transcript</span><span class="sh">"</span><span class="p">:</span> <span class="n">transcript</span><span class="p">}</span>
</code></pre></div></div>

<p><strong>Grafana Dashboard:</strong></p>
<ul>
  <li><strong>Map View:</strong> Show latency heatmap by region.</li>
  <li><strong>Alerts:</strong> If EU-West p99 &gt; 500ms, send alert.</li>
</ul>

<h2 id="12-real-world-case-studies">12. Real-World Case Studies</h2>

<h3 id="case-study-1-google-assistant-multi-region">Case Study 1: Google Assistant Multi-Region</h3>
<p>Google deploys ASR models to <strong>20+ regions</strong>.</p>

<p><strong>Architecture:</strong></p>
<ul>
  <li>Each region has a cluster of GPU servers.</li>
  <li>Models stored in regional Google Cloud Storage buckets.</li>
  <li>Canary deployments in US-Central1 first, then global rollout.</li>
</ul>

<p><strong>Result:</strong> &lt; 100ms latency for 95% of users globally.</p>

<h3 id="case-study-2-amazon-alexa-edge-deployment">Case Study 2: Amazon Alexa Edge Deployment</h3>
<p>Alexa uses a hybrid approach:</p>
<ul>
  <li><strong>Wake Word Detection:</strong> Runs on-device (edge).</li>
  <li><strong>Full ASR:</strong> Runs in the cloud (regional clusters).</li>
</ul>

<p><strong>Why?</strong></p>
<ul>
  <li>Wake word detection is lightweight (&lt; 1 MB model).</li>
  <li>Full ASR is heavy (&gt; 500 MB model).</li>
</ul>

<h3 id="case-study-3-zooms-real-time-transcription">Case Study 3: Zoom’s Real-Time Transcription</h3>
<p>Zoom deploys ASR models in <strong>17 AWS regions</strong>.</p>

<p><strong>Strategy:</strong></p>
<ul>
  <li>Each meeting is routed to the closest region.</li>
  <li>If the region is overloaded, fallback to the next closest.</li>
  <li>Models updated weekly via blue-green deployment.</li>
</ul>

<h2 id="implementation-multi-region-speech-api">Implementation: Multi-Region Speech API</h2>

<p><strong>Step 1: Dockerize the ASR Model</strong></p>
<div class="language-dockerfile highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">FROM</span><span class="s"> nvidia/cuda:11.8-runtime-ubuntu20.04</span>
<span class="k">WORKDIR</span><span class="s"> /app</span>
<span class="k">COPY</span><span class="s"> requirements.txt .</span>
<span class="k">RUN </span>pip <span class="nb">install</span> <span class="nt">-r</span> requirements.txt
<span class="k">COPY</span><span class="s"> asr_model.pt .</span>
<span class="k">COPY</span><span class="s"> serve.py .</span>
<span class="k">EXPOSE</span><span class="s"> 8000</span>
<span class="k">CMD</span><span class="s"> ["python", "serve.py"]</span>
</code></pre></div></div>

<p><strong>Step 2: Deploy to Multi-Region Kubernetes</strong></p>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">asr-us-west</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">us-west-2</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">10</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">asr</span>
        <span class="na">image</span><span class="pi">:</span> <span class="s">my-registry/asr:v1</span>
        <span class="na">resources</span><span class="pi">:</span>
          <span class="na">limits</span><span class="pi">:</span>
            <span class="na">nvidia.com/gpu</span><span class="pi">:</span> <span class="m">1</span>
<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">asr-eu-west</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">eu-west-1</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">10</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">asr</span>
        <span class="na">image</span><span class="pi">:</span> <span class="s">my-registry/asr:v1</span>
        <span class="na">resources</span><span class="pi">:</span>
          <span class="na">limits</span><span class="pi">:</span>
            <span class="na">nvidia.com/gpu</span><span class="pi">:</span> <span class="m">1</span>
</code></pre></div></div>

<p><strong>Step 3: Global Load Balancer (Cloudflare)</strong></p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-X</span> POST <span class="s2">"https://api.cloudflare.com/client/v4/zones/{zone_id}/load_balancers"</span> <span class="se">\</span>
  <span class="nt">-H</span> <span class="s2">"Authorization: Bearer {api_token}"</span> <span class="se">\</span>
  <span class="nt">-d</span> <span class="s1">'{
    "name": "speech-api.example.com",
    "default_pools": ["us-west", "eu-west", "asia-pacific"],
    "region_pools": {
      "WNAM": ["us-west"],
      "EEUR": ["eu-west"],
      "SEAS": ["asia-pacific"]
    }
  }'</span>
</code></pre></div></div>

<h2 id="top-interview-questions">Top Interview Questions</h2>

<p><strong>Q1: How do you ensure low latency for global users?</strong>
<em>Answer:</em></p>
<ul>
  <li><strong>GeoDNS:</strong> Route users to the nearest region.</li>
  <li><strong>Edge Deployment:</strong> Deploy lightweight models at CDN edge locations.</li>
  <li><strong>Caching:</strong> Cache frequent TTS outputs and ASR results.</li>
</ul>

<p><strong>Q2: What happens if a region goes down?</strong>
<em>Answer:</em></p>
<ul>
  <li><strong>Failover:</strong> GeoDNS automatically routes to the next closest healthy region.</li>
  <li><strong>Active-Active:</strong> Deploy to multiple regions per continent for redundancy.</li>
  <li><strong>Monitoring:</strong> Real-time health checks detect failures within seconds.</li>
</ul>

<p><strong>Q3: How do you handle model updates across 10 regions?</strong>
<em>Answer:</em></p>
<ul>
  <li><strong>Canary Deployment:</strong> Roll out to 1% in one region first.</li>
  <li><strong>Progressive Rollout:</strong> If healthy, deploy to all regions sequentially.</li>
  <li><strong>Automated Rollback:</strong> If error rate spikes, revert to the previous version.</li>
</ul>

<p><strong>Q4: How do you comply with GDPR for EU users?</strong>
<em>Answer:</em></p>
<ul>
  <li><strong>Regional Isolation:</strong> EU audio data never leaves EU servers.</li>
  <li><strong>Separate Models:</strong> Train EU-specific models on EU data.</li>
  <li><strong>Network Policies:</strong> Block cross-region traffic from EU to other regions.</li>
</ul>

<p><strong>Q5: What’s the difference between edge and regional deployment?</strong>
<em>Answer:</em></p>
<ul>
  <li><strong>Regional:</strong> Models run in data centers (full GPU, high compute).</li>
  <li><strong>Edge:</strong> Models run at CDN PoPs (limited compute, quantized models).</li>
  <li><strong>Use Case:</strong> Edge for ultra-low latency (&lt; 10ms), Regional for high accuracy.</li>
</ul>

<h2 id="13-deep-dive-streaming-asr-with-webrtc">13. Deep Dive: Streaming ASR with WebRTC</h2>

<p>For real-time applications (video calls, live captioning), audio streams chunk-by-chunk over WebRTC.</p>

<p><strong>Challenge:</strong> Each audio chunk arrives every 20ms. ASR must process faster than real-time.</p>

<p><strong>Architecture:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>User Microphone
    ↓
WebRTC Stream (20ms chunks)
    ↓
Regional ASR Server (Streaming Model)
    ↓
Transcript (partial results every 100ms)
</code></pre></div></div>

<p><strong>Streaming ASR Implementation:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">grpc</span>
<span class="kn">from</span> <span class="n">google.cloud</span> <span class="kn">import</span> <span class="n">speech_v1p1beta1</span> <span class="k">as</span> <span class="n">speech</span>

<span class="k">def</span> <span class="nf">stream_transcribe</span><span class="p">():</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">speech</span><span class="p">.</span><span class="nc">SpeechClient</span><span class="p">()</span>
    
    <span class="n">config</span> <span class="o">=</span> <span class="n">speech</span><span class="p">.</span><span class="nc">StreamingRecognitionConfig</span><span class="p">(</span>
        <span class="n">config</span><span class="o">=</span><span class="n">speech</span><span class="p">.</span><span class="nc">RecognitionConfig</span><span class="p">(</span>
            <span class="n">encoding</span><span class="o">=</span><span class="n">speech</span><span class="p">.</span><span class="n">RecognitionConfig</span><span class="p">.</span><span class="n">AudioEncoding</span><span class="p">.</span><span class="n">LINEAR16</span><span class="p">,</span>
            <span class="n">sample_rate_hertz</span><span class="o">=</span><span class="mi">16000</span><span class="p">,</span>
            <span class="n">language_code</span><span class="o">=</span><span class="sh">'</span><span class="s">en-US</span><span class="sh">'</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">interim_results</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>  <span class="c1"># Get partial results
</span>    <span class="p">)</span>
    
    <span class="c1"># Generator for audio chunks
</span>    <span class="k">def</span> <span class="nf">audio_generator</span><span class="p">():</span>
        <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
            <span class="n">chunk</span> <span class="o">=</span> <span class="nf">get_audio_chunk</span><span class="p">()</span>  <span class="c1"># 20ms of audio
</span>            <span class="k">yield</span> <span class="n">speech</span><span class="p">.</span><span class="nc">StreamingRecognizeRequest</span><span class="p">(</span><span class="n">audio_content</span><span class="o">=</span><span class="n">chunk</span><span class="p">)</span>
    
    <span class="n">requests</span> <span class="o">=</span> <span class="nf">audio_generator</span><span class="p">()</span>
    <span class="n">responses</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="nf">streaming_recognize</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">requests</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">response</span> <span class="ow">in</span> <span class="n">responses</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">response</span><span class="p">.</span><span class="n">results</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">result</span><span class="p">.</span><span class="n">is_final</span><span class="p">:</span>
                <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Final: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">alternatives</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">transcript</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Partial: </span><span class="si">{</span><span class="n">result</span><span class="p">.</span><span class="n">alternatives</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">transcript</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Key Requirement:</strong> Model must process in &lt; 20ms to keep up with audio stream.</p>

<h2 id="14-deep-dive-voice-quality-monitoring">14. Deep Dive: Voice Quality Monitoring</h2>

<p>How do we measure if multi-region speech systems are working well?</p>

<p><strong>Metrics:</strong></p>

<p><strong>1. Word Error Rate (WER):</strong>
\[
\text{WER} = \frac{\text{Substitutions} + \text{Insertions} + \text{Deletions}}{\text{Total Words}}
\]</p>

<p><strong>2. Mean Opinion Score (MOS) for TTS:</strong></p>
<ul>
  <li>Human raters score voice quality from 1 (terrible) to 5 (excellent).</li>
  <li>Target: MOS &gt; 4.0.</li>
</ul>

<p><strong>3. Real-Time Factor (RTF):</strong>
\[
\text{RTF} = \frac{\text{Processing Time}}{\text{Audio Duration}}
\]</p>
<ul>
  <li>RTF &lt; 1.0 means faster than real-time.</li>
  <li>Target for streaming: RTF &lt; 0.5.</li>
</ul>

<p><strong>Automated Testing:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">time</span>

<span class="k">def</span> <span class="nf">measure_rtf</span><span class="p">(</span><span class="n">asr_model</span><span class="p">,</span> <span class="n">audio_file</span><span class="p">):</span>
    <span class="n">audio_duration</span> <span class="o">=</span> <span class="nf">get_audio_duration</span><span class="p">(</span><span class="n">audio_file</span><span class="p">)</span>  <span class="c1"># e.g., 10 seconds
</span>    
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
    <span class="n">transcript</span> <span class="o">=</span> <span class="n">asr_model</span><span class="p">.</span><span class="nf">transcribe</span><span class="p">(</span><span class="n">audio_file</span><span class="p">)</span>
    <span class="n">processing_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>
    
    <span class="n">rtf</span> <span class="o">=</span> <span class="n">processing_time</span> <span class="o">/</span> <span class="n">audio_duration</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">RTF: </span><span class="si">{</span><span class="n">rtf</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">rtf</span> <span class="o">&gt;</span> <span class="mf">1.0</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">WARNING: Model is slower than real-time!</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">rtf</span>
</code></pre></div></div>

<h2 id="15-deep-dive-bandwidth-management">15. Deep Dive: Bandwidth Management</h2>

<p>Streaming audio consumes significant bandwidth. Optimization is critical for mobile users.</p>

<p><strong>Audio Compression:</strong></p>
<ul>
  <li><strong>Uncompressed PCM:</strong> 16kHz, 16-bit = 256 kbps</li>
  <li><strong>Opus Codec:</strong> 16 kbps (16x compression)</li>
  <li><strong>Speex:</strong> 8 kbps (ultra-low bitrate)</li>
</ul>

<p><strong>Implementation:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pyaudio</span>
<span class="kn">import</span> <span class="n">opuslib</span>

<span class="k">def</span> <span class="nf">stream_compressed_audio</span><span class="p">():</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">pyaudio</span><span class="p">.</span><span class="nc">PyAudio</span><span class="p">()</span>
    <span class="n">encoder</span> <span class="o">=</span> <span class="n">opuslib</span><span class="p">.</span><span class="nc">Encoder</span><span class="p">(</span><span class="mi">16000</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">opuslib</span><span class="p">.</span><span class="n">APPLICATION_VOIP</span><span class="p">)</span>
    
    <span class="n">stream</span> <span class="o">=</span> <span class="n">p</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="n">pyaudio</span><span class="p">.</span><span class="n">paInt16</span><span class="p">,</span>
                    <span class="n">channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">rate</span><span class="o">=</span><span class="mi">16000</span><span class="p">,</span>
                    <span class="nb">input</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                    <span class="n">frames_per_buffer</span><span class="o">=</span><span class="mi">320</span><span class="p">)</span>  <span class="c1"># 20ms chunks
</span>    
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">audio_chunk</span> <span class="o">=</span> <span class="n">stream</span><span class="p">.</span><span class="nf">read</span><span class="p">(</span><span class="mi">320</span><span class="p">)</span>
        <span class="n">compressed</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="n">audio_chunk</span><span class="p">,</span> <span class="mi">320</span><span class="p">)</span>
        
        <span class="c1"># Send compressed chunk to server
</span>        <span class="nf">send_to_server</span><span class="p">(</span><span class="n">compressed</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Trade-off:</strong> Lower bitrate = worse audio quality = higher WER.</p>

<h2 id="16-deep-dive-cost-optimization-for-global-speech">16. Deep Dive: Cost Optimization for Global Speech</h2>

<p>Running GPU-based ASR globally is expensive. How do we reduce cost?</p>

<p><strong>Strategy 1: CPU Inference with ONNX Runtime</strong>
Convert model from PyTorch to ONNX for optimized CPU inference.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">onnx</span>

<span class="c1"># Export to ONNX
</span><span class="n">dummy_input</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>  <span class="c1"># Mel spectrogram
</span><span class="n">torch</span><span class="p">.</span><span class="n">onnx</span><span class="p">.</span><span class="nf">export</span><span class="p">(</span><span class="n">asr_model</span><span class="p">,</span> <span class="n">dummy_input</span><span class="p">,</span> <span class="sh">"</span><span class="s">asr.onnx</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Inference with ONNX Runtime (2-3x faster than PyTorch CPU)
</span><span class="kn">import</span> <span class="n">onnxruntime</span> <span class="k">as</span> <span class="n">ort</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">ort</span><span class="p">.</span><span class="nc">InferenceSession</span><span class="p">(</span><span class="sh">"</span><span class="s">asr.onnx</span><span class="sh">"</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">session</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="p">{</span><span class="sh">"</span><span class="s">input</span><span class="sh">"</span><span class="p">:</span> <span class="n">audio_features</span><span class="p">})</span>
</code></pre></div></div>

<p><strong>Result:</strong> CPU instances are 5x cheaper than GPU instances.</p>

<p><strong>Strategy 2: Autoscaling Based on Region-Specific Traffic</strong>
Don’t run 24/7 in all regions. Scale down at night.</p>

<p><strong>Traffic Patterns:</strong></p>
<ul>
  <li><strong>US-West:</strong> Peak at 2pm PST (5pm EST).</li>
  <li><strong>EU-West:</strong> Peak at 2pm CET (8am EST).</li>
  <li><strong>Asia-Pacific:</strong> Peak at 2pm JST (1am EST).</li>
</ul>

<p><strong>Autoscaling Policy:</strong></p>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">autoscaling/v2</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">HorizontalPodAutoscaler</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">asr-us-west</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">scaleTargetRef</span><span class="pi">:</span>
    <span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">asr-us-west</span>
  <span class="na">minReplicas</span><span class="pi">:</span> <span class="m">2</span>   <span class="c1"># Night</span>
  <span class="na">maxReplicas</span><span class="pi">:</span> <span class="m">50</span>  <span class="c1"># Day</span>
  <span class="na">metrics</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">type</span><span class="pi">:</span> <span class="s">Resource</span>
    <span class="na">resource</span><span class="pi">:</span>
      <span class="na">name</span><span class="pi">:</span> <span class="s">cpu</span>
      <span class="na">target</span><span class="pi">:</span>
        <span class="na">type</span><span class="pi">:</span> <span class="s">Utilization</span>
        <span class="na">averageUtilization</span><span class="pi">:</span> <span class="m">60</span>
</code></pre></div></div>

<p><strong>Strategy 3: Spot Instances for Batch Transcription</strong>
For non-real-time workloads (podcast transcription), use spot instances.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Kubernetes Toleration for Spot Instances
</span><span class="n">spec</span><span class="p">:</span>
  <span class="n">tolerations</span><span class="p">:</span>
  <span class="o">-</span> <span class="n">key</span><span class="p">:</span> <span class="sh">"</span><span class="s">spot</span><span class="sh">"</span>
    <span class="n">operator</span><span class="p">:</span> <span class="sh">"</span><span class="s">Equal</span><span class="sh">"</span>
    <span class="n">value</span><span class="p">:</span> <span class="sh">"</span><span class="s">true</span><span class="sh">"</span>
    <span class="n">effect</span><span class="p">:</span> <span class="sh">"</span><span class="s">NoSchedule</span><span class="sh">"</span>
  <span class="n">nodeSelector</span><span class="p">:</span>
    <span class="n">instance</span><span class="o">-</span><span class="nb">type</span><span class="p">:</span> <span class="sh">"</span><span class="s">spot</span><span class="sh">"</span>
</code></pre></div></div>

<h2 id="17-deep-dive-multi-language-support">17. Deep Dive: Multi-Language Support</h2>

<p><strong>Challenge:</strong> Support 100+ languages across all regions.</p>

<p><strong>Option 1: Separate Models per Language</strong></p>
<ul>
  <li>Deploy <code class="language-plaintext highlighter-rouge">asr-en</code>, <code class="language-plaintext highlighter-rouge">asr-fr</code>, <code class="language-plaintext highlighter-rouge">asr-es</code>, etc.</li>
  <li><strong>Pros:</strong> Best accuracy per language.</li>
  <li><strong>Cons:</strong> 100x storage and compute.</li>
</ul>

<p><strong>Option 2: Multilingual Model</strong></p>
<ul>
  <li>Single model trained on 100 languages.</li>
  <li><strong>Pros:</strong> 1x storage, universal model.</li>
  <li><strong>Cons:</strong> Slightly lower accuracy per language.</li>
</ul>

<p><strong>Hybrid Approach:</strong>
Deploy multilingual model globally. Deploy language-specific models in high-demand regions.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_model</span><span class="p">(</span><span class="n">language_code</span><span class="p">,</span> <span class="n">region</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">language_code</span> <span class="o">==</span> <span class="sh">'</span><span class="s">en</span><span class="sh">'</span> <span class="ow">and</span> <span class="n">region</span> <span class="o">==</span> <span class="sh">'</span><span class="s">us-west</span><span class="sh">'</span><span class="p">:</span>
        <span class="k">return</span> <span class="nf">load_model</span><span class="p">(</span><span class="sh">'</span><span class="s">asr-en-specialized</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="nf">load_model</span><span class="p">(</span><span class="sh">'</span><span class="s">asr-multilingual</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="18-deep-dive-failover-testing-and-chaos-engineering">18. Deep Dive: Failover Testing and Chaos Engineering</h2>

<p><strong>Problem:</strong> How do you verify that failover actually works?</p>

<p><strong>Chaos Engineering Test:</strong></p>
<ol>
  <li><strong>Simulate Region Failure:</strong> Terminate all pods in EU-West.</li>
  <li><strong>Observe:</strong> Do EU users get routed to US-East?</li>
  <li><strong>Measure:</strong> What’s the latency increase? Any errors?</li>
</ol>

<p><strong>Automated Failover Test:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">requests</span>
<span class="kn">import</span> <span class="n">time</span>

<span class="k">def</span> <span class="nf">test_failover</span><span class="p">():</span>
    <span class="c1"># Baseline: All regions healthy
</span>    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">https://speech-api.example.com/health</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">response</span><span class="p">.</span><span class="nf">json</span><span class="p">()[</span><span class="sh">'</span><span class="s">all_healthy</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="bp">True</span>
    
    <span class="c1"># Simulate EU-West failure
</span>    <span class="nf">kill_region</span><span class="p">(</span><span class="sh">'</span><span class="s">eu-west</span><span class="sh">'</span><span class="p">)</span>
    
    <span class="n">time</span><span class="p">.</span><span class="nf">sleep</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>  <span class="c1"># Wait for DNS update
</span>    
    <span class="c1"># Test from EU client
</span>    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">post</span><span class="p">(</span>
        <span class="sh">"</span><span class="s">https://speech-api.example.com/asr</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">data</span><span class="o">=</span><span class="n">audio_data</span><span class="p">,</span>
        <span class="n">headers</span><span class="o">=</span><span class="p">{</span><span class="sh">"</span><span class="s">X-Client-Location</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">EU</span><span class="sh">"</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="n">latency</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>
    
    <span class="k">assert</span> <span class="n">response</span><span class="p">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">200</span>
    <span class="k">assert</span> <span class="n">latency</span> <span class="o">&lt;</span> <span class="mi">200</span>  <span class="c1"># Acceptable degraded latency
</span>    
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Failover successful. Latency: </span><span class="si">{</span><span class="n">latency</span><span class="o">*</span><span class="mi">1000</span><span class="si">:</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="si">}</span><span class="s">ms</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Run Monthly:</strong> Ensure team knows how to handle regional outages.</p>

<h2 id="19-deep-dive-shadow-traffic-for-model-validation">19. Deep Dive: Shadow Traffic for Model Validation</h2>

<p>Before deploying a new ASR model to prod, validate it using shadow traffic.</p>

<p><strong>Shadow Traffic Strategy:</strong></p>
<ol>
  <li>Deploy new model alongside old model.</li>
  <li>Send 100% of live traffic to both models.</li>
  <li>Serve old model’s response to users.</li>
  <li>Log new model’s response for comparison.</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">asyncio</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">shadow_predict</span><span class="p">(</span><span class="n">audio</span><span class="p">):</span>
    <span class="c1"># Primary prediction
</span>    <span class="n">primary_task</span> <span class="o">=</span> <span class="n">asyncio</span><span class="p">.</span><span class="nf">create_task</span><span class="p">(</span><span class="n">model_v1</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">audio</span><span class="p">))</span>
    
    <span class="c1"># Shadow prediction (async, non-blocking)
</span>    <span class="n">shadow_task</span> <span class="o">=</span> <span class="n">asyncio</span><span class="p">.</span><span class="nf">create_task</span><span class="p">(</span><span class="n">model_v2</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">audio</span><span class="p">))</span>
    
    <span class="c1"># Wait for primary
</span>    <span class="n">primary_result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">primary_task</span>
    
    <span class="c1"># Log shadow result (don't wait)
</span>    <span class="n">asyncio</span><span class="p">.</span><span class="nf">create_task</span><span class="p">(</span><span class="nf">log_shadow_result</span><span class="p">(</span><span class="n">shadow_task</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">primary_result</span>
</code></pre></div></div>

<p><strong>Comparison Metrics:</strong></p>
<ul>
  <li>WER difference</li>
  <li>Latency difference</li>
  <li>Vocabulary coverage</li>
</ul>

<h2 id="20-production-war-stories">20. Production War Stories</h2>

<p><strong>War Story 1: The DNS Caching Disaster</strong>
A team deployed to a new region. Updated DNS. But users kept going to the old region for 2 hours.
<strong>Root Cause:</strong> ISPs cached DNS records (TTL = 3600s).
<strong>Lesson:</strong> Set TTL = 60s for DNS records that might change.</p>

<p><strong>War Story 2: The Cross-Region Bandwidth Bill</strong>
A team accidentally routed EU traffic to US servers for a week.
<strong>Cost:</strong> $50,000 in cross-region data transfer fees.
<strong>Lesson:</strong> Monitor traffic routing with dashboards.</p>

<p><strong>War Story 3: The GDPR Violation</strong>
A bug caused EU user audio to be logged in US servers.
<strong>Result:</strong> GDPR fine, PR disaster.
<strong>Lesson:</strong> Implement fail-safe network policies (block cross-region traffic at firewall level).</p>

<h2 id="21-deep-dive-network-optimization-for-speech">21. Deep Dive: Network Optimization for Speech</h2>

<p>Speech data requires significant bandwidth. Optimize network usage.</p>

<p><strong>Optimization 1: WebSocket Connection Pooling</strong>
Reuse connections instead of creating new ones for each request.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">websockets</span>
<span class="kn">import</span> <span class="n">asyncio</span>

<span class="k">class</span> <span class="nc">ConnectionPool</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">uri</span><span class="p">,</span> <span class="n">pool_size</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">uri</span> <span class="o">=</span> <span class="n">uri</span>
        <span class="n">self</span><span class="p">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">asyncio</span><span class="p">.</span><span class="nc">Queue</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="n">pool_size</span><span class="p">)</span>
        <span class="n">asyncio</span><span class="p">.</span><span class="nf">create_task</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">_fill_pool</span><span class="p">(</span><span class="n">pool_size</span><span class="p">))</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">_fill_pool</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
            <span class="n">conn</span> <span class="o">=</span> <span class="k">await</span> <span class="n">websockets</span><span class="p">.</span><span class="nf">connect</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">uri</span><span class="p">)</span>
            <span class="k">await</span> <span class="n">self</span><span class="p">.</span><span class="n">pool</span><span class="p">.</span><span class="nf">put</span><span class="p">(</span><span class="n">conn</span><span class="p">)</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">get_connection</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="k">await</span> <span class="n">self</span><span class="p">.</span><span class="n">pool</span><span class="p">.</span><span class="nf">get</span><span class="p">()</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">return_connection</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">conn</span><span class="p">):</span>
        <span class="k">await</span> <span class="n">self</span><span class="p">.</span><span class="n">pool</span><span class="p">.</span><span class="nf">put</span><span class="p">(</span><span class="n">conn</span><span class="p">)</span>

<span class="c1"># Usage
</span><span class="n">pool</span> <span class="o">=</span> <span class="nc">ConnectionPool</span><span class="p">(</span><span class="sh">'</span><span class="s">wss://speech-api.example.com</span><span class="sh">'</span><span class="p">)</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">stream_audio</span><span class="p">(</span><span class="n">audio_data</span><span class="p">):</span>
    <span class="n">conn</span> <span class="o">=</span> <span class="k">await</span> <span class="n">pool</span><span class="p">.</span><span class="nf">get_connection</span><span class="p">()</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">await</span> <span class="n">conn</span><span class="p">.</span><span class="nf">send</span><span class="p">(</span><span class="n">audio_data</span><span class="p">)</span>
        <span class="n">response</span> <span class="o">=</span> <span class="k">await</span> <span class="n">conn</span><span class="p">.</span><span class="nf">recv</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">response</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="k">await</span> <span class="n">pool</span><span class="p">.</span><span class="nf">return_connection</span><span class="p">(</span><span class="n">conn</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Optimization 2: gRPC Streaming with Multiplexing</strong>
gRPC multiplexes multiple streams over a single TCP connection.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">grpc</span>
<span class="kn">from</span> <span class="n">concurrent</span> <span class="kn">import</span> <span class="n">futures</span>

<span class="k">class</span> <span class="nc">SpeechService</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">StreamingRecognize</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">request_iterator</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">request</span> <span class="ow">in</span> <span class="n">request_iterator</span><span class="p">:</span>
            <span class="n">audio_chunk</span> <span class="o">=</span> <span class="n">request</span><span class="p">.</span><span class="n">audio_content</span>
            <span class="n">transcript</span> <span class="o">=</span> <span class="n">asr_model</span><span class="p">.</span><span class="nf">process_chunk</span><span class="p">(</span><span class="n">audio_chunk</span><span class="p">)</span>
            <span class="k">yield</span> <span class="nc">SpeechResponse</span><span class="p">(</span><span class="n">transcript</span><span class="o">=</span><span class="n">transcript</span><span class="p">)</span>

<span class="c1"># Server
</span><span class="n">server</span> <span class="o">=</span> <span class="n">grpc</span><span class="p">.</span><span class="nf">server</span><span class="p">(</span><span class="n">futures</span><span class="p">.</span><span class="nc">ThreadPoolExecutor</span><span class="p">(</span><span class="n">max_workers</span><span class="o">=</span><span class="mi">100</span><span class="p">))</span>
<span class="nf">add_SpeechServiceServicer_to_server</span><span class="p">(</span><span class="nc">SpeechService</span><span class="p">(),</span> <span class="n">server</span><span class="p">)</span>
<span class="n">server</span><span class="p">.</span><span class="nf">add_insecure_port</span><span class="p">(</span><span class="sh">'</span><span class="s">[::]:50051</span><span class="sh">'</span><span class="p">)</span>
<span class="n">server</span><span class="p">.</span><span class="nf">start</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="22-deep-dive-latency-slas-and-penalties">22. Deep Dive: Latency SLAs and Penalties</h2>

<p>Production systems often have strict latency SLAs.</p>

<p><strong>Example SLA:</strong></p>
<ul>
  <li><strong>P50 latency:</strong> &lt; 50ms (99% of time)</li>
  <li><strong>P95 latency:</strong> &lt; 150ms</li>
  <li><strong>P99 latency:</strong> &lt; 300ms</li>
</ul>

<p><strong>Penalty:</strong> If P95 &gt; 150ms for &gt; 1 hour, pay $10,000.</p>

<p><strong>How to Meet SLAs:</strong></p>
<ol>
  <li><strong>Over-provision:</strong> Run 30% more replicas than needed.</li>
  <li><strong>Circuit Breaker:</strong> If a region’s latency spikes, stop routing traffic there.</li>
  <li><strong>Fallback:</strong> Route to next-closest region if primary is overloaded.</li>
</ol>

<p><strong>Circuit Breaker Implementation:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">enum</span> <span class="kn">import</span> <span class="n">Enum</span>
<span class="kn">import</span> <span class="n">time</span>

<span class="k">class</span> <span class="nc">CircuitState</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="n">CLOSED</span> <span class="o">=</span> <span class="sh">"</span><span class="s">closed</span><span class="sh">"</span>  <span class="c1"># Normal operation
</span>    <span class="n">OPEN</span> <span class="o">=</span> <span class="sh">"</span><span class="s">open</span><span class="sh">"</span>      <span class="c1"># Circuit tripped
</span>    <span class="n">HALF_OPEN</span> <span class="o">=</span> <span class="sh">"</span><span class="s">half_open</span><span class="sh">"</span>  <span class="c1"># Testing recovery
</span>
<span class="k">class</span> <span class="nc">CircuitBreaker</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">failure_threshold</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">60</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">CircuitState</span><span class="p">.</span><span class="n">CLOSED</span>
        <span class="n">self</span><span class="p">.</span><span class="n">failure_count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">self</span><span class="p">.</span><span class="n">failure_threshold</span> <span class="o">=</span> <span class="n">failure_threshold</span>
        <span class="n">self</span><span class="p">.</span><span class="n">timeout</span> <span class="o">=</span> <span class="n">timeout</span>
        <span class="n">self</span><span class="p">.</span><span class="n">last_failure_time</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">state</span> <span class="o">==</span> <span class="n">CircuitState</span><span class="p">.</span><span class="n">OPEN</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">last_failure_time</span> <span class="o">&gt;</span> <span class="n">self</span><span class="p">.</span><span class="n">timeout</span><span class="p">:</span>
                <span class="n">self</span><span class="p">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">CircuitState</span><span class="p">.</span><span class="n">HALF_OPEN</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="nc">Exception</span><span class="p">(</span><span class="sh">"</span><span class="s">Circuit breaker is OPEN</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="k">try</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="nf">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">state</span> <span class="o">==</span> <span class="n">CircuitState</span><span class="p">.</span><span class="n">HALF_OPEN</span><span class="p">:</span>
                <span class="n">self</span><span class="p">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">CircuitState</span><span class="p">.</span><span class="n">CLOSED</span>
                <span class="n">self</span><span class="p">.</span><span class="n">failure_count</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">return</span> <span class="n">result</span>
        <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">failure_count</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">self</span><span class="p">.</span><span class="n">last_failure_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
            
            <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">failure_count</span> <span class="o">&gt;=</span> <span class="n">self</span><span class="p">.</span><span class="n">failure_threshold</span><span class="p">:</span>
                <span class="n">self</span><span class="p">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">CircuitState</span><span class="p">.</span><span class="n">OPEN</span>
            <span class="k">raise</span> <span class="n">e</span>

<span class="c1"># Usage
</span><span class="n">breaker</span> <span class="o">=</span> <span class="nc">CircuitBreaker</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">call_asr_service</span><span class="p">(</span><span class="n">audio</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">breaker</span><span class="p">.</span><span class="nf">call</span><span class="p">(</span><span class="n">asr_model</span><span class="p">.</span><span class="n">transcribe</span><span class="p">,</span> <span class="n">audio</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="23-production-deployment-checklist">23. Production Deployment Checklist</h2>

<p>Before deploying speech models to production, verify:</p>

<p><strong>Pre-Launch Checklist:</strong></p>
<ul class="task-list">
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" /><strong>Load Testing:</strong> Test with 10x expected peak traffic.</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" /><strong>Failover Drill:</strong> Kill one region, verify traffic shifts.</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" /><strong>Latency Benchmarks:</strong> P99 &lt; 300ms in all regions.</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" /><strong>GDPR Compliance:</strong> EU data stays in EU.</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" /><strong>Monitoring Dashboards:</strong> Grafana dashboards for each region.</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" /><strong>Alerting Rules:</strong> PagerDuty alerts for p99 &gt; 500ms.</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" /><strong>Runbooks:</strong> Documented procedures for common incidents.</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" /><strong>Rollback Plan:</strong> Can revert to previous model in &lt; 5 minutes.</li>
</ul>

<p><strong>Load Testing Script:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">asyncio</span>
<span class="kn">import</span> <span class="n">aiohttp</span>
<span class="kn">import</span> <span class="n">time</span>

<span class="k">async</span> <span class="k">def</span> <span class="nf">stress_test</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">audio_file</span><span class="p">,</span> <span class="n">num_requests</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
    <span class="k">async</span> <span class="k">with</span> <span class="n">aiohttp</span><span class="p">.</span><span class="nc">ClientSession</span><span class="p">()</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
        <span class="n">tasks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_requests</span><span class="p">):</span>
            <span class="n">task</span> <span class="o">=</span> <span class="n">session</span><span class="p">.</span><span class="nf">post</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="nf">open</span><span class="p">(</span><span class="n">audio_file</span><span class="p">,</span> <span class="sh">'</span><span class="s">rb</span><span class="sh">'</span><span class="p">))</span>
            <span class="n">tasks</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">task</span><span class="p">)</span>
        
        <span class="n">responses</span> <span class="o">=</span> <span class="k">await</span> <span class="n">asyncio</span><span class="p">.</span><span class="nf">gather</span><span class="p">(</span><span class="o">*</span><span class="n">tasks</span><span class="p">)</span>
        
        <span class="n">duration</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>
        <span class="n">rps</span> <span class="o">=</span> <span class="n">num_requests</span> <span class="o">/</span> <span class="n">duration</span>
        
        <span class="n">latencies</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span><span class="p">.</span><span class="n">headers</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">X-Latency-Ms</span><span class="sh">'</span><span class="p">)</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">responses</span><span class="p">]</span>
        <span class="n">p99</span> <span class="o">=</span> <span class="nf">sorted</span><span class="p">([</span><span class="nf">float</span><span class="p">(</span><span class="n">l</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">latencies</span> <span class="k">if</span> <span class="n">l</span><span class="p">])[</span><span class="nf">int</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">latencies</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.99</span><span class="p">)]</span>
        
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">RPS: </span><span class="si">{</span><span class="n">rps</span><span class="si">:</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">P99 Latency: </span><span class="si">{</span><span class="n">p99</span><span class="si">:</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="si">}</span><span class="s">ms</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Run
</span><span class="n">asyncio</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="nf">stress_test</span><span class="p">(</span>
    <span class="sh">'</span><span class="s">https://speech-api.example.com/asr</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">test_audio.wav</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">num_requests</span><span class="o">=</span><span class="mi">10000</span>
<span class="p">))</span>
</code></pre></div></div>

<h2 id="24-future-trends-serverless-speech">24. Future Trends: Serverless Speech</h2>

<p><strong>Trend:</strong> Instead of running servers 24/7, use serverless (AWS Lambda, Google Cloud Run).</p>

<p><strong>Pros:</strong></p>
<ul>
  <li><strong>Cost:</strong> Pay only for actual usage (not idle time).</li>
  <li><strong>Auto-Scaling:</strong> Scales to zero when not in use.</li>
</ul>

<p><strong>Cons:</strong></p>
<ul>
  <li><strong>Cold Start:</strong> First request is slow (5-10 seconds to load model).</li>
  <li><strong>Memory Limits:</strong> Lambda has 10GB max memory.</li>
</ul>

<p><strong>Workaround: Provisioned Concurrency</strong>
Keep N instances warm at all times.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># AWS Lambda with Provisioned Concurrency</span>
<span class="na">Resources</span><span class="pi">:</span>
  <span class="na">SpeechFunction</span><span class="pi">:</span>
    <span class="na">Type</span><span class="pi">:</span> <span class="s">AWS::Lambda::Function</span>
    <span class="na">Properties</span><span class="pi">:</span>
      <span class="na">Runtime</span><span class="pi">:</span> <span class="s">python3.9</span>
      <span class="na">Handler</span><span class="pi">:</span> <span class="s">app.handler</span>
      <span class="na">MemorySize</span><span class="pi">:</span> <span class="m">10240</span>  <span class="c1"># 10 GB</span>
      <span class="na">Timeout</span><span class="pi">:</span> <span class="m">60</span>
  
  <span class="na">ProvisionedConcurrency</span><span class="pi">:</span>
    <span class="na">Type</span><span class="pi">:</span> <span class="s">AWS::Lambda::Alias</span>
    <span class="na">Properties</span><span class="pi">:</span>
      <span class="na">FunctionName</span><span class="pi">:</span> <span class="kt">!Ref</span> <span class="s">SpeechFunction</span>
      <span class="na">ProvisionedConcurrencyConfig</span><span class="pi">:</span>
        <span class="na">ProvisionedConcurrentExecutions</span><span class="pi">:</span> <span class="m">10</span>  <span class="c1"># Keep 10 warm</span>
</code></pre></div></div>

<h2 id="key-takeaways">Key Takeaways</h2>

<ol>
  <li><strong>Multi-Region is Essential:</strong> Reduces latency and ensures high availability.</li>
  <li><strong>GeoDNS:</strong> Routes users to the nearest region automatically.</li>
  <li><strong>Edge Deployment:</strong> For ultra-low latency, deploy quantized models at the edge.</li>
  <li><strong>Canary Deployments:</strong> Reduce risk when rolling out new models.</li>
  <li><strong>GDPR Compliance:</strong> Regional isolation is critical for EU users.</li>
</ol>

<h2 id="summary">Summary</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Aspect</th>
      <th style="text-align: left">Insight</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><strong>Goal</strong></td>
      <td style="text-align: left">Low latency, high availability, global reach</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Architecture</strong></td>
      <td style="text-align: left">Multi-region clusters + GeoDNS + Edge caching</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Challenges</strong></td>
      <td style="text-align: left">Model sync, data compliance, disaster recovery</td>
    </tr>
    <tr>
      <td style="text-align: left"><strong>Key Metrics</strong></td>
      <td style="text-align: left">Latency (p99), error rate, traffic distribution</td>
    </tr>
  </tbody>
</table>

<hr />

<p><strong>Originally published at:</strong> <a href="https://www.arunbaby.com/speech-tech/0033-multi-region-speech-deployment/">arunbaby.com/speech-tech/0033-multi-region-speech-deployment</a></p>

<p><em>If you found this helpful, consider sharing it with others who might benefit.</em></p>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#asr" class="page__taxonomy-item p-category" rel="tag">asr</a><span class="sep">, </span>
    
      <a href="/tags/#deployment" class="page__taxonomy-item p-category" rel="tag">deployment</a><span class="sep">, </span>
    
      <a href="/tags/#distributed-systems" class="page__taxonomy-item p-category" rel="tag">distributed-systems</a><span class="sep">, </span>
    
      <a href="/tags/#edge-computing" class="page__taxonomy-item p-category" rel="tag">edge-computing</a><span class="sep">, </span>
    
      <a href="/tags/#tts" class="page__taxonomy-item p-category" rel="tag">tts</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#speech-tech" class="page__taxonomy-item p-category" rel="tag">speech_tech</a>
    
    </span>
  </p>


        
      </footer>

      <div class="page__related page__related--full">
  <h2 class="page__related-title">Related across topics</h2>
  <style>
    /* Make section span full content width and use 2 equal columns */
    .page__related--full { float: inline-start; width: 100%; padding: 0; }
    .cross-related-grid { display: grid; grid-template-columns: repeat(2, minmax(0, 1fr)); gap: 2rem; }
    @media (max-width: 768px) { .cross-related-grid { grid-template-columns: 1fr; } }
    /* Ensure archive cards stretch nicely in the grid */
    .cross-related-grid .list__item, .cross-related-grid .grid__item { width: auto; float: none; margin: 0; }
  </style>
  <div class="cross-related-grid">
    



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/dsa/0033-clone-graph/" rel="permalink">Clone Graph (DFS/BFS)
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          21 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“Creating a deep copy of a graph structure.”
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ml-system-design/0033-model-replication-systems/" rel="permalink">Model Replication Systems
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          19 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“Ensuring your ML models are available everywhere, all the time.”
</p>
  </article>
</div>

  </div>
</div>

      <section class="page__share">
  <h4 class="page__share-title">Share on</h4>

  <a href="https://twitter.com/intent/tweet?via=arunbaby0&text=Multi-region+Speech+Deployment%20https%3A%2F%2Fwww.arunbaby.com%2Fspeech-tech%2F0033-multi-region-speech-deployment%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.arunbaby.com%2Fspeech-tech%2F0033-multi-region-speech-deployment%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.arunbaby.com/speech-tech/0033-multi-region-speech-deployment/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/speech-tech/0032-phonetic-search/" class="pagination--pager" title="Phonetic Search in Speech">Previous</a>
    
    
      <a href="/speech-tech/0034-dialog-state-tracking/" class="pagination--pager" title="Dialog State Tracking (DST)">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 1990 - 2143 <a href="https://www.arunbaby.com">Arun Baby</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JRJPEC9SS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0JRJPEC9SS', { 'anonymize_ip': false});
</script>








  </body>
</html>
