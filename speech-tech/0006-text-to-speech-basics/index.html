<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Text-to-Speech (TTS) System Fundamentals - Arun Baby</title>
<meta name="description" content="From text to natural speech: understanding modern neural TTS architectures that power Alexa, Google Assistant, and Siri.">


  <meta name="author" content="Arun Baby">
  
  <meta property="article:author" content="Arun Baby">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Arun Baby">
<meta property="og:title" content="Text-to-Speech (TTS) System Fundamentals">
<meta property="og:url" content="https://www.arunbaby.com/speech-tech/0006-text-to-speech-basics/">


  <meta property="og:description" content="From text to natural speech: understanding modern neural TTS architectures that power Alexa, Google Assistant, and Siri.">



  <meta property="og:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">



  <meta name="twitter:site" content="@arunbaby0">
  <meta name="twitter:title" content="Text-to-Speech (TTS) System Fundamentals">
  <meta name="twitter:description" content="From text to natural speech: understanding modern neural TTS architectures that power Alexa, Google Assistant, and Siri.">
  <meta name="twitter:url" content="https://www.arunbaby.com/speech-tech/0006-text-to-speech-basics/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">
    
  

  



  <meta property="article:published_time" content="2025-12-13T22:45:49+05:30">





  

  


<link rel="canonical" href="https://www.arunbaby.com/speech-tech/0006-text-to-speech-basics/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Baby Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          <span class="site-subtitle">Arun Baby</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/dsa/"
                
                
              >DSA</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ml-system-design/"
                
                
              >ML Systems</a>
            </li><li class="masthead__menu-item">
              <a
                href="/speech-tech/"
                
                
              >Speech Tech</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li><li class="masthead__menu-item">
              <a
                href="/statuses/"
                
                
              >Statuses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/contact/"
                
                
              >Contact</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main" class="no-author-sidebar">
  
  <div class="sidebar sticky">
  
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Text-to-Speech (TTS) System Fundamentals">
    <meta itemprop="description" content="From text to natural speech: understanding modern neural TTS architectures that power Alexa, Google Assistant, and Siri.">
    <meta itemprop="datePublished" content="2025-12-13T22:45:49+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://www.arunbaby.com/speech-tech/0006-text-to-speech-basics/" itemprop="url">Text-to-Speech (TTS) System Fundamentals
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          20 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#introduction">Introduction</a></li><li><a href="#tts-pipeline-architecture">TTS Pipeline Architecture</a><ul><li><a href="#traditional-two-stage-pipeline">Traditional Two-Stage Pipeline</a></li><li><a href="#why-two-stages">Why Two Stages?</a></li></ul></li><li><a href="#key-components">Key Components</a><ul><li><a href="#1-text-processing-frontend">1. Text Processing (Frontend)</a></li><li><a href="#2-acoustic-model">2. Acoustic Model</a></li><li><a href="#3-vocoder">3. Vocoder</a></li></ul></li><li><a href="#modern-tts-fastspeech-2">Modern TTS: FastSpeech 2</a></li><li><a href="#prosody-control">Prosody Control</a></li><li><a href="#connection-to-evaluation-metrics">Connection to Evaluation Metrics</a><ul><li><a href="#objective-metrics">Objective Metrics</a></li><li><a href="#subjective-metrics">Subjective Metrics</a></li></ul></li><li><a href="#production-considerations">Production Considerations</a><ul><li><a href="#latency">Latency</a></li><li><a href="#multi-speaker-tts">Multi-Speaker TTS</a></li></ul></li><li><a href="#training-data-requirements">Training Data Requirements</a><ul><li><a href="#dataset-characteristics">Dataset Characteristics</a></li><li><a href="#data-preparation-pipeline">Data Preparation Pipeline</a></li><li><a href="#data-quality-challenges">Data Quality Challenges</a></li></ul></li><li><a href="#voice-cloning--few-shot-learning">Voice Cloning &amp; Few-Shot Learning</a><ul><li><a href="#approaches">Approaches</a></li></ul></li><li><a href="#production-deployment-patterns">Production Deployment Patterns</a><ul><li><a href="#pattern-1-caching--dynamic-generation">Pattern 1: Caching + Dynamic Generation</a></li><li><a href="#pattern-2-streaming-tts">Pattern 2: Streaming TTS</a></li><li><a href="#pattern-3-edge-deployment">Pattern 3: Edge Deployment</a></li></ul></li><li><a href="#quality-assessment-in-production">Quality Assessment in Production</a><ul><li><a href="#automated-quality-monitoring">Automated Quality Monitoring</a></li></ul></li><li><a href="#comparative-analysis">Comparative Analysis</a><ul><li><a href="#tacotron-2-vs-fastspeech-2">Tacotron 2 vs FastSpeech 2</a></li><li><a href="#when-to-use-each">When to Use Each</a></li></ul></li><li><a href="#recent-advances-2023-2024">Recent Advances (2023-2024)</a><ul><li><a href="#1-vall-e-zero-shot-voice-cloning">1. VALL-E (Zero-Shot Voice Cloning)</a></li><li><a href="#2-vits-end-to-end-tts">2. VITS (End-to-End TTS)</a></li><li><a href="#3-yourtts-multi-lingual-voice-cloning">3. YourTTS (Multi-lingual Voice Cloning)</a></li><li><a href="#4-bark-generative-audio-model">4. Bark (Generative Audio Model)</a></li></ul></li><li><a href="#key-takeaways">Key Takeaways</a></li></ul>
            </nav>
          </aside>
        
        <p><strong>From text to natural speech: understanding modern neural TTS architectures that power Alexa, Google Assistant, and Siri.</strong></p>

<h2 id="introduction">Introduction</h2>

<p><strong>Text-to-Speech (TTS)</strong> converts written text into spoken audio. Modern TTS systems produce human-like speech quality using deep learning.</p>

<p><strong>Why TTS matters:</strong></p>
<ul>
  <li><strong>Virtual assistants:</strong> Alexa, Google Assistant, Siri</li>
  <li><strong>Accessibility:</strong> Screen readers for visually impaired</li>
  <li><strong>Content creation:</strong> Audiobooks, podcasts, voiceovers</li>
  <li><strong>Conversational AI:</strong> Voice bots, IVR systems</li>
  <li><strong>Education:</strong> Language learning apps</li>
</ul>

<p><strong>Evolution:</strong></p>
<ol>
  <li><strong>Concatenative synthesis</strong> (1990s-2000s): Stitch pre-recorded audio units</li>
  <li><strong>Parametric synthesis</strong> (2000s-2010s): Statistical models (HMM)</li>
  <li><strong>Neural TTS</strong> (2016+): End-to-end deep learning (Tacotron, WaveNet)</li>
  <li><strong>Modern TTS</strong> (2020+): Fast, controllable, expressive (FastSpeech, VITS)</li>
</ol>

<hr />

<h2 id="tts-pipeline-architecture">TTS Pipeline Architecture</h2>

<h3 id="traditional-two-stage-pipeline">Traditional Two-Stage Pipeline</h3>

<p>Most TTS systems use a two-stage approach:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text → [Acoustic Model] → Mel Spectrogram → [Vocoder] → Audio Waveform
</code></pre></div></div>

<p><strong>Stage 1: Acoustic Model (Text → Mel Spectrogram)</strong></p>
<ul>
  <li>Input: Text (characters/phonemes)</li>
  <li>Output: Mel spectrogram (acoustic features)</li>
  <li>Examples: Tacotron 2, FastSpeech 2</li>
</ul>

<p><strong>Stage 2: Vocoder (Mel Spectrogram → Waveform)</strong></p>
<ul>
  <li>Input: Mel spectrogram</li>
  <li>Output: Audio waveform</li>
  <li>Examples: WaveNet, WaveGlow, HiFi-GAN</li>
</ul>

<h3 id="why-two-stages">Why Two Stages?</h3>

<p><strong>Advantages:</strong></p>
<ul>
  <li><strong>Modularity:</strong> Train acoustic model and vocoder separately</li>
  <li><strong>Efficiency:</strong> Mel spectrogram is compressed representation</li>
  <li><strong>Controllability:</strong> Can modify prosody at mel spectrogram level</li>
</ul>

<p><strong>Alternative: End-to-End Models</strong></p>
<ul>
  <li>VITS (Variational Inference with adversarial learning for end-to-end Text-to-Speech)</li>
  <li>Directly generates waveform from text</li>
  <li>Faster inference, fewer components</li>
</ul>

<hr />

<h2 id="key-components">Key Components</h2>

<h3 id="1-text-processing-frontend">1. Text Processing (Frontend)</h3>

<p>Transform raw text into model-ready input.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TextProcessor</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Text normalization and phoneme conversion
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">normalizer</span> <span class="o">=</span> <span class="nc">TextNormalizer</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">g2p</span> <span class="o">=</span> <span class="nc">Grapheme2Phoneme</span><span class="p">()</span>  <span class="c1"># Grapheme-to-Phoneme
</span>    
    <span class="k">def</span> <span class="nf">process</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">
        Convert text to phoneme sequence
        
        Args:
            text: Raw input text
        
        Returns:
            List of phonemes
        </span><span class="sh">"""</span>
        <span class="c1"># 1. Normalize text
</span>        <span class="n">normalized</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">normalizer</span><span class="p">.</span><span class="nf">normalize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="c1"># "Dr. Smith has $100" → "Doctor Smith has one hundred dollars"
</span>        
        <span class="c1"># 2. Convert to phonemes
</span>        <span class="n">phonemes</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">g2p</span><span class="p">.</span><span class="nf">convert</span><span class="p">(</span><span class="n">normalized</span><span class="p">)</span>
        <span class="c1"># "hello" → ['HH', 'AH', 'L', 'OW']
</span>        
        <span class="k">return</span> <span class="n">phonemes</span>

<span class="k">class</span> <span class="nc">TextNormalizer</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Normalize text (expand abbreviations, numbers, etc.)
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_expand_abbreviations</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_expand_numbers</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_expand_symbols</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">text</span>
    
    <span class="k">def</span> <span class="nf">_expand_abbreviations</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Dr. → Doctor, Mr. → Mister, etc.</span><span class="sh">"""</span>
        <span class="n">expansions</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">Dr.</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">Doctor</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Mr.</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">Mister</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Mrs.</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">Misses</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">Ms.</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">Miss</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">St.</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">Street</span><span class="sh">'</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">for</span> <span class="n">abbr</span><span class="p">,</span> <span class="n">expansion</span> <span class="ow">in</span> <span class="n">expansions</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="n">abbr</span><span class="p">,</span> <span class="n">expansion</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">text</span>
    
    <span class="k">def</span> <span class="nf">_expand_numbers</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">$100 → one hundred dollars</span><span class="sh">"""</span>
        <span class="kn">import</span> <span class="n">re</span>
        
        <span class="c1"># Currency
</span>        <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">\$(\d+)</span><span class="sh">'</span><span class="p">,</span> <span class="sa">r</span><span class="sh">'</span><span class="s">\1 dollars</span><span class="sh">'</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
        
        <span class="c1"># Years
</span>        <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sa">r</span><span class="sh">'</span><span class="s">(\d{4})</span><span class="sh">'</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">_year_to_words</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">text</span>
    
    <span class="k">def</span> <span class="nf">_year_to_words</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">match</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Convert year to words: 2024 → twenty twenty-four</span><span class="sh">"""</span>
        <span class="c1"># Simplified implementation
</span>        <span class="k">return</span> <span class="k">match</span><span class="p">.</span><span class="nf">group</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Placeholder
</span>    
    <span class="k">def</span> <span class="nf">_expand_symbols</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">@ → at, % → percent, etc.</span><span class="sh">"""</span>
        <span class="n">symbols</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">@</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">at</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">%</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">percent</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">#</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">number</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">&amp;</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">and</span><span class="sh">'</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">for</span> <span class="n">symbol</span><span class="p">,</span> <span class="n">expansion</span> <span class="ow">in</span> <span class="n">symbols</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="n">symbol</span><span class="p">,</span> <span class="n">expansion</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">text</span>
</code></pre></div></div>

<h3 id="2-acoustic-model">2. Acoustic Model</h3>

<p>Generates mel spectrogram from text/phonemes.</p>

<p><strong>Tacotron 2 Architecture (simplified):</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Input: Phoneme sequence
   ↓
[Character Embeddings]
   ↓
[Encoder] (Bidirectional LSTM)
   ↓
[Attention] (Location-sensitive)
   ↓
[Decoder] (Autoregressive LSTM)
   ↓
[Mel Predictor]
   ↓
Output: Mel Spectrogram
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">SimplifiedTacotron</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Simplified Tacotron-style acoustic model
    
    Real Tacotron 2 is much more complex!
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span>
        <span class="n">encoder_hidden</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
        <span class="n">decoder_hidden</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
        <span class="n">n_mels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">80</span>
    <span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="c1"># Character/phoneme embeddings
</span>        <span class="n">self</span><span class="p">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
        
        <span class="c1"># Encoder
</span>        <span class="n">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LSTM</span><span class="p">(</span>
            <span class="n">embedding_dim</span><span class="p">,</span>
            <span class="n">encoder_hidden</span><span class="p">,</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">bidirectional</span><span class="o">=</span><span class="bp">True</span>
        <span class="p">)</span>
        
        <span class="c1"># Attention
</span>        <span class="n">self</span><span class="p">.</span><span class="n">attention</span> <span class="o">=</span> <span class="nc">LocationSensitiveAttention</span><span class="p">(</span>
            <span class="n">encoder_hidden</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span>  <span class="c1"># Bidirectional
</span>            <span class="n">decoder_hidden</span>
        <span class="p">)</span>
        
        <span class="c1"># Decoder
</span>        <span class="n">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LSTMCell</span><span class="p">(</span>
            <span class="n">encoder_hidden</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">n_mels</span><span class="p">,</span>  <span class="c1"># Context + previous mel frame
</span>            <span class="n">decoder_hidden</span>
        <span class="p">)</span>
        
        <span class="c1"># Mel predictor
</span>        <span class="n">self</span><span class="p">.</span><span class="n">mel_predictor</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">n_mels</span><span class="p">)</span>
        
        <span class="c1"># Stop token predictor
</span>        <span class="n">self</span><span class="p">.</span><span class="n">stop_predictor</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">decoder_hidden</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">mel_targets</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Forward pass
        
        Args:
            text: [batch, seq_len] phoneme indices
            mel_targets: [batch, mel_len, n_mels] target mels (training only)
        
        Returns:
            mels: [batch, mel_len, n_mels]
            stop_tokens: [batch, mel_len]
        </span><span class="sh">"""</span>
        <span class="c1"># Encode text
</span>        <span class="n">embedded</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">embedding</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>  <span class="c1"># [batch, seq_len, embed_dim]
</span>        <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">encoder</span><span class="p">(</span><span class="n">embedded</span><span class="p">)</span>  <span class="c1"># [batch, seq_len, hidden*2]
</span>        
        <span class="c1"># Decode (autoregressive)
</span>        <span class="k">if</span> <span class="n">mel_targets</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="c1"># Teacher forcing during training
</span>            <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">_decode_teacher_forcing</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">mel_targets</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Autoregressive during inference
</span>            <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">_decode_autoregressive</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_decode_autoregressive</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">max_len</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Autoregressive decoding (inference)</span><span class="sh">"""</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">encoder_outputs</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">n_mels</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">mel_predictor</span><span class="p">.</span><span class="n">out_features</span>
        
        <span class="c1"># Initialize
</span>        <span class="n">decoder_hidden</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">decoder</span><span class="p">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="n">decoder_cell</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">decoder</span><span class="p">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="n">attention_context</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">mel_frame</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">n_mels</span><span class="p">)</span>
        
        <span class="n">mels</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">stop_tokens</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">max_len</span><span class="p">):</span>
            <span class="c1"># Compute attention
</span>            <span class="n">attention_context</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">attention</span><span class="p">(</span>
                <span class="n">decoder_hidden</span><span class="p">,</span>
                <span class="n">encoder_outputs</span>
            <span class="p">)</span>
            
            <span class="c1"># Decoder step
</span>            <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">attention_context</span><span class="p">,</span> <span class="n">mel_frame</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">decoder_cell</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">decoder</span><span class="p">(</span>
                <span class="n">decoder_input</span><span class="p">,</span>
                <span class="p">(</span><span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">decoder_cell</span><span class="p">)</span>
            <span class="p">)</span>
            
            <span class="c1"># Predict mel frame and stop token
</span>            <span class="n">mel_frame</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">mel_predictor</span><span class="p">(</span><span class="n">decoder_hidden</span><span class="p">)</span>
            <span class="n">stop_token</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">stop_predictor</span><span class="p">(</span><span class="n">decoder_hidden</span><span class="p">))</span>
            
            <span class="n">mels</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">mel_frame</span><span class="p">)</span>
            <span class="n">stop_tokens</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">stop_token</span><span class="p">)</span>
            
            <span class="c1"># Check if should stop
</span>            <span class="nf">if </span><span class="p">(</span><span class="n">stop_token</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">).</span><span class="nf">all</span><span class="p">():</span>
                <span class="k">break</span>
        
        <span class="n">mels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span><span class="n">mels</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [batch, mel_len, n_mels]
</span>        <span class="n">stop_tokens</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span><span class="n">stop_tokens</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [batch, mel_len, 1]
</span>        
        <span class="k">return</span> <span class="n">mels</span><span class="p">,</span> <span class="n">stop_tokens</span>

<span class="k">class</span> <span class="nc">LocationSensitiveAttention</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Location-sensitive attention (simplified)
    
    Note: Real Tacotron uses cumulative attention features; this
    minimal version omits location convolution for brevity.
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">encoder_dim</span><span class="p">,</span> <span class="n">decoder_dim</span><span class="p">,</span> <span class="n">attention_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">query_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">decoder_dim</span><span class="p">,</span> <span class="n">attention_dim</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">key_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">encoder_dim</span><span class="p">,</span> <span class="n">attention_dim</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">value_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">attention_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># For brevity, location features are omitted in this simplified demo
</span>    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">keys</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Compute attention context
        
        Args:
            query: [batch, decoder_dim] - current decoder state
            keys: [batch, seq_len, encoder_dim] - encoder outputs
        
        Returns:
            context: [batch, encoder_dim]
            attention_weights: [batch, seq_len]
        </span><span class="sh">"""</span>
        <span class="c1"># Compute attention scores
</span>        <span class="n">query_proj</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">query_layer</span><span class="p">(</span><span class="n">query</span><span class="p">).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [batch, 1, attn_dim]
</span>        <span class="n">keys_proj</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">key_layer</span><span class="p">(</span><span class="n">keys</span><span class="p">)</span>  <span class="c1"># [batch, seq_len, attn_dim]
</span>        
        <span class="n">scores</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">value_layer</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">tanh</span><span class="p">(</span><span class="n">query_proj</span> <span class="o">+</span> <span class="n">keys_proj</span><span class="p">)).</span><span class="nf">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [batch, seq_len]
</span>        
        <span class="c1"># Compute context
</span>        <span class="n">context</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">bmm</span><span class="p">(</span>
            <span class="n">attention_weights</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">keys</span>
        <span class="p">).</span><span class="nf">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [batch, encoder_dim]
</span>        
        <span class="k">return</span> <span class="n">context</span><span class="p">,</span> <span class="n">attention_weights</span>
</code></pre></div></div>

<h3 id="3-vocoder">3. Vocoder</h3>

<p>Converts mel spectrogram to waveform.</p>

<p><strong>Popular Vocoders:</strong></p>

<table>
  <thead>
    <tr>
      <th>Model</th>
      <th>Type</th>
      <th>Quality</th>
      <th>Speed</th>
      <th>Notes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>WaveNet</td>
      <td>Autoregressive</td>
      <td>Excellent</td>
      <td>Slow</td>
      <td>Original neural vocoder</td>
    </tr>
    <tr>
      <td>WaveGlow</td>
      <td>Flow-based</td>
      <td>Excellent</td>
      <td>Fast</td>
      <td>Parallel generation</td>
    </tr>
    <tr>
      <td>HiFi-GAN</td>
      <td>GAN-based</td>
      <td>Excellent</td>
      <td>Very Fast</td>
      <td>Current SOTA</td>
    </tr>
    <tr>
      <td>MelGAN</td>
      <td>GAN-based</td>
      <td>Good</td>
      <td>Very Fast</td>
      <td>Lightweight</td>
    </tr>
  </tbody>
</table>

<p><strong>HiFi-GAN Architecture:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">HiFiGANGenerator</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Simplified HiFi-GAN generator
    
    Upsamples mel spectrogram to waveform
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">n_mels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">80</span><span class="p">,</span>
        <span class="n">upsample_rates</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="n">upsample_kernel_sizes</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
        <span class="n">resblock_kernel_sizes</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span>
        <span class="n">resblock_dilation_sizes</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">]]</span>
    <span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">num_kernels</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">resblock_kernel_sizes</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">num_upsamples</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">upsample_rates</span><span class="p">)</span>
        
        <span class="c1"># Initial conv
</span>        <span class="n">self</span><span class="p">.</span><span class="n">conv_pre</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Conv1d</span><span class="p">(</span><span class="n">n_mels</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
        
        <span class="c1"># Upsampling layers
</span>        <span class="n">self</span><span class="p">.</span><span class="n">ups</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">upsample_rates</span><span class="p">,</span> <span class="n">upsample_kernel_sizes</span><span class="p">)):</span>
            <span class="n">self</span><span class="p">.</span><span class="n">ups</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span>
                <span class="n">nn</span><span class="p">.</span><span class="nc">ConvTranspose1d</span><span class="p">(</span>
                    <span class="mi">512</span> <span class="o">//</span> <span class="p">(</span><span class="mi">2</span> <span class="o">**</span> <span class="n">i</span><span class="p">),</span>
                    <span class="mi">512</span> <span class="o">//</span> <span class="p">(</span><span class="mi">2</span> <span class="o">**</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)),</span>
                    <span class="n">kernel_size</span><span class="o">=</span><span class="n">k</span><span class="p">,</span>
                    <span class="n">stride</span><span class="o">=</span><span class="n">u</span><span class="p">,</span>
                    <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="n">k</span> <span class="o">-</span> <span class="n">u</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
                <span class="p">)</span>
            <span class="p">)</span>
        
        <span class="c1"># Residual blocks
</span>        <span class="n">self</span><span class="p">.</span><span class="n">resblocks</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">ups</span><span class="p">)):</span>
            <span class="n">ch</span> <span class="o">=</span> <span class="mi">512</span> <span class="o">//</span> <span class="p">(</span><span class="mi">2</span> <span class="o">**</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">resblock_kernel_sizes</span><span class="p">,</span> <span class="n">resblock_dilation_sizes</span><span class="p">):</span>
                <span class="n">self</span><span class="p">.</span><span class="n">resblocks</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nc">ResBlock</span><span class="p">(</span><span class="n">ch</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">d</span><span class="p">))</span>
        
        <span class="c1"># Final conv
</span>        <span class="n">self</span><span class="p">.</span><span class="n">conv_post</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Conv1d</span><span class="p">(</span><span class="n">ch</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mel</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Generate waveform from mel spectrogram
        
        Args:
            mel: [batch, n_mels, mel_len]
        
        Returns:
            waveform: [batch, 1, audio_len]
        </span><span class="sh">"""</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv_pre</span><span class="p">(</span><span class="n">mel</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">up</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">ups</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">leaky_relu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="nf">up</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            
            <span class="c1"># Apply residual blocks
</span>            <span class="n">xs</span> <span class="o">=</span> <span class="bp">None</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">num_kernels</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">xs</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                    <span class="n">xs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">resblocks</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">num_kernels</span> <span class="o">+</span> <span class="n">j</span><span class="p">](</span><span class="n">x</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">xs</span> <span class="o">+=</span> <span class="n">self</span><span class="p">.</span><span class="n">resblocks</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">num_kernels</span> <span class="o">+</span> <span class="n">j</span><span class="p">](</span><span class="n">x</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">xs</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">num_kernels</span>
        
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">leaky_relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv_post</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">x</span>

<span class="k">class</span> <span class="nc">ResBlock</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Residual block with dilated convolutions</span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">dilations</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">convs</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">ModuleList</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">dilations</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">convs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span>
                <span class="n">nn</span><span class="p">.</span><span class="nc">Conv1d</span><span class="p">(</span>
                    <span class="n">channels</span><span class="p">,</span>
                    <span class="n">channels</span><span class="p">,</span>
                    <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
                    <span class="n">dilation</span><span class="o">=</span><span class="n">d</span><span class="p">,</span>
                    <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="n">kernel_size</span> <span class="o">*</span> <span class="n">d</span> <span class="o">-</span> <span class="n">d</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
                <span class="p">)</span>
            <span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">conv</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">convs</span><span class="p">:</span>
            <span class="n">xt</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">leaky_relu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
            <span class="n">xt</span> <span class="o">=</span> <span class="nf">conv</span><span class="p">(</span><span class="n">xt</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">xt</span>
        <span class="k">return</span> <span class="n">x</span>
</code></pre></div></div>

<hr />

<h2 id="modern-tts-fastspeech-2">Modern TTS: FastSpeech 2</h2>

<p><strong>Problem with Tacotron:</strong> Autoregressive decoding is slow and can have attention errors.</p>

<p><strong>FastSpeech 2 advantages:</strong></p>
<ul>
  <li><strong>Non-autoregressive:</strong> Generates all mel frames in parallel (much faster)</li>
  <li><strong>Duration prediction:</strong> Predicts phoneme durations explicitly</li>
  <li><strong>Controllability:</strong> Can control pitch, energy, duration</li>
</ul>

<p><strong>Architecture:</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Input: Phoneme sequence
   ↓
[Phoneme Embeddings]
   ↓
[Feed-Forward Transformer]
   ↓
[Duration Predictor] → phoneme durations
[Pitch Predictor] → pitch contour
[Energy Predictor] → energy contour
   ↓
[Length Regulator] (expand phonemes by duration)
   ↓
[Feed-Forward Transformer]
   ↓
Output: Mel Spectrogram
</code></pre></div></div>

<p><strong>Key innovation: Length Regulator</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">length_regulator</span><span class="p">(</span><span class="n">phoneme_features</span><span class="p">,</span> <span class="n">durations</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Expand phoneme features based on predicted durations
    
    Args:
        phoneme_features: [batch, phoneme_len, hidden]
        durations: [batch, phoneme_len] - frames per phoneme
    
    Returns:
        expanded: [batch, mel_len, hidden]
    </span><span class="sh">"""</span>
    <span class="n">expanded</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">batch_idx</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">phoneme_features</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)):</span>
        <span class="n">batch_expanded</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">phoneme_idx</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">phoneme_features</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)):</span>
            <span class="n">feature</span> <span class="o">=</span> <span class="n">phoneme_features</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">,</span> <span class="n">phoneme_idx</span><span class="p">]</span>
            <span class="n">duration</span> <span class="o">=</span> <span class="n">durations</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">,</span> <span class="n">phoneme_idx</span><span class="p">].</span><span class="nf">int</span><span class="p">()</span>
            
            <span class="c1"># Repeat feature 'duration' times
</span>            <span class="n">batch_expanded</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">feature</span><span class="p">.</span><span class="nf">repeat</span><span class="p">(</span><span class="n">duration</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        
        <span class="n">batch_expanded</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">(</span><span class="n">batch_expanded</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">expanded</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">batch_expanded</span><span class="p">)</span>
    
    <span class="c1"># Pad to max length
</span>    <span class="n">max_len</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">e</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">expanded</span><span class="p">)</span>
    <span class="n">expanded</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">pad</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">max_len</span> <span class="o">-</span> <span class="n">e</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)))</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">expanded</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span><span class="n">expanded</span><span class="p">)</span>

<span class="c1"># Example
</span><span class="n">phoneme_features</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>  <span class="c1"># 10 phonemes
</span><span class="n">durations</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>  <span class="c1"># Frames per phoneme
</span>
<span class="n">expanded</span> <span class="o">=</span> <span class="nf">length_regulator</span><span class="p">(</span><span class="n">phoneme_features</span><span class="p">,</span> <span class="n">durations</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Input shape: </span><span class="si">{</span><span class="n">phoneme_features</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Output shape: </span><span class="si">{</span><span class="n">expanded</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>  <span class="c1"># [1, 44, 256] (sum of durations)
</span></code></pre></div></div>

<hr />

<h2 id="prosody-control">Prosody Control</h2>

<p><strong>Prosody:</strong> Rhythm, stress, and intonation of speech</p>

<p><strong>Control dimensions:</strong></p>
<ul>
  <li><strong>Pitch:</strong> Fundamental frequency (F0)</li>
  <li><strong>Duration:</strong> Phoneme/word length</li>
  <li><strong>Energy:</strong> Loudness</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ProsodyController</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Control prosody in TTS generation
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
    
    <span class="k">def</span> <span class="nf">synthesize_with_prosody</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">pitch_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">duration_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">energy_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Generate speech with prosody control
        
        Args:
            text: Input text
            pitch_scale: Multiply pitch by this factor (&gt;1 = higher, &lt;1 = lower)
            duration_scale: Multiply duration by this factor (&gt;1 = slower, &lt;1 = faster)
            energy_scale: Multiply energy by this factor (&gt;1 = louder, &lt;1 = softer)
        
        Returns:
            audio: Generated waveform
        </span><span class="sh">"""</span>
        <span class="c1"># Get model predictions
</span>        <span class="n">phonemes</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">text_to_phonemes</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="n">mel_spec</span><span class="p">,</span> <span class="n">pitch</span><span class="p">,</span> <span class="n">duration</span><span class="p">,</span> <span class="n">energy</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">phonemes</span><span class="p">)</span>
        
        <span class="c1"># Apply prosody modifications
</span>        <span class="n">pitch_modified</span> <span class="o">=</span> <span class="n">pitch</span> <span class="o">*</span> <span class="n">pitch_scale</span>
        <span class="n">duration_modified</span> <span class="o">=</span> <span class="n">duration</span> <span class="o">*</span> <span class="n">duration_scale</span>
        <span class="n">energy_modified</span> <span class="o">=</span> <span class="n">energy</span> <span class="o">*</span> <span class="n">energy_scale</span>
        
        <span class="c1"># Regenerate mel spectrogram with modified prosody
</span>        <span class="n">mel_spec_modified</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">synthesize_mel</span><span class="p">(</span>
            <span class="n">phonemes</span><span class="p">,</span>
            <span class="n">pitch</span><span class="o">=</span><span class="n">pitch_modified</span><span class="p">,</span>
            <span class="n">duration</span><span class="o">=</span><span class="n">duration_modified</span><span class="p">,</span>
            <span class="n">energy</span><span class="o">=</span><span class="n">energy_modified</span>
        <span class="p">)</span>
        
        <span class="c1"># Vocoder: mel → waveform
</span>        <span class="n">audio</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">vocoder</span><span class="p">(</span><span class="n">mel_spec_modified</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">audio</span>

<span class="c1"># Usage example
</span><span class="n">controller</span> <span class="o">=</span> <span class="nc">ProsodyController</span><span class="p">(</span><span class="n">tts_model</span><span class="p">)</span>

<span class="c1"># Happy speech: higher pitch, faster
</span><span class="n">happy_audio</span> <span class="o">=</span> <span class="n">controller</span><span class="p">.</span><span class="nf">synthesize_with_prosody</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">Hello, how are you?</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">pitch_scale</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span>
    <span class="n">duration_scale</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
    <span class="n">energy_scale</span><span class="o">=</span><span class="mf">1.1</span>
<span class="p">)</span>

<span class="c1"># Sad speech: lower pitch, slower
</span><span class="n">sad_audio</span> <span class="o">=</span> <span class="n">controller</span><span class="p">.</span><span class="nf">synthesize_with_prosody</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">Hello, how are you?</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">pitch_scale</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="n">duration_scale</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span>
    <span class="n">energy_scale</span><span class="o">=</span><span class="mf">0.9</span>
<span class="p">)</span>
</code></pre></div></div>

<hr />

<h2 id="connection-to-evaluation-metrics">Connection to Evaluation Metrics</h2>

<p>Like ML model evaluation, TTS systems need multiple metrics:</p>

<h3 id="objective-metrics">Objective Metrics</h3>

<p><strong>Mel Cepstral Distortion (MCD):</strong></p>
<ul>
  <li>Measures distance between generated and ground truth mels</li>
  <li>Lower is better</li>
  <li>Correlates with quality but not perfectly</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">librosa</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">mel_cepstral_distortion</span><span class="p">(</span><span class="n">generated_mel</span><span class="p">,</span> <span class="n">target_mel</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Compute MCD between generated and target mel spectrograms
    
    Args:
        generated_mel: [n_mels, time]
        target_mel: [n_mels, time]
    
    Returns:
        MCD score (lower is better)
    </span><span class="sh">"""</span>
    <span class="c1"># Align lengths
</span>    <span class="n">min_len</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="n">generated_mel</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">target_mel</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">generated_mel</span> <span class="o">=</span> <span class="n">generated_mel</span><span class="p">[:,</span> <span class="p">:</span><span class="n">min_len</span><span class="p">]</span>
    <span class="n">target_mel</span> <span class="o">=</span> <span class="n">target_mel</span><span class="p">[:,</span> <span class="p">:</span><span class="n">min_len</span><span class="p">]</span>
    
    <span class="c1"># Compute simple L2 distance over mel frames (proxy for MCD)
</span>    <span class="n">diff</span> <span class="o">=</span> <span class="n">generated_mel</span> <span class="o">-</span> <span class="n">target_mel</span>
    <span class="n">mcd</span> <span class="o">=</span> <span class="nf">float</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">diff</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">mean</span><span class="p">())</span>
    
    <span class="k">return</span> <span class="n">mcd</span>
</code></pre></div></div>

<p><strong>F0 RMSE:</strong> Root mean squared error of pitch</p>

<p><strong>Duration Accuracy:</strong> How well predicted durations match ground truth</p>

<h3 id="subjective-metrics">Subjective Metrics</h3>

<p><strong>Mean Opinion Score (MOS):</strong></p>
<ul>
  <li>Human raters score quality 1-5</li>
  <li>Gold standard for TTS evaluation</li>
  <li>Expensive and time-consuming</li>
</ul>

<p><strong>MUSHRA Test:</strong> Compare multiple systems side-by-side</p>

<hr />

<h2 id="production-considerations">Production Considerations</h2>

<h3 id="latency">Latency</h3>

<p><strong>Components of TTS latency:</strong></p>
<ol>
  <li><strong>Text processing:</strong> 5-10ms</li>
  <li><strong>Acoustic model:</strong> 50-200ms (depends on text length)</li>
  <li><strong>Vocoder:</strong> 20-100ms</li>
  <li><strong>Total:</strong> 75-310ms</li>
</ol>

<p><strong>Optimization strategies:</strong></p>
<ul>
  <li><strong>Streaming TTS:</strong> Generate audio incrementally</li>
  <li><strong>Model distillation:</strong> Smaller, faster models</li>
  <li><strong>Quantization:</strong> INT8 inference</li>
  <li><strong>Caching:</strong> Pre-generate common phrases</li>
</ul>

<h3 id="multi-speaker-tts">Multi-Speaker TTS</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MultiSpeakerTTS</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    TTS supporting multiple voices
    
    Approach 1: Speaker embedding
    Approach 2: Separate models per speaker
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">speaker_embeddings</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="n">self</span><span class="p">.</span><span class="n">speaker_embeddings</span> <span class="o">=</span> <span class="n">speaker_embeddings</span>
    
    <span class="k">def</span> <span class="nf">synthesize</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">speaker_id</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Generate speech in specific speaker</span><span class="sh">'</span><span class="s">s voice
        
        Args:
            text: Input text
            speaker_id: Speaker identifier
        
        Returns:
            audio: Waveform in target speaker</span><span class="sh">'</span><span class="s">s voice
        </span><span class="sh">"""</span>
        <span class="c1"># Get speaker embedding
</span>        <span class="n">speaker_emb</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">speaker_embeddings</span><span class="p">[</span><span class="n">speaker_id</span><span class="p">]</span>
        
        <span class="c1"># Generate with speaker conditioning
</span>        <span class="n">mel</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">generate_mel</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">speaker_embedding</span><span class="o">=</span><span class="n">speaker_emb</span><span class="p">)</span>
        <span class="n">audio</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">vocoder</span><span class="p">(</span><span class="n">mel</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">audio</span>
</code></pre></div></div>

<hr />

<h2 id="training-data-requirements">Training Data Requirements</h2>

<h3 id="dataset-characteristics">Dataset Characteristics</h3>

<p><strong>Typical single-speaker TTS training:</strong></p>
<ul>
  <li><strong>Audio hours:</strong> 10-24 hours of clean speech</li>
  <li><strong>Utterances:</strong> 5,000-15,000 sentences</li>
  <li><strong>Recording quality:</strong> Studio quality, 22 kHz+ sample rate</li>
  <li><strong>Text diversity:</strong> Cover phonetic diversity of language</li>
</ul>

<p><strong>Multi-speaker TTS:</strong></p>
<ul>
  <li><strong>Speakers:</strong> 100-10,000 speakers</li>
  <li><strong>Hours per speaker:</strong> 1-5 hours</li>
  <li><strong>Total hours:</strong> 100-50,000 hours (e.g., LibriTTS: 585 hours, 2,456 speakers)</li>
</ul>

<h3 id="data-preparation-pipeline">Data Preparation Pipeline</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TTSDataPreparation</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Prepare data for TTS training
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">sample_rate</span><span class="o">=</span><span class="mi">22050</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
    
    <span class="k">def</span> <span class="nf">prepare_dataset</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">audio_files</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">text_files</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">
        Prepare audio-text pairs
        
        Steps:
        1. Text normalization
        2. Audio preprocessing
        3. Alignment (forced alignment)
        4. Feature extraction
        </span><span class="sh">"""</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">audio_file</span><span class="p">,</span> <span class="n">text_file</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">audio_files</span><span class="p">,</span> <span class="n">text_files</span><span class="p">):</span>
            <span class="c1"># Load audio
</span>            <span class="n">audio</span><span class="p">,</span> <span class="n">sr</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">audio_file</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">sample_rate</span><span class="p">)</span>
            
            <span class="c1"># Load text
</span>            <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">text_file</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">text</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="nf">read</span><span class="p">().</span><span class="nf">strip</span><span class="p">()</span>
            
            <span class="c1"># Normalize text
</span>            <span class="n">normalized_text</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">normalize_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
            
            <span class="c1"># Convert to phonemes
</span>            <span class="n">phonemes</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">text_to_phonemes</span><span class="p">(</span><span class="n">normalized_text</span><span class="p">)</span>
            
            <span class="c1"># Extract mel spectrogram
</span>            <span class="n">mel</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">extract_mel</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
            
            <span class="c1"># Extract prosody features
</span>            <span class="n">pitch</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">extract_pitch</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
            <span class="n">energy</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">extract_energy</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
            
            <span class="c1"># Compute duration (requires forced alignment)
</span>            <span class="n">duration</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">compute_durations</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">phonemes</span><span class="p">)</span>
            
            <span class="n">dataset</span><span class="p">.</span><span class="nf">append</span><span class="p">({</span>
                <span class="sh">'</span><span class="s">audio_path</span><span class="sh">'</span><span class="p">:</span> <span class="n">audio_file</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">text</span><span class="sh">'</span><span class="p">:</span> <span class="n">text</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">normalized_text</span><span class="sh">'</span><span class="p">:</span> <span class="n">normalized_text</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">phonemes</span><span class="sh">'</span><span class="p">:</span> <span class="n">phonemes</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">mel</span><span class="sh">'</span><span class="p">:</span> <span class="n">mel</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">pitch</span><span class="sh">'</span><span class="p">:</span> <span class="n">pitch</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">energy</span><span class="sh">'</span><span class="p">:</span> <span class="n">energy</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">duration</span><span class="sh">'</span><span class="p">:</span> <span class="n">duration</span>
            <span class="p">})</span>
        
        <span class="k">return</span> <span class="n">dataset</span>
    
    <span class="k">def</span> <span class="nf">extract_mel</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Extract mel spectrogram</span><span class="sh">"""</span>
        <span class="n">mel</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="n">feature</span><span class="p">.</span><span class="nf">melspectrogram</span><span class="p">(</span>
            <span class="n">y</span><span class="o">=</span><span class="n">audio</span><span class="p">,</span>
            <span class="n">sr</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">sample_rate</span><span class="p">,</span>
            <span class="n">n_fft</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
            <span class="n">hop_length</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
            <span class="n">n_mels</span><span class="o">=</span><span class="mi">80</span>
        <span class="p">)</span>
        <span class="n">mel_db</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="nf">power_to_db</span><span class="p">(</span><span class="n">mel</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mel_db</span>
    
    <span class="k">def</span> <span class="nf">extract_pitch</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Extract pitch (F0) contour</span><span class="sh">"""</span>
        <span class="n">f0</span><span class="p">,</span> <span class="n">voiced_flag</span><span class="p">,</span> <span class="n">voiced_probs</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="nf">pyin</span><span class="p">(</span>
            <span class="n">audio</span><span class="p">,</span>
            <span class="n">fmin</span><span class="o">=</span><span class="n">librosa</span><span class="p">.</span><span class="nf">note_to_hz</span><span class="p">(</span><span class="sh">'</span><span class="s">C2</span><span class="sh">'</span><span class="p">),</span>
            <span class="n">fmax</span><span class="o">=</span><span class="n">librosa</span><span class="p">.</span><span class="nf">note_to_hz</span><span class="p">(</span><span class="sh">'</span><span class="s">C7</span><span class="sh">'</span><span class="p">),</span>
            <span class="n">sr</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">sample_rate</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">f0</span>
    
    <span class="k">def</span> <span class="nf">extract_energy</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Extract energy (RMS)</span><span class="sh">"""</span>
        <span class="n">energy</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="n">feature</span><span class="p">.</span><span class="nf">rms</span><span class="p">(</span>
            <span class="n">y</span><span class="o">=</span><span class="n">audio</span><span class="p">,</span>
            <span class="n">frame_length</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
            <span class="n">hop_length</span><span class="o">=</span><span class="mi">256</span>
        <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">energy</span>
</code></pre></div></div>

<h3 id="data-quality-challenges">Data Quality Challenges</h3>

<p><strong>1. Noisy Audio:</strong></p>
<ul>
  <li>Background noise degrades quality</li>
  <li>Solution: Use noise reduction, or data augmentation</li>
</ul>

<p><strong>2. Alignment Errors:</strong></p>
<ul>
  <li>Text-audio misalignment breaks training</li>
  <li>Solution: Forced alignment with Montreal Forced Aligner (MFA)</li>
</ul>

<p><strong>3. Prosody Variation:</strong></p>
<ul>
  <li>Inconsistent prosody confuses models</li>
  <li>Solution: Filter outliers, normalize prosody</li>
</ul>

<p><strong>4. Out-of-Domain Text:</strong></p>
<ul>
  <li>Model struggles with unseen words/names</li>
  <li>Solution: Diverse training text, robust G2P</li>
</ul>

<hr />

<h2 id="voice-cloning--few-shot-learning">Voice Cloning &amp; Few-Shot Learning</h2>

<p><strong>Voice cloning:</strong> Generate speech in a target voice with minimal data.</p>

<h3 id="approaches">Approaches</h3>

<p><strong>1. Speaker Embedding (Zero-Shot/Few-Shot)</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SpeakerEncoder</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Encode speaker characteristics from reference audio
    
    Architecture: Similar to speaker recognition
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mel_dim</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="c1"># LSTM encoder
</span>        <span class="n">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LSTM</span><span class="p">(</span>
            <span class="n">mel_dim</span><span class="p">,</span>
            <span class="n">embedding_dim</span><span class="p">,</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span>
        <span class="p">)</span>
        
        <span class="c1"># Projection to speaker embedding
</span>        <span class="n">self</span><span class="p">.</span><span class="n">projection</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">mel</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Extract speaker embedding from mel spectrogram
        
        Args:
            mel: [batch, mel_len, mel_dim]
        
        Returns:
            speaker_embedding: [batch, embedding_dim]
        </span><span class="sh">"""</span>
        <span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">encoder</span><span class="p">(</span><span class="n">mel</span><span class="p">)</span>
        
        <span class="c1"># Use last hidden state
</span>        <span class="n">speaker_emb</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">projection</span><span class="p">(</span><span class="n">hidden</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        
        <span class="c1"># L2 normalize
</span>        <span class="n">speaker_emb</span> <span class="o">=</span> <span class="n">speaker_emb</span> <span class="o">/</span> <span class="p">(</span><span class="n">speaker_emb</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">speaker_emb</span>

<span class="k">class</span> <span class="nc">VoiceCloningTTS</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    TTS with voice cloning capability
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">acoustic_model</span><span class="p">,</span> <span class="n">vocoder</span><span class="p">,</span> <span class="n">speaker_encoder</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">acoustic_model</span> <span class="o">=</span> <span class="n">acoustic_model</span>
        <span class="n">self</span><span class="p">.</span><span class="n">vocoder</span> <span class="o">=</span> <span class="n">vocoder</span>
        <span class="n">self</span><span class="p">.</span><span class="n">speaker_encoder</span> <span class="o">=</span> <span class="n">speaker_encoder</span>
    
    <span class="k">def</span> <span class="nf">clone_voice</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">reference_audio</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span>
    <span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Generate speech in reference voice
        
        Args:
            text: Text to synthesize
            reference_audio: Audio sample of target voice (3-10 seconds)
        
        Returns:
            synthesized_audio: Speech in target voice
        </span><span class="sh">"""</span>
        <span class="c1"># Extract speaker embedding from reference
</span>        <span class="n">reference_mel</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">extract_mel</span><span class="p">(</span><span class="n">reference_audio</span><span class="p">)</span>
        <span class="n">speaker_embedding</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">speaker_encoder</span><span class="p">(</span><span class="n">reference_mel</span><span class="p">)</span>
        
        <span class="c1"># Generate mel spectrogram conditioned on speaker
</span>        <span class="n">mel</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">acoustic_model</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span>
            <span class="n">text</span><span class="p">,</span>
            <span class="n">speaker_embedding</span><span class="o">=</span><span class="n">speaker_embedding</span>
        <span class="p">)</span>
        
        <span class="c1"># Vocoder: mel → waveform
</span>        <span class="n">audio</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">vocoder</span><span class="p">(</span><span class="n">mel</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">audio</span>

<span class="c1"># Usage
</span><span class="n">tts</span> <span class="o">=</span> <span class="nc">VoiceCloningTTS</span><span class="p">(</span><span class="n">acoustic_model</span><span class="p">,</span> <span class="n">vocoder</span><span class="p">,</span> <span class="n">speaker_encoder</span><span class="p">)</span>

<span class="c1"># Clone voice from 5-second reference
</span><span class="n">reference_audio</span> <span class="o">=</span> <span class="nf">load_audio</span><span class="p">(</span><span class="sh">"</span><span class="s">reference_voice.wav</span><span class="sh">"</span><span class="p">)</span>
<span class="n">cloned_speech</span> <span class="o">=</span> <span class="n">tts</span><span class="p">.</span><span class="nf">clone_voice</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">Hello, this is a cloned voice!</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">reference_audio</span>
<span class="p">)</span>
</code></pre></div></div>

<p><strong>2. Fine-Tuning (10-60 minutes of data)</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">VoiceCloner</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Fine-tune pre-trained TTS on target voice
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">pretrained_model</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">pretrained_model</span>
    
    <span class="k">def</span> <span class="nf">fine_tune</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">target_voice_data</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">],</span>  <span class="c1"># [(audio, text), ...]
</span>        <span class="n">num_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span>
    <span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Fine-tune model on target voice
        
        Args:
            target_voice_data: Audio-text pairs for target speaker
            num_steps: Training steps
            learning_rate: Learning rate
        </span><span class="sh">"""</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_steps</span><span class="p">):</span>
            <span class="c1"># Sample batch
</span>            <span class="n">batch</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="n">target_voice_data</span><span class="p">,</span> <span class="nf">min</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">target_voice_data</span><span class="p">)))</span>
            
            <span class="c1"># Forward pass
</span>            <span class="n">loss</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">compute_loss</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
            
            <span class="c1"># Backward pass
</span>            <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
            
            <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s">, Loss: </span><span class="si">{</span><span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span>

<span class="c1"># Usage
</span><span class="n">cloner</span> <span class="o">=</span> <span class="nc">VoiceCloner</span><span class="p">(</span><span class="n">pretrained_tts_model</span><span class="p">)</span>

<span class="c1"># Collect 30 minutes of target voice
</span><span class="n">target_data</span> <span class="o">=</span> <span class="p">[...]</span>  <span class="c1"># List of (audio, text) pairs
</span>
<span class="c1"># Fine-tune
</span><span class="n">cloned_model</span> <span class="o">=</span> <span class="n">cloner</span><span class="p">.</span><span class="nf">fine_tune</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</code></pre></div></div>

<hr />

<h2 id="production-deployment-patterns">Production Deployment Patterns</h2>

<h3 id="pattern-1-caching--dynamic-generation">Pattern 1: Caching + Dynamic Generation</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">HybridTTSSystem</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Hybrid system: Cache common phrases, generate on-the-fly for novel text
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">tts_model</span><span class="p">,</span> <span class="n">cache_backend</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">tts</span> <span class="o">=</span> <span class="n">tts_model</span>
        <span class="n">self</span><span class="p">.</span><span class="n">cache</span> <span class="o">=</span> <span class="n">cache_backend</span>  <span class="c1"># e.g., Redis
</span>        <span class="n">self</span><span class="p">.</span><span class="n">common_phrases</span> <span class="o">=</span> <span class="p">[</span>
            <span class="sh">"</span><span class="s">Welcome</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Thank you</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Goodbye</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">Please hold</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">One moment please</span><span class="sh">"</span>
        <span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">_warm_cache</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">_warm_cache</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Pre-generate and cache common phrases</span><span class="sh">"""</span>
        <span class="k">for</span> <span class="n">phrase</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">common_phrases</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">self</span><span class="p">.</span><span class="n">cache</span><span class="p">.</span><span class="nf">exists</span><span class="p">(</span><span class="n">phrase</span><span class="p">):</span>
                <span class="n">audio</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">tts</span><span class="p">.</span><span class="nf">synthesize</span><span class="p">(</span><span class="n">phrase</span><span class="p">)</span>
                <span class="n">self</span><span class="p">.</span><span class="n">cache</span><span class="p">.</span><span class="nf">set</span><span class="p">(</span><span class="n">phrase</span><span class="p">,</span> <span class="n">audio</span><span class="p">,</span> <span class="n">ttl</span><span class="o">=</span><span class="mi">86400</span><span class="p">)</span>  <span class="c1"># 24-hour TTL
</span>    
    <span class="k">def</span> <span class="nf">synthesize</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Synthesize with caching
        
        Cache hit: &lt;5ms
        Cache miss: 100-300ms (generate)
        </span><span class="sh">"""</span>
        <span class="c1"># Check cache
</span>        <span class="n">cached</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">cache</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cached</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">cached</span>
        
        <span class="c1"># Generate
</span>        <span class="n">audio</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">tts</span><span class="p">.</span><span class="nf">synthesize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        
        <span class="c1"># Cache if frequently requested
</span>        <span class="n">request_count</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">cache</span><span class="p">.</span><span class="nf">increment</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">count:</span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">request_count</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">cache</span><span class="p">.</span><span class="nf">set</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">audio</span><span class="p">,</span> <span class="n">ttl</span><span class="o">=</span><span class="mi">3600</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">audio</span>
</code></pre></div></div>

<h3 id="pattern-2-streaming-tts">Pattern 2: Streaming TTS</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">StreamingTTS</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Stream audio as it</span><span class="sh">'</span><span class="s">s generated (reduce latency)
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">acoustic_model</span><span class="p">,</span> <span class="n">vocoder</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">acoustic_model</span> <span class="o">=</span> <span class="n">acoustic_model</span>
        <span class="n">self</span><span class="p">.</span><span class="n">vocoder</span> <span class="o">=</span> <span class="n">vocoder</span>
    
    <span class="k">def</span> <span class="nf">stream_synthesize</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Generate audio in chunks
        
        Yields audio chunks as they</span><span class="sh">'</span><span class="s">re ready
        </span><span class="sh">"""</span>
        <span class="c1"># Generate mel spectrogram
</span>        <span class="n">mel_frames</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">acoustic_model</span><span class="p">.</span><span class="nf">generate_streaming</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        
        <span class="c1"># Stream vocoder output
</span>        <span class="n">mel_buffer</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">chunk_size</span> <span class="o">=</span> <span class="mi">50</span>  <span class="c1"># mel frames per chunk
</span>        
        <span class="k">for</span> <span class="n">mel_frame</span> <span class="ow">in</span> <span class="n">mel_frames</span><span class="p">:</span>
            <span class="n">mel_buffer</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">mel_frame</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">mel_buffer</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">chunk_size</span><span class="p">:</span>
                <span class="c1"># Vocoder: mel chunk → audio chunk
</span>                <span class="n">mel_chunk</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span><span class="n">mel_buffer</span><span class="p">)</span>
                <span class="n">audio_chunk</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">vocoder</span><span class="p">(</span><span class="n">mel_chunk</span><span class="p">)</span>
                
                <span class="k">yield</span> <span class="n">audio_chunk</span>
                
                <span class="c1"># Keep overlap for smoothness
</span>                <span class="n">mel_buffer</span> <span class="o">=</span> <span class="n">mel_buffer</span><span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">:]</span>
        
        <span class="c1"># Final chunk
</span>        <span class="k">if</span> <span class="n">mel_buffer</span><span class="p">:</span>
            <span class="n">mel_chunk</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span><span class="n">mel_buffer</span><span class="p">)</span>
            <span class="n">audio_chunk</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">vocoder</span><span class="p">(</span><span class="n">mel_chunk</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">audio_chunk</span>

<span class="c1"># Usage
</span><span class="n">streaming_tts</span> <span class="o">=</span> <span class="nc">StreamingTTS</span><span class="p">(</span><span class="n">acoustic_model</span><span class="p">,</span> <span class="n">vocoder</span><span class="p">)</span>

<span class="c1"># Stream audio
</span><span class="k">for</span> <span class="n">audio_chunk</span> <span class="ow">in</span> <span class="n">streaming_tts</span><span class="p">.</span><span class="nf">stream_synthesize</span><span class="p">(</span><span class="sh">"</span><span class="s">Long text to synthesize...</span><span class="sh">"</span><span class="p">):</span>
    <span class="c1"># Play audio_chunk immediately
</span>    <span class="nf">play_audio</span><span class="p">(</span><span class="n">audio_chunk</span><span class="p">)</span>
    <span class="c1"># User starts hearing speech before full generation completes!
</span></code></pre></div></div>

<h3 id="pattern-3-edge-deployment">Pattern 3: Edge Deployment</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">EdgeTTS</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    TTS optimized for edge devices (phones, IoT)
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">load_optimized_model</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">load_optimized_model</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Load quantized, pruned model
        
        Techniques:
        - INT8 quantization (4x smaller, 2-4x faster)
        - Knowledge distillation (smaller student model)
        - Pruning (remove 30-50% of weights)
        </span><span class="sh">"""</span>
        <span class="kn">import</span> <span class="n">torch.quantization</span>
        
        <span class="c1"># Load full precision model
</span>        <span class="n">model</span> <span class="o">=</span> <span class="nf">load_full_model</span><span class="p">()</span>
        
        <span class="c1"># Quantize to INT8
</span>        <span class="c1"># Use dynamic quantization for linear-heavy modules as a safe default
</span>        <span class="n">model_quantized</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">quantization</span><span class="p">.</span><span class="nf">quantize_dynamic</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span>
            <span class="p">{</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">},</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">qint8</span>
        <span class="p">)</span>
        
        <span class="k">return</span> <span class="n">model_quantized</span>
    
    <span class="k">def</span> <span class="nf">synthesize_on_device</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Synthesize on edge device
        
        Latency: 50-150ms
        Memory: &lt;100MB
        </span><span class="sh">"""</span>
        <span class="n">audio</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">audio</span>
</code></pre></div></div>

<hr />

<h2 id="quality-assessment-in-production">Quality Assessment in Production</h2>

<h3 id="automated-quality-monitoring">Automated Quality Monitoring</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TTSQualityMonitor</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Monitor TTS quality in production
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">baseline_mcd</span> <span class="o">=</span> <span class="mf">2.5</span>  <span class="c1"># Expected MCD
</span>        <span class="n">self</span><span class="p">.</span><span class="n">alert_threshold</span> <span class="o">=</span> <span class="mf">3.5</span>  <span class="c1"># Alert if MCD &gt; this
</span>    
    <span class="k">def</span> <span class="nf">monitor_synthesis</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">generated_audio</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Check quality of generated audio
        
        Red flags:
        - Abnormal duration
        - Clipping / distortion
        - Silent segments
        - MCD drift
        </span><span class="sh">"""</span>
        <span class="n">issues</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="c1"># Check duration
</span>        <span class="n">expected_duration</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">text</span><span class="p">.</span><span class="nf">split</span><span class="p">())</span> <span class="o">*</span> <span class="mf">0.5</span>  <span class="c1"># ~0.5s per word
</span>        <span class="n">actual_duration</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">generated_audio</span><span class="p">)</span> <span class="o">/</span> <span class="mi">22050</span>
        <span class="k">if</span> <span class="nf">abs</span><span class="p">(</span><span class="n">actual_duration</span> <span class="o">-</span> <span class="n">expected_duration</span><span class="p">)</span> <span class="o">/</span> <span class="n">expected_duration</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
            <span class="n">issues</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Abnormal duration: </span><span class="si">{</span><span class="n">actual_duration</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">s vs </span><span class="si">{</span><span class="n">expected_duration</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">s expected</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="c1"># Check for clipping
</span>        <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">generated_audio</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mf">0.99</span><span class="p">:</span>
            <span class="n">issues</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">"</span><span class="s">Clipping detected</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="c1"># Check for silent segments
</span>        <span class="n">rms</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="n">feature</span><span class="p">.</span><span class="nf">rms</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">generated_audio</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">silent_ratio</span> <span class="o">=</span> <span class="p">(</span><span class="n">rms</span> <span class="o">&lt;</span> <span class="mf">0.01</span><span class="p">).</span><span class="nf">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">rms</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">silent_ratio</span> <span class="o">&gt;</span> <span class="mf">0.3</span><span class="p">:</span>
            <span class="n">issues</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Too much silence: </span><span class="si">{</span><span class="n">silent_ratio</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="o">%</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="c1"># Log for drift detection
</span>        <span class="n">self</span><span class="p">.</span><span class="nf">log_quality_metrics</span><span class="p">({</span>
            <span class="sh">'</span><span class="s">text_length</span><span class="sh">'</span><span class="p">:</span> <span class="nf">len</span><span class="p">(</span><span class="n">text</span><span class="p">),</span>
            <span class="sh">'</span><span class="s">audio_duration</span><span class="sh">'</span><span class="p">:</span> <span class="n">actual_duration</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">max_amplitude</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">generated_audio</span><span class="p">)),</span>
            <span class="sh">'</span><span class="s">silent_ratio</span><span class="sh">'</span><span class="p">:</span> <span class="n">silent_ratio</span>
        <span class="p">})</span>
        
        <span class="k">return</span> <span class="n">issues</span>
    
    <span class="k">def</span> <span class="nf">log_quality_metrics</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">metrics</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Log metrics for drift detection</span><span class="sh">"""</span>
        <span class="c1"># Send to monitoring system (Datadog, Prometheus, etc.)
</span>        <span class="k">pass</span>
</code></pre></div></div>

<hr />

<h2 id="comparative-analysis">Comparative Analysis</h2>

<h3 id="tacotron-2-vs-fastspeech-2">Tacotron 2 vs FastSpeech 2</h3>

<table>
  <thead>
    <tr>
      <th>Aspect</th>
      <th>Tacotron 2</th>
      <th>FastSpeech 2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Speed</strong></td>
      <td>Slow (autoregressive)</td>
      <td>Fast (parallel)</td>
    </tr>
    <tr>
      <td><strong>Quality</strong></td>
      <td>Excellent</td>
      <td>Excellent</td>
    </tr>
    <tr>
      <td><strong>Robustness</strong></td>
      <td>Can skip/repeat words</td>
      <td>More robust</td>
    </tr>
    <tr>
      <td><strong>Controllability</strong></td>
      <td>Limited</td>
      <td>Explicit control (pitch, duration)</td>
    </tr>
    <tr>
      <td><strong>Training</strong></td>
      <td>Simpler (no duration model)</td>
      <td>Needs duration labels</td>
    </tr>
    <tr>
      <td><strong>Latency</strong></td>
      <td>200-500ms</td>
      <td>50-150ms</td>
    </tr>
  </tbody>
</table>

<h3 id="when-to-use-each">When to Use Each</h3>

<p><strong>Use Tacotron 2 when:</strong></p>
<ul>
  <li>Maximum naturalness is critical</li>
  <li>Training data is limited (easier to train)</li>
  <li>Latency is acceptable</li>
</ul>

<p><strong>Use FastSpeech 2 when:</strong></p>
<ul>
  <li>Low latency required</li>
  <li>Need prosody control</li>
  <li>Robustness is critical (production systems)</li>
</ul>

<hr />

<h2 id="recent-advances-2023-2024">Recent Advances (2023-2024)</h2>

<h3 id="1-vall-e-zero-shot-voice-cloning">1. VALL-E (Zero-Shot Voice Cloning)</h3>

<p>Microsoft’s VALL-E can clone a voice from a 3-second sample using language model approach.</p>

<p><strong>Key idea:</strong> Treat TTS as conditional language modeling over discrete audio codes.</p>

<h3 id="2-vits-end-to-end-tts">2. VITS (End-to-End TTS)</h3>

<p>Combines acoustic model and vocoder into single model.</p>

<p><strong>Advantages:</strong></p>
<ul>
  <li>Faster training and inference</li>
  <li>Better audio quality</li>
  <li>Simplified pipeline</li>
</ul>

<h3 id="3-yourtts-multi-lingual-voice-cloning">3. YourTTS (Multi-lingual Voice Cloning)</h3>

<p>Zero-shot multi-lingual TTS supporting 16+ languages.</p>

<h3 id="4-bark-generative-audio-model">4. Bark (Generative Audio Model)</h3>

<p>Text-to-audio model that can generate music, sound effects, and speech with emotions.</p>

<hr />

<h2 id="key-takeaways">Key Takeaways</h2>

<p>✅ <strong>Two-stage pipeline</strong> - Acoustic model + vocoder is standard<br />
✅ <strong>Text processing critical</strong> - Normalization and G2P affect quality<br />
✅ <strong>Autoregressive vs non-autoregressive</strong> - Tacotron vs FastSpeech trade-offs<br />
✅ <strong>Prosody control</strong> - Pitch, duration, energy for expressiveness<br />
✅ <strong>Multiple metrics</strong> - Objective (MCD) and subjective (MOS) both needed<br />
✅ <strong>Production optimization</strong> - Latency, caching, streaming for real-time use<br />
✅ <strong>Like climbing stairs</strong> - Build incrementally (phoneme → mel → waveform)</p>

<hr />

<p><strong>Originally published at:</strong> <a href="https://www.arunbaby.com/speech-tech/0006-text-to-speech-basics/">arunbaby.com/speech-tech/0006-text-to-speech-basics</a></p>

<p><em>If you found this helpful, consider sharing it with others who might benefit.</em></p>


        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#neural-tts" class="page__taxonomy-item p-category" rel="tag">neural-tts</a><span class="sep">, </span>
    
      <a href="/tags/#prosody" class="page__taxonomy-item p-category" rel="tag">prosody</a><span class="sep">, </span>
    
      <a href="/tags/#synthesis" class="page__taxonomy-item p-category" rel="tag">synthesis</a><span class="sep">, </span>
    
      <a href="/tags/#tts" class="page__taxonomy-item p-category" rel="tag">tts</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#speech-tech" class="page__taxonomy-item p-category" rel="tag">speech-tech</a>
    
    </span>
  </p>


        
      </footer>

      <div class="page__related page__related--full">
  <h2 class="page__related-title">Related across topics</h2>
  <style>
    /* Make section span full content width and use 2 equal columns */
    .page__related--full { float: inline-start; width: 100%; padding: 0; }
    .cross-related-grid { display: grid; grid-template-columns: repeat(2, minmax(0, 1fr)); gap: 2rem; }
    @media (max-width: 768px) { .cross-related-grid { grid-template-columns: 1fr; } }
    /* Ensure archive cards stretch nicely in the grid */
    .cross-related-grid .list__item, .cross-related-grid .grid__item { width: auto; float: none; margin: 0; }
  </style>
  <div class="cross-related-grid">
    



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/dsa/0006-climbing-stairs/" rel="permalink">Climbing Stairs
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          25 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">The Fibonacci problem in disguise, teaching the fundamental transition from recursion to dynamic programming to space optimization.
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ml-system-design/0006-model-evaluation-metrics/" rel="permalink">Model Evaluation Metrics
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          24 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">How to measure if your ML model is actually good, choosing the right metrics is as important as building the model itself.
</p>
  </article>
</div>

  </div>
</div>

      <section class="page__share">
  <h4 class="page__share-title">Share on</h4>

  <a href="https://twitter.com/intent/tweet?via=arunbaby0&text=Text-to-Speech+%28TTS%29+System+Fundamentals%20https%3A%2F%2Fwww.arunbaby.com%2Fspeech-tech%2F0006-text-to-speech-basics%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.arunbaby.com%2Fspeech-tech%2F0006-text-to-speech-basics%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.arunbaby.com/speech-tech/0006-text-to-speech-basics/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/speech-tech/0005-speaker-recognition/" class="pagination--pager" title="Speaker Recognition &amp; Verification">Previous</a>
    
    
      <a href="/speech-tech/0007-audio-preprocessing/" class="pagination--pager" title="Audio Preprocessing &amp; Signal Processing">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 1990 - 2143 <a href="https://www.arunbaby.com">Arun Baby</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JRJPEC9SS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0JRJPEC9SS', { 'anonymize_ip': false});
</script>








  </body>
</html>
