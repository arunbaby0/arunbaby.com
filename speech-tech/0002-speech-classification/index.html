<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Speech Command Classification - Arun Baby</title>
<meta name="description" content="How voice assistants recognize “turn on the lights” from raw audio in under 100ms without full ASR transcription.">


  <meta name="author" content="Arun Baby">
  
  <meta property="article:author" content="Arun Baby">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Arun Baby">
<meta property="og:title" content="Speech Command Classification">
<meta property="og:url" content="https://www.arunbaby.com/speech-tech/0002-speech-classification/">


  <meta property="og:description" content="How voice assistants recognize “turn on the lights” from raw audio in under 100ms without full ASR transcription.">



  <meta property="og:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">



  <meta name="twitter:site" content="@arunbaby0">
  <meta name="twitter:title" content="Speech Command Classification">
  <meta name="twitter:description" content="How voice assistants recognize “turn on the lights” from raw audio in under 100ms without full ASR transcription.">
  <meta name="twitter:url" content="https://www.arunbaby.com/speech-tech/0002-speech-classification/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">
    
  

  



  <meta property="article:published_time" content="2025-12-16T00:28:52+05:30">





  

  


<link rel="canonical" href="https://www.arunbaby.com/speech-tech/0002-speech-classification/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Baby Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          <span class="site-subtitle">Arun Baby</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/dsa/"
                
                
              >DSA</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ml-system-design/"
                
                
              >ML Systems</a>
            </li><li class="masthead__menu-item">
              <a
                href="/speech-tech/"
                
                
              >Speech Tech</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ai-agents/"
                
                
              >AI Agents</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li><li class="masthead__menu-item">
              <a
                href="/statuses/"
                
                
              >Statuses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/contact/"
                
                
              >Contact</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main" class="no-author-sidebar">
  
  <div class="sidebar sticky">
  
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Speech Command Classification">
    <meta itemprop="description" content="How voice assistants recognize “turn on the lights” from raw audio in under 100ms without full ASR transcription.">
    <meta itemprop="datePublished" content="2025-12-16T00:28:52+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://www.arunbaby.com/speech-tech/0002-speech-classification/" itemprop="url">Speech Command Classification
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          28 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#introduction">Introduction</a></li><li><a href="#problem-definition">Problem Definition</a><ul><li><a href="#functional-requirements">Functional Requirements</a></li><li><a href="#non-functional-requirements">Non-Functional Requirements</a></li></ul></li><li><a href="#why-not-asr--nlu">Why Not ASR + NLU?</a><ul><li><a href="#traditional-pipeline">Traditional Pipeline</a></li><li><a href="#direct-classification">Direct Classification</a></li></ul></li><li><a href="#architecture">Architecture</a></li><li><a href="#component-1-audio-preprocessing">Component 1: Audio Preprocessing</a><ul><li><a href="#fixed-length-input">Fixed-Length Input</a></li><li><a href="#normalization">Normalization</a></li></ul></li><li><a href="#component-2-feature-extraction">Component 2: Feature Extraction</a><ul><li><a href="#option-1-mfccs-mel-frequency-cepstral-coefficients">Option 1: MFCCs (Mel-Frequency Cepstral Coefficients)</a></li><li><a href="#option-2-mel-spectrogram">Option 2: Mel-Spectrogram</a></li></ul></li><li><a href="#component-3-model-architectures">Component 3: Model Architectures</a><ul><li><a href="#architecture-1-cnn-fastest-for-on-device">Architecture 1: CNN (Fastest for On-Device)</a></li><li><a href="#architecture-2-rnn-better-temporal-modeling">Architecture 2: RNN (Better Temporal Modeling)</a></li><li><a href="#architecture-3-attention-based-best-accuracy">Architecture 3: Attention-Based (Best Accuracy)</a></li><li><a href="#model-comparison">Model Comparison</a></li></ul></li><li><a href="#training-strategy">Training Strategy</a><ul><li><a href="#data-collection">Data Collection</a></li><li><a href="#data-augmentation">Data Augmentation</a></li><li><a href="#training-loop">Training Loop</a></li></ul></li><li><a href="#component-4-handling-unknown-commands">Component 4: Handling Unknown Commands</a><ul><li><a href="#strategy-1-add-unknown-class">Strategy 1: Add “Unknown” Class</a></li><li><a href="#strategy-2-confidence-thresholding">Strategy 2: Confidence Thresholding</a></li><li><a href="#strategy-3-out-of-distribution-ood-detection">Strategy 3: Out-of-Distribution (OOD) Detection</a></li></ul></li><li><a href="#model-optimization-for-edge-deployment">Model Optimization for Edge Deployment</a><ul><li><a href="#quantization">Quantization</a></li><li><a href="#pruning">Pruning</a></li><li><a href="#knowledge-distillation">Knowledge Distillation</a></li></ul></li><li><a href="#on-device-deployment">On-Device Deployment</a><ul><li><a href="#export-to-mobile-formats">Export to Mobile Formats</a></li><li><a href="#mobile-inference-code">Mobile Inference Code</a></li></ul></li><li><a href="#monitoring--evaluation">Monitoring &amp; Evaluation</a><ul><li><a href="#metrics-dashboard">Metrics Dashboard</a></li><li><a href="#online-monitoring">Online Monitoring</a></li></ul></li><li><a href="#multi-language-support">Multi-Language Support</a><ul><li><a href="#approach-1-separate-models-per-language">Approach 1: Separate Models per Language</a></li><li><a href="#approach-2-multilingual-shared-model">Approach 2: Multilingual Shared Model</a></li></ul></li><li><a href="#failure-cases--mitigation">Failure Cases &amp; Mitigation</a><ul><li><a href="#common-failure-modes">Common Failure Modes</a><ul><li><a href="#1-background-speechtv">1. Background Speech/TV</a></li><li><a href="#2-accented-speech">2. Accented Speech</a></li><li><a href="#3-noisy-environments">3. Noisy Environments</a></li><li><a href="#4-similar-sounding-commands">4. Similar Sounding Commands</a></li></ul></li></ul></li><li><a href="#production-deployment-architecture">Production Deployment Architecture</a><ul><li><a href="#edge-deployment-smart-speaker">Edge Deployment (Smart Speaker)</a></li><li><a href="#hybrid-edge-cloud-architecture">Hybrid Edge-Cloud Architecture</a></li></ul></li><li><a href="#ab-testing--gradual-rollout">A/B Testing &amp; Gradual Rollout</a><ul><li><a href="#experiment-framework">Experiment Framework</a></li><li><a href="#metrics-to-track">Metrics to Track</a></li></ul></li><li><a href="#real-world-examples">Real-World Examples</a><ul><li><a href="#google-assistant">Google Assistant</a></li><li><a href="#amazon-alexa">Amazon Alexa</a></li><li><a href="#apple-siri">Apple Siri</a></li></ul></li><li><a href="#key-takeaways">Key Takeaways</a></li><li><a href="#further-reading">Further Reading</a></li></ul>
            </nav>
          </aside>
        
        <p><strong>How voice assistants recognize “turn on the lights” from raw audio in under 100ms without full ASR transcription.</strong></p>

<h2 id="introduction">Introduction</h2>

<p>When you say “Alexa, turn off the lights” or “Hey Google, set a timer,” your voice assistant doesn’t actually transcribe your speech to text first. Instead, it uses a <strong>direct audio-to-intent classification</strong> system that’s:</p>

<ul>
  <li><strong>Faster</strong> than ASR + NLU (50-100ms vs 200-500ms)</li>
  <li><strong>Smaller</strong> models (&lt; 10MB vs 100MB+)</li>
  <li><strong>Works offline</strong> (on-device inference)</li>
  <li><strong>More privacy-preserving</strong> (no text sent to cloud)</li>
</ul>

<p>This approach is perfect for a <strong>limited vocabulary of commands</strong> (30-100 commands) where you care more about speed and privacy than open-ended understanding.</p>

<p><strong>What you’ll learn:</strong></p>
<ul>
  <li>Why direct audio→intent beats ASR→NLU for commands</li>
  <li>Audio feature extraction (MFCCs, mel-spectrograms)</li>
  <li>Model architectures (CNN, RNN, Attention)</li>
  <li>Training strategies and data augmentation</li>
  <li>On-device deployment and optimization</li>
  <li>Unknown command handling (OOD detection)</li>
  <li>Real-world examples from Google, Amazon, Apple</li>
</ul>

<hr />

<h2 id="problem-definition">Problem Definition</h2>

<p>Design a speech command classification system for a voice assistant that:</p>

<h3 id="functional-requirements">Functional Requirements</h3>

<ol>
  <li><strong>Multi-class Classification</strong>
    <ul>
      <li>30-50 predefined commands</li>
      <li>Examples: “lights on”, “volume up”, “play music”, “stop timer”</li>
      <li>Support synonyms and variations</li>
    </ul>
  </li>
  <li><strong>Unknown Detection</strong>
    <ul>
      <li>Detect and reject out-of-vocabulary audio</li>
      <li>Handle background conversation</li>
      <li>Distinguish commands from non-commands</li>
    </ul>
  </li>
  <li><strong>Multi-language Support</strong>
    <ul>
      <li>5+ languages initially</li>
      <li>Shared model or separate models per language</li>
    </ul>
  </li>
  <li><strong>Context Awareness</strong>
    <ul>
      <li>Optional: Use device state as context</li>
      <li>Example: “turn it off” depends on what’s currently on</li>
    </ul>
  </li>
</ol>

<h3 id="non-functional-requirements">Non-Functional Requirements</h3>

<ol>
  <li><strong>Latency</strong>
    <ul>
      <li>End-to-end &lt; 100ms</li>
      <li>Includes audio buffering, processing, inference</li>
    </ul>
  </li>
  <li><strong>Model Constraints</strong>
    <ul>
      <li>Model size &lt; 10MB (on-device)</li>
      <li>RAM usage &lt; 50MB during inference</li>
      <li>CPU-only (no GPU on most devices)</li>
    </ul>
  </li>
  <li><strong>Accuracy</strong>
    <ul>
      <li>
        <blockquote>
          <p>95% on target commands (clean audio)</p>
        </blockquote>
      </li>
      <li>
        <blockquote>
          <p>90% on noisy audio</p>
        </blockquote>
      </li>
      <li>&lt; 5% false positive rate</li>
    </ul>
  </li>
  <li><strong>Throughput</strong>
    <ul>
      <li>1000 QPS per server (cloud)</li>
      <li>Single inference on device</li>
    </ul>
  </li>
</ol>

<hr />

<h2 id="why-not-asr--nlu">Why Not ASR + NLU?</h2>

<h3 id="traditional-pipeline">Traditional Pipeline</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Audio → ASR → Text → NLU → Intent
"lights on" → ASR (200ms) → "lights on" → NLU (50ms) → {action: "lights", state: "on"}
Total latency: 250ms
</code></pre></div></div>

<h3 id="direct-classification">Direct Classification</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Audio → Audio Features → CNN → Intent
"lights on" → Mel-spec (5ms) → CNN (40ms) → {action: "lights", state: "on"}
Total latency: 45ms
</code></pre></div></div>

<p><strong>Advantages:</strong></p>
<ul>
  <li>✅ 5x faster (45ms vs 250ms)</li>
  <li>✅ 10x smaller model (5MB vs 50MB)</li>
  <li>✅ Works offline</li>
  <li>✅ More private (no text)</li>
  <li>✅ Fewer points of failure</li>
</ul>

<p><strong>Disadvantages:</strong></p>
<ul>
  <li>❌ Limited vocabulary (30-50 commands vs unlimited)</li>
  <li>❌ Less flexible (new commands need retraining)</li>
  <li>❌ Can’t handle complex queries (“turn on the lights in the living room at 8pm”)</li>
</ul>

<p><strong>When to use each:</strong></p>
<ul>
  <li><strong>Direct classification:</strong> Simple commands, latency-critical, on-device</li>
  <li><strong>ASR + NLU:</strong> Complex queries, unlimited vocabulary, cloud-based</li>
</ul>

<hr />

<h2 id="architecture">Architecture</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Audio Input (1-2 seconds @ 16kHz)
    ↓
Audio Preprocessing
    ├─ Resampling (if needed)
    ├─ Padding/Trimming to fixed length
    └─ Normalization
    ↓
Feature Extraction
    ├─ MFCCs (40 coefficients)
    or
    ├─ Mel-Spectrogram (40 bins)
    ↓
Neural Network
    ├─ CNN (fastest, on-device)
    or
    ├─ RNN (better temporal modeling)
    or
    ├─ Attention (best accuracy, slower)
    ↓
Softmax Layer (31 classes)
    ├─ 30 command classes
    └─ 1 unknown class
    ↓
Post-processing
    ├─ Confidence thresholding
    ├─ Unknown detection
    └─ Output filtering
    ↓
Prediction: {command: "lights_on", confidence: 0.94}
</code></pre></div></div>

<hr />

<h2 id="component-1-audio-preprocessing">Component 1: Audio Preprocessing</h2>

<h3 id="fixed-length-input">Fixed-Length Input</h3>

<p><strong>Problem:</strong> Audio clips have variable duration (0.5s - 3s)</p>

<p><strong>Solution:</strong> Standardize to fixed length (e.g., 1 second)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">preprocess_audio</span><span class="p">(</span><span class="n">audio</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="mi">16000</span><span class="p">,</span> <span class="n">target_duration</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Ensure all audio clips are same length
    
    Args:
        audio: Audio waveform
        sr: Sample rate
        target_duration: Target duration in seconds
    
    Returns:
        Processed audio of length sr * target_duration
    </span><span class="sh">"""</span>
    <span class="n">target_length</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">sr</span> <span class="o">*</span> <span class="n">target_duration</span><span class="p">)</span>
    
    <span class="c1"># Pad if too short
</span>    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">target_length</span><span class="p">:</span>
        <span class="n">pad_length</span> <span class="o">=</span> <span class="n">target_length</span> <span class="o">-</span> <span class="nf">len</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
        <span class="n">audio</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">pad</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_length</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="sh">'</span><span class="s">constant</span><span class="sh">'</span><span class="p">)</span>
    
    <span class="c1"># Trim if too long
</span>    <span class="k">elif</span> <span class="nf">len</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">target_length</span><span class="p">:</span>
        <span class="c1"># Take central portion
</span>        <span class="n">start</span> <span class="o">=</span> <span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span> <span class="o">-</span> <span class="n">target_length</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="n">audio</span> <span class="o">=</span> <span class="n">audio</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">start</span> <span class="o">+</span> <span class="n">target_length</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="n">audio</span>
</code></pre></div></div>

<p><strong>Why fixed length?</strong></p>
<ul>
  <li>Neural networks expect fixed-size inputs</li>
  <li>Enables batching during training</li>
  <li>Simplifies model architecture</li>
</ul>

<p><strong>Alternative: Variable-length with padding</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">pad_sequence</span><span class="p">(</span><span class="n">audios</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="mi">16000</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Pad multiple audio clips to longest length
    Used during batched inference
    </span><span class="sh">"""</span>
    <span class="n">max_length</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">audios</span><span class="p">)</span>
    
    <span class="n">padded</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">masks</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">audio</span> <span class="ow">in</span> <span class="n">audios</span><span class="p">:</span>
        <span class="n">pad_length</span> <span class="o">=</span> <span class="n">max_length</span> <span class="o">-</span> <span class="nf">len</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
        <span class="n">padded_audio</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">pad</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_length</span><span class="p">))</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">audio</span><span class="p">)).</span><span class="nf">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">pad_length</span>
        
        <span class="n">padded</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">padded_audio</span><span class="p">)</span>
        <span class="n">masks</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">padded</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">masks</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="normalization">Normalization</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">normalize_audio</span><span class="p">(</span><span class="n">audio</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Normalize audio to [-1, 1] range
    
    Improves model convergence and generalization
    </span><span class="sh">"""</span>
    <span class="c1"># Peak normalization
</span>    <span class="n">max_val</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">audio</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">max_val</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">audio</span> <span class="o">=</span> <span class="n">audio</span> <span class="o">/</span> <span class="n">max_val</span>
    
    <span class="k">return</span> <span class="n">audio</span>


<span class="k">def</span> <span class="nf">normalize_rms</span><span class="p">(</span><span class="n">audio</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">target_rms</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Normalize by RMS (root mean square) energy
    
    Better for handling volume variations
    </span><span class="sh">"""</span>
    <span class="n">current_rms</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">audio</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">current_rms</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">audio</span> <span class="o">=</span> <span class="n">audio</span> <span class="o">*</span> <span class="p">(</span><span class="n">target_rms</span> <span class="o">/</span> <span class="n">current_rms</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">audio</span>
</code></pre></div></div>

<hr />

<h2 id="component-2-feature-extraction">Component 2: Feature Extraction</h2>

<h3 id="option-1-mfccs-mel-frequency-cepstral-coefficients">Option 1: MFCCs (Mel-Frequency Cepstral Coefficients)</h3>

<p><strong>MFCCs</strong> capture the spectral envelope of speech, which is important for phonetic content.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">librosa</span>

<span class="k">def</span> <span class="nf">extract_mfcc</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="mi">16000</span><span class="p">,</span> <span class="n">n_mfcc</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">n_fft</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">hop_length</span><span class="o">=</span><span class="mi">160</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Extract MFCC features
    
    Args:
        audio: Waveform
        sr: Sample rate (Hz)
        n_mfcc: Number of MFCC coefficients
        n_fft: FFT window size
        hop_length: Hop length between frames (10ms at 16kHz)
    
    Returns:
        MFCCs: (n_mfcc, time_steps)
    </span><span class="sh">"""</span>
    <span class="c1"># Compute MFCCs
</span>    <span class="n">mfccs</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="n">feature</span><span class="p">.</span><span class="nf">mfcc</span><span class="p">(</span>
        <span class="n">y</span><span class="o">=</span><span class="n">audio</span><span class="p">,</span>
        <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span>
        <span class="n">n_mfcc</span><span class="o">=</span><span class="n">n_mfcc</span><span class="p">,</span>
        <span class="n">n_fft</span><span class="o">=</span><span class="n">n_fft</span><span class="p">,</span>
        <span class="n">hop_length</span><span class="o">=</span><span class="n">hop_length</span><span class="p">,</span>
        <span class="n">n_mels</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>          <span class="c1"># Number of mel bands
</span>        <span class="n">fmin</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>            <span class="c1"># Minimum frequency
</span>        <span class="n">fmax</span><span class="o">=</span><span class="n">sr</span><span class="o">//</span><span class="mi">2</span>          <span class="c1"># Maximum frequency (Nyquist)
</span>    <span class="p">)</span>
    
    <span class="c1"># Add delta (velocity) and delta-delta (acceleration)
</span>    <span class="n">delta</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="n">feature</span><span class="p">.</span><span class="nf">delta</span><span class="p">(</span><span class="n">mfccs</span><span class="p">)</span>
    <span class="n">delta2</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="n">feature</span><span class="p">.</span><span class="nf">delta</span><span class="p">(</span><span class="n">mfccs</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="c1"># Stack all features
</span>    <span class="n">features</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">vstack</span><span class="p">([</span><span class="n">mfccs</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">delta2</span><span class="p">])</span>  <span class="c1"># (120, time)
</span>    
    <span class="k">return</span> <span class="n">features</span><span class="p">.</span><span class="n">T</span>  <span class="c1"># (time, 120)
</span></code></pre></div></div>

<p><strong>Why delta features?</strong></p>
<ul>
  <li><strong>MFCCs:</strong> Spectral shape (what phonemes)</li>
  <li><strong>Delta:</strong> How spectral shape is changing (dynamics)</li>
  <li><strong>Delta-delta:</strong> Rate of change (acceleration)</li>
</ul>

<p>Together they capture both static and dynamic characteristics of speech.</p>

<h3 id="option-2-mel-spectrogram">Option 2: Mel-Spectrogram</h3>

<p><strong>Mel-spectrograms</strong> preserve more temporal resolution than MFCCs.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">extract_mel_spectrogram</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="mi">16000</span><span class="p">,</span> <span class="n">n_mels</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">n_fft</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">hop_length</span><span class="o">=</span><span class="mi">160</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Extract log mel-spectrogram
    
    Returns:
        Log mel-spectrogram: (time, n_mels)
    </span><span class="sh">"""</span>
    <span class="c1"># Compute mel spectrogram
</span>    <span class="n">mel_spec</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="n">feature</span><span class="p">.</span><span class="nf">melspectrogram</span><span class="p">(</span>
        <span class="n">y</span><span class="o">=</span><span class="n">audio</span><span class="p">,</span>
        <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span>
        <span class="n">n_fft</span><span class="o">=</span><span class="n">n_fft</span><span class="p">,</span>
        <span class="n">hop_length</span><span class="o">=</span><span class="n">hop_length</span><span class="p">,</span>
        <span class="n">n_mels</span><span class="o">=</span><span class="n">n_mels</span><span class="p">,</span>
        <span class="n">fmin</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">fmax</span><span class="o">=</span><span class="n">sr</span><span class="o">//</span><span class="mi">2</span>
    <span class="p">)</span>
    
    <span class="c1"># Convert to log scale (dB)
</span>    <span class="n">log_mel</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="nf">power_to_db</span><span class="p">(</span><span class="n">mel_spec</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">log_mel</span><span class="p">.</span><span class="n">T</span>  <span class="c1"># (time, n_mels)
</span></code></pre></div></div>

<p><strong>MFCCs vs Mel-Spectrogram:</strong></p>

<table>
  <thead>
    <tr>
      <th>Feature</th>
      <th>MFCCs</th>
      <th>Mel-Spectrogram</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Size</td>
      <td>(time, 13-40)</td>
      <td>(time, 40-80)</td>
    </tr>
    <tr>
      <td>Information</td>
      <td>Spectral envelope</td>
      <td>Full spectrum</td>
    </tr>
    <tr>
      <td>Works better with</td>
      <td>Small models</td>
      <td>CNNs (image-like)</td>
    </tr>
    <tr>
      <td>Training time</td>
      <td>Faster</td>
      <td>Slower</td>
    </tr>
    <tr>
      <td>Accuracy</td>
      <td>Slightly lower</td>
      <td>Slightly higher</td>
    </tr>
  </tbody>
</table>

<p><strong>Recommendation:</strong> Use <strong>mel-spectrograms with CNNs</strong> for best accuracy.</p>

<hr />

<h2 id="component-3-model-architectures">Component 3: Model Architectures</h2>

<h3 id="architecture-1-cnn-fastest-for-on-device">Architecture 1: CNN (Fastest for On-Device)</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">CommandCNN</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    CNN for audio command classification
    
    Treats mel-spectrogram as 2D image
    </span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">31</span><span class="p">,</span> <span class="n">input_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="c1"># Convolutional layers
</span>        <span class="n">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">BatchNorm2d</span><span class="p">(</span><span class="mi">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="p">)</span>
        
        <span class="c1"># Global average pooling (instead of fully-connected)
</span>        <span class="n">self</span><span class="p">.</span><span class="n">gap</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        
        <span class="c1"># Classification head
</span>        <span class="n">self</span><span class="p">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
        <span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># x: (batch, 1, time, freq)
</span>        
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>   <span class="c1"># → (batch, 32, time/2, freq/2)
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>   <span class="c1"># → (batch, 64, time/4, freq/4)
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>   <span class="c1"># → (batch, 128, time/8, freq/8)
</span>        
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">gap</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>     <span class="c1"># → (batch, 128, 1, 1)
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># → (batch, 128)
</span>        
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># → (batch, num_classes)
</span>        
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># Model size: ~2MB
# Inference time (CPU): 15ms
# Accuracy: ~93%
</span></code></pre></div></div>

<p><strong>Why CNNs work for audio:</strong></p>
<ul>
  <li><strong>Local patterns:</strong> Phonemes have localized frequency patterns</li>
  <li><strong>Translation invariance:</strong> Command can start at different times</li>
  <li><strong>Parameter sharing:</strong> Same filters across time/frequency</li>
  <li><strong>Efficient:</strong> Mostly matrix operations, highly optimized</li>
</ul>

<h3 id="architecture-2-rnn-better-temporal-modeling">Architecture 2: RNN (Better Temporal Modeling)</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">CommandRNN</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    RNN for command classification
    
    Better at capturing temporal dependencies
    </span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">31</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="c1"># LSTM layers
</span>        <span class="n">self</span><span class="p">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LSTM</span><span class="p">(</span>
            <span class="n">input_size</span><span class="o">=</span><span class="n">input_dim</span><span class="p">,</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">bidirectional</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span>
        <span class="p">)</span>
        
        <span class="c1"># Attention mechanism (optional)
</span>        <span class="n">self</span><span class="p">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># Classification head
</span>        <span class="n">self</span><span class="p">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># x: (batch, time, features)
</span>        
        <span class="c1"># LSTM
</span>        <span class="n">lstm_out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">lstm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># → (batch, time, hidden*2)
</span>        
        <span class="c1"># Attention pooling (instead of taking last time step)
</span>        <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span>
            <span class="n">self</span><span class="p">.</span><span class="nf">attention</span><span class="p">(</span><span class="n">lstm_out</span><span class="p">),</span>  <span class="c1"># → (batch, time, 1)
</span>            <span class="n">dim</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span>
        
        <span class="c1"># Weighted sum
</span>        <span class="n">context</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">attention_weights</span> <span class="o">*</span> <span class="n">lstm_out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># → (batch, hidden*2)
</span>        
        <span class="c1"># Classify
</span>        <span class="n">logits</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">classifier</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>  <span class="c1"># → (batch, num_classes)
</span>        
        <span class="k">return</span> <span class="n">logits</span>

<span class="c1"># Model size: ~5MB
# Inference time (CPU): 30ms
# Accuracy: ~95%
</span></code></pre></div></div>

<h3 id="architecture-3-attention-based-best-accuracy">Architecture 3: Attention-Based (Best Accuracy)</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">CommandTransformer</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Transformer for command classification
    
    Best accuracy but slower inference
    </span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">nhead</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">31</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="c1"># Input projection
</span>        <span class="n">self</span><span class="p">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        
        <span class="c1"># Positional encoding
</span>        <span class="n">self</span><span class="p">.</span><span class="n">pos_encoder</span> <span class="o">=</span> <span class="nc">PositionalEncoding</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        
        <span class="c1"># Transformer encoder
</span>        <span class="n">encoder_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">TransformerEncoderLayer</span><span class="p">(</span>
            <span class="n">d_model</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span>
            <span class="n">nhead</span><span class="o">=</span><span class="n">nhead</span><span class="p">,</span>
            <span class="n">dim_feedforward</span><span class="o">=</span><span class="n">d_model</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span>
        <span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">transformer</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">TransformerEncoder</span><span class="p">(</span><span class="n">encoder_layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">)</span>
        
        <span class="c1"># Classification head
</span>        <span class="n">self</span><span class="p">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># x: (batch, time, features)
</span>        
        <span class="c1"># Project to d_model
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># → (batch, time, d_model)
</span>        
        <span class="c1"># Add positional encoding
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">pos_encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="c1"># Transformer expects (time, batch, d_model)
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">transformer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># Average pool over time
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># → (batch, d_model)
</span>        
        <span class="c1"># Classify
</span>        <span class="n">logits</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># → (batch, num_classes)
</span>        
        <span class="k">return</span> <span class="n">logits</span>

<span class="k">class</span> <span class="nc">PositionalEncoding</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">5000</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="n">pe</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="n">position</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">div_term</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="mi">2</span><span class="p">).</span><span class="nf">float</span><span class="p">()</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="mf">10000.0</span><span class="p">)</span> <span class="o">/</span> <span class="n">d_model</span><span class="p">))</span>
        
        <span class="n">pe</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
        <span class="n">pe</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cos</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="nf">register_buffer</span><span class="p">(</span><span class="sh">'</span><span class="s">pe</span><span class="sh">'</span><span class="p">,</span> <span class="n">pe</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="n">pe</span><span class="p">[:,</span> <span class="p">:</span><span class="n">x</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="p">:]</span>

<span class="c1"># Model size: ~8MB
# Inference time (CPU): 50ms
# Accuracy: ~97%
</span></code></pre></div></div>

<h3 id="model-comparison">Model Comparison</h3>

<table>
  <thead>
    <tr>
      <th>Model</th>
      <th>Params</th>
      <th>Size</th>
      <th>CPU Latency</th>
      <th>GPU Latency</th>
      <th>Accuracy</th>
      <th>Best For</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>CNN</td>
      <td>500K</td>
      <td>2MB</td>
      <td>15ms</td>
      <td>3ms</td>
      <td>93%</td>
      <td>Mobile devices</td>
    </tr>
    <tr>
      <td>RNN</td>
      <td>1.2M</td>
      <td>5MB</td>
      <td>30ms</td>
      <td>5ms</td>
      <td>95%</td>
      <td>Balanced</td>
    </tr>
    <tr>
      <td>Transformer</td>
      <td>2M</td>
      <td>8MB</td>
      <td>50ms</td>
      <td>8ms</td>
      <td>97%</td>
      <td>Cloud/high-end</td>
    </tr>
  </tbody>
</table>

<p><strong>Production choice:</strong> CNN for on-device, RNN for cloud</p>

<hr />

<h2 id="training-strategy">Training Strategy</h2>

<h3 id="data-collection">Data Collection</h3>

<p><strong>Per command, need:</strong></p>
<ul>
  <li>1000-5000 examples</li>
  <li>100+ speakers (diversity)</li>
  <li>Both genders, various ages</li>
  <li>Different accents</li>
  <li>Background noise variations</li>
  <li>Different recording devices</li>
</ul>

<p><strong>Example dataset structure:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>data/
├── lights_on/
│   ├── speaker001_01.wav
│   ├── speaker001_02.wav
│   ├── speaker002_01.wav
│   └── ...
├── lights_off/
│   └── ...
├── volume_up/
│   └── ...
└── unknown/
    ├── random_speech/
    ├── music/
    ├── noise/
    └── silence/
</code></pre></div></div>

<h3 id="data-augmentation">Data Augmentation</h3>

<p><strong>Critical for robustness!</strong> Augment during training:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">random</span>

<span class="k">def</span> <span class="nf">augment_audio</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="mi">16000</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Apply random augmentation
    
    Each training example augmented differently
    </span><span class="sh">"""</span>
    <span class="n">augmentations</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">add_noise</span><span class="p">,</span>
        <span class="n">time_shift</span><span class="p">,</span>
        <span class="n">time_stretch</span><span class="p">,</span>
        <span class="n">pitch_shift</span><span class="p">,</span>
        <span class="n">add_reverb</span>
    <span class="p">]</span>
    
    <span class="c1"># Apply 1-3 random augmentations
</span>    <span class="n">num_augs</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">selected</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="n">augmentations</span><span class="p">,</span> <span class="n">num_augs</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">aug_fn</span> <span class="ow">in</span> <span class="n">selected</span><span class="p">:</span>
        <span class="n">audio</span> <span class="o">=</span> <span class="nf">aug_fn</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">sr</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">audio</span>


<span class="k">def</span> <span class="nf">add_noise</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">sr</span><span class="p">,</span> <span class="n">snr_db</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">20</span><span class="p">)):</span>
    <span class="sh">"""</span><span class="s">Add background noise at specific SNR</span><span class="sh">"""</span>
    <span class="c1"># Load random noise sample
</span>    <span class="n">noise</span> <span class="o">=</span> <span class="nf">load_random_noise_sample</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">audio</span><span class="p">))</span>
    
    <span class="c1"># Calculate noise power for target SNR
</span>    <span class="n">audio_power</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">audio</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">noise_power</span> <span class="o">=</span> <span class="n">audio_power</span> <span class="o">/</span> <span class="p">(</span><span class="mi">10</span> <span class="o">**</span> <span class="p">(</span><span class="n">snr_db</span> <span class="o">/</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">noise_scaled</span> <span class="o">=</span> <span class="n">noise</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">noise_power</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">noise</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">audio</span> <span class="o">+</span> <span class="n">noise_scaled</span>


<span class="k">def</span> <span class="nf">time_shift</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">sr</span><span class="p">,</span> <span class="n">shift_max</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Shift audio in time (simulates different reaction times)</span><span class="sh">"""</span>
    <span class="n">shift</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">sr</span> <span class="o">*</span> <span class="n">shift_max</span> <span class="o">*</span> <span class="p">(</span><span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">()</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">roll</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">shift</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">time_stretch</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">sr</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">)):</span>
    <span class="sh">"""</span><span class="s">Change speed without changing pitch</span><span class="sh">"""</span>
    <span class="k">return</span> <span class="n">librosa</span><span class="p">.</span><span class="n">effects</span><span class="p">.</span><span class="nf">time_stretch</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="n">rate</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">pitch_shift</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">sr</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)):</span>
    <span class="sh">"""</span><span class="s">Shift pitch (simulates different speakers)</span><span class="sh">"""</span>
    <span class="k">return</span> <span class="n">librosa</span><span class="p">.</span><span class="n">effects</span><span class="p">.</span><span class="nf">pitch_shift</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="n">n_steps</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">add_reverb</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">sr</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Add room reverb (simulates different environments)</span><span class="sh">"""</span>
    <span class="c1"># Simple reverb using convolution with impulse response
</span>    <span class="n">impulse_response</span> <span class="o">=</span> <span class="nf">generate_simple_reverb</span><span class="p">(</span><span class="n">sr</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">convolve</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">impulse_response</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="sh">'</span><span class="s">same</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Impact:</strong> 2-3x effective dataset size, 10-20% accuracy improvement</p>

<h3 id="training-loop">Training Loop</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train_command_classifier</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> 
    <span class="n">train_loader</span><span class="p">,</span> 
    <span class="n">val_loader</span><span class="p">,</span> 
    <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> 
    <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span>
<span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Train speech command classifier
    </span><span class="sh">"""</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">lr_scheduler</span><span class="p">.</span><span class="nc">ReduceLROnPlateau</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="sh">'</span><span class="s">max</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">patience</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span>
    <span class="p">)</span>
    
    <span class="n">best_val_acc</span> <span class="o">=</span> <span class="mf">0.0</span>
    
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="c1"># Training
</span>        <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">train_correct</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">train_total</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
            <span class="c1"># Extract features
</span>            <span class="n">features</span> <span class="o">=</span> <span class="nf">extract_features_batch</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="mi">16000</span><span class="p">)</span>
            <span class="n">features</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
            
            <span class="c1"># Add channel dimension for CNN
</span>            <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">features</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                <span class="n">features</span> <span class="o">=</span> <span class="n">features</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (batch, 1, time, freq)
</span>            
            <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">)</span>
            
            <span class="c1"># Forward
</span>            <span class="n">outputs</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            
            <span class="c1"># Backward
</span>            <span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
            
            <span class="c1"># Track accuracy
</span>            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">train_correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">).</span><span class="nf">sum</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span>
            <span class="n">train_total</span> <span class="o">+=</span> <span class="n">labels</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>
        
        <span class="n">train_acc</span> <span class="o">=</span> <span class="n">train_correct</span> <span class="o">/</span> <span class="n">train_total</span>
        <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">train_loss</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
        
        <span class="c1"># Validation
</span>        <span class="n">val_acc</span> <span class="o">=</span> <span class="nf">validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">)</span>
        
        <span class="c1"># Learning rate scheduling
</span>        <span class="n">scheduler</span><span class="p">.</span><span class="nf">step</span><span class="p">(</span><span class="n">val_acc</span><span class="p">)</span>
        
        <span class="c1"># Save best model
</span>        <span class="k">if</span> <span class="n">val_acc</span> <span class="o">&gt;</span> <span class="n">best_val_acc</span><span class="p">:</span>
            <span class="n">best_val_acc</span> <span class="o">=</span> <span class="n">val_acc</span>
            <span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">(),</span> <span class="sh">'</span><span class="s">best_model.pth</span><span class="sh">'</span><span class="p">)</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">✓ New best model: </span><span class="si">{</span><span class="n">val_acc</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s">: </span><span class="sh">"</span>
              <span class="sa">f</span><span class="sh">"</span><span class="s">Loss=</span><span class="si">{</span><span class="n">avg_loss</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">, </span><span class="sh">"</span>
              <span class="sa">f</span><span class="sh">"</span><span class="s">Train Acc=</span><span class="si">{</span><span class="n">train_acc</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">, </span><span class="sh">"</span>
              <span class="sa">f</span><span class="sh">"</span><span class="s">Val Acc=</span><span class="si">{</span><span class="n">val_acc</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">model</span>


<span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Evaluate on validation set</span><span class="sh">"""</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">audio</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
            <span class="n">features</span> <span class="o">=</span> <span class="nf">extract_features_batch</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
            <span class="n">features</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">features</span><span class="p">).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
            
            <span class="n">outputs</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            
            <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">).</span><span class="nf">sum</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
</code></pre></div></div>

<hr />

<h2 id="component-4-handling-unknown-commands">Component 4: Handling Unknown Commands</h2>

<h3 id="strategy-1-add-unknown-class">Strategy 1: Add “Unknown” Class</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Training data
</span><span class="n">command_classes</span> <span class="o">=</span> <span class="p">[</span>
    <span class="sh">"</span><span class="s">lights_on</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">lights_off</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">volume_up</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">volume_down</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">play_music</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">stop</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">pause</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">next</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">previous</span><span class="sh">"</span><span class="p">,</span>
    <span class="c1"># ... 30 total commands
</span><span class="p">]</span>

<span class="c1"># Collect negative examples
</span><span class="n">unknown_class</span> <span class="o">=</span> <span class="p">[</span>
    <span class="sh">"</span><span class="s">random_speech</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># Conversations
</span>    <span class="sh">"</span><span class="s">music</span><span class="sh">"</span><span class="p">,</span>          <span class="c1"># Background music
</span>    <span class="sh">"</span><span class="s">noise</span><span class="sh">"</span><span class="p">,</span>          <span class="c1"># Environmental sounds
</span>    <span class="sh">"</span><span class="s">silence</span><span class="sh">"</span>         <span class="c1"># No speech
</span><span class="p">]</span>

<span class="c1"># Labels: 0-29 for commands, 30 for unknown
</span><span class="n">all_classes</span> <span class="o">=</span> <span class="n">command_classes</span> <span class="o">+</span> <span class="p">[</span><span class="sh">"</span><span class="s">unknown</span><span class="sh">"</span><span class="p">]</span>
</code></pre></div></div>

<p><strong>Collecting unknown data:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Record actual user interactions
# Label anything that's NOT a command as "unknown"
</span>
<span class="n">unknown_samples</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">audio</span> <span class="ow">in</span> <span class="n">production_audio_stream</span><span class="p">:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nf">is_valid_command</span><span class="p">(</span><span class="n">audio</span><span class="p">):</span>
        <span class="n">unknown_samples</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">unknown_samples</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">10000</span><span class="p">:</span>
            <span class="c1"># Add to training set
</span>            <span class="nf">augment_and_save</span><span class="p">(</span><span class="n">unknown_samples</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">unknown</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="strategy-2-confidence-thresholding">Strategy 2: Confidence Thresholding</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">predict_with_threshold</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">audio</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.7</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Reject low-confidence predictions as unknown
    </span><span class="sh">"""</span>
    <span class="c1"># Extract features
</span>    <span class="n">features</span> <span class="o">=</span> <span class="nf">extract_mel_spectrogram</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">features</span><span class="p">).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="c1"># Predict
</span>    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="c1"># Get top prediction
</span>    <span class="n">max_prob</span><span class="p">,</span> <span class="n">predicted_class</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    
    <span class="c1"># Threshold check
</span>    <span class="k">if</span> <span class="n">max_prob</span> <span class="o">&lt;</span> <span class="n">threshold</span><span class="p">:</span>
        <span class="k">return</span> <span class="sh">"</span><span class="s">unknown</span><span class="sh">"</span><span class="p">,</span> <span class="nf">float</span><span class="p">(</span><span class="n">max_prob</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">command_classes</span><span class="p">[</span><span class="n">predicted_class</span><span class="p">],</span> <span class="nf">float</span><span class="p">(</span><span class="n">max_prob</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="strategy-3-out-of-distribution-ood-detection">Strategy 3: Out-of-Distribution (OOD) Detection</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">detect_ood_with_entropy</span><span class="p">(</span><span class="n">probs</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    High entropy = model is uncertain = likely OOD
    </span><span class="sh">"""</span>
    <span class="n">entropy</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">probs</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">probs</span> <span class="o">+</span> <span class="mf">1e-10</span><span class="p">))</span>
    
    <span class="c1"># Calibrate threshold on validation set
</span>    <span class="c1"># In-distribution: entropy ~0.5
</span>    <span class="c1"># Out-of-distribution: entropy &gt; 2.0
</span>    
    <span class="k">if</span> <span class="n">entropy</span> <span class="o">&gt;</span> <span class="mf">2.0</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">True</span>  <span class="c1"># OOD
</span>    <span class="k">return</span> <span class="bp">False</span>


<span class="k">def</span> <span class="nf">detect_ood_with_mahalanobis</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">class_means</span><span class="p">,</span> <span class="n">class_covariances</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Mahalanobis distance to class centroids
    
    Far from all classes = likely OOD
    </span><span class="sh">"""</span>
    <span class="n">min_distance</span> <span class="o">=</span> <span class="nf">float</span><span class="p">(</span><span class="sh">'</span><span class="s">inf</span><span class="sh">'</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">class_idx</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">class_means</span><span class="p">)):</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">class_means</span><span class="p">[</span><span class="n">class_idx</span><span class="p">]</span>
        <span class="n">cov</span> <span class="o">=</span> <span class="n">class_covariances</span><span class="p">[</span><span class="n">class_idx</span><span class="p">]</span>
        
        <span class="c1"># Mahalanobis distance
</span>        <span class="n">diff</span> <span class="o">=</span> <span class="n">features</span> <span class="o">-</span> <span class="n">mean</span>
        <span class="n">distance</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">diff</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">inv</span><span class="p">(</span><span class="n">cov</span><span class="p">)</span> <span class="o">@</span> <span class="n">diff</span><span class="p">)</span>
        
        <span class="n">min_distance</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="n">min_distance</span><span class="p">,</span> <span class="n">distance</span><span class="p">)</span>
    
    <span class="c1"># Threshold: 3-sigma rule
</span>    <span class="k">if</span> <span class="n">min_distance</span> <span class="o">&gt;</span> <span class="mf">3.0</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">True</span>  <span class="c1"># OOD
</span>    <span class="k">return</span> <span class="bp">False</span>
</code></pre></div></div>

<hr />

<h2 id="model-optimization-for-edge-deployment">Model Optimization for Edge Deployment</h2>

<h3 id="quantization">Quantization</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Post-training quantization (dynamic quantization targets Linear; Conv2d not supported)
</span><span class="n">model_fp32</span> <span class="o">=</span> <span class="nc">CommandCNN</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">31</span><span class="p">)</span>
<span class="n">model_fp32</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">'</span><span class="s">model.pth</span><span class="sh">'</span><span class="p">))</span>
<span class="n">model_fp32</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>

<span class="c1"># Dynamic quantization (Linear layers)
</span><span class="n">model_int8</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">quantization</span><span class="p">.</span><span class="nf">quantize_dynamic</span><span class="p">(</span>
    <span class="n">model_fp32</span><span class="p">,</span>
    <span class="p">{</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">},</span>
    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">qint8</span>
<span class="p">)</span>

<span class="c1"># Save
</span><span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="n">model_int8</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">(),</span> <span class="sh">'</span><span class="s">model_int8.pth</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Results (typical on CPU with CNN head including Linear):
# - Model size: 2MB → ~1.2MB (1.6x smaller)
# - Inference: 15ms → ~10-12ms (1.3-1.5x faster)
# - Accuracy: ~93.2% → ~93.0% (≤0.2% drop)
</span></code></pre></div></div>

<h3 id="pruning">Pruning</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch.nn.utils.prune</span> <span class="k">as</span> <span class="n">prune</span>

<span class="k">def</span> <span class="nf">prune_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">amount</span><span class="o">=</span><span class="mf">0.3</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Remove 30% of weights with lowest magnitude
    </span><span class="sh">"""</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">named_modules</span><span class="p">():</span>
        <span class="k">if</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">,</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">)):</span>
            <span class="n">prune</span><span class="p">.</span><span class="nf">l1_unstructured</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">weight</span><span class="sh">'</span><span class="p">,</span> <span class="n">amount</span><span class="o">=</span><span class="n">amount</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">model</span>

<span class="c1"># Results with 30% pruning:
# - Model size: 2MB → 1.4MB
# - Inference: 15ms → 12ms
# - Accuracy: 93.2% → 92.7%
</span></code></pre></div></div>

<h3 id="knowledge-distillation">Knowledge Distillation</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">distillation_loss</span><span class="p">(</span><span class="n">student_logits</span><span class="p">,</span> <span class="n">teacher_logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Train small student to mimic large teacher
    
    Args:
        temperature: Soften probability distributions
        alpha: Weight between soft and hard targets
    </span><span class="sh">"""</span>
    <span class="c1"># Soft targets from teacher
</span>    <span class="n">soft_targets</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">teacher_logits</span> <span class="o">/</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">soft_prob</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">log_softmax</span><span class="p">(</span><span class="n">student_logits</span> <span class="o">/</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">soft_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">soft_targets</span> <span class="o">*</span> <span class="n">soft_prob</span><span class="p">)</span> <span class="o">/</span> <span class="n">soft_prob</span><span class="p">.</span><span class="nf">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">soft_loss</span> <span class="o">=</span> <span class="n">soft_loss</span> <span class="o">*</span> <span class="p">(</span><span class="n">temperature</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    
    <span class="c1"># Hard targets (ground truth)
</span>    <span class="n">hard_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">()(</span><span class="n">student_logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    
    <span class="c1"># Combine
</span>    <span class="k">return</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">soft_loss</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">hard_loss</span>


<span class="c1"># Train student
</span><span class="n">teacher</span> <span class="o">=</span> <span class="nc">CommandTransformer</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">31</span><span class="p">)</span>  <span class="c1"># 8MB, 97% accuracy
</span><span class="n">student</span> <span class="o">=</span> <span class="nc">CommandCNN</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">31</span><span class="p">)</span>          <span class="c1"># 2MB, 93% accuracy
</span>
<span class="k">for</span> <span class="n">audio</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
    <span class="c1"># Teacher predictions (frozen)
</span>    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="n">teacher_logits</span> <span class="o">=</span> <span class="nf">teacher</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
    
    <span class="c1"># Student predictions
</span>    <span class="n">student_logits</span> <span class="o">=</span> <span class="nf">student</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
    
    <span class="c1"># Distillation loss
</span>    <span class="n">loss</span> <span class="o">=</span> <span class="nf">distillation_loss</span><span class="p">(</span><span class="n">student_logits</span><span class="p">,</span> <span class="n">teacher_logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    
    <span class="c1"># Optimize student
</span>    <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

<span class="c1"># Result: Student achieves 95% (vs 93% without distillation)
</span></code></pre></div></div>

<hr />

<h2 id="on-device-deployment">On-Device Deployment</h2>

<h3 id="export-to-mobile-formats">Export to Mobile Formats</h3>

<p><strong>TensorFlow Lite (Android):</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="c1"># Convert PyTorch to TensorFlow (via ONNX)
# 1. Export PyTorch to ONNX
</span><span class="n">torch</span><span class="p">.</span><span class="n">onnx</span><span class="p">.</span><span class="nf">export</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">dummy_input</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">model.onnx</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">input_names</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">input</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">output_names</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">output</span><span class="sh">'</span><span class="p">]</span>
<span class="p">)</span>

<span class="c1"># 2. Convert ONNX to TF
</span><span class="kn">import</span> <span class="n">onnx</span>
<span class="kn">from</span> <span class="n">onnx_tf.backend</span> <span class="kn">import</span> <span class="n">prepare</span>

<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">onnx</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">model.onnx</span><span class="sh">"</span><span class="p">)</span>
<span class="n">tf_model</span> <span class="o">=</span> <span class="nf">prepare</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>
<span class="n">tf_model</span><span class="p">.</span><span class="nf">export_graph</span><span class="p">(</span><span class="sh">"</span><span class="s">model_tf</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># 3. Convert TF to TFLite
</span><span class="n">converter</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">lite</span><span class="p">.</span><span class="n">TFLiteConverter</span><span class="p">.</span><span class="nf">from_saved_model</span><span class="p">(</span><span class="sh">"</span><span class="s">model_tf</span><span class="sh">"</span><span class="p">)</span>
<span class="n">converter</span><span class="p">.</span><span class="n">optimizations</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="p">.</span><span class="n">lite</span><span class="p">.</span><span class="n">Optimize</span><span class="p">.</span><span class="n">DEFAULT</span><span class="p">]</span>
<span class="n">tflite_model</span> <span class="o">=</span> <span class="n">converter</span><span class="p">.</span><span class="nf">convert</span><span class="p">()</span>

<span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">'</span><span class="s">command_classifier.tflite</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">wb</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="n">tflite_model</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Core ML (iOS):</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">coremltools</span> <span class="k">as</span> <span class="n">ct</span>

<span class="c1"># Trace PyTorch model
</span><span class="n">example_input</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">40</span><span class="p">)</span>
<span class="n">traced_model</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="nf">trace</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">example_input</span><span class="p">)</span>

<span class="c1"># Convert to Core ML
</span><span class="n">coreml_model</span> <span class="o">=</span> <span class="n">ct</span><span class="p">.</span><span class="nf">convert</span><span class="p">(</span>
    <span class="n">traced_model</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">ct</span><span class="p">.</span><span class="nc">TensorType</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">audio</span><span class="sh">"</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">40</span><span class="p">))],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">ct</span><span class="p">.</span><span class="nc">TensorType</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">logits</span><span class="sh">"</span><span class="p">)]</span>
<span class="p">)</span>

<span class="c1"># Add metadata
</span><span class="n">coreml_model</span><span class="p">.</span><span class="n">author</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Arun Baby</span><span class="sh">"</span>
<span class="n">coreml_model</span><span class="p">.</span><span class="n">short_description</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Speech command classifier</span><span class="sh">"</span>
<span class="n">coreml_model</span><span class="p">.</span><span class="n">version</span> <span class="o">=</span> <span class="sh">"</span><span class="s">1.0</span><span class="sh">"</span>

<span class="c1"># Save
</span><span class="n">coreml_model</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="sh">"</span><span class="s">CommandClassifier.mlmodel</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="mobile-inference-code">Mobile Inference Code</h3>

<p><strong>Android (Kotlin):</strong></p>

<div class="language-kotlin highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">org.tensorflow.lite.Interpreter</span>
<span class="k">import</span> <span class="nn">java.nio.ByteBuffer</span>

<span class="kd">class</span> <span class="nc">CommandClassifier</span><span class="p">(</span><span class="k">private</span> <span class="kd">val</span> <span class="py">context</span><span class="p">:</span> <span class="nc">Context</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">private</span> <span class="k">lateinit</span> <span class="kd">var</span> <span class="py">interpreter</span><span class="p">:</span> <span class="nc">Interpreter</span>
    
    <span class="nf">init</span> <span class="p">{</span>
        <span class="c1">// Load model</span>
        <span class="kd">val</span> <span class="py">model</span> <span class="p">=</span> <span class="nf">loadModelFile</span><span class="p">(</span><span class="s">"command_classifier.tflite"</span><span class="p">)</span>
        <span class="n">interpreter</span> <span class="p">=</span> <span class="nc">Interpreter</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="p">}</span>
    
    <span class="k">fun</span> <span class="nf">classify</span><span class="p">(</span><span class="n">audio</span><span class="p">:</span> <span class="nc">FloatArray</span><span class="p">):</span> <span class="nc">Pair</span><span class="p">&lt;</span><span class="nc">String</span><span class="p">,</span> <span class="nc">Float</span><span class="p">&gt;</span> <span class="p">{</span>
        <span class="c1">// Extract features</span>
        <span class="kd">val</span> <span class="py">features</span> <span class="p">=</span> <span class="nf">extractMelSpectrogram</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
        
        <span class="c1">// Prepare input</span>
        <span class="kd">val</span> <span class="py">inputBuffer</span> <span class="p">=</span> <span class="nc">ByteBuffer</span><span class="p">.</span><span class="nf">allocateDirect</span><span class="p">(</span><span class="mi">4</span> <span class="p">*</span> <span class="n">features</span><span class="p">.</span><span class="n">size</span><span class="p">)</span>
        <span class="n">inputBuffer</span><span class="p">.</span><span class="nf">order</span><span class="p">(</span><span class="nc">ByteOrder</span><span class="p">.</span><span class="nf">nativeOrder</span><span class="p">())</span>
        <span class="n">features</span><span class="p">.</span><span class="nf">forEach</span> <span class="p">{</span> <span class="n">inputBuffer</span><span class="p">.</span><span class="nf">putFloat</span><span class="p">(</span><span class="n">it</span><span class="p">)</span> <span class="p">}</span>
        
        <span class="c1">// Prepare output</span>
        <span class="kd">val</span> <span class="py">output</span> <span class="p">=</span> <span class="nc">Array</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span> <span class="nc">FloatArray</span><span class="p">(</span><span class="mi">31</span><span class="p">)</span> <span class="p">}</span>
        
        <span class="c1">// Run inference</span>
        <span class="n">interpreter</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">inputBuffer</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
        
        <span class="c1">// Get top prediction</span>
        <span class="kd">val</span> <span class="py">probabilities</span> <span class="p">=</span> <span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="kd">val</span> <span class="py">maxIndex</span> <span class="p">=</span> <span class="n">probabilities</span><span class="p">.</span><span class="n">indices</span><span class="p">.</span><span class="nf">maxByOrNull</span> <span class="p">{</span> <span class="n">probabilities</span><span class="p">[</span><span class="n">it</span><span class="p">]</span> <span class="p">}</span> <span class="o">?:</span> <span class="mi">0</span>
        <span class="kd">val</span> <span class="py">confidence</span> <span class="p">=</span> <span class="n">probabilities</span><span class="p">[</span><span class="n">maxIndex</span><span class="p">]</span>
        
        <span class="k">return</span> <span class="nc">Pair</span><span class="p">(</span><span class="n">commandNames</span><span class="p">[</span><span class="n">maxIndex</span><span class="p">],</span> <span class="n">confidence</span><span class="p">)</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p><strong>iOS (Swift):</strong></p>

<div class="language-swift highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">import</span> <span class="kt">CoreML</span>

<span class="kd">class</span> <span class="kt">CommandClassifier</span> <span class="p">{</span>
    <span class="kd">private</span> <span class="k">var</span> <span class="nv">model</span><span class="p">:</span> <span class="kt">CommandClassifierModel</span><span class="o">!</span>
    
    <span class="nf">init</span><span class="p">()</span> <span class="p">{</span>
        <span class="n">model</span> <span class="o">=</span> <span class="k">try!</span> <span class="kt">CommandClassifierModel</span><span class="p">(</span><span class="nv">configuration</span><span class="p">:</span> <span class="kt">MLModelConfiguration</span><span class="p">())</span>
    <span class="p">}</span>
    
    <span class="kd">func</span> <span class="nf">classify</span><span class="p">(</span><span class="nv">audio</span><span class="p">:</span> <span class="p">[</span><span class="kt">Float</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="nv">command</span><span class="p">:</span> <span class="kt">String</span><span class="p">,</span> <span class="nv">confidence</span><span class="p">:</span> <span class="kt">Double</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// Extract features</span>
        <span class="k">let</span> <span class="nv">features</span> <span class="o">=</span> <span class="nf">extractMelSpectrogram</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
        
        <span class="c1">// Create MLMultiArray</span>
        <span class="k">let</span> <span class="nv">input</span> <span class="o">=</span> <span class="k">try!</span> <span class="kt">MLMultiArray</span><span class="p">(</span><span class="nv">shape</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">40</span><span class="p">],</span> <span class="nv">dataType</span><span class="p">:</span> <span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">0</span><span class="o">..&lt;</span><span class="n">features</span><span class="o">.</span><span class="n">count</span> <span class="p">{</span>
            <span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="kt">NSNumber</span><span class="p">(</span><span class="nv">value</span><span class="p">:</span> <span class="n">features</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="p">}</span>
        
        <span class="c1">// Run inference</span>
        <span class="k">let</span> <span class="nv">output</span> <span class="o">=</span> <span class="k">try!</span> <span class="n">model</span><span class="o">.</span><span class="nf">prediction</span><span class="p">(</span><span class="nv">audio</span><span class="p">:</span> <span class="n">input</span><span class="p">)</span>
        
        <span class="c1">// Get top prediction</span>
        <span class="k">let</span> <span class="nv">probabilities</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">logits</span>
        <span class="k">let</span> <span class="nv">maxIndex</span> <span class="o">=</span> <span class="n">probabilities</span><span class="o">.</span><span class="nf">argmax</span><span class="p">()</span>
        <span class="k">let</span> <span class="nv">confidence</span> <span class="o">=</span> <span class="n">probabilities</span><span class="p">[</span><span class="n">maxIndex</span><span class="p">]</span>
        
        <span class="nf">return</span> <span class="p">(</span><span class="n">commandNames</span><span class="p">[</span><span class="n">maxIndex</span><span class="p">],</span> <span class="kt">Double</span><span class="p">(</span><span class="n">confidence</span><span class="p">))</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<hr />

<h2 id="monitoring--evaluation">Monitoring &amp; Evaluation</h2>

<h3 id="metrics-dashboard">Metrics Dashboard</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">List</span>

<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">ClassificationMetrics</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">Per-class metrics</span><span class="sh">"""</span>
    <span class="n">precision</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">recall</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">f1_score</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">support</span><span class="p">:</span> <span class="nb">int</span>  <span class="c1"># Number of samples
</span>    
<span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">y_true</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Compute detailed metrics per class
    </span><span class="sh">"""</span>
    <span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>
    
    <span class="c1"># Per-class metrics
</span>    <span class="n">report</span> <span class="o">=</span> <span class="nf">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">output_dict</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    
    <span class="c1"># Confusion matrix
</span>    <span class="n">cm</span> <span class="o">=</span> <span class="nf">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    
    <span class="c1"># Identify problematic classes
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_classes</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">report</span><span class="p">[</span><span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)][</span><span class="sh">'</span><span class="s">f1-score</span><span class="sh">'</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.85</span><span class="p">:</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">⚠️  Class </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s"> (</span><span class="si">{</span><span class="n">command_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s">) has low F1: </span><span class="si">{</span><span class="n">report</span><span class="p">[</span><span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)][</span><span class="sh">'</span><span class="s">f1-score</span><span class="sh">'</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
            
            <span class="c1"># Find most confused class
</span>            <span class="n">confused_with</span> <span class="o">=</span> <span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">argmax</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">confused_with</span> <span class="o">!=</span> <span class="n">i</span><span class="p">:</span>
                <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">   Most confused with class </span><span class="si">{</span><span class="n">confused_with</span><span class="si">}</span><span class="s"> (</span><span class="si">{</span><span class="n">command_names</span><span class="p">[</span><span class="n">confused_with</span><span class="p">]</span><span class="si">}</span><span class="s">)</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">report</span><span class="p">,</span> <span class="n">cm</span>
</code></pre></div></div>

<h3 id="online-monitoring">Online Monitoring</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">OnlineMetricsTracker</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Track metrics in production
    </span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">confidences</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">latencies</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">def</span> <span class="nf">record</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">prediction</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">confidence</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">latency_ms</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Record single prediction</span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="n">predictions</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">confidences</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">confidence</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">latencies</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">latency_ms</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">get_stats</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">last_n</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Get recent statistics</span><span class="sh">"""</span>
        <span class="n">recent_preds</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">predictions</span><span class="p">[</span><span class="o">-</span><span class="n">last_n</span><span class="p">:]</span>
        <span class="n">recent_confs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">confidences</span><span class="p">[</span><span class="o">-</span><span class="n">last_n</span><span class="p">:]</span>
        <span class="n">recent_lats</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">latencies</span><span class="p">[</span><span class="o">-</span><span class="n">last_n</span><span class="p">:]</span>
        
        <span class="c1"># Class distribution
</span>        <span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
        <span class="n">class_dist</span> <span class="o">=</span> <span class="nc">Counter</span><span class="p">(</span><span class="n">recent_preds</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">total_predictions</span><span class="sh">'</span><span class="p">:</span> <span class="nf">len</span><span class="p">(</span><span class="n">recent_preds</span><span class="p">),</span>
            <span class="sh">'</span><span class="s">class_distribution</span><span class="sh">'</span><span class="p">:</span> <span class="nf">dict</span><span class="p">(</span><span class="n">class_dist</span><span class="p">),</span>
            <span class="sh">'</span><span class="s">avg_confidence</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">recent_confs</span><span class="p">),</span>
            <span class="sh">'</span><span class="s">low_confidence_rate</span><span class="sh">'</span><span class="p">:</span> <span class="nf">sum</span><span class="p">(</span><span class="n">c</span> <span class="o">&lt;</span> <span class="mf">0.7</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">recent_confs</span><span class="p">)</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">recent_confs</span><span class="p">),</span>
            <span class="sh">'</span><span class="s">p50_latency</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">(</span><span class="n">recent_lats</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
            <span class="sh">'</span><span class="s">p95_latency</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">(</span><span class="n">recent_lats</span><span class="p">,</span> <span class="mi">95</span><span class="p">),</span>
            <span class="sh">'</span><span class="s">p99_latency</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">(</span><span class="n">recent_lats</span><span class="p">,</span> <span class="mi">99</span><span class="p">)</span>
        <span class="p">}</span>
</code></pre></div></div>

<hr />

<h2 id="multi-language-support">Multi-Language Support</h2>

<h3 id="approach-1-separate-models-per-language">Approach 1: Separate Models per Language</h3>

<p><strong>Pros:</strong></p>
<ul>
  <li>Best accuracy per language</li>
  <li>Language-specific optimizations</li>
  <li>Easier to add new languages</li>
</ul>

<p><strong>Cons:</strong></p>
<ul>
  <li>Multiple models to maintain</li>
  <li>Higher storage footprint</li>
  <li>Language detection needed first</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MultilingualClassifier</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Separate model per language
    </span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">models</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">en</span><span class="sh">'</span><span class="p">:</span> <span class="nf">load_model</span><span class="p">(</span><span class="sh">'</span><span class="s">command_en.pth</span><span class="sh">'</span><span class="p">),</span>
            <span class="sh">'</span><span class="s">es</span><span class="sh">'</span><span class="p">:</span> <span class="nf">load_model</span><span class="p">(</span><span class="sh">'</span><span class="s">command_es.pth</span><span class="sh">'</span><span class="p">),</span>
            <span class="sh">'</span><span class="s">fr</span><span class="sh">'</span><span class="p">:</span> <span class="nf">load_model</span><span class="p">(</span><span class="sh">'</span><span class="s">command_fr.pth</span><span class="sh">'</span><span class="p">),</span>
            <span class="sh">'</span><span class="s">de</span><span class="sh">'</span><span class="p">:</span> <span class="nf">load_model</span><span class="p">(</span><span class="sh">'</span><span class="s">command_de.pth</span><span class="sh">'</span><span class="p">),</span>
            <span class="sh">'</span><span class="s">ja</span><span class="sh">'</span><span class="p">:</span> <span class="nf">load_model</span><span class="p">(</span><span class="sh">'</span><span class="s">command_ja.pth</span><span class="sh">'</span><span class="p">)</span>
        <span class="p">}</span>
        <span class="n">self</span><span class="p">.</span><span class="n">language_detector</span> <span class="o">=</span> <span class="nf">load_model</span><span class="p">(</span><span class="sh">'</span><span class="s">lang_detect.pth</span><span class="sh">'</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio</span><span class="p">):</span>
        <span class="c1"># Detect language first
</span>        <span class="n">language</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">language_detector</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
        
        <span class="c1"># Use language-specific model
</span>        <span class="n">model</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">models</span><span class="p">[</span><span class="n">language</span><span class="p">]</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">prediction</span><span class="p">,</span> <span class="n">language</span>
</code></pre></div></div>

<p><strong>Storage requirement:</strong> 5 languages × 2MB = 10MB</p>

<h3 id="approach-2-multilingual-shared-model">Approach 2: Multilingual Shared Model</h3>

<p><strong>Training strategy:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train_multilingual_model</span><span class="p">():</span>
    <span class="sh">"""</span><span class="s">
    Single model trained on all languages
    
    Add language ID as auxiliary input
    </span><span class="sh">"""</span>
    <span class="n">model</span> <span class="o">=</span> <span class="nc">MultilingualCommandCNN</span><span class="p">(</span>
        <span class="n">num_classes</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
        <span class="n">num_languages</span><span class="o">=</span><span class="mi">5</span>
    <span class="p">)</span>
    
    <span class="c1"># Training data from all languages
</span>    <span class="k">for</span> <span class="n">audio</span><span class="p">,</span> <span class="n">command_label</span><span class="p">,</span> <span class="n">lang_id</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="n">features</span> <span class="o">=</span> <span class="nf">extract_features</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
        
        <span class="c1"># Forward pass with language embedding
</span>        <span class="n">command_pred</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">lang_id</span><span class="p">)</span>
        
        <span class="c1"># Loss
</span>        <span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">command_pred</span><span class="p">,</span> <span class="n">command_label</span><span class="p">)</span>
        
        <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">model</span>
</code></pre></div></div>

<p><strong>Model architecture:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MultilingualCommandCNN</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Shared model with language embeddings
    </span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">num_languages</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">16</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="c1"># Language embedding
</span>        <span class="n">self</span><span class="p">.</span><span class="n">lang_embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Embedding</span><span class="p">(</span><span class="n">num_languages</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
        
        <span class="c1"># Shared CNN backbone
</span>        <span class="n">self</span><span class="p">.</span><span class="n">cnn</span> <span class="o">=</span> <span class="nc">CommandCNN</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>  <span class="c1"># Feature extractor
</span>        
        <span class="c1"># Language-conditioned classifier
</span>        <span class="n">self</span><span class="p">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">128</span> <span class="o">+</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio_features</span><span class="p">,</span> <span class="n">language_id</span><span class="p">):</span>
        <span class="c1"># CNN features
</span>        <span class="n">cnn_features</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">cnn</span><span class="p">(</span><span class="n">audio_features</span><span class="p">)</span>  <span class="c1"># (batch, 128)
</span>        
        <span class="c1"># Language embedding
</span>        <span class="n">lang_emb</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">lang_embedding</span><span class="p">(</span><span class="n">language_id</span><span class="p">)</span>  <span class="c1"># (batch, 16)
</span>        
        <span class="c1"># Concatenate
</span>        <span class="n">combined</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">([</span><span class="n">cnn_features</span><span class="p">,</span> <span class="n">lang_emb</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (batch, 144)
</span>        
        <span class="c1"># Classify
</span>        <span class="n">logits</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">classifier</span><span class="p">(</span><span class="n">combined</span><span class="p">)</span>  <span class="c1"># (batch, num_classes)
</span>        
        <span class="k">return</span> <span class="n">logits</span>
</code></pre></div></div>

<p><strong>Pros:</strong></p>
<ul>
  <li>Single model (2-3MB)</li>
  <li>Shared representations across languages</li>
  <li>Transfer learning for low-resource languages</li>
</ul>

<p><strong>Cons:</strong></p>
<ul>
  <li>Slightly lower accuracy per language</li>
  <li>All languages must use same command set</li>
</ul>

<hr />

<h2 id="failure-cases--mitigation">Failure Cases &amp; Mitigation</h2>

<h3 id="common-failure-modes">Common Failure Modes</h3>

<h4 id="1-background-speechtv">1. <strong>Background Speech/TV</strong></h4>

<p><strong>Problem:</strong> Model activates on TV dialogue or background conversation</p>

<p><strong>Mitigation:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">detect_background_speech</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="mi">16000</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Detect if audio is from TV/background vs direct user speech
    
    Features:
    - Energy envelope variation (TV more consistent)
    - Reverb characteristics (TV more reverberant)
    - Spectral rolloff (TV often compressed)
    </span><span class="sh">"""</span>
    <span class="c1"># Energy variation
</span>    <span class="n">frame_energy</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="n">feature</span><span class="p">.</span><span class="nf">rms</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">audio</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">energy_std</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">std</span><span class="p">(</span><span class="n">frame_energy</span><span class="p">)</span>
    
    <span class="c1"># TV has lower energy variation
</span>    <span class="k">if</span> <span class="n">energy_std</span> <span class="o">&lt;</span> <span class="mf">0.01</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">True</span>  <span class="c1"># Likely background
</span>    
    <span class="c1"># Spectral centroid (TV often band-limited)
</span>    <span class="n">spectral_centroid</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="n">feature</span><span class="p">.</span><span class="nf">spectral_centroid</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">audio</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sr</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">avg_centroid</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">spectral_centroid</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">avg_centroid</span> <span class="o">&lt;</span> <span class="mi">1000</span><span class="p">:</span>  <span class="c1"># Hz
</span>        <span class="k">return</span> <span class="bp">True</span>  <span class="c1"># Likely background
</span>    
    <span class="k">return</span> <span class="bp">False</span>
</code></pre></div></div>

<p><strong>Additional strategy:</strong> Use speaker verification to check if it’s the registered user</p>

<h4 id="2-accented-speech">2. <strong>Accented Speech</strong></h4>

<p><strong>Problem:</strong> Model trained on standard accent performs poorly on regional accents</p>

<p><strong>Mitigation:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Data collection strategy
</span><span class="n">accent_distribution</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">general_american</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">british</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.15</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">australian</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">indian</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.15</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">southern_us</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">canadian</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">other</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.1</span>
<span class="p">}</span>

<span class="c1"># Ensure balanced training data
</span><span class="k">for</span> <span class="n">accent</span><span class="p">,</span> <span class="n">proportion</span> <span class="ow">in</span> <span class="n">accent_distribution</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
    <span class="n">required_samples</span> <span class="o">=</span> <span class="n">total_samples</span> <span class="o">*</span> <span class="n">proportion</span>
    <span class="nf">collect_samples</span><span class="p">(</span><span class="n">accent</span><span class="p">,</span> <span class="n">required_samples</span><span class="p">)</span>

<span class="c1"># Use accent-aware data augmentation
</span><span class="k">def</span> <span class="nf">accent_aware_augmentation</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">accent_type</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Apply accent-specific augmentations</span><span class="sh">"""</span>
    <span class="k">if</span> <span class="n">accent_type</span> <span class="o">==</span> <span class="sh">'</span><span class="s">indian</span><span class="sh">'</span><span class="p">:</span>
        <span class="c1"># Indian English: Stronger pitch variation
</span>        <span class="n">audio</span> <span class="o">=</span> <span class="nf">pitch_shift</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">accent_type</span> <span class="o">==</span> <span class="sh">'</span><span class="s">southern_us</span><span class="sh">'</span><span class="p">:</span>
        <span class="c1"># Southern US: Slower speech
</span>        <span class="n">audio</span> <span class="o">=</span> <span class="nf">time_stretch</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="mf">0.85</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">audio</span>
</code></pre></div></div>

<h4 id="3-noisy-environments">3. <strong>Noisy Environments</strong></h4>

<p><strong>Problem:</strong> Model degrades in cafes, cars, streets</p>

<p><strong>Mitigation:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">enhance_audio_for_inference</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="mi">16000</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Lightweight denoising for inference
    
    Must be &lt; 5ms to maintain latency budget
    </span><span class="sh">"""</span>
    <span class="c1"># Spectral gating (simple but effective)
</span>    <span class="n">stft</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="nf">stft</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
    <span class="n">magnitude</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">stft</span><span class="p">)</span>
    
    <span class="c1"># Estimate noise floor (first 100ms)
</span>    <span class="n">noise_frames</span> <span class="o">=</span> <span class="n">magnitude</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">10</span><span class="p">]</span>
    <span class="n">noise_threshold</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">noise_frames</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.5</span>
    
    <span class="c1"># Gate
</span>    <span class="n">mask</span> <span class="o">=</span> <span class="n">magnitude</span> <span class="o">&gt;</span> <span class="n">noise_threshold</span>
    <span class="n">stft_denoised</span> <span class="o">=</span> <span class="n">stft</span> <span class="o">*</span> <span class="n">mask</span>
    
    <span class="c1"># Inverse STFT
</span>    <span class="n">audio_denoised</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="nf">istft</span><span class="p">(</span><span class="n">stft_denoised</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">audio_denoised</span>
</code></pre></div></div>

<p><strong>Better approach:</strong> Train with noisy data</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Use diverse noise types during training
</span><span class="n">noise_types</span> <span class="o">=</span> <span class="p">[</span>
    <span class="sh">'</span><span class="s">cafe_ambiance</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">car_interior</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">street_traffic</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">office_chatter</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">home_appliances</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">rain</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">wind</span><span class="sh">'</span>
<span class="p">]</span>

<span class="k">for</span> <span class="n">audio</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
    <span class="c1"># Add random noise
</span>    <span class="n">noise_type</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="n">noise_types</span><span class="p">)</span>
    <span class="n">noisy_audio</span> <span class="o">=</span> <span class="nf">add_noise</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">noise_type</span><span class="p">,</span> <span class="n">snr_db</span><span class="o">=</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
</code></pre></div></div>

<h4 id="4-similar-sounding-commands">4. <strong>Similar Sounding Commands</strong></h4>

<p><strong>Problem:</strong> “lights on” vs “lights off”, “volume up” vs “volume down”</p>

<p><strong>Mitigation:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Use contrastive learning during training
</span><span class="k">def</span> <span class="nf">contrastive_loss</span><span class="p">(</span><span class="n">anchor</span><span class="p">,</span> <span class="n">positive</span><span class="p">,</span> <span class="n">negative</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Pull together similar commands, push apart confusable ones
    </span><span class="sh">"""</span>
    <span class="n">pos_distance</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">anchor</span> <span class="o">-</span> <span class="n">positive</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">neg_distance</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">anchor</span> <span class="o">-</span> <span class="n">negative</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">relu</span><span class="p">(</span><span class="n">pos_distance</span> <span class="o">-</span> <span class="n">neg_distance</span> <span class="o">+</span> <span class="n">margin</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">loss</span><span class="p">.</span><span class="nf">mean</span><span class="p">()</span>

<span class="c1"># Identify confusable pairs
</span><span class="n">confusable_pairs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">lights_on</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">lights_off</span><span class="sh">'</span><span class="p">),</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">volume_up</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">volume_down</span><span class="sh">'</span><span class="p">),</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">next</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">previous</span><span class="sh">'</span><span class="p">),</span>
    <span class="p">(</span><span class="sh">'</span><span class="s">play</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">pause</span><span class="sh">'</span><span class="p">)</span>
<span class="p">]</span>

<span class="c1"># During training
</span><span class="k">for</span> <span class="n">audio</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">extract_features</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
    
    <span class="c1"># For confusable commands, add contrastive loss
</span>    <span class="k">if</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">confusable_commands</span><span class="p">:</span>
        <span class="n">opposite_label</span> <span class="o">=</span> <span class="nf">get_opposite_command</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
        <span class="n">opposite_audio</span> <span class="o">=</span> <span class="nf">sample_from_class</span><span class="p">(</span><span class="n">opposite_label</span><span class="p">)</span>
        <span class="n">opposite_features</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">extract_features</span><span class="p">(</span><span class="n">opposite_audio</span><span class="p">)</span>
        
        <span class="n">total_loss</span> <span class="o">=</span> <span class="n">classification_loss</span> <span class="o">+</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="nf">contrastive_loss</span><span class="p">(</span>
            <span class="n">features</span><span class="p">,</span> 
            <span class="n">features</span><span class="p">,</span>  <span class="c1"># Anchor to itself
</span>            <span class="n">opposite_features</span>
        <span class="p">)</span>
</code></pre></div></div>

<hr />

<h2 id="production-deployment-architecture">Production Deployment Architecture</h2>

<h3 id="edge-deployment-smart-speaker">Edge Deployment (Smart Speaker)</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>┌─────────────────────────────────────────┐
│         Smart Speaker Device            │
├─────────────────────────────────────────┤
│                                         │
│  Microphone Array                       │
│       ↓                                 │
│  Beamforming (5ms)                      │
│       ↓                                 │
│  Wake Word Detection (10ms)             │
│       ↓                                 │
│  [If wake word detected]                │
│       ↓                                 │
│  Audio Buffer (1 second)                │
│       ↓                                 │
│  Feature Extraction (5ms)               │
│       ↓                                 │
│  Command CNN Inference (15ms)           │
│       ↓                                 │
│  ┌──────────────┐                       │
│  │ Confidence   │                       │
│  │   &gt; 0.85?    │                       │
│  └──────┬───────┘                       │
│         │                               │
│    Yes  │  No                           │
│         ↓                               │
│  Execute Command    Send to Cloud ASR   │
│                                         │
└─────────────────────────────────────────┘

Total latency (on-device): &lt; 40ms
Power consumption: &lt; 100mW during inference
</code></pre></div></div>

<h3 id="hybrid-edge-cloud-architecture">Hybrid Edge-Cloud Architecture</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">HybridCommandClassifier</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Intelligent routing between edge and cloud
    </span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">edge_model</span> <span class="o">=</span> <span class="nf">load_edge_model</span><span class="p">()</span>  <span class="c1"># Small CNN
</span>        <span class="n">self</span><span class="p">.</span><span class="n">cloud_client</span> <span class="o">=</span> <span class="nc">CloudASRClient</span><span class="p">()</span>
        
        <span class="c1"># Common commands handled on-device
</span>        <span class="n">self</span><span class="p">.</span><span class="n">edge_commands</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">lights_on</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">lights_off</span><span class="sh">'</span><span class="p">,</span> 
            <span class="sh">'</span><span class="s">volume_up</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">volume_down</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">play</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">pause</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">stop</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">next</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">previous</span><span class="sh">'</span>
        <span class="p">}</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">classify</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio</span><span class="p">):</span>
        <span class="c1"># Try edge first
</span>        <span class="n">edge_pred</span><span class="p">,</span> <span class="n">edge_conf</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">edge_model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
        
        <span class="c1"># High confidence + known command → use edge
</span>        <span class="k">if</span> <span class="n">edge_conf</span> <span class="o">&gt;</span> <span class="mf">0.85</span> <span class="ow">and</span> <span class="n">edge_pred</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">edge_commands</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span>
                <span class="sh">'</span><span class="s">command</span><span class="sh">'</span><span class="p">:</span> <span class="n">edge_pred</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">confidence</span><span class="sh">'</span><span class="p">:</span> <span class="n">edge_conf</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">source</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">edge</span><span class="sh">'</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">latency_ms</span><span class="sh">'</span><span class="p">:</span> <span class="mi">35</span>
            <span class="p">}</span>
        
        <span class="c1"># Otherwise → cloud ASR
</span>        <span class="n">cloud_result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">self</span><span class="p">.</span><span class="n">cloud_client</span><span class="p">.</span><span class="nf">recognize</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">command</span><span class="sh">'</span><span class="p">:</span> <span class="n">cloud_result</span><span class="p">[</span><span class="sh">'</span><span class="s">text</span><span class="sh">'</span><span class="p">],</span>
            <span class="sh">'</span><span class="s">confidence</span><span class="sh">'</span><span class="p">:</span> <span class="n">cloud_result</span><span class="p">[</span><span class="sh">'</span><span class="s">confidence</span><span class="sh">'</span><span class="p">],</span>
            <span class="sh">'</span><span class="s">source</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">cloud</span><span class="sh">'</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">latency_ms</span><span class="sh">'</span><span class="p">:</span> <span class="mi">250</span>
        <span class="p">}</span>
</code></pre></div></div>

<p><strong>Benefits:</strong></p>
<ul>
  <li>✅ 90% of commands handled on-device (&lt; 50ms)</li>
  <li>✅ 10% fall back to cloud for complex queries</li>
  <li>✅ Privacy for common commands</li>
  <li>✅ Graceful degradation if network unavailable</li>
</ul>

<hr />

<h2 id="ab-testing--gradual-rollout">A/B Testing &amp; Gradual Rollout</h2>

<h3 id="experiment-framework">Experiment Framework</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ModelExperiment</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    A/B test new model versions
    </span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">control_model</span><span class="p">,</span> <span class="n">treatment_model</span><span class="p">,</span> <span class="n">treatment_percentage</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">control</span> <span class="o">=</span> <span class="n">control_model</span>
        <span class="n">self</span><span class="p">.</span><span class="n">treatment</span> <span class="o">=</span> <span class="n">treatment_model</span>
        <span class="n">self</span><span class="p">.</span><span class="n">treatment_pct</span> <span class="o">=</span> <span class="n">treatment_percentage</span>
    
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio</span><span class="p">,</span> <span class="n">user_id</span><span class="p">):</span>
        <span class="c1"># Deterministic assignment based on user_id
</span>        <span class="n">bucket</span> <span class="o">=</span> <span class="nf">hash</span><span class="p">(</span><span class="n">user_id</span><span class="p">)</span> <span class="o">%</span> <span class="mi">100</span>
        
        <span class="k">if</span> <span class="n">bucket</span> <span class="o">&lt;</span> <span class="n">self</span><span class="p">.</span><span class="n">treatment_pct</span><span class="p">:</span>
            <span class="c1"># Treatment group
</span>            <span class="n">pred</span><span class="p">,</span> <span class="n">conf</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">treatment</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
            <span class="n">variant</span> <span class="o">=</span> <span class="sh">'</span><span class="s">treatment</span><span class="sh">'</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Control group
</span>            <span class="n">pred</span><span class="p">,</span> <span class="n">conf</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">control</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
            <span class="n">variant</span> <span class="o">=</span> <span class="sh">'</span><span class="s">control</span><span class="sh">'</span>
        
        <span class="c1"># Log for analysis
</span>        <span class="n">self</span><span class="p">.</span><span class="nf">log_prediction</span><span class="p">(</span><span class="n">user_id</span><span class="p">,</span> <span class="n">variant</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">conf</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">pred</span><span class="p">,</span> <span class="n">conf</span>
    
    <span class="k">def</span> <span class="nf">log_prediction</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">user_id</span><span class="p">,</span> <span class="n">variant</span><span class="p">,</span> <span class="n">prediction</span><span class="p">,</span> <span class="n">confidence</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Log to analytics system</span><span class="sh">"""</span>
        <span class="n">event</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">user_id</span><span class="sh">'</span><span class="p">:</span> <span class="n">user_id</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">timestamp</span><span class="sh">'</span><span class="p">:</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">(),</span>
            <span class="sh">'</span><span class="s">variant</span><span class="sh">'</span><span class="p">:</span> <span class="n">variant</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">prediction</span><span class="sh">'</span><span class="p">:</span> <span class="n">prediction</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">confidence</span><span class="sh">'</span><span class="p">:</span> <span class="n">confidence</span>
        <span class="p">}</span>
        
        <span class="n">analytics_logger</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">event</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="metrics-to-track">Metrics to Track</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">compute_experiment_metrics</span><span class="p">(</span><span class="n">control_group</span><span class="p">,</span> <span class="n">treatment_group</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Compare model versions
    </span><span class="sh">"""</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="p">{}</span>
    
    <span class="c1"># Accuracy (if ground truth available)
</span>    <span class="k">if</span> <span class="n">has_ground_truth</span><span class="p">:</span>
        <span class="n">metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">accuracy_control</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">compute_accuracy</span><span class="p">(</span><span class="n">control_group</span><span class="p">)</span>
        <span class="n">metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">accuracy_treatment</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">compute_accuracy</span><span class="p">(</span><span class="n">treatment_group</span><span class="p">)</span>
    
    <span class="c1"># Confidence distribution
</span>    <span class="n">metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">avg_confidence_control</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="sh">'</span><span class="s">confidence</span><span class="sh">'</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">control_group</span><span class="p">])</span>
    <span class="n">metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">avg_confidence_treatment</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="sh">'</span><span class="s">confidence</span><span class="sh">'</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">treatment_group</span><span class="p">])</span>
    
    <span class="c1"># Latency
</span>    <span class="n">metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">p95_latency_control</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="sh">'</span><span class="s">latency</span><span class="sh">'</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">control_group</span><span class="p">],</span> <span class="mi">95</span><span class="p">)</span>
    <span class="n">metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">p95_latency_treatment</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="sh">'</span><span class="s">latency</span><span class="sh">'</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">treatment_group</span><span class="p">],</span> <span class="mi">95</span><span class="p">)</span>
    
    <span class="c1"># User engagement (proxy for accuracy)
</span>    <span class="n">metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">retry_rate_control</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">compute_retry_rate</span><span class="p">(</span><span class="n">control_group</span><span class="p">)</span>
    <span class="n">metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">retry_rate_treatment</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">compute_retry_rate</span><span class="p">(</span><span class="n">treatment_group</span><span class="p">)</span>
    
    <span class="c1"># Statistical significance
</span>    <span class="kn">from</span> <span class="n">scipy.stats</span> <span class="kn">import</span> <span class="n">ttest_ind</span>
    
    <span class="n">control_success</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="sh">'</span><span class="s">success</span><span class="sh">'</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">control_group</span><span class="p">]</span>
    <span class="n">treatment_success</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="sh">'</span><span class="s">success</span><span class="sh">'</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">treatment_group</span><span class="p">]</span>
    
    <span class="n">t_stat</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="nf">ttest_ind</span><span class="p">(</span><span class="n">control_success</span><span class="p">,</span> <span class="n">treatment_success</span><span class="p">)</span>
    <span class="n">metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">p_value</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_value</span>
    <span class="n">metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">is_significant</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="mf">0.05</span>
    
    <span class="k">return</span> <span class="n">metrics</span>
</code></pre></div></div>

<hr />

<h2 id="real-world-examples">Real-World Examples</h2>

<h3 id="google-assistant">Google Assistant</h3>

<p><strong>“Hey Google” Wake Word:</strong></p>
<ul>
  <li>Always-on detection using tiny model (&lt; 1MB)</li>
  <li>Runs on low-power co-processor (DSP)</li>
  <li>&lt; 10ms latency, ~0.5mW power</li>
  <li>~ 99.5% accuracy on target phrase</li>
  <li>Personalized over time with on-device learning</li>
</ul>

<p><strong>Command Classification:</strong></p>
<ul>
  <li>Separate model for common commands (~30 commands)</li>
  <li>Fallback to full ASR for complex queries</li>
  <li>On-device for privacy (no audio sent to cloud)</li>
  <li>Multi-language support (40+ languages)</li>
</ul>

<p><strong>Architecture:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Microphone → Beamformer → Wake Word → Command CNN → Execute
                                              ↓
                                         (if low conf)
                                              ↓
                                         Cloud ASR
</code></pre></div></div>

<h3 id="amazon-alexa">Amazon Alexa</h3>

<p><strong>“Alexa” Wake Word:</strong></p>
<ul>
  <li>Multi-stage cascade:
    <ul>
      <li>Stage 1: Energy detector (&lt; 1ms, filters silence)</li>
      <li>Stage 2: Keyword spotter (&lt; 10ms, CNN)</li>
      <li>Stage 3: Full verification (&lt; 50ms, larger model)</li>
    </ul>
  </li>
  <li>Reduces false positives by 10x</li>
  <li>Power-efficient (only stage 3 uses main CPU)</li>
</ul>

<p><strong>Custom Skills:</strong></p>
<ul>
  <li>Slot-filling approach for structured commands</li>
  <li>Template: “play {song} by {artist}”</li>
  <li>Combined classification + entity extraction</li>
  <li>~100K custom skills available</li>
</ul>

<p><strong>Deployment:</strong></p>
<ul>
  <li>Edge: Wake word + simple commands</li>
  <li>Cloud: Everything else (200ms latency acceptable)</li>
</ul>

<h3 id="apple-siri">Apple Siri</h3>

<p><strong>“Hey Siri” Detection:</strong></p>
<ul>
  <li>Neural network on Neural Engine (dedicated ML chip)</li>
  <li>Personalized to user’s voice during setup</li>
  <li>Continuously adapts to voice changes</li>
  <li>&lt; 50ms latency</li>
  <li>Works offline (completely on-device)</li>
  <li>Power: &lt; 1mW in always-listening mode</li>
</ul>

<p><strong>Privacy Design:</strong></p>
<ul>
  <li>Audio never sent to cloud without explicit activation</li>
  <li>Voice profile stored locally (encrypted)</li>
  <li>Random identifier (not tied to Apple ID)</li>
</ul>

<p><strong>Technical Details:</strong></p>
<ul>
  <li>Uses LSTM for temporal modeling</li>
  <li>Trained on millions of “Hey Siri” variations</li>
  <li>Negative examples: TV shows, movies, other voices</li>
</ul>

<hr />

<h2 id="key-takeaways">Key Takeaways</h2>

<p>✅ <strong>Direct audio→intent</strong> faster than ASR→NLU for limited commands<br />
✅ <strong>CNNs on mel-spectrograms</strong> work excellently for on-device<br />
✅ <strong>Data augmentation</strong> critical for robustness (noise, time shift, pitch)<br />
✅ <strong>Unknown class handling</strong> prevents false activations<br />
✅ <strong>Quantization</strong> achieves 4x compression with &lt; 1% accuracy loss<br />
✅ <strong>Threshold tuning</strong> balances precision/recall for business needs</p>

<hr />

<h2 id="further-reading">Further Reading</h2>

<p><strong>Papers:</strong></p>
<ul>
  <li><a href="https://arxiv.org/abs/1804.03209">Speech Commands Dataset (Google)</a></li>
  <li><a href="https://arxiv.org/abs/1711.07128">Efficient Keyword Spotting</a></li>
  <li><a href="https://arxiv.org/abs/1811.07684">Hey Snips</a></li>
</ul>

<p><strong>Datasets:</strong></p>
<ul>
  <li><a href="https://www.tensorflow.org/datasets/catalog/speech_commands">Google Speech Commands v2</a></li>
  <li><a href="https://commonvoice.mozilla.org/">Mozilla Common Voice</a></li>
</ul>

<p><strong>Tools:</strong></p>
<ul>
  <li><a href="https://www.tensorflow.org/lite">TensorFlow Lite</a></li>
  <li><a href="https://developer.apple.com/documentation/coreml">Core ML</a></li>
  <li><a href="https://librosa.org/">Librosa</a> - Audio processing</li>
</ul>

<hr />

<p><strong>Originally published at:</strong> <a href="https://www.arunbaby.com/speech-tech/0002-speech-classification/">arunbaby.com/speech-tech/0002-speech-classification</a></p>

<p><em>If you found this helpful, consider sharing it with others who might benefit.</em></p>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#classification" class="page__taxonomy-item p-category" rel="tag">classification</a><span class="sep">, </span>
    
      <a href="/tags/#intent-recognition" class="page__taxonomy-item p-category" rel="tag">intent-recognition</a><span class="sep">, </span>
    
      <a href="/tags/#voice-commands" class="page__taxonomy-item p-category" rel="tag">voice-commands</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#speech-tech" class="page__taxonomy-item p-category" rel="tag">speech-tech</a>
    
    </span>
  </p>


        
      </footer>

      <div class="page__related page__related--full">
  <h2 class="page__related-title">Related across topics</h2>
  <style>
    /* Make section span full content width and use 2 equal columns */
    .page__related--full { float: inline-start; width: 100%; padding: 0; }
    .cross-related-grid { display: grid; grid-template-columns: repeat(2, minmax(0, 1fr)); gap: 2rem; }
    @media (max-width: 768px) { .cross-related-grid { grid-template-columns: 1fr; } }
    /* Ensure archive cards stretch nicely in the grid */
    .cross-related-grid .list__item, .cross-related-grid .grid__item { width: auto; float: none; margin: 0; }
  </style>
  <div class="cross-related-grid">
    



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/dsa/0002-valid-parentheses/" rel="permalink">Valid Parentheses
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          24 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Why a simple stack solves bracket matching, expression parsing, and even neural network depth management in one elegant pattern.
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ml-system-design/0002-classification-pipeline/" rel="permalink">Classification Pipeline Design
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          16 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">From raw data to production predictions: building a classification pipeline that handles millions of requests with 99.9% uptime.
</p>
  </article>
</div>

  </div>
</div>

      <section class="page__share">
  <h4 class="page__share-title">Share on</h4>

  <a href="https://twitter.com/intent/tweet?via=arunbaby0&text=Speech+Command+Classification%20https%3A%2F%2Fwww.arunbaby.com%2Fspeech-tech%2F0002-speech-classification%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.arunbaby.com%2Fspeech-tech%2F0002-speech-classification%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.arunbaby.com/speech-tech/0002-speech-classification/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/speech-tech/0001-streaming-asr/" class="pagination--pager" title="Streaming ASR Architecture">Previous</a>
    
    
      <a href="/speech-tech/0003-audio-feature-extraction/" class="pagination--pager" title="Audio Feature Extraction for Speech ML">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 1990 - 2143 <a href="https://www.arunbaby.com">Arun Baby</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JRJPEC9SS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0JRJPEC9SS', { 'anonymize_ip': false});
</script>








  </body>
</html>
