<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Multi-model Speech Ensemble - Arun Baby</title>
<meta name="description" content="Build production speech systems that combine multiple ASR/TTS models using backtracking-based selection strategies to achieve state-of-the-art accuracy.">


  <meta name="author" content="Arun Baby">
  
  <meta property="article:author" content="Arun Baby">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Arun Baby">
<meta property="og:title" content="Multi-model Speech Ensemble">
<meta property="og:url" content="https://www.arunbaby.com/speech-tech/0014-multi-model-speech-ensemble/">


  <meta property="og:description" content="Build production speech systems that combine multiple ASR/TTS models using backtracking-based selection strategies to achieve state-of-the-art accuracy.">



  <meta property="og:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">



  <meta name="twitter:site" content="@arunbaby0">
  <meta name="twitter:title" content="Multi-model Speech Ensemble">
  <meta name="twitter:description" content="Build production speech systems that combine multiple ASR/TTS models using backtracking-based selection strategies to achieve state-of-the-art accuracy.">
  <meta name="twitter:url" content="https://www.arunbaby.com/speech-tech/0014-multi-model-speech-ensemble/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">
    
  

  



  <meta property="article:published_time" content="2025-10-27T23:15:41+05:30">





  

  


<link rel="canonical" href="https://www.arunbaby.com/speech-tech/0014-multi-model-speech-ensemble/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Baby Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          <span class="site-subtitle">Arun Baby</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/dsa/"
                
                
              >DSA</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ml-system-design/"
                
                
              >ML Systems</a>
            </li><li class="masthead__menu-item">
              <a
                href="/speech-tech/"
                
                
              >Speech Tech</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li><li class="masthead__menu-item">
              <a
                href="/statuses/"
                
                
              >Statuses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/contact/"
                
                
              >Contact</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main" class="no-author-sidebar">
  
  <div class="sidebar sticky">
  
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Multi-model Speech Ensemble">
    <meta itemprop="description" content="Build production speech systems that combine multiple ASR/TTS models using backtracking-based selection strategies to achieve state-of-the-art accuracy.">
    <meta itemprop="datePublished" content="2025-10-27T23:15:41+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://www.arunbaby.com/speech-tech/0014-multi-model-speech-ensemble/" itemprop="url">Multi-model Speech Ensemble
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          23 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#problem-statement">Problem Statement</a><ul><li><a href="#functional-requirements">Functional Requirements</a></li><li><a href="#non-functional-requirements">Non-Functional Requirements</a></li></ul></li><li><a href="#understanding-the-problem">Understanding the Problem</a><ul><li><a href="#real-world-examples">Real-World Examples</a></li><li><a href="#the-backtracking-connection">The Backtracking Connection</a></li></ul></li><li><a href="#high-level-architecture">High-Level Architecture</a><ul><li><a href="#key-components">Key Components</a></li></ul></li><li><a href="#component-deep-dives">Component Deep-Dives</a><ul><li><a href="#1-model-selection-using-backtracking">1. Model Selection Using Backtracking</a></li><li><a href="#2-rover---recognizer-output-voting-error-reduction">2. ROVER - Recognizer Output Voting Error Reduction</a></li><li><a href="#3-confidence-based-fusion">3. Confidence-Based Fusion</a></li><li><a href="#4-voting-based-fusion">4. Voting-Based Fusion</a></li><li><a href="#5-complete-ensemble-system">5. Complete Ensemble System</a></li></ul></li><li><a href="#production-deployment">Production Deployment</a><ul><li><a href="#streaming-asr-ensemble">Streaming ASR Ensemble</a></li><li><a href="#kubernetes-deployment">Kubernetes Deployment</a></li></ul></li><li><a href="#scaling-strategies">Scaling Strategies</a><ul><li><a href="#model-parallelism">Model Parallelism</a></li></ul></li><li><a href="#real-world-case-study-google-voice-search">Real-World Case Study: Google Voice Search</a><ul><li><a href="#googles-multi-model-approach">Google’s Multi-Model Approach</a></li><li><a href="#key-lessons">Key Lessons</a></li></ul></li><li><a href="#cost-analysis">Cost Analysis</a><ul><li><a href="#cost-breakdown-100k-utterancesday">Cost Breakdown (100K utterances/day)</a></li><li><a href="#optimization-strategies">Optimization Strategies</a></li></ul></li><li><a href="#key-takeaways">Key Takeaways</a><ul><li><a href="#connection-to-thematic-link-backtracking-and-combination-strategies">Connection to Thematic Link: Backtracking and Combination Strategies</a></li><li><a href="#universal-pattern">Universal Pattern</a></li></ul></li></ul>
            </nav>
          </aside>
        
        <p><strong>Build production speech systems that combine multiple ASR/TTS models using backtracking-based selection strategies to achieve state-of-the-art accuracy.</strong></p>

<h2 id="problem-statement">Problem Statement</h2>

<p>Design a <strong>Multi-model Speech Ensemble System</strong> that combines predictions from multiple speech recognition (ASR) or synthesis (TTS) models to achieve better accuracy and robustness than any single model.</p>

<h3 id="functional-requirements">Functional Requirements</h3>

<ol>
  <li><strong>Multi-model fusion:</strong> Combine outputs from N ASR/TTS models</li>
  <li><strong>Combination strategies:</strong> Support voting, ROVER, confidence-based fusion</li>
  <li><strong>Dynamic model selection:</strong> Choose model subset based on audio characteristics</li>
  <li><strong>Confidence scoring:</strong> Aggregate confidence from multiple models</li>
  <li><strong>Real-time performance:</strong> Meet latency requirements (&lt;150ms)</li>
  <li><strong>Fallback handling:</strong> Handle individual model failures gracefully</li>
  <li><strong>Streaming support:</strong> Work with both batch and streaming audio</li>
  <li><strong>Language support:</strong> Handle multiple languages/accents</li>
</ol>

<h3 id="non-functional-requirements">Non-Functional Requirements</h3>

<ol>
  <li><strong>Accuracy:</strong> WER &lt; 3% (vs single model ~5%)</li>
  <li><strong>Latency:</strong> p95 &lt; 150ms for real-time ASR</li>
  <li><strong>Throughput:</strong> 10,000+ concurrent requests</li>
  <li><strong>Availability:</strong> 99.9% uptime</li>
  <li><strong>Cost:</strong> &lt;$0.002 per utterance</li>
  <li><strong>Scalability:</strong> Support 20+ models in ensemble</li>
  <li><strong>Robustness:</strong> Graceful degradation with model failures</li>
</ol>

<h2 id="understanding-the-problem">Understanding the Problem</h2>

<p>Speech models are <strong>noisy and uncertain</strong>. Ensembles help because:</p>

<ol>
  <li><strong>Different models capture different patterns:</strong>
    <ul>
      <li>Acoustic models: Wav2Vec2 vs Conformer vs Whisper</li>
      <li>Language models: Transformer vs LSTM vs n-gram</li>
      <li>Training data: Different datasets, accents, domains</li>
    </ul>
  </li>
  <li><strong>Reduce errors through voting:</strong>
    <ul>
      <li>One model mishears “their” as “there”</li>
      <li>Ensemble consensus corrects it</li>
    </ul>
  </li>
  <li><strong>Improve confidence calibration:</strong>
    <ul>
      <li>Single model might be overconfident</li>
      <li>Ensemble agreement provides better confidence</li>
    </ul>
  </li>
  <li><strong>Increase robustness:</strong>
    <ul>
      <li>If one model fails, others continue</li>
      <li>No single point of failure</li>
    </ul>
  </li>
</ol>

<h3 id="real-world-examples">Real-World Examples</h3>

<table>
  <thead>
    <tr>
      <th>Company</th>
      <th>Use Case</th>
      <th>Ensemble Approach</th>
      <th>Results</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Google</td>
      <td>Google Assistant</td>
      <td>Multiple AM + LM combinations</td>
      <td>-15% WER</td>
    </tr>
    <tr>
      <td>Amazon</td>
      <td>Alexa</td>
      <td>Wav2Vec2 + Conformer + RNN-T</td>
      <td>-12% WER</td>
    </tr>
    <tr>
      <td>Microsoft</td>
      <td>Azure Speech</td>
      <td>5+ acoustic models + LM fusion</td>
      <td>-20% WER</td>
    </tr>
    <tr>
      <td>Apple</td>
      <td>Siri</td>
      <td>On-device + cloud hybrid ensemble</td>
      <td>-10% WER</td>
    </tr>
    <tr>
      <td>Baidu</td>
      <td>DeepSpeech</td>
      <td>LSTM + CNN + Transformer ensemble</td>
      <td>-18% WER</td>
    </tr>
  </tbody>
</table>

<h3 id="the-backtracking-connection">The Backtracking Connection</h3>

<p>Just like the <strong>Generate Parentheses</strong> problem and <strong>Model Ensembling</strong> systems:</p>

<table>
  <thead>
    <tr>
      <th>Generate Parentheses</th>
      <th>Speech Ensemble</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Generate valid string combinations</td>
      <td>Generate valid model combinations</td>
    </tr>
    <tr>
      <td>Constraints: balanced parens</td>
      <td>Constraints: latency, accuracy, diversity</td>
    </tr>
    <tr>
      <td>Backtracking exploration</td>
      <td>Backtracking to find optimal model subset</td>
    </tr>
    <tr>
      <td>Prune invalid early</td>
      <td>Prune low-confidence combinations</td>
    </tr>
    <tr>
      <td>Result: all valid strings</td>
      <td>Result: optimal ensemble configuration</td>
    </tr>
  </tbody>
</table>

<p><strong>Core pattern:</strong> Use backtracking to explore model combinations and select the best configuration for each utterance.</p>

<h2 id="high-level-architecture">High-Level Architecture</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>┌─────────────────────────────────────────────────────────────────┐
│                  Speech Ensemble System                          │
└─────────────────────────────────────────────────────────────────┘

                    Audio Input (PCM)
                           ↓
              ┌────────────────────────┐
              │  Audio Preprocessor    │
              │  - Resample to 16kHz   │
              │  - Normalize           │
              │  - Feature extraction  │
              └───────────┬────────────┘
                          │
        ┌─────────────────┼─────────────────┐
        │                 │                 │
┌───────▼────────┐ ┌─────▼──────┐ ┌───────▼────────┐
│  ASR Model 1   │ │ ASR Model 2│ │  ASR Model N   │
│  (Wav2Vec2)    │ │ (Conformer)│ │  (Whisper)     │
│                │ │            │ │                │
│ "the cat"      │ │ "the cat"  │ │ "the cat"      │
│ conf: 0.92     │ │ conf: 0.88 │ │ conf: 0.85     │
└───────┬────────┘ └─────┬──────┘ └───────┬────────┘
        │                │                │
        └────────────────┼────────────────┘
                         │
              ┌──────────▼────────────┐
              │   Fusion Module       │
              │   - ROVER             │
              │   - Voting            │
              │   - Confidence-based  │
              └──────────┬────────────┘
                         │
              ┌──────────▼────────────┐
              │  Language Model       │
              │  Rescoring (optional) │
              └──────────┬────────────┘
                         │
                  "the cat" (WER: 0%)
                  confidence: 0.95
</code></pre></div></div>

<h3 id="key-components">Key Components</h3>

<ol>
  <li><strong>Audio Preprocessor:</strong> Prepares audio for all models</li>
  <li><strong>ASR Models:</strong> Multiple models with different architectures</li>
  <li><strong>Fusion Module:</strong> Combines model outputs (ROVER, voting, etc.)</li>
  <li><strong>Language Model:</strong> Optional rescoring for better accuracy</li>
  <li><strong>Confidence Estimator:</strong> Aggregates confidence from models</li>
</ol>

<h2 id="component-deep-dives">Component Deep-Dives</h2>

<h3 id="1-model-selection-using-backtracking">1. Model Selection Using Backtracking</h3>

<p>Select optimal model subset based on audio characteristics:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span>
<span class="kn">from</span> <span class="n">enum</span> <span class="kn">import</span> <span class="n">Enum</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">class</span> <span class="nc">ModelType</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Speech model types.</span><span class="sh">"""</span>
    <span class="n">WAV2VEC2</span> <span class="o">=</span> <span class="sh">"</span><span class="s">wav2vec2</span><span class="sh">"</span>
    <span class="n">CONFORMER</span> <span class="o">=</span> <span class="sh">"</span><span class="s">conformer</span><span class="sh">"</span>
    <span class="n">WHISPER</span> <span class="o">=</span> <span class="sh">"</span><span class="s">whisper</span><span class="sh">"</span>
    <span class="n">RNN_T</span> <span class="o">=</span> <span class="sh">"</span><span class="s">rnn_t</span><span class="sh">"</span>
    <span class="n">LSTM</span> <span class="o">=</span> <span class="sh">"</span><span class="s">lstm</span><span class="sh">"</span>

<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">SpeechModel</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">Represents a speech recognition model.</span><span class="sh">"""</span>
    <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">model_type</span><span class="p">:</span> <span class="n">ModelType</span>
    <span class="n">avg_latency_ms</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">wer</span><span class="p">:</span> <span class="nb">float</span>  <span class="c1"># Word Error Rate on validation set
</span>    
    <span class="c1"># Specialization
</span>    <span class="n">best_for_accent</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">"</span><span class="s">general</span><span class="sh">"</span>  <span class="c1"># "us", "uk", "in", etc.
</span>    <span class="n">best_for_noise</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">"</span><span class="s">clean</span><span class="sh">"</span>  <span class="c1"># "clean", "noisy", "very_noisy"
</span>    <span class="n">best_for_domain</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">"</span><span class="s">general</span><span class="sh">"</span>  <span class="c1"># "general", "medical", "legal"
</span>    
    <span class="c1"># Resource requirements
</span>    <span class="n">gpu_memory_mb</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">500</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">transcribe</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Transcribe audio.
        
        Returns:
            Dictionary with text, confidence, and word-level timings
        </span><span class="sh">"""</span>
        <span class="c1"># In production: call actual model
</span>        <span class="c1"># For demo: return dummy prediction
</span>        
        <span class="kn">import</span> <span class="n">asyncio</span>
        <span class="k">await</span> <span class="n">asyncio</span><span class="p">.</span><span class="nf">sleep</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">avg_latency_ms</span> <span class="o">/</span> <span class="mf">1000.0</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="p">{</span>
            <span class="sh">"</span><span class="s">text</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">the quick brown fox</span><span class="sh">"</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">confidence</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.85</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">()</span> <span class="o">*</span> <span class="mf">0.10</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">words</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span>
                <span class="p">{</span><span class="sh">"</span><span class="s">word</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">the</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">confidence</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.95</span><span class="p">,</span> <span class="sh">"</span><span class="s">start</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="sh">"</span><span class="s">end</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">},</span>
                <span class="p">{</span><span class="sh">"</span><span class="s">word</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">quick</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">confidence</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.88</span><span class="p">,</span> <span class="sh">"</span><span class="s">start</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="sh">"</span><span class="s">end</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">},</span>
                <span class="p">{</span><span class="sh">"</span><span class="s">word</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">brown</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">confidence</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.82</span><span class="p">,</span> <span class="sh">"</span><span class="s">start</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span> <span class="sh">"</span><span class="s">end</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">},</span>
                <span class="p">{</span><span class="sh">"</span><span class="s">word</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">fox</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">confidence</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.90</span><span class="p">,</span> <span class="sh">"</span><span class="s">start</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span> <span class="sh">"</span><span class="s">end</span><span class="sh">"</span><span class="p">:</span> <span class="mf">1.1</span><span class="p">},</span>
            <span class="p">]</span>
        <span class="p">}</span>

<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">AudioCharacteristics</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">Characteristics of input audio.</span><span class="sh">"""</span>
    <span class="n">snr_db</span><span class="p">:</span> <span class="nb">float</span>  <span class="c1"># Signal-to-noise ratio
</span>    <span class="n">duration_sec</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">accent</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">"</span><span class="s">us</span><span class="sh">"</span>
    <span class="n">domain</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">"</span><span class="s">general</span><span class="sh">"</span>
    
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">noise_level</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Categorize noise level.</span><span class="sh">"""</span>
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">snr_db</span> <span class="o">&gt;</span> <span class="mi">30</span><span class="p">:</span>
            <span class="k">return</span> <span class="sh">"</span><span class="s">clean</span><span class="sh">"</span>
        <span class="k">elif</span> <span class="n">self</span><span class="p">.</span><span class="n">snr_db</span> <span class="o">&gt;</span> <span class="mi">15</span><span class="p">:</span>
            <span class="k">return</span> <span class="sh">"</span><span class="s">noisy</span><span class="sh">"</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="sh">"</span><span class="s">very_noisy</span><span class="sh">"</span>


<span class="k">class</span> <span class="nc">ModelSelector</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Select optimal model subset using backtracking.
    
    Similar to Generate Parentheses backtracking:
    - Explore combinations of models
    - Prune based on constraints
    - Select configuration with best expected accuracy
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">models</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">SpeechModel</span><span class="p">],</span>
        <span class="n">max_models</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
        <span class="n">max_latency_ms</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">150.0</span><span class="p">,</span>
        <span class="n">max_gpu_memory_mb</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2000</span>
    <span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">models</span> <span class="o">=</span> <span class="n">models</span>
        <span class="n">self</span><span class="p">.</span><span class="n">max_models</span> <span class="o">=</span> <span class="n">max_models</span>
        <span class="n">self</span><span class="p">.</span><span class="n">max_latency_ms</span> <span class="o">=</span> <span class="n">max_latency_ms</span>
        <span class="n">self</span><span class="p">.</span><span class="n">max_gpu_memory_mb</span> <span class="o">=</span> <span class="n">max_gpu_memory_mb</span>
    
    <span class="k">def</span> <span class="nf">select_models</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">audio_chars</span><span class="p">:</span> <span class="n">AudioCharacteristics</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">SpeechModel</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">
        Select best model subset using backtracking.
        
        Algorithm (like parentheses generation):
        1. Start with empty selection
        2. Try adding each model
        3. Check constraints (latency, memory, diversity)
        4. Recurse to explore further
        5. Backtrack if constraints violated
        6. Return selection with best expected WER
        
        Returns:
            List of selected models
        </span><span class="sh">"""</span>
        <span class="n">best_selection</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">best_score</span> <span class="o">=</span> <span class="nf">float</span><span class="p">(</span><span class="sh">'</span><span class="s">inf</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># Lower WER is better
</span>        
        <span class="k">def</span> <span class="nf">estimate_ensemble_wer</span><span class="p">(</span><span class="n">models</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">SpeechModel</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
            <span class="sh">"""</span><span class="s">
            Estimate ensemble WER based on individual model WERs.
            
            Heuristic: ensemble WER ≈ 0.7 × average individual WER
            (empirically, ensembles reduce WER by ~30%)
            </span><span class="sh">"""</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">models</span><span class="p">:</span>
                <span class="k">return</span> <span class="nf">float</span><span class="p">(</span><span class="sh">'</span><span class="s">inf</span><span class="sh">'</span><span class="p">)</span>
            
            <span class="c1"># Weight by specialization match
</span>            <span class="n">weighted_wers</span> <span class="o">=</span> <span class="p">[]</span>
            
            <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
                <span class="n">wer</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">wer</span>
                
                <span class="c1"># Bonus for accent match
</span>                <span class="k">if</span> <span class="n">model</span><span class="p">.</span><span class="n">best_for_accent</span> <span class="o">==</span> <span class="n">audio_chars</span><span class="p">.</span><span class="n">accent</span><span class="p">:</span>
                    <span class="n">wer</span> <span class="o">*=</span> <span class="mf">0.9</span>
                
                <span class="c1"># Bonus for noise level match
</span>                <span class="k">if</span> <span class="n">model</span><span class="p">.</span><span class="n">best_for_noise</span> <span class="o">==</span> <span class="n">audio_chars</span><span class="p">.</span><span class="n">noise_level</span><span class="p">:</span>
                    <span class="n">wer</span> <span class="o">*=</span> <span class="mf">0.85</span>
                
                <span class="c1"># Bonus for domain match
</span>                <span class="k">if</span> <span class="n">model</span><span class="p">.</span><span class="n">best_for_domain</span> <span class="o">==</span> <span class="n">audio_chars</span><span class="p">.</span><span class="n">domain</span><span class="p">:</span>
                    <span class="n">wer</span> <span class="o">*=</span> <span class="mf">0.95</span>
                
                <span class="n">weighted_wers</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">wer</span><span class="p">)</span>
            
            <span class="c1"># Ensemble effect
</span>            <span class="n">avg_wer</span> <span class="o">=</span> <span class="nf">sum</span><span class="p">(</span><span class="n">weighted_wers</span><span class="p">)</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">weighted_wers</span><span class="p">)</span>
            <span class="n">ensemble_wer</span> <span class="o">=</span> <span class="n">avg_wer</span> <span class="o">*</span> <span class="mf">0.7</span>  <span class="c1"># 30% improvement from ensemble
</span>            
            <span class="k">return</span> <span class="n">ensemble_wer</span>
        
        <span class="k">def</span> <span class="nf">calculate_diversity</span><span class="p">(</span><span class="n">models</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">SpeechModel</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
            <span class="sh">"""</span><span class="s">Calculate model diversity (different architectures).</span><span class="sh">"""</span>
            <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">models</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="mf">1.0</span>
            
            <span class="n">unique_types</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="nf">set</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">model_type</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">models</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">unique_types</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">models</span><span class="p">)</span>
        
        <span class="k">def</span> <span class="nf">backtrack</span><span class="p">(</span>
            <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
            <span class="n">current_selection</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">SpeechModel</span><span class="p">],</span>
            <span class="n">current_latency</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
            <span class="n">current_memory</span><span class="p">:</span> <span class="nb">int</span>
        <span class="p">):</span>
            <span class="sh">"""</span><span class="s">Backtracking function.</span><span class="sh">"""</span>
            <span class="k">nonlocal</span> <span class="n">best_selection</span><span class="p">,</span> <span class="n">best_score</span>
            
            <span class="c1"># Base case: evaluated all models
</span>            <span class="k">if</span> <span class="n">index</span> <span class="o">==</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">models</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">current_selection</span><span class="p">:</span>
                    <span class="n">score</span> <span class="o">=</span> <span class="nf">estimate_ensemble_wer</span><span class="p">(</span><span class="n">current_selection</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">score</span> <span class="o">&lt;</span> <span class="n">best_score</span><span class="p">:</span>
                        <span class="n">best_score</span> <span class="o">=</span> <span class="n">score</span>
                        <span class="n">best_selection</span> <span class="o">=</span> <span class="n">current_selection</span><span class="p">[:]</span>
                <span class="k">return</span>
            
            <span class="n">model</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">models</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
            
            <span class="c1"># Choice 1: Include current model
</span>            <span class="c1"># Check constraints (like checking parentheses validity)
</span>            <span class="n">new_latency</span> <span class="o">=</span> <span class="n">current_latency</span> <span class="o">+</span> <span class="n">model</span><span class="p">.</span><span class="n">avg_latency_ms</span>
            <span class="n">new_memory</span> <span class="o">=</span> <span class="n">current_memory</span> <span class="o">+</span> <span class="n">model</span><span class="p">.</span><span class="n">gpu_memory_mb</span>
            
            <span class="n">can_add</span> <span class="o">=</span> <span class="p">(</span>
                <span class="nf">len</span><span class="p">(</span><span class="n">current_selection</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">self</span><span class="p">.</span><span class="n">max_models</span> <span class="ow">and</span>
                <span class="n">new_latency</span> <span class="o">&lt;=</span> <span class="n">self</span><span class="p">.</span><span class="n">max_latency_ms</span> <span class="ow">and</span>
                <span class="n">new_memory</span> <span class="o">&lt;=</span> <span class="n">self</span><span class="p">.</span><span class="n">max_gpu_memory_mb</span> <span class="ow">and</span>
                <span class="nf">calculate_diversity</span><span class="p">(</span><span class="n">current_selection</span> <span class="o">+</span> <span class="p">[</span><span class="n">model</span><span class="p">])</span> <span class="o">&gt;=</span> <span class="mf">0.5</span>
            <span class="p">)</span>
            
            <span class="k">if</span> <span class="n">can_add</span><span class="p">:</span>
                <span class="n">current_selection</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
                <span class="nf">backtrack</span><span class="p">(</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">current_selection</span><span class="p">,</span> <span class="n">new_latency</span><span class="p">,</span> <span class="n">new_memory</span><span class="p">)</span>
                <span class="n">current_selection</span><span class="p">.</span><span class="nf">pop</span><span class="p">()</span>  <span class="c1"># Backtrack
</span>            
            <span class="c1"># Choice 2: Skip current model
</span>            <span class="nf">backtrack</span><span class="p">(</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">current_selection</span><span class="p">,</span> <span class="n">current_latency</span><span class="p">,</span> <span class="n">current_memory</span><span class="p">)</span>
        
        <span class="c1"># Start backtracking
</span>        <span class="nf">backtrack</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">[],</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        
        <span class="c1"># Ensure at least one model
</span>        <span class="k">if</span> <span class="ow">not</span> <span class="n">best_selection</span> <span class="ow">and</span> <span class="n">self</span><span class="p">.</span><span class="n">models</span><span class="p">:</span>
            <span class="c1"># Fallback: use single best model
</span>            <span class="n">best_selection</span> <span class="o">=</span> <span class="p">[</span><span class="nf">min</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">models</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">m</span><span class="p">:</span> <span class="n">m</span><span class="p">.</span><span class="n">wer</span><span class="p">)]</span>
        
        <span class="k">return</span> <span class="n">best_selection</span>
</code></pre></div></div>

<h3 id="2-rover---recognizer-output-voting-error-reduction">2. ROVER - Recognizer Output Voting Error Reduction</h3>

<p>ROVER is the <strong>standard algorithm</strong> for combining ASR outputs:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span>
<span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">Word</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">Word with timing and confidence.</span><span class="sh">"""</span>
    <span class="n">text</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">confidence</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">start_time</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">end_time</span><span class="p">:</span> <span class="nb">float</span>
    
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">duration</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">end_time</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">start_time</span>

<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">Hypothesis</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">A single ASR hypothesis (from one model).</span><span class="sh">"""</span>
    <span class="n">words</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Word</span><span class="p">]</span>
    <span class="n">confidence</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">model_id</span><span class="p">:</span> <span class="nb">str</span>
    
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">text</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">w</span><span class="p">.</span><span class="n">text</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">words</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">ROVERFusion</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    ROVER (Recognizer Output Voting Error Reduction) algorithm.
    
    Core idea:
    1. Align hypotheses from different models
    2. At each time position, vote on the word
    3. Select word with highest confidence × votes
    
    This is the gold standard for ASR ensemble fusion.
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model_weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Initialize ROVER.
        
        Args:
            model_weights: Optional weights for each model
        </span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model_weights</span> <span class="o">=</span> <span class="n">model_weights</span> <span class="ow">or</span> <span class="p">{}</span>
    
    <span class="k">def</span> <span class="nf">fuse</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">hypotheses</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Hypothesis</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Hypothesis</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Fuse multiple hypotheses using ROVER.
        
        Algorithm:
        1. Build word confusion network (WCN)
        2. Align words by time
        3. Vote at each position
        4. Select best word at each position
        
        Returns:
            Fused hypothesis
        </span><span class="sh">"""</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">hypotheses</span><span class="p">:</span>
            <span class="k">return</span> <span class="nc">Hypothesis</span><span class="p">(</span><span class="n">words</span><span class="o">=</span><span class="p">[],</span> <span class="n">confidence</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">model_id</span><span class="o">=</span><span class="sh">"</span><span class="s">ensemble</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">hypotheses</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">hypotheses</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="c1"># Build word confusion network
</span>        <span class="n">wcn</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_build_confusion_network</span><span class="p">(</span><span class="n">hypotheses</span><span class="p">)</span>
        
        <span class="c1"># Vote at each position
</span>        <span class="n">fused_words</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">time_slot</span><span class="p">,</span> <span class="n">candidates</span> <span class="ow">in</span> <span class="n">wcn</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
            <span class="c1"># Vote for best word
</span>            <span class="n">best_word</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_vote</span><span class="p">(</span><span class="n">candidates</span><span class="p">,</span> <span class="n">hypotheses</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">best_word</span><span class="p">:</span>
                <span class="n">fused_words</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">best_word</span><span class="p">)</span>
        
        <span class="c1"># Calculate overall confidence
</span>        <span class="n">avg_confidence</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nf">sum</span><span class="p">(</span><span class="n">w</span><span class="p">.</span><span class="n">confidence</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">fused_words</span><span class="p">)</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">fused_words</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">fused_words</span> <span class="k">else</span> <span class="mf">0.0</span>
        <span class="p">)</span>
        
        <span class="k">return</span> <span class="nc">Hypothesis</span><span class="p">(</span>
            <span class="n">words</span><span class="o">=</span><span class="n">fused_words</span><span class="p">,</span>
            <span class="n">confidence</span><span class="o">=</span><span class="n">avg_confidence</span><span class="p">,</span>
            <span class="n">model_id</span><span class="o">=</span><span class="sh">"</span><span class="s">rover_ensemble</span><span class="sh">"</span>
        <span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_build_confusion_network</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">hypotheses</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Hypothesis</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Word</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]]:</span>
        <span class="sh">"""</span><span class="s">
        Build word confusion network.
        
        Groups words by approximate time position.
        
        Returns:
            Dictionary mapping time -&gt; [(word, model_id), ...]
        </span><span class="sh">"""</span>
        <span class="c1"># Discretize time into 100ms bins
</span>        <span class="n">time_bin_size</span> <span class="o">=</span> <span class="mf">0.1</span>
        <span class="n">wcn</span> <span class="o">=</span> <span class="nf">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">hyp</span> <span class="ow">in</span> <span class="n">hypotheses</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">hyp</span><span class="p">.</span><span class="n">words</span><span class="p">:</span>
                <span class="c1"># Assign to time bin
</span>                <span class="n">time_bin</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">word</span><span class="p">.</span><span class="n">start_time</span> <span class="o">/</span> <span class="n">time_bin_size</span><span class="p">)</span>
                <span class="n">wcn</span><span class="p">[</span><span class="n">time_bin</span><span class="p">].</span><span class="nf">append</span><span class="p">((</span><span class="n">word</span><span class="p">,</span> <span class="n">hyp</span><span class="p">.</span><span class="n">model_id</span><span class="p">))</span>
        
        <span class="k">return</span> <span class="n">wcn</span>
    
    <span class="k">def</span> <span class="nf">_vote</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">candidates</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Word</span><span class="p">,</span> <span class="nb">str</span><span class="p">]],</span>
        <span class="n">hypotheses</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Hypothesis</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Word</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">
        Vote for best word among candidates.
        
        Voting strategy:
        1. Group identical words
        2. Calculate score = sum(confidence × model_weight × vote_count)
        3. Return highest scoring word
        </span><span class="sh">"""</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">candidates</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">None</span>
        
        <span class="c1"># Group by word text
</span>        <span class="n">word_groups</span> <span class="o">=</span> <span class="nf">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">model_id</span> <span class="ow">in</span> <span class="n">candidates</span><span class="p">:</span>
            <span class="c1"># Normalize word (lowercase, remove punctuation)
</span>            <span class="n">normalized</span> <span class="o">=</span> <span class="n">word</span><span class="p">.</span><span class="n">text</span><span class="p">.</span><span class="nf">lower</span><span class="p">().</span><span class="nf">strip</span><span class="p">(</span><span class="sh">'</span><span class="s">.,!?</span><span class="sh">'</span><span class="p">)</span>
            <span class="n">word_groups</span><span class="p">[</span><span class="n">normalized</span><span class="p">].</span><span class="nf">append</span><span class="p">((</span><span class="n">word</span><span class="p">,</span> <span class="n">model_id</span><span class="p">))</span>
        
        <span class="c1"># Vote
</span>        <span class="n">best_word</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="n">best_score</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span>
        
        <span class="k">for</span> <span class="n">word_text</span><span class="p">,</span> <span class="n">occurrences</span> <span class="ow">in</span> <span class="n">word_groups</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
            <span class="c1"># Calculate score
</span>            <span class="n">score</span> <span class="o">=</span> <span class="mf">0.0</span>
            
            <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">model_id</span> <span class="ow">in</span> <span class="n">occurrences</span><span class="p">:</span>
                <span class="n">weight</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">model_weights</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
                <span class="n">score</span> <span class="o">+=</span> <span class="n">word</span><span class="p">.</span><span class="n">confidence</span> <span class="o">*</span> <span class="n">weight</span>
            
            <span class="c1"># Bonus for agreement (more models)
</span>            <span class="n">score</span> <span class="o">*=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="nf">len</span><span class="p">(</span><span class="n">occurrences</span><span class="p">))</span>
            
            <span class="k">if</span> <span class="n">score</span> <span class="o">&gt;</span> <span class="n">best_score</span><span class="p">:</span>
                <span class="n">best_score</span> <span class="o">=</span> <span class="n">score</span>
                <span class="c1"># Use word with highest individual confidence
</span>                <span class="n">best_word</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">occurrences</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">confidence</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="k">return</span> <span class="n">best_word</span>
    
    <span class="k">def</span> <span class="nf">compute_confidence</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">hypotheses</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Hypothesis</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Compute ensemble confidence based on agreement.
        
        High agreement = high confidence.
        </span><span class="sh">"""</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">hypotheses</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">0.0</span>
        
        <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">hypotheses</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">hypotheses</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">confidence</span>
        
        <span class="c1"># Calculate pairwise word-level agreement
</span>        <span class="n">agreements</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">hypotheses</span><span class="p">)):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">hypotheses</span><span class="p">)):</span>
                <span class="n">agreement</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_compute_agreement</span><span class="p">(</span>
                    <span class="n">hypotheses</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                    <span class="n">hypotheses</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="n">agreements</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">agreement</span><span class="p">)</span>
        
        <span class="c1"># Average agreement
</span>        <span class="n">avg_agreement</span> <span class="o">=</span> <span class="nf">sum</span><span class="p">(</span><span class="n">agreements</span><span class="p">)</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">agreements</span><span class="p">)</span>
        
        <span class="c1"># Combine with average model confidence
</span>        <span class="n">avg_confidence</span> <span class="o">=</span> <span class="nf">sum</span><span class="p">(</span><span class="n">h</span><span class="p">.</span><span class="n">confidence</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">hypotheses</span><span class="p">)</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">hypotheses</span><span class="p">)</span>
        
        <span class="c1"># Final confidence = weighted combination
</span>        <span class="k">return</span> <span class="mf">0.6</span> <span class="o">*</span> <span class="n">avg_confidence</span> <span class="o">+</span> <span class="mf">0.4</span> <span class="o">*</span> <span class="n">avg_agreement</span>
    
    <span class="k">def</span> <span class="nf">_compute_agreement</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">hyp1</span><span class="p">:</span> <span class="n">Hypothesis</span><span class="p">,</span> <span class="n">hyp2</span><span class="p">:</span> <span class="n">Hypothesis</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Compute word-level agreement between two hypotheses.
        
        Uses edit distance and word overlap.
        </span><span class="sh">"""</span>
        <span class="n">words1</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="p">.</span><span class="n">text</span><span class="p">.</span><span class="nf">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">hyp1</span><span class="p">.</span><span class="n">words</span><span class="p">]</span>
        <span class="n">words2</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="p">.</span><span class="n">text</span><span class="p">.</span><span class="nf">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">hyp2</span><span class="p">.</span><span class="n">words</span><span class="p">]</span>
        
        <span class="c1"># Calculate word overlap
</span>        <span class="n">common</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">words1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="nf">set</span><span class="p">(</span><span class="n">words2</span><span class="p">)</span>
        <span class="n">union</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">words1</span><span class="p">)</span> <span class="o">|</span> <span class="nf">set</span><span class="p">(</span><span class="n">words2</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="n">union</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">0.0</span>
        
        <span class="c1"># Jaccard similarity
</span>        <span class="k">return</span> <span class="nf">len</span><span class="p">(</span><span class="n">common</span><span class="p">)</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">union</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="3-confidence-based-fusion">3. Confidence-Based Fusion</h3>

<p>Alternative to ROVER: select words based on per-word confidence:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ConfidenceFusion</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Confidence-based fusion: select word with highest confidence.
    
    Simpler than ROVER but can work well when models are well-calibrated.
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">confidence_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.7</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">confidence_threshold</span> <span class="o">=</span> <span class="n">confidence_threshold</span>
    
    <span class="k">def</span> <span class="nf">fuse</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">hypotheses</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Hypothesis</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Hypothesis</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Fuse hypotheses by selecting highest-confidence words.
        
        Algorithm:
        1. For each word position (by time)
        2. Select word with highest confidence
        3. If all confidences &lt; threshold, mark as uncertain
        </span><span class="sh">"""</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">hypotheses</span><span class="p">:</span>
            <span class="k">return</span> <span class="nc">Hypothesis</span><span class="p">(</span><span class="n">words</span><span class="o">=</span><span class="p">[],</span> <span class="n">confidence</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">model_id</span><span class="o">=</span><span class="sh">"</span><span class="s">ensemble</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">hypotheses</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">hypotheses</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="c1"># Collect all words with time positions
</span>        <span class="n">all_words</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">hyp</span> <span class="ow">in</span> <span class="n">hypotheses</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">hyp</span><span class="p">.</span><span class="n">words</span><span class="p">:</span>
                <span class="n">all_words</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">word</span><span class="p">,</span> <span class="n">hyp</span><span class="p">.</span><span class="n">model_id</span><span class="p">))</span>
        
        <span class="c1"># Sort by start time
</span>        <span class="n">all_words</span><span class="p">.</span><span class="nf">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">start_time</span><span class="p">)</span>
        
        <span class="c1"># Greedily select non-overlapping high-confidence words
</span>        <span class="n">fused_words</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">last_end_time</span> <span class="o">=</span> <span class="mf">0.0</span>
        
        <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">model_id</span> <span class="ow">in</span> <span class="n">all_words</span><span class="p">:</span>
            <span class="c1"># Skip if overlaps with previous word
</span>            <span class="k">if</span> <span class="n">word</span><span class="p">.</span><span class="n">start_time</span> <span class="o">&lt;</span> <span class="n">last_end_time</span><span class="p">:</span>
                <span class="c1"># Check if this word has higher confidence
</span>                <span class="k">if</span> <span class="n">fused_words</span> <span class="ow">and</span> <span class="n">word</span><span class="p">.</span><span class="n">confidence</span> <span class="o">&gt;</span> <span class="n">fused_words</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">confidence</span><span class="p">:</span>
                    <span class="c1"># Replace previous word with this one
</span>                    <span class="n">fused_words</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span>
                    <span class="n">last_end_time</span> <span class="o">=</span> <span class="n">word</span><span class="p">.</span><span class="n">end_time</span>
                <span class="k">continue</span>
            
            <span class="c1"># Add word if confidence sufficient
</span>            <span class="k">if</span> <span class="n">word</span><span class="p">.</span><span class="n">confidence</span> <span class="o">&gt;=</span> <span class="n">self</span><span class="p">.</span><span class="n">confidence_threshold</span><span class="p">:</span>
                <span class="n">fused_words</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
                <span class="n">last_end_time</span> <span class="o">=</span> <span class="n">word</span><span class="p">.</span><span class="n">end_time</span>
        
        <span class="c1"># Calculate ensemble confidence
</span>        <span class="n">avg_conf</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nf">sum</span><span class="p">(</span><span class="n">w</span><span class="p">.</span><span class="n">confidence</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">fused_words</span><span class="p">)</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">fused_words</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">fused_words</span> <span class="k">else</span> <span class="mf">0.0</span>
        <span class="p">)</span>
        
        <span class="k">return</span> <span class="nc">Hypothesis</span><span class="p">(</span>
            <span class="n">words</span><span class="o">=</span><span class="n">fused_words</span><span class="p">,</span>
            <span class="n">confidence</span><span class="o">=</span><span class="n">avg_conf</span><span class="p">,</span>
            <span class="n">model_id</span><span class="o">=</span><span class="sh">"</span><span class="s">confidence_ensemble</span><span class="sh">"</span>
        <span class="p">)</span>
</code></pre></div></div>

<h3 id="4-voting-based-fusion">4. Voting-Based Fusion</h3>

<p>Simple voting approach for word-level decisions:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">VotingFusion</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Simple voting: most common word wins.
    
    Good for:
    - Quick prototyping
    - When models have similar quality
    - When speed is critical
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">fuse</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">hypotheses</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Hypothesis</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Hypothesis</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Fuse using majority voting.
        
        Algorithm:
        1. For each word position
        2. Vote among models
        3. Select majority (or plurality)
        </span><span class="sh">"""</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">hypotheses</span><span class="p">:</span>
            <span class="k">return</span> <span class="nc">Hypothesis</span><span class="p">(</span><span class="n">words</span><span class="o">=</span><span class="p">[],</span> <span class="n">confidence</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">model_id</span><span class="o">=</span><span class="sh">"</span><span class="s">ensemble</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">hypotheses</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">hypotheses</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="c1"># Use ROVER's WCN but simple majority voting
</span>        <span class="n">wcn</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_build_wcn</span><span class="p">(</span><span class="n">hypotheses</span><span class="p">)</span>
        
        <span class="n">fused_words</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">time_slot</span><span class="p">,</span> <span class="n">candidates</span> <span class="ow">in</span> <span class="nf">sorted</span><span class="p">(</span><span class="n">wcn</span><span class="p">.</span><span class="nf">items</span><span class="p">()):</span>
            <span class="c1"># Count votes for each word
</span>            <span class="n">votes</span> <span class="o">=</span> <span class="nf">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
            <span class="n">word_objects</span> <span class="o">=</span> <span class="p">{}</span>
            
            <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">model_id</span> <span class="ow">in</span> <span class="n">candidates</span><span class="p">:</span>
                <span class="n">normalized</span> <span class="o">=</span> <span class="n">word</span><span class="p">.</span><span class="n">text</span><span class="p">.</span><span class="nf">lower</span><span class="p">()</span>
                <span class="n">votes</span><span class="p">[</span><span class="n">normalized</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                
                <span class="c1"># Keep track of word object (use one with highest confidence)
</span>                <span class="nf">if </span><span class="p">(</span><span class="n">normalized</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">word_objects</span> <span class="ow">or</span>
                    <span class="n">word</span><span class="p">.</span><span class="n">confidence</span> <span class="o">&gt;</span> <span class="n">word_objects</span><span class="p">[</span><span class="n">normalized</span><span class="p">].</span><span class="n">confidence</span><span class="p">):</span>
                    <span class="n">word_objects</span><span class="p">[</span><span class="n">normalized</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span>
            
            <span class="c1"># Select winner (plurality)
</span>            <span class="k">if</span> <span class="n">votes</span><span class="p">:</span>
                <span class="n">winner</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">votes</span><span class="p">.</span><span class="nf">keys</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">w</span><span class="p">:</span> <span class="n">votes</span><span class="p">[</span><span class="n">w</span><span class="p">])</span>
                <span class="n">fused_words</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">word_objects</span><span class="p">[</span><span class="n">winner</span><span class="p">])</span>
        
        <span class="n">avg_conf</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nf">sum</span><span class="p">(</span><span class="n">w</span><span class="p">.</span><span class="n">confidence</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">fused_words</span><span class="p">)</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">fused_words</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">fused_words</span> <span class="k">else</span> <span class="mf">0.0</span>
        <span class="p">)</span>
        
        <span class="k">return</span> <span class="nc">Hypothesis</span><span class="p">(</span>
            <span class="n">words</span><span class="o">=</span><span class="n">fused_words</span><span class="p">,</span>
            <span class="n">confidence</span><span class="o">=</span><span class="n">avg_conf</span><span class="p">,</span>
            <span class="n">model_id</span><span class="o">=</span><span class="sh">"</span><span class="s">voting_ensemble</span><span class="sh">"</span>
        <span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_build_wcn</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">hypotheses</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Build word confusion network (simplified).</span><span class="sh">"""</span>
        <span class="n">time_bin_size</span> <span class="o">=</span> <span class="mf">0.1</span>
        <span class="n">wcn</span> <span class="o">=</span> <span class="nf">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">hyp</span> <span class="ow">in</span> <span class="n">hypotheses</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">hyp</span><span class="p">.</span><span class="n">words</span><span class="p">:</span>
                <span class="n">time_bin</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">word</span><span class="p">.</span><span class="n">start_time</span> <span class="o">/</span> <span class="n">time_bin_size</span><span class="p">)</span>
                <span class="n">wcn</span><span class="p">[</span><span class="n">time_bin</span><span class="p">].</span><span class="nf">append</span><span class="p">((</span><span class="n">word</span><span class="p">,</span> <span class="n">hyp</span><span class="p">.</span><span class="n">model_id</span><span class="p">))</span>
        
        <span class="k">return</span> <span class="n">wcn</span>
</code></pre></div></div>

<h3 id="5-complete-ensemble-system">5. Complete Ensemble System</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">asyncio</span>
<span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span>
<span class="kn">import</span> <span class="n">time</span>
<span class="kn">import</span> <span class="n">logging</span>

<span class="k">class</span> <span class="nc">SpeechEnsemble</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Complete multi-model speech ensemble system.
    
    Features:
    - Model selection using backtracking
    - Multiple fusion strategies
    - Parallel model execution
    - Fallback handling
    - Performance monitoring
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">models</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">SpeechModel</span><span class="p">],</span>
        <span class="n">fusion_strategy</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">"</span><span class="s">rover</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">max_models</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
        <span class="n">max_latency_ms</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">150.0</span>
    <span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">models</span> <span class="o">=</span> <span class="n">models</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fusion_strategy</span> <span class="o">=</span> <span class="n">fusion_strategy</span>
        <span class="n">self</span><span class="p">.</span><span class="n">selector</span> <span class="o">=</span> <span class="nc">ModelSelector</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">max_models</span><span class="p">,</span> <span class="n">max_latency_ms</span><span class="p">)</span>
        
        <span class="c1"># Create fusion engine
</span>        <span class="k">if</span> <span class="n">fusion_strategy</span> <span class="o">==</span> <span class="sh">"</span><span class="s">rover</span><span class="sh">"</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">fusion</span> <span class="o">=</span> <span class="nc">ROVERFusion</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">fusion_strategy</span> <span class="o">==</span> <span class="sh">"</span><span class="s">confidence</span><span class="sh">"</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">fusion</span> <span class="o">=</span> <span class="nc">ConfidenceFusion</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">fusion_strategy</span> <span class="o">==</span> <span class="sh">"</span><span class="s">voting</span><span class="sh">"</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">fusion</span> <span class="o">=</span> <span class="nc">VotingFusion</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="nc">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Unknown fusion strategy: </span><span class="si">{</span><span class="n">fusion_strategy</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="p">.</span><span class="nf">getLogger</span><span class="p">(</span><span class="n">__name__</span><span class="p">)</span>
        
        <span class="c1"># Metrics
</span>        <span class="n">self</span><span class="p">.</span><span class="n">request_count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">self</span><span class="p">.</span><span class="n">total_latency</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fallback_count</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">transcribe</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">audio</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">sample_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16000</span><span class="p">,</span>
        <span class="n">audio_chars</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">AudioCharacteristics</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Transcribe audio using ensemble.
        
        Args:
            audio: Audio samples
            sample_rate: Sample rate (Hz)
            audio_chars: Optional audio characteristics for model selection
            
        Returns:
            Dictionary with transcription and metadata
        </span><span class="sh">"""</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">perf_counter</span><span class="p">()</span>
        
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Analyze audio if characteristics not provided
</span>            <span class="k">if</span> <span class="n">audio_chars</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">audio_chars</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_analyze_audio</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">)</span>
            
            <span class="c1"># Select models using backtracking
</span>            <span class="n">selected_models</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">selector</span><span class="p">.</span><span class="nf">select_models</span><span class="p">(</span><span class="n">audio_chars</span><span class="p">)</span>
            
            <span class="n">self</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="sh">"</span><span class="s">Selected </span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">selected_models</span><span class="p">)</span><span class="si">}</span><span class="s"> models: </span><span class="sh">"</span>
                <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="p">[</span><span class="n">m</span><span class="p">.</span><span class="n">model_id</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">selected_models</span><span class="p">]</span><span class="si">}</span><span class="sh">"</span>
            <span class="p">)</span>
            
            <span class="c1"># Run models in parallel
</span>            <span class="n">transcription_tasks</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">model</span><span class="p">.</span><span class="nf">transcribe</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">selected_models</span>
            <span class="p">]</span>
            
            <span class="n">model_outputs</span> <span class="o">=</span> <span class="k">await</span> <span class="n">asyncio</span><span class="p">.</span><span class="nf">gather</span><span class="p">(</span>
                <span class="o">*</span><span class="n">transcription_tasks</span><span class="p">,</span>
                <span class="n">return_exceptions</span><span class="o">=</span><span class="bp">True</span>
            <span class="p">)</span>
            
            <span class="c1"># Build hypotheses (filter out failures)
</span>            <span class="n">hypotheses</span> <span class="o">=</span> <span class="p">[]</span>
            
            <span class="k">for</span> <span class="n">model</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">selected_models</span><span class="p">,</span> <span class="n">model_outputs</span><span class="p">):</span>
                <span class="k">if</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="nb">Exception</span><span class="p">):</span>
                    <span class="n">self</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="nf">warning</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Model </span><span class="si">{</span><span class="n">model</span><span class="p">.</span><span class="n">model_id</span><span class="si">}</span><span class="s"> failed: </span><span class="si">{</span><span class="n">output</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
                    <span class="k">continue</span>
                
                <span class="c1"># Convert to Hypothesis
</span>                <span class="n">words</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="nc">Word</span><span class="p">(</span>
                        <span class="n">text</span><span class="o">=</span><span class="n">w</span><span class="p">[</span><span class="sh">"</span><span class="s">word</span><span class="sh">"</span><span class="p">],</span>
                        <span class="n">confidence</span><span class="o">=</span><span class="n">w</span><span class="p">[</span><span class="sh">"</span><span class="s">confidence</span><span class="sh">"</span><span class="p">],</span>
                        <span class="n">start_time</span><span class="o">=</span><span class="n">w</span><span class="p">[</span><span class="sh">"</span><span class="s">start</span><span class="sh">"</span><span class="p">],</span>
                        <span class="n">end_time</span><span class="o">=</span><span class="n">w</span><span class="p">[</span><span class="sh">"</span><span class="s">end</span><span class="sh">"</span><span class="p">]</span>
                    <span class="p">)</span>
                    <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">output</span><span class="p">[</span><span class="sh">"</span><span class="s">words</span><span class="sh">"</span><span class="p">]</span>
                <span class="p">]</span>
                
                <span class="n">hypotheses</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nc">Hypothesis</span><span class="p">(</span>
                    <span class="n">words</span><span class="o">=</span><span class="n">words</span><span class="p">,</span>
                    <span class="n">confidence</span><span class="o">=</span><span class="n">output</span><span class="p">[</span><span class="sh">"</span><span class="s">confidence</span><span class="sh">"</span><span class="p">],</span>
                    <span class="n">model_id</span><span class="o">=</span><span class="n">model</span><span class="p">.</span><span class="n">model_id</span>
                <span class="p">))</span>
            
            <span class="k">if</span> <span class="ow">not</span> <span class="n">hypotheses</span><span class="p">:</span>
                <span class="k">raise</span> <span class="nc">RuntimeError</span><span class="p">(</span><span class="sh">"</span><span class="s">All models failed</span><span class="sh">"</span><span class="p">)</span>
            
            <span class="c1"># Fuse hypotheses
</span>            <span class="n">fused</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">fusion</span><span class="p">.</span><span class="nf">fuse</span><span class="p">(</span><span class="n">hypotheses</span><span class="p">)</span>
            
            <span class="c1"># Calculate latency
</span>            <span class="n">latency_ms</span> <span class="o">=</span> <span class="p">(</span><span class="n">time</span><span class="p">.</span><span class="nf">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span>
            
            <span class="c1"># Update metrics
</span>            <span class="n">self</span><span class="p">.</span><span class="n">request_count</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">self</span><span class="p">.</span><span class="n">total_latency</span> <span class="o">+=</span> <span class="n">latency_ms</span>
            
            <span class="n">result</span> <span class="o">=</span> <span class="p">{</span>
                <span class="sh">"</span><span class="s">text</span><span class="sh">"</span><span class="p">:</span> <span class="n">fused</span><span class="p">.</span><span class="n">text</span><span class="p">,</span>
                <span class="sh">"</span><span class="s">confidence</span><span class="sh">"</span><span class="p">:</span> <span class="n">fused</span><span class="p">.</span><span class="n">confidence</span><span class="p">,</span>
                <span class="sh">"</span><span class="s">latency_ms</span><span class="sh">"</span><span class="p">:</span> <span class="n">latency_ms</span><span class="p">,</span>
                <span class="sh">"</span><span class="s">models_used</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span><span class="n">h</span><span class="p">.</span><span class="n">model_id</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">hypotheses</span><span class="p">],</span>
                <span class="sh">"</span><span class="s">individual_results</span><span class="sh">"</span><span class="p">:</span> <span class="p">[</span>
                    <span class="p">{</span><span class="sh">"</span><span class="s">model</span><span class="sh">"</span><span class="p">:</span> <span class="n">h</span><span class="p">.</span><span class="n">model_id</span><span class="p">,</span> <span class="sh">"</span><span class="s">text</span><span class="sh">"</span><span class="p">:</span> <span class="n">h</span><span class="p">.</span><span class="n">text</span><span class="p">,</span> <span class="sh">"</span><span class="s">confidence</span><span class="sh">"</span><span class="p">:</span> <span class="n">h</span><span class="p">.</span><span class="n">confidence</span><span class="p">}</span>
                    <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">hypotheses</span>
                <span class="p">],</span>
                <span class="sh">"</span><span class="s">success</span><span class="sh">"</span><span class="p">:</span> <span class="bp">True</span>
            <span class="p">}</span>
            
            <span class="n">self</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="sh">"</span><span class="s">Transcription: </span><span class="sh">'</span><span class="si">{</span><span class="n">fused</span><span class="p">.</span><span class="n">text</span><span class="si">}</span><span class="sh">'</span><span class="s"> </span><span class="sh">"</span>
                <span class="sa">f</span><span class="sh">"</span><span class="s">(confidence: </span><span class="si">{</span><span class="n">fused</span><span class="p">.</span><span class="n">confidence</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">, </span><span class="sh">"</span>
                <span class="sa">f</span><span class="sh">"</span><span class="s">latency: </span><span class="si">{</span><span class="n">latency_ms</span><span class="si">:</span><span class="p">.</span><span class="mi">1</span><span class="n">f</span><span class="si">}</span><span class="s">ms)</span><span class="sh">"</span>
            <span class="p">)</span>
            
            <span class="k">return</span> <span class="n">result</span>
            
        <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="c1"># Fallback: return error
</span>            <span class="n">self</span><span class="p">.</span><span class="n">fallback_count</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">self</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="nf">error</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Ensemble transcription failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
            
            <span class="n">latency_ms</span> <span class="o">=</span> <span class="p">(</span><span class="n">time</span><span class="p">.</span><span class="nf">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span>
            
            <span class="k">return</span> <span class="p">{</span>
                <span class="sh">"</span><span class="s">text</span><span class="sh">"</span><span class="p">:</span> <span class="sh">""</span><span class="p">,</span>
                <span class="sh">"</span><span class="s">confidence</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
                <span class="sh">"</span><span class="s">latency_ms</span><span class="sh">"</span><span class="p">:</span> <span class="n">latency_ms</span><span class="p">,</span>
                <span class="sh">"</span><span class="s">models_used</span><span class="sh">"</span><span class="p">:</span> <span class="p">[],</span>
                <span class="sh">"</span><span class="s">individual_results</span><span class="sh">"</span><span class="p">:</span> <span class="p">[],</span>
                <span class="sh">"</span><span class="s">success</span><span class="sh">"</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
                <span class="sh">"</span><span class="s">error</span><span class="sh">"</span><span class="p">:</span> <span class="nf">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
            <span class="p">}</span>
    
    <span class="k">def</span> <span class="nf">_analyze_audio</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">audio</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">sample_rate</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AudioCharacteristics</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Analyze audio to determine characteristics.
        
        In production: use signal processing to detect:
        - SNR (signal-to-noise ratio)
        - Accent (using acoustic features)
        - Domain (using language model probabilities)
        </span><span class="sh">"""</span>
        <span class="c1"># Calculate duration
</span>        <span class="n">duration_sec</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span> <span class="o">/</span> <span class="n">sample_rate</span>
        
        <span class="c1"># Estimate SNR (simplified)
</span>        <span class="c1"># In production: use proper SNR estimation
</span>        <span class="n">signal_power</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">audio</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">snr_db</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">log10</span><span class="p">(</span><span class="n">signal_power</span> <span class="o">+</span> <span class="mf">1e-10</span><span class="p">)</span> <span class="o">+</span> <span class="mi">30</span>
        
        <span class="k">return</span> <span class="nc">AudioCharacteristics</span><span class="p">(</span>
            <span class="n">snr_db</span><span class="o">=</span><span class="n">snr_db</span><span class="p">,</span>
            <span class="n">duration_sec</span><span class="o">=</span><span class="n">duration_sec</span><span class="p">,</span>
            <span class="n">accent</span><span class="o">=</span><span class="sh">"</span><span class="s">us</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">domain</span><span class="o">=</span><span class="sh">"</span><span class="s">general</span><span class="sh">"</span>
        <span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">get_metrics</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Get performance metrics.</span><span class="sh">"""</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="sh">"</span><span class="s">request_count</span><span class="sh">"</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">request_count</span><span class="p">,</span>
            <span class="sh">"</span><span class="s">avg_latency_ms</span><span class="sh">"</span><span class="p">:</span> <span class="p">(</span>
                <span class="n">self</span><span class="p">.</span><span class="n">total_latency</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">request_count</span>
                <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">request_count</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">0.0</span>
            <span class="p">),</span>
            <span class="sh">"</span><span class="s">fallback_rate</span><span class="sh">"</span><span class="p">:</span> <span class="p">(</span>
                <span class="n">self</span><span class="p">.</span><span class="n">fallback_count</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">request_count</span>
                <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">request_count</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">0.0</span>
            <span class="p">),</span>
            <span class="sh">"</span><span class="s">num_models</span><span class="sh">"</span><span class="p">:</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">models</span><span class="p">)</span>
        <span class="p">}</span>


<span class="c1"># Example usage
</span><span class="k">async</span> <span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="c1"># Create models
</span>    <span class="n">models</span> <span class="o">=</span> <span class="p">[</span>
        <span class="nc">SpeechModel</span><span class="p">(</span>
            <span class="sh">"</span><span class="s">wav2vec2_large</span><span class="sh">"</span><span class="p">,</span> <span class="n">ModelType</span><span class="p">.</span><span class="n">WAV2VEC2</span><span class="p">,</span> <span class="mf">30.0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span>
            <span class="n">best_for_accent</span><span class="o">=</span><span class="sh">"</span><span class="s">us</span><span class="sh">"</span><span class="p">,</span> <span class="n">best_for_noise</span><span class="o">=</span><span class="sh">"</span><span class="s">clean</span><span class="sh">"</span>
        <span class="p">),</span>
        <span class="nc">SpeechModel</span><span class="p">(</span>
            <span class="sh">"</span><span class="s">conformer_base</span><span class="sh">"</span><span class="p">,</span> <span class="n">ModelType</span><span class="p">.</span><span class="n">CONFORMER</span><span class="p">,</span> <span class="mf">25.0</span><span class="p">,</span> <span class="mf">0.048</span><span class="p">,</span>
            <span class="n">best_for_accent</span><span class="o">=</span><span class="sh">"</span><span class="s">general</span><span class="sh">"</span><span class="p">,</span> <span class="n">best_for_noise</span><span class="o">=</span><span class="sh">"</span><span class="s">noisy</span><span class="sh">"</span>
        <span class="p">),</span>
        <span class="nc">SpeechModel</span><span class="p">(</span>
            <span class="sh">"</span><span class="s">whisper_medium</span><span class="sh">"</span><span class="p">,</span> <span class="n">ModelType</span><span class="p">.</span><span class="n">WHISPER</span><span class="p">,</span> <span class="mf">40.0</span><span class="p">,</span> <span class="mf">0.042</span><span class="p">,</span>
            <span class="n">best_for_accent</span><span class="o">=</span><span class="sh">"</span><span class="s">general</span><span class="sh">"</span><span class="p">,</span> <span class="n">best_for_noise</span><span class="o">=</span><span class="sh">"</span><span class="s">clean</span><span class="sh">"</span>
        <span class="p">),</span>
        <span class="nc">SpeechModel</span><span class="p">(</span>
            <span class="sh">"</span><span class="s">rnn_t_streaming</span><span class="sh">"</span><span class="p">,</span> <span class="n">ModelType</span><span class="p">.</span><span class="n">RNN_T</span><span class="p">,</span> <span class="mf">15.0</span><span class="p">,</span> <span class="mf">0.055</span><span class="p">,</span>
            <span class="n">best_for_accent</span><span class="o">=</span><span class="sh">"</span><span class="s">us</span><span class="sh">"</span><span class="p">,</span> <span class="n">best_for_noise</span><span class="o">=</span><span class="sh">"</span><span class="s">very_noisy</span><span class="sh">"</span>
        <span class="p">),</span>
    <span class="p">]</span>
    
    <span class="c1"># Create ensemble
</span>    <span class="n">ensemble</span> <span class="o">=</span> <span class="nc">SpeechEnsemble</span><span class="p">(</span>
        <span class="n">models</span><span class="o">=</span><span class="n">models</span><span class="p">,</span>
        <span class="n">fusion_strategy</span><span class="o">=</span><span class="sh">"</span><span class="s">rover</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">max_models</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">max_latency_ms</span><span class="o">=</span><span class="mf">100.0</span>
    <span class="p">)</span>
    
    <span class="c1"># Generate dummy audio
</span>    <span class="n">audio</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">16000</span> <span class="o">*</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># 3 seconds
</span>    
    <span class="c1"># Transcribe
</span>    <span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">ensemble</span><span class="p">.</span><span class="nf">transcribe</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">sample_rate</span><span class="o">=</span><span class="mi">16000</span><span class="p">)</span>
    
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Result: </span><span class="si">{</span><span class="n">result</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Metrics: </span><span class="si">{</span><span class="n">ensemble</span><span class="p">.</span><span class="nf">get_metrics</span><span class="p">()</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">"</span><span class="s">__main__</span><span class="sh">"</span><span class="p">:</span>
    <span class="n">logging</span><span class="p">.</span><span class="nf">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="p">.</span><span class="n">INFO</span><span class="p">)</span>
    <span class="n">asyncio</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="nf">main</span><span class="p">())</span>
</code></pre></div></div>

<h2 id="production-deployment">Production Deployment</h2>

<h3 id="streaming-asr-ensemble">Streaming ASR Ensemble</h3>

<p>For real-time streaming applications:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">StreamingEnsemble</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Streaming speech ensemble.
    
    Challenges:
    - Models produce output at different rates
    - Need to fuse incrementally
    - Maintain low latency
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">models</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">SpeechModel</span><span class="p">]):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">models</span> <span class="o">=</span> <span class="n">models</span>
        <span class="n">self</span><span class="p">.</span><span class="n">partial_hypotheses</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Word</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{}</span>
    
    <span class="k">async</span> <span class="k">def</span> <span class="nf">process_chunk</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">audio_chunk</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">is_final</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">
        Process audio chunk and return partial/final transcription.
        
        Args:
            audio_chunk: Audio data
            is_final: Whether this is the last chunk
            
        Returns:
            Partial or final transcription
        </span><span class="sh">"""</span>
        <span class="c1"># Send chunk to all models
</span>        <span class="n">tasks</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">model</span><span class="p">.</span><span class="nf">transcribe_chunk</span><span class="p">(</span><span class="n">audio_chunk</span><span class="p">,</span> <span class="n">is_final</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">models</span>
        <span class="p">]</span>
        
        <span class="n">results</span> <span class="o">=</span> <span class="k">await</span> <span class="n">asyncio</span><span class="p">.</span><span class="nf">gather</span><span class="p">(</span><span class="o">*</span><span class="n">tasks</span><span class="p">,</span> <span class="n">return_exceptions</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        
        <span class="c1"># Update partial hypotheses
</span>        <span class="k">for</span> <span class="n">model</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">models</span><span class="p">,</span> <span class="n">results</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="nb">Exception</span><span class="p">):</span>
                <span class="n">self</span><span class="p">.</span><span class="n">partial_hypotheses</span><span class="p">[</span><span class="n">model</span><span class="p">.</span><span class="n">model_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="sh">"</span><span class="s">words</span><span class="sh">"</span><span class="p">]</span>
        
        <span class="c1"># Fuse partial results
</span>        <span class="k">if</span> <span class="n">is_final</span><span class="p">:</span>
            <span class="c1"># Final fusion using ROVER
</span>            <span class="n">hypotheses</span> <span class="o">=</span> <span class="p">[</span>
                <span class="nc">Hypothesis</span><span class="p">(</span><span class="n">words</span><span class="o">=</span><span class="n">words</span><span class="p">,</span> <span class="n">confidence</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">model_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">model_id</span><span class="p">,</span> <span class="n">words</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">partial_hypotheses</span><span class="p">.</span><span class="nf">items</span><span class="p">()</span>
            <span class="p">]</span>
            
            <span class="n">fused</span> <span class="o">=</span> <span class="nc">ROVERFusion</span><span class="p">().</span><span class="nf">fuse</span><span class="p">(</span><span class="n">hypotheses</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">fused</span><span class="p">.</span><span class="n">text</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Quick partial fusion (simple voting)
</span>            <span class="c1"># Return most common partial result
</span>            <span class="n">texts</span> <span class="o">=</span> <span class="p">[</span>
                <span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">w</span><span class="p">.</span><span class="n">text</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">words</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">partial_hypotheses</span><span class="p">.</span><span class="nf">values</span><span class="p">()</span>
            <span class="p">]</span>
            
            <span class="k">if</span> <span class="n">texts</span><span class="p">:</span>
                <span class="c1"># Return most common (mode)
</span>                <span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
                <span class="k">return</span> <span class="nc">Counter</span><span class="p">(</span><span class="n">texts</span><span class="p">).</span><span class="nf">most_common</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            
            <span class="k">return</span> <span class="bp">None</span>
</code></pre></div></div>

<h3 id="kubernetes-deployment">Kubernetes Deployment</h3>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># speech-ensemble-deployment.yaml</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">speech-ensemble</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">3</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">speech-ensemble</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">metadata</span><span class="pi">:</span>
      <span class="na">labels</span><span class="pi">:</span>
        <span class="na">app</span><span class="pi">:</span> <span class="s">speech-ensemble</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">ensemble-server</span>
        <span class="na">image</span><span class="pi">:</span> <span class="s">speech-ensemble:v1.0</span>
        <span class="na">resources</span><span class="pi">:</span>
          <span class="na">requests</span><span class="pi">:</span>
            <span class="na">nvidia.com/gpu</span><span class="pi">:</span> <span class="m">2</span>  <span class="c1"># Need multiple GPUs for models</span>
            <span class="na">cpu</span><span class="pi">:</span> <span class="s2">"</span><span class="s">8"</span>
            <span class="na">memory</span><span class="pi">:</span> <span class="s2">"</span><span class="s">16Gi"</span>
          <span class="na">limits</span><span class="pi">:</span>
            <span class="na">nvidia.com/gpu</span><span class="pi">:</span> <span class="m">2</span>
            <span class="na">cpu</span><span class="pi">:</span> <span class="s2">"</span><span class="s">16"</span>
            <span class="na">memory</span><span class="pi">:</span> <span class="s2">"</span><span class="s">32Gi"</span>
        <span class="na">env</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">FUSION_STRATEGY</span>
          <span class="na">value</span><span class="pi">:</span> <span class="s2">"</span><span class="s">rover"</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">MAX_MODELS</span>
          <span class="na">value</span><span class="pi">:</span> <span class="s2">"</span><span class="s">3"</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">MAX_LATENCY_MS</span>
          <span class="na">value</span><span class="pi">:</span> <span class="s2">"</span><span class="s">150"</span>
        <span class="na">ports</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">containerPort</span><span class="pi">:</span> <span class="m">8080</span>
        <span class="na">livenessProbe</span><span class="pi">:</span>
          <span class="na">httpGet</span><span class="pi">:</span>
            <span class="na">path</span><span class="pi">:</span> <span class="s">/health</span>
            <span class="na">port</span><span class="pi">:</span> <span class="m">8080</span>
          <span class="na">initialDelaySeconds</span><span class="pi">:</span> <span class="m">60</span>
          <span class="na">periodSeconds</span><span class="pi">:</span> <span class="m">10</span>
        <span class="na">readinessProbe</span><span class="pi">:</span>
          <span class="na">httpGet</span><span class="pi">:</span>
            <span class="na">path</span><span class="pi">:</span> <span class="s">/ready</span>
            <span class="na">port</span><span class="pi">:</span> <span class="m">8080</span>
          <span class="na">initialDelaySeconds</span><span class="pi">:</span> <span class="m">30</span>
          <span class="na">periodSeconds</span><span class="pi">:</span> <span class="m">5</span>
<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Service</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">speech-ensemble-service</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">speech-ensemble</span>
  <span class="na">ports</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">protocol</span><span class="pi">:</span> <span class="s">TCP</span>
    <span class="na">port</span><span class="pi">:</span> <span class="m">80</span>
    <span class="na">targetPort</span><span class="pi">:</span> <span class="m">8080</span>
  <span class="na">type</span><span class="pi">:</span> <span class="s">LoadBalancer</span>
</code></pre></div></div>

<h2 id="scaling-strategies">Scaling Strategies</h2>

<h3 id="model-parallelism">Model Parallelism</h3>

<p>Distribute models across multiple GPUs:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch.distributed</span> <span class="k">as</span> <span class="n">dist</span>

<span class="k">class</span> <span class="nc">DistributedEnsemble</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">Distribute models across multiple GPUs/nodes.</span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">models</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">SpeechModel</span><span class="p">],</span> <span class="n">world_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">models</span> <span class="o">=</span> <span class="n">models</span>
        <span class="n">self</span><span class="p">.</span><span class="n">world_size</span> <span class="o">=</span> <span class="n">world_size</span>
        
        <span class="c1"># Assign models to GPUs
</span>        <span class="n">self</span><span class="p">.</span><span class="n">model_assignments</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_assign_models</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">_assign_models</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
        <span class="sh">"""</span><span class="s">Assign models to GPUs for load balancing.</span><span class="sh">"""</span>
        <span class="n">assignments</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">world_size</span><span class="p">)}</span>
        
        <span class="c1"># Sort models by resource requirements
</span>        <span class="n">sorted_models</span> <span class="o">=</span> <span class="nf">sorted</span><span class="p">(</span>
            <span class="n">self</span><span class="p">.</span><span class="n">models</span><span class="p">,</span>
            <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">m</span><span class="p">:</span> <span class="n">m</span><span class="p">.</span><span class="n">gpu_memory_mb</span><span class="p">,</span>
            <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span>
        <span class="p">)</span>
        
        <span class="c1"># Greedy bin packing
</span>        <span class="n">gpu_loads</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">world_size</span>
        
        <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">sorted_models</span><span class="p">:</span>
            <span class="c1"># Assign to least loaded GPU
</span>            <span class="n">min_gpu</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">world_size</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">gpu_loads</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">assignments</span><span class="p">[</span><span class="n">min_gpu</span><span class="p">].</span><span class="nf">append</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">model_id</span><span class="p">)</span>
            <span class="n">gpu_loads</span><span class="p">[</span><span class="n">min_gpu</span><span class="p">]</span> <span class="o">+=</span> <span class="n">model</span><span class="p">.</span><span class="n">gpu_memory_mb</span>
        
        <span class="k">return</span> <span class="n">assignments</span>
</code></pre></div></div>

<h2 id="real-world-case-study-google-voice-search">Real-World Case Study: Google Voice Search</h2>

<h3 id="googles-multi-model-approach">Google’s Multi-Model Approach</h3>

<p>Google uses sophisticated multi-model ensembles for Voice Search:</p>

<p><strong>Architecture:</strong></p>
<ol>
  <li><strong>Multiple acoustic models:</strong>
    <ul>
      <li>Conformer (primary)</li>
      <li>RNN-T (streaming)</li>
      <li>Listen-Attend-Spell (rescoring)</li>
    </ul>
  </li>
  <li><strong>Ensemble strategy:</strong>
    <ul>
      <li>Parallel inference on all models</li>
      <li>ROVER-style fusion with learned weights</li>
      <li>Context-aware selection (device, environment)</li>
    </ul>
  </li>
  <li><strong>Dynamic optimization:</strong>
    <ul>
      <li>On-device: single fast model</li>
      <li>Server-side: full ensemble (5-10 models)</li>
      <li>Hybrid: progressive enhancement</li>
    </ul>
  </li>
  <li><strong>Specialized models:</strong>
    <ul>
      <li>Accent-specific models (US, UK, Indian, etc.)</li>
      <li>Noise-specific (clean, car, crowd)</li>
      <li>Domain-specific (voice commands, dictation)</li>
    </ul>
  </li>
</ol>

<p><strong>Results:</strong></p>
<ul>
  <li><strong>WER: 2.5%</strong> (vs 4.9% single model)</li>
  <li><strong>Latency: 120ms</strong> p95 (server-side)</li>
  <li><strong>Languages: 100+</strong> supported</li>
  <li><strong>Robustness:</strong> &lt;0.5% failure rate</li>
</ul>

<h3 id="key-lessons">Key Lessons</h3>

<ol>
  <li><strong>Specialization matters:</strong> Models trained for specific conditions outperform general models</li>
  <li><strong>Dynamic selection critical:</strong> Choose models based on input characteristics</li>
  <li><strong>ROVER is standard:</strong> Industry standard for ASR fusion</li>
  <li><strong>Streaming requires adaptation:</strong> Can’t wait for all models in real-time</li>
  <li><strong>Diminishing returns:</strong> 3-5 diverse models capture most of the benefit</li>
</ol>

<h2 id="cost-analysis">Cost Analysis</h2>

<h3 id="cost-breakdown-100k-utterancesday">Cost Breakdown (100K utterances/day)</h3>

<table>
  <thead>
    <tr>
      <th>Component</th>
      <th>Single Model</th>
      <th>Ensemble (3 models)</th>
      <th>Cost/Benefit</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Compute (GPU)</strong></td>
      <td>$50/day</td>
      <td>$150/day</td>
      <td>+$100/day</td>
    </tr>
    <tr>
      <td><strong>Latency (p95)</strong></td>
      <td>30ms</td>
      <td>100ms</td>
      <td>+70ms</td>
    </tr>
    <tr>
      <td><strong>WER</strong></td>
      <td>5.0%</td>
      <td>3.2%</td>
      <td>-1.8%</td>
    </tr>
    <tr>
      <td><strong>User satisfaction</strong></td>
      <td>80%</td>
      <td>92%</td>
      <td>+12%</td>
    </tr>
  </tbody>
</table>

<p><strong>Value calculation:</strong></p>
<ul>
  <li>WER reduction: 5.0% → 3.2% (36% relative improvement)</li>
  <li>Cost per utterance: $0.0015 (single) → $0.0015 (ensemble, amortized)</li>
  <li>User satisfaction increase: worth ~$5-10 per satisfied user</li>
  <li><strong>Net benefit:</strong> Higher quality justifies cost</li>
</ul>

<h3 id="optimization-strategies">Optimization Strategies</h3>

<ol>
  <li><strong>Hybrid deployment:</strong>
    <ul>
      <li>Simple queries: single fast model</li>
      <li>Complex queries: full ensemble</li>
      <li>Savings: 60%</li>
    </ul>
  </li>
  <li><strong>Model pruning:</strong>
    <ul>
      <li>Remove least-contributing models</li>
      <li>3 models often enough (vs 5-10)</li>
      <li>Savings: 40%</li>
    </ul>
  </li>
  <li><strong>Cached predictions:</strong>
    <ul>
      <li>Common queries cached</li>
      <li>Hit rate: 20-30%</li>
      <li>Savings: 25%</li>
    </ul>
  </li>
  <li><strong>Progressive enhancement:</strong>
    <ul>
      <li>Start with fast model</li>
      <li>Add models if confidence low</li>
      <li>Savings: 50%</li>
    </ul>
  </li>
</ol>

<h2 id="key-takeaways">Key Takeaways</h2>

<p>✅ <strong>Speech ensembles reduce WER by 30-50%</strong> over single best model</p>

<p>✅ <strong>ROVER is the gold standard</strong> for ASR output fusion</p>

<p>✅ <strong>Model diversity is critical</strong> - different architectures, training data</p>

<p>✅ <strong>Dynamic model selection</strong> based on audio characteristics improves efficiency</p>

<p>✅ <strong>Backtracking explores model combinations</strong> to find optimal subset</p>

<p>✅ <strong>Specialization beats generalization</strong> - accent/noise/domain-specific models</p>

<p>✅ <strong>Parallel inference is essential</strong> for managing latency</p>

<p>✅ <strong>Streaming requires different approach</strong> - incremental fusion</p>

<p>✅ <strong>3-5 diverse models capture most benefit</strong> - diminishing returns after</p>

<p>✅ <strong>Same pattern as DSA and ML</strong> - explore combinations with constraints</p>

<h3 id="connection-to-thematic-link-backtracking-and-combination-strategies">Connection to Thematic Link: Backtracking and Combination Strategies</h3>

<p>All three topics converge on the same core algorithm:</p>

<p><strong>DSA (Generate Parentheses):</strong></p>
<ul>
  <li>Backtrack to generate all valid parentheses strings</li>
  <li>Constraints: balanced, n pairs</li>
  <li>Prune: close_count &gt; open_count</li>
  <li>Result: all valid combinations</li>
</ul>

<p><strong>ML System Design (Model Ensembling):</strong></p>
<ul>
  <li>Backtrack to explore model combinations</li>
  <li>Constraints: latency, diversity, accuracy</li>
  <li>Prune: violates SLA or budget</li>
  <li>Result: optimal ensemble configuration</li>
</ul>

<p><strong>Speech Tech (Multi-model Speech Ensemble):</strong></p>
<ul>
  <li>Backtrack to select ASR model subset</li>
  <li>Constraints: latency, WER, specialization match</li>
  <li>Prune: slow or redundant models</li>
  <li>Result: optimal speech model combination</li>
</ul>

<h3 id="universal-pattern">Universal Pattern</h3>

<p><strong>Backtracking for Constrained Combination Generation:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1. Start with empty selection
2. Try adding each candidate
3. Check constraints (validity, resources, quality)
4. If valid: recurse to explore further
5. If invalid: prune (backtrack)
6. Return best combination found
</code></pre></div></div>

<p>This pattern applies to:</p>
<ul>
  <li>String generation (parentheses)</li>
  <li>Model selection (ensembles)</li>
  <li>Resource allocation</li>
  <li>Feature selection</li>
  <li>Configuration generation</li>
  <li>Path finding</li>
  <li>Scheduling</li>
</ul>

<p><strong>Why it works:</strong></p>
<ul>
  <li>Systematic exploration of search space</li>
  <li>Early pruning reduces computation</li>
  <li>Guarantees finding optimal solution (if exists)</li>
  <li>Easy to implement and reason about</li>
  <li>Scales to large search spaces with good pruning</li>
</ul>

<hr />

<p><strong>Originally published at:</strong> <a href="https://www.arunbaby.com/speech-tech/0014-multi-model-speech-ensemble/">arunbaby.com/speech-tech/0014-multi-model-speech-ensemble</a></p>

<p><em>If you found this helpful, consider sharing it with others who might benefit.</em></p>


        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#asr" class="page__taxonomy-item p-category" rel="tag">asr</a><span class="sep">, </span>
    
      <a href="/tags/#ensemble-learning" class="page__taxonomy-item p-category" rel="tag">ensemble-learning</a><span class="sep">, </span>
    
      <a href="/tags/#model-fusion" class="page__taxonomy-item p-category" rel="tag">model-fusion</a><span class="sep">, </span>
    
      <a href="/tags/#multi-model" class="page__taxonomy-item p-category" rel="tag">multi-model</a><span class="sep">, </span>
    
      <a href="/tags/#rover" class="page__taxonomy-item p-category" rel="tag">rover</a><span class="sep">, </span>
    
      <a href="/tags/#speech-recognition" class="page__taxonomy-item p-category" rel="tag">speech-recognition</a><span class="sep">, </span>
    
      <a href="/tags/#voting" class="page__taxonomy-item p-category" rel="tag">voting</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#speech-tech" class="page__taxonomy-item p-category" rel="tag">speech-tech</a>
    
    </span>
  </p>


        
      </footer>

      <div class="page__related page__related--full">
  <h2 class="page__related-title">Related across topics</h2>
  <style>
    /* Make section span full content width and use 2 equal columns */
    .page__related--full { float: inline-start; width: 100%; padding: 0; }
    .cross-related-grid { display: grid; grid-template-columns: repeat(2, minmax(0, 1fr)); gap: 2rem; }
    @media (max-width: 768px) { .cross-related-grid { grid-template-columns: 1fr; } }
    /* Ensure archive cards stretch nicely in the grid */
    .cross-related-grid .list__item, .cross-related-grid .grid__item { width: auto; float: none; margin: 0; }
  </style>
  <div class="cross-related-grid">
    



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/dsa/0014-generate-parentheses/" rel="permalink">Generate Parentheses
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          24 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Master backtracking to generate all valid combinations—the foundation of ensemble model selection and multi-model systems.
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ml-system-design/0014-model-ensembling/" rel="permalink">Model Ensembling
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          25 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Build production ensemble systems that combine multiple models using backtracking strategies to explore optimal combinations.
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/speech-tech/0014-multi-model-speech-ensemble/" rel="permalink">Multi-model Speech Ensemble
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          23 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Build production speech systems that combine multiple ASR/TTS models using backtracking-based selection strategies to achieve state-of-the-art accuracy.
</p>
  </article>
</div>

  </div>
</div>

      <section class="page__share">
  <h4 class="page__share-title">Share on</h4>

  <a href="https://twitter.com/intent/tweet?via=arunbaby0&text=Multi-model+Speech+Ensemble%20https%3A%2F%2Fwww.arunbaby.com%2Fspeech-tech%2F0014-multi-model-speech-ensemble%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.arunbaby.com%2Fspeech-tech%2F0014-multi-model-speech-ensemble%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.arunbaby.com/speech-tech/0014-multi-model-speech-ensemble/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/speech-tech/0013-compute-allocation-for-speech-models/" class="pagination--pager" title="Compute Allocation for Speech Models">Previous</a>
    
    
      <a href="#" class="pagination--pager disabled">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 1990 - 2143 <a href="https://www.arunbaby.com">Arun Baby</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JRJPEC9SS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0JRJPEC9SS', { 'anonymize_ip': false});
</script>








  </body>
</html>
