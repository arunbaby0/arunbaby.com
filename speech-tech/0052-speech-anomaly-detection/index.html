<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Speech Anomaly Detection - Arun Baby</title>
<meta name="description" content="“If ASR is the brain, anomaly detection is the nervous system—it tells you when the audio reality changed.”">


  <meta name="author" content="Arun Baby">
  
  <meta property="article:author" content="Arun Baby">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Arun Baby">
<meta property="og:title" content="Speech Anomaly Detection">
<meta property="og:url" content="https://www.arunbaby.com/speech-tech/0052-speech-anomaly-detection/">


  <meta property="og:description" content="“If ASR is the brain, anomaly detection is the nervous system—it tells you when the audio reality changed.”">



  <meta property="og:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">



  <meta name="twitter:site" content="@arunbaby0">
  <meta name="twitter:title" content="Speech Anomaly Detection">
  <meta name="twitter:description" content="“If ASR is the brain, anomaly detection is the nervous system—it tells you when the audio reality changed.”">
  <meta name="twitter:url" content="https://www.arunbaby.com/speech-tech/0052-speech-anomaly-detection/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">
    
  

  



  <meta property="article:published_time" content="2025-12-29T13:14:56+05:30">





  

  


<link rel="canonical" href="https://www.arunbaby.com/speech-tech/0052-speech-anomaly-detection/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Baby Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          <span class="site-subtitle">Arun Baby</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/dsa/"
                
                
              >DSA</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ml-system-design/"
                
                
              >ML Systems</a>
            </li><li class="masthead__menu-item">
              <a
                href="/speech-tech/"
                
                
              >Speech Tech</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ai-agents/"
                
                
              >AI Agents</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li><li class="masthead__menu-item">
              <a
                href="/statuses/"
                
                
              >Statuses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/contact/"
                
                
              >Contact</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main" class="no-author-sidebar">
  
  <div class="sidebar sticky">
  
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Speech Anomaly Detection">
    <meta itemprop="description" content="“If ASR is the brain, anomaly detection is the nervous system—it tells you when the audio reality changed.”">
    <meta itemprop="datePublished" content="2025-12-29T13:14:56+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://www.arunbaby.com/speech-tech/0052-speech-anomaly-detection/" itemprop="url">Speech Anomaly Detection
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          19 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#1-problem-statement">1. Problem Statement</a></li><li><a href="#2-fundamentals-what-is-an-anomaly-in-speech">2. Fundamentals (What is an “Anomaly” in Speech?)</a><ul><li><a href="#21-categories-of-anomalies">2.1 Categories of anomalies</a></li><li><a href="#22-threat-model-what-you-can-and-cant-observe">2.2 Threat model: what you can and can’t observe</a></li><li><a href="#23-the-normal-baseline-is-not-universal">2.3 The “normal” baseline is not universal</a></li><li><a href="#24-what-good-looks-like-the-reliability-slos">2.4 What “good” looks like (the reliability SLOs)</a></li><li><a href="#25-boundary-invariants-for-speech-what-to-monitor-first">2.5 Boundary invariants for speech (what to monitor first)</a></li></ul></li><li><a href="#3-architecture-end-to-end-reliability-system">3. Architecture (End-to-End Reliability System)</a><ul><li><a href="#31-high-level-diagram">3.1 High-level diagram</a></li><li><a href="#32-key-design-principle">3.2 Key design principle</a></li></ul></li><li><a href="#4-model-selection-detectors-for-speech">4. Model Selection (Detectors for Speech)</a><ul><li><a href="#41-rules-fast-robust-interpretable">4.1 Rules (fast, robust, interpretable)</a></li><li><a href="#42-statistical-detectors">4.2 Statistical detectors</a></li><li><a href="#43-ml-detectors-used-selectively">4.3 ML detectors (used selectively)</a></li><li><a href="#44-a-practical-detector-stack-what-most-teams-ship">4.4 A practical detector stack (what most teams ship)</a></li></ul></li><li><a href="#5-implementation-python-examples">5. Implementation (Python Examples)</a><ul><li><a href="#51-basic-signal-quality-features">5.1 Basic signal quality features</a></li><li><a href="#52-a-simple-rule-based-detector">5.2 A simple rule-based detector</a></li><li><a href="#53-distribution-shift-detector-histogram-distance">5.3 Distribution shift detector (histogram distance)</a></li><li><a href="#54-feature-extraction-notes-what-to-compute-in-real-systems">5.4 Feature extraction notes (what to compute in real systems)</a></li></ul></li><li><a href="#6-training-considerations">6. Training Considerations</a><ul><li><a href="#61-labels-are-hard-what-is-anomalous">6.1 Labels are hard (what is “anomalous”?)</a></li><li><a href="#62-segment-aware-baselines">6.2 Segment-aware baselines</a></li><li><a href="#63-evaluation-strategy-how-you-know-youre-helping">6.3 Evaluation strategy (how you know you’re helping)</a></li><li><a href="#64-privacy-safe-debugging-loop">6.4 Privacy-safe debugging loop</a></li></ul></li><li><a href="#7-production-deployment">7. Production Deployment</a><ul><li><a href="#71-on-device-vs-server">7.1 On-device vs server</a></li><li><a href="#72-attribution-turning-audio-is-bad-into-this-rollout-is-bad">7.2 Attribution: turning “audio is bad” into “this rollout is bad”</a></li><li><a href="#73-mitigation-strategies">7.3 Mitigation strategies</a></li><li><a href="#74-mitigation-safety-dont-auto-fix-yourself-into-a-worse-state">7.4 Mitigation safety: don’t auto-fix yourself into a worse state</a></li></ul></li><li><a href="#8-streaming--real-time-considerations">8. Streaming / Real-time Considerations</a><ul><li><a href="#81-jitter-buffers-and-audio-holes">8.1 Jitter buffers and “audio holes”</a></li><li><a href="#82-real-time-detector-design-dont-block-the-audio-path">8.2 Real-time detector design (don’t block the audio path)</a></li></ul></li><li><a href="#9-quality-metrics">9. Quality Metrics</a><ul><li><a href="#91-speech-specific-diagnostic-metrics-high-signal">9.1 Speech-specific diagnostic metrics (high signal)</a></li></ul></li><li><a href="#10-common-failure-modes-and-debugging">10. Common Failure Modes (and Debugging)</a><ul><li><a href="#101-false-positives-from-normal-variability">10.1 False positives from normal variability</a></li><li><a href="#102-privacy-limited-debugging">10.2 Privacy-limited debugging</a></li><li><a href="#103-confusing-model-issues-with-audio-pipeline-issues">10.3 Confusing model issues with audio pipeline issues</a></li><li><a href="#104-debugging-playbook-what-you-do-during-an-incident">10.4 Debugging playbook (what you do during an incident)</a></li><li><a href="#105-a-realistic-failure-story-sample-rate-mismatch">10.5 A realistic failure story: sample rate mismatch</a></li></ul></li><li><a href="#11-state-of-the-art">11. State-of-the-Art</a><ul><li><a href="#111-toward-closed-loop-speech-reliability">11.1 Toward “closed-loop” speech reliability</a></li></ul></li><li><a href="#12-key-takeaways">12. Key Takeaways</a><ul><li><a href="#121-a-simple-starter-checklist">12.1 A simple “starter checklist”</a></li><li><a href="#122-appendix-anomaly-catalog-quick-mapping-from-symptom--suspect">12.2 Appendix: anomaly catalog (quick mapping from symptom → suspect)</a></li><li><a href="#123-appendix-what-telemetry-to-keep-privacy-safe-and-still-useful">12.3 Appendix: what telemetry to keep privacy-safe (and still useful)</a></li><li><a href="#124-appendix-how-this-connects-to-the-broader-anomaly-detection-system">12.4 Appendix: how this connects to the broader “anomaly detection” system</a></li><li><a href="#125-appendix-synthetic-corruption-recipes-for-reliable-evaluation">12.5 Appendix: synthetic corruption recipes (for reliable evaluation)</a></li><li><a href="#126-appendix-on-device-vs-server-trade-offs-what-to-decide-explicitly">12.6 Appendix: on-device vs server trade-offs (what to decide explicitly)</a></li><li><a href="#127-appendix-an-incident-response-checklist-speech-edition">12.7 Appendix: an incident response checklist (speech edition)</a></li><li><a href="#128-appendix-what-to-page-on-avoiding-alert-fatigue">12.8 Appendix: what to page on (avoiding alert fatigue)</a></li><li><a href="#129-appendix-cardinality-discipline-for-speech-telemetry">12.9 Appendix: cardinality discipline for speech telemetry</a></li><li><a href="#1210-appendix-a-minimal-speech-reliability-dashboard">12.10 Appendix: a minimal “speech reliability dashboard”</a></li></ul></li></ul>
            </nav>
          </aside>
        
        <p><strong>“If ASR is the brain, anomaly detection is the nervous system—it tells you when the audio reality changed.”</strong></p>

<h2 id="1-problem-statement">1. Problem Statement</h2>

<p>Speech systems degrade for many reasons that have nothing to do with the model weights:</p>
<ul>
  <li>microphone changes and device heterogeneity</li>
  <li>network jitter in streaming</li>
  <li>audio clipping and saturation</li>
  <li>background noise shifts (construction, cafe, car)</li>
  <li>codec/transcoding bugs</li>
  <li>silent dropouts (0-valued frames)</li>
  <li>data pipeline regressions (wrong sample rate, channel swap)</li>
</ul>

<p>If you don’t detect these anomalies early, they show up as:</p>
<ul>
  <li>higher WER</li>
  <li>worse intent accuracy</li>
  <li>user frustration (“it stopped understanding me”)</li>
  <li>expensive incidents that look like “model regressions” but are actually audio/system failures</li>
</ul>

<p>Goal: design a <strong>speech anomaly detection system</strong> that:</p>
<ul>
  <li>works for streaming and batch speech</li>
  <li>runs in real time (or near real time)</li>
  <li>attributes root causes (device, region, codec, environment)</li>
  <li>supports mitigation (fallback codecs, threshold changes, routing)</li>
</ul>

<p>Thematic link: <strong>pattern recognition</strong>.
Like “Trapping Rain Water”, the best detectors rely on stable boundary invariants (energy, SNR, clipping rate) and trigger when those boundaries are violated.</p>

<hr />

<h2 id="2-fundamentals-what-is-an-anomaly-in-speech">2. Fundamentals (What is an “Anomaly” in Speech?)</h2>

<h3 id="21-categories-of-anomalies">2.1 Categories of anomalies</h3>

<ol>
  <li><strong>Signal-level anomalies</strong>
    <ul>
      <li>silence where there shouldn’t be</li>
      <li>extreme loudness or clipping</li>
      <li>DC offset, hum</li>
      <li>sample rate mismatches</li>
    </ul>
  </li>
  <li><strong>Feature-level anomalies</strong>
    <ul>
      <li>mel spectrogram distributions shift</li>
      <li>pitch/voicing patterns abnormal</li>
      <li>embeddings drift (speaker or acoustic embeddings)</li>
    </ul>
  </li>
  <li><strong>Model-level anomalies</strong>
    <ul>
      <li>confidence collapses</li>
      <li>beam search produces garbage tokens</li>
      <li>decoder emits repeated characters (“aaaaa”)</li>
    </ul>
  </li>
  <li><strong>System-level anomalies</strong>
    <ul>
      <li>packet loss/jitter affects streaming</li>
      <li>CPU throttling causes dropped frames</li>
      <li>codec bugs introduce artifacts</li>
    </ul>
  </li>
</ol>

<h3 id="22-threat-model-what-you-can-and-cant-observe">2.2 Threat model: what you can and can’t observe</h3>

<p>In many production systems:</p>
<ul>
  <li>you cannot ship raw audio to the server by default (privacy)</li>
  <li>you can ship aggregated metrics and privacy-safe features</li>
</ul>

<p>So the design must support:</p>
<ul>
  <li>on-device detection for sensitive signals</li>
  <li>federated analytics / aggregated telemetry for monitoring at scale</li>
</ul>

<h3 id="23-the-normal-baseline-is-not-universal">2.3 The “normal” baseline is not universal</h3>

<p>Speech is inherently heterogeneous:</p>
<ul>
  <li>two phones from the same manufacturer can have different mic characteristics</li>
  <li>Bluetooth headsets introduce codec artifacts and latency</li>
  <li>far-field microphones behave differently from near-field</li>
  <li>background noise is highly contextual (car, office, street)</li>
</ul>

<p>So anomaly detection must be <strong>segment-aware</strong>. Common segmentation axes:</p>
<ul>
  <li>device model / OS version</li>
  <li>input route (built-in mic vs wired vs Bluetooth)</li>
  <li>locale / language</li>
  <li>environment proxy (SNR bucket, VAD speech fraction)</li>
  <li>network type (Wi‑Fi vs cellular) for streaming</li>
</ul>

<p>If you ignore segmentation, you’ll:</p>
<ul>
  <li>over-alert on low-end devices (false positives)</li>
  <li>miss regressions that only affect a subset (false negatives)</li>
</ul>

<h3 id="24-what-good-looks-like-the-reliability-slos">2.4 What “good” looks like (the reliability SLOs)</h3>

<p>Speech anomaly detection is typically in service of product-level reliability goals:</p>
<ul>
  <li>keep WER (or command success) stable over time</li>
  <li>detect and mitigate audio pipeline regressions within minutes/hours</li>
  <li>reduce incident MTTR by attributing to root cause segments</li>
</ul>

<p>Concrete reliability metrics teams often adopt:</p>
<ul>
  <li><strong>p95 time-to-detect</strong> for fleet regressions (minutes)</li>
  <li><strong>false positive rate</strong> for paging alerts (very low)</li>
  <li><strong>coverage</strong>: percent of traffic where anomaly signals are available (telemetry completeness)</li>
</ul>

<h3 id="25-boundary-invariants-for-speech-what-to-monitor-first">2.5 Boundary invariants for speech (what to monitor first)</h3>

<p>The highest-signal “boundary” metrics that catch many failures:</p>
<ul>
  <li><strong>RMS energy</strong> distribution (silence vs too loud)</li>
  <li><strong>clipping rate</strong> (saturation)</li>
  <li><strong>zero fraction</strong> (dropouts)</li>
  <li><strong>sample rate / frame rate</strong> correctness</li>
  <li><strong>VAD speech fraction</strong> (sudden shifts can indicate frontend bugs)</li>
  <li><strong>ASR confidence</strong> distributions (silent model or pipeline failures)</li>
</ul>

<p>These are the speech equivalent of maintaining <code class="language-plaintext highlighter-rouge">left_max</code> and <code class="language-plaintext highlighter-rouge">right_max</code>:
small, stable summaries that let you detect large classes of failures early.</p>

<hr />

<h2 id="3-architecture-end-to-end-reliability-system">3. Architecture (End-to-End Reliability System)</h2>

<h3 id="31-high-level-diagram">3.1 High-level diagram</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   Device / Client (streaming audio)
        |
        |  (frames)
        v
  +-------------------+
  | Audio Frontend    |  -&gt; resample, AGC, VAD
  +---------+---------+
            |
            v
  +-------------------+      +-------------------+
  | Feature Extractor | ---&gt; | Local Detectors   |
  | (mel, energy, etc)|      | (fast rules + ML) |
  +---------+---------+      +---------+---------+
            |                          |
            | aggregated telemetry     | local actions
            v                          v
  +-------------------+       +-------------------+
  | Telemetry Uploader|       | Mitigation Layer  |
  | (privacy-safe)    |       | (fallbacks)       |
  +---------+---------+       +-------------------+
            |
            v
  +-------------------+       +-------------------+
  | Streaming Backend | ----&gt; | Server Detectors  |
  | (Kafka/Flink)     |       | (fleet signals)   |
  +---------+---------+       +---------+---------+
            |                          |
            v                          v
  +-------------------+       +-------------------+
  | Dashboards/TSDB   |       | Alerting + RCA    |
  +-------------------+       +-------------------+
</code></pre></div></div>

<h3 id="32-key-design-principle">3.2 Key design principle</h3>

<p>Speech anomalies are best handled as a layered system:</p>
<ul>
  <li><strong>local</strong> (device) for fast detection + privacy-sensitive signals</li>
  <li><strong>fleet</strong> (server) for aggregate monitoring and attribution</li>
</ul>

<hr />

<h2 id="4-model-selection-detectors-for-speech">4. Model Selection (Detectors for Speech)</h2>

<h3 id="41-rules-fast-robust-interpretable">4.1 Rules (fast, robust, interpretable)</h3>

<p>Examples:</p>
<ul>
  <li>RMS energy too low for too long (unexpected silence)</li>
  <li>clipping rate &gt; threshold</li>
  <li>sample rate mismatch detection</li>
  <li>VAD says “speech present” but amplitude ~0 (dropout)</li>
</ul>

<p>Rules catch common production failures cheaply.</p>

<h3 id="42-statistical-detectors">4.2 Statistical detectors</h3>

<ul>
  <li>robust z-score on energy or SNR</li>
  <li>EWMA change detection on confidence</li>
  <li>histogram distance on mel distributions</li>
</ul>

<p>Statistical detectors are a strong default because they’re explainable.</p>

<h3 id="43-ml-detectors-used-selectively">4.3 ML detectors (used selectively)</h3>

<p>Use ML when patterns are complex:</p>
<ul>
  <li>autoencoder reconstruction error on mel patches</li>
  <li>Isolation Forest on feature vectors (energy, zero-crossing, spectral centroid)</li>
  <li>embedding drift detection (acoustic embeddings)</li>
</ul>

<p>Production caution:
ML detectors can be fragile to distribution shift; use them behind guardrails and with strong evaluation.</p>

<h3 id="44-a-practical-detector-stack-what-most-teams-ship">4.4 A practical detector stack (what most teams ship)</h3>

<p>In production, a common “good enough” detector stack looks like:</p>

<ol>
  <li><strong>Frontend sanity checks</strong>
    <ul>
      <li>sample rate correctness</li>
      <li>channel count checks (mono vs stereo)</li>
      <li>frame rate / buffering health</li>
    </ul>
  </li>
  <li><strong>Signal-level rules</strong>
    <ul>
      <li>RMS energy too low/high</li>
      <li>clipping rate</li>
      <li>zero fraction / dropout detection</li>
    </ul>
  </li>
  <li><strong>Feature-level statistics</strong>
    <ul>
      <li>mel band energy histograms vs baseline</li>
      <li>SNR bucket shifts</li>
      <li>VAD speech fraction shifts</li>
    </ul>
  </li>
  <li><strong>Model-level health</strong>
    <ul>
      <li>confidence distribution shift</li>
      <li>repeated token loops</li>
      <li>“no speech detected” spikes</li>
    </ul>
  </li>
  <li><strong>Selective ML</strong>
    <ul>
      <li>only after the above indicates subtle drift (slow distortion, creeping artifacts)</li>
    </ul>
  </li>
</ol>

<p>This layering keeps compute low and explanations clear, which is what you want during incidents.</p>

<hr />

<h2 id="5-implementation-python-examples">5. Implementation (Python Examples)</h2>

<p>Below are “building blocks” that you can run on audio frames (or short windows).</p>

<h3 id="51-basic-signal-quality-features">5.1 Basic signal quality features</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>


<span class="k">def</span> <span class="nf">rms</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="k">return</span> <span class="nf">float</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-12</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">clipping_rate</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">clip_value</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.99</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="k">return</span> <span class="nf">float</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">clip_value</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">zero_fraction</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="k">return</span> <span class="nf">float</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">eps</span><span class="p">))</span>
</code></pre></div></div>

<p>Interpretation:</p>
<ul>
  <li>high <code class="language-plaintext highlighter-rouge">clipping_rate</code> indicates saturation</li>
  <li>high <code class="language-plaintext highlighter-rouge">zero_fraction</code> can indicate dropouts or muted mic</li>
</ul>

<h3 id="52-a-simple-rule-based-detector">5.2 A simple rule-based detector</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>


<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">SpeechAnomaly</span><span class="p">:</span>
    <span class="n">is_anomaly</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="n">reason</span><span class="p">:</span> <span class="nb">str</span>


<span class="k">def</span> <span class="nf">detect_signal_anomaly</span><span class="p">(</span><span class="n">frame</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SpeechAnomaly</span><span class="p">:</span>
    <span class="n">r</span> <span class="o">=</span> <span class="nf">rms</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>
    <span class="n">c</span> <span class="o">=</span> <span class="nf">clipping_rate</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="nf">zero_fraction</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>

    <span class="c1"># Tune thresholds per product/device segment.
</span>    <span class="k">if</span> <span class="n">z</span> <span class="o">&gt;</span> <span class="mf">0.95</span><span class="p">:</span>
        <span class="k">return</span> <span class="nc">SpeechAnomaly</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span> <span class="sh">"</span><span class="s">dropout_or_muted</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">c</span> <span class="o">&gt;</span> <span class="mf">0.02</span><span class="p">:</span>
        <span class="k">return</span> <span class="nc">SpeechAnomaly</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span> <span class="sh">"</span><span class="s">clipping</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">r</span> <span class="o">&lt;</span> <span class="mf">1e-3</span><span class="p">:</span>
        <span class="k">return</span> <span class="nc">SpeechAnomaly</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span> <span class="sh">"</span><span class="s">unexpected_silence</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="nc">SpeechAnomaly</span><span class="p">(</span><span class="bp">False</span><span class="p">,</span> <span class="sh">"</span><span class="s">ok</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="53-distribution-shift-detector-histogram-distance">5.3 Distribution shift detector (histogram distance)</h3>

<p>For fleet monitoring, you can compare feature histograms over time windows.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">l1_hist_distance</span><span class="p">(</span><span class="n">h1</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">h2</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="n">h1</span> <span class="o">=</span> <span class="n">h1</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">h1</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-9</span><span class="p">)</span>
    <span class="n">h2</span> <span class="o">=</span> <span class="n">h2</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">h2</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-9</span><span class="p">)</span>
    <span class="k">return</span> <span class="nf">float</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">h1</span> <span class="o">-</span> <span class="n">h2</span><span class="p">)))</span>
</code></pre></div></div>

<p>This works well for:</p>
<ul>
  <li>mel energy band histograms</li>
  <li>confidence histograms</li>
  <li>VAD speech/non-speech ratios</li>
</ul>

<h3 id="54-feature-extraction-notes-what-to-compute-in-real-systems">5.4 Feature extraction notes (what to compute in real systems)</h3>

<p>If you can compute only a few things, prioritize features that are:</p>
<ul>
  <li>cheap</li>
  <li>stable across devices (after normalization)</li>
  <li>strongly correlated with real failures</li>
</ul>

<p>High-signal features:</p>
<ul>
  <li><strong>log-mel spectrogram summaries</strong>: band-wise energy statistics (mean/median/percentiles)</li>
  <li><strong>spectral centroid / rolloff</strong>: detects “thin” or band-limited audio vs normal speech</li>
  <li><strong>spectral flatness</strong>: distinguishes tonal speech from noisy/flat signals</li>
  <li><strong>pitch / voicing probability</strong> distributions: catches weird frontend effects and noise shifts</li>
  <li><strong>frame drop rate</strong> and jitter stats: catches transport issues in streaming</li>
</ul>

<p>Important: you usually don’t need to upload raw features.
You can upload aggregated histograms per time window, which preserves privacy and reduces bandwidth.</p>

<hr />

<h2 id="6-training-considerations">6. Training Considerations</h2>

<h3 id="61-labels-are-hard-what-is-anomalous">6.1 Labels are hard (what is “anomalous”?)</h3>

<p>Unlike supervised ASR, anomalies often lack clean labels.
Common strategies:</p>
<ul>
  <li>weak labeling from incident logs (“codec bug rollout window”)</li>
  <li>synthetic corruption (add clipping, drop frames, resample wrong)</li>
  <li>human review on opt-in debug samples (with consent)</li>
</ul>

<h3 id="62-segment-aware-baselines">6.2 Segment-aware baselines</h3>

<p>Speech baselines vary by:</p>
<ul>
  <li>device microphone quality</li>
  <li>locale/accent</li>
  <li>environment</li>
  <li>network conditions (for streaming)</li>
</ul>

<p>So detection must be segment-aware, otherwise you:</p>
<ul>
  <li>over-alert for low-end devices</li>
  <li>miss regressions in high-end devices</li>
</ul>

<h3 id="63-evaluation-strategy-how-you-know-youre-helping">6.3 Evaluation strategy (how you know you’re helping)</h3>

<p>Anomaly detection has messy labels, so evaluate with multiple lenses:</p>

<ul>
  <li><strong>Incident replay</strong>
    <ul>
      <li>replay historical telemetry</li>
      <li>check if detectors would have fired on known incidents</li>
    </ul>
  </li>
  <li><strong>Synthetic corruptions</strong>
    <ul>
      <li>inject clipping, dropouts, resampling errors, packet loss</li>
      <li>validate detection delay and severity mapping</li>
    </ul>
  </li>
  <li><strong>Controlled rollouts</strong>
    <ul>
      <li>roll out detector configs gradually</li>
      <li>measure alert volume, confirmed true positives, and mitigation impact</li>
    </ul>
  </li>
</ul>

<p>Metrics that matter:</p>
<ul>
  <li>p95 time-to-detect for fleet regressions</li>
  <li>precision of paging alerts (very high)</li>
  <li>mitigation success rate (did fallback improve quality?)</li>
</ul>

<h3 id="64-privacy-safe-debugging-loop">6.4 Privacy-safe debugging loop</h3>

<p>When privacy prevents raw audio upload, build a workflow that still improves systems:</p>
<ul>
  <li>federated analytics for aggregate signals (clipping rates, dropout rates, confidence shifts)</li>
  <li>opt-in debug cohorts for sample-level analysis (explicit consent)</li>
  <li>synthetic test harnesses to reproduce failures without user audio</li>
</ul>

<p>Treat “debuggability under privacy constraints” as a first-class requirement.</p>

<hr />

<h2 id="7-production-deployment">7. Production Deployment</h2>

<h3 id="71-on-device-vs-server">7.1 On-device vs server</h3>

<p>On-device:</p>
<ul>
  <li>immediate mitigation (fallback mic mode, prompt user)</li>
  <li>privacy-safe (no raw audio upload)</li>
  <li>limited compute</li>
</ul>

<p>Server:</p>
<ul>
  <li>fleet-wide attribution (“Android vX in region Y is clipping”)</li>
  <li>cross-device correlation</li>
  <li>dashboards and alerts</li>
</ul>

<h3 id="72-attribution-turning-audio-is-bad-into-this-rollout-is-bad">7.2 Attribution: turning “audio is bad” into “this rollout is bad”</h3>

<p>The highest ROI capability is fast attribution.
Common attribution dimensions:</p>
<ul>
  <li>app version / firmware version</li>
  <li>codec type (Opus vs AAC)</li>
  <li>input route (built-in mic vs headset)</li>
  <li>device model</li>
  <li>region / ISP (streaming transport issues)</li>
</ul>

<p>Many real incidents come from:</p>
<ul>
  <li>a rollout that changed AGC/VAD parameters</li>
  <li>a codec library update</li>
  <li>a streaming transport change</li>
</ul>

<p>If your anomaly system can quickly show:</p>
<blockquote>
  <p>“Clipping rate spiked 10x for Android v123 in region IN after rollout R”
you will cut MTTR dramatically.</p>
</blockquote>

<h3 id="73-mitigation-strategies">7.3 Mitigation strategies</h3>

<p>When anomalies are detected, mitigation might include:</p>
<ul>
  <li>switch codec (Opus → PCM for a session)</li>
  <li>reset AGC/VAD parameters</li>
  <li>reduce streaming chunk size to handle jitter</li>
  <li>fall back to offline transcription when streaming is unstable</li>
  <li>prompt the user (“Your mic seems muted”)</li>
</ul>

<p>The mitigation layer is what turns detection into product reliability.</p>

<h3 id="74-mitigation-safety-dont-auto-fix-yourself-into-a-worse-state">7.4 Mitigation safety: don’t auto-fix yourself into a worse state</h3>

<p>Auto-mitigation is powerful but risky.
Guardrails:</p>
<ul>
  <li>canary mitigations (apply to small traffic first)</li>
  <li>time-bounded mitigations (auto-expire)</li>
  <li>measure impact (did confidence/quality improve?)</li>
</ul>

<p>This is the same lesson as general anomaly detection: detection is only valuable if the action path is safe.</p>

<hr />

<h2 id="8-streaming--real-time-considerations">8. Streaming / Real-time Considerations</h2>

<p>Streaming introduces its own anomalies:</p>
<ul>
  <li>packet loss</li>
  <li>jitter buffer underruns</li>
  <li>misordered frames</li>
</ul>

<p>Monitor:</p>
<ul>
  <li>frame arrival rate vs expected</li>
  <li>jitter distribution</li>
  <li>percent of frames dropped/retransmitted</li>
</ul>

<p>Couple these with signal-level metrics:</p>
<ul>
  <li>if jitter rises and <code class="language-plaintext highlighter-rouge">zero_fraction</code> spikes, you likely have a transport issue</li>
</ul>

<h3 id="81-jitter-buffers-and-audio-holes">8.1 Jitter buffers and “audio holes”</h3>

<p>In real-time speech, audio often flows as packets.
Even small network issues can create “audio holes”:</p>
<ul>
  <li>missing frames</li>
  <li>repeated frames</li>
  <li>time-warp artifacts from resampling</li>
</ul>

<p>Practical metrics to instrument:</p>
<ul>
  <li><strong>buffer occupancy</strong> (how close to underrun)</li>
  <li><strong>underrun count</strong> (holes per minute)</li>
  <li><strong>concealment rate</strong> (how often PLC fills missing audio)</li>
</ul>

<p>Why this matters:</p>
<ul>
  <li>ASR models are brittle to missing phonetic transitions</li>
  <li>even if WER rises only slightly, the user experience can collapse (“it keeps missing my command”)</li>
</ul>

<h3 id="82-real-time-detector-design-dont-block-the-audio-path">8.2 Real-time detector design (don’t block the audio path)</h3>

<p>Detectors must not introduce latency.
Design guidelines:</p>
<ul>
  <li>compute cheap features per frame/window (RMS, zero fraction, clipping)</li>
  <li>use rolling windows (e.g., 1s, 5s) with O(1) updates</li>
  <li>run heavier models asynchronously (background thread)</li>
</ul>

<p>If a detector blocks the streaming path, it becomes the anomaly.</p>

<hr />

<h2 id="9-quality-metrics">9. Quality Metrics</h2>

<p>Beyond WER, track:</p>
<ul>
  <li>confidence calibration drift</li>
  <li>“no speech detected” rates</li>
  <li>command completion rates</li>
  <li>user correction rates</li>
</ul>

<p>For anomaly detection itself:</p>
<ul>
  <li>alert precision (how many alerts correspond to real issues)</li>
  <li>time-to-detect</li>
  <li>time-to-mitigate</li>
</ul>

<h3 id="91-speech-specific-diagnostic-metrics-high-signal">9.1 Speech-specific diagnostic metrics (high signal)</h3>

<p>In addition to generic “precision/latency”, speech teams track metrics that map to real failure modes:</p>

<ul>
  <li><strong>Audio frontend health</strong>
    <ul>
      <li>sample rate distribution (should be stable)</li>
      <li>input route distribution (BT vs wired vs built-in mic)</li>
      <li>VAD speech fraction (sudden changes suggest frontend bugs)</li>
    </ul>
  </li>
  <li><strong>ASR decode health</strong>
    <ul>
      <li>blank token rate (CTC-like systems)</li>
      <li>average token entropy / confidence</li>
      <li>repetition rate (looping outputs)</li>
    </ul>
  </li>
  <li><strong>User experience proxies</strong>
    <ul>
      <li>re-try rate (“user repeated the command”)</li>
      <li>correction rate (“user edited the transcript”)</li>
      <li>abort rate (user cancels mid-utterance)</li>
    </ul>
  </li>
</ul>

<p>These metrics help you distinguish:</p>
<ul>
  <li>“model got worse” vs “audio got worse” vs “system got slower”.</li>
</ul>

<hr />

<h2 id="10-common-failure-modes-and-debugging">10. Common Failure Modes (and Debugging)</h2>

<h3 id="101-false-positives-from-normal-variability">10.1 False positives from normal variability</h3>
<p>Mitigation:</p>
<ul>
  <li>segment baselines</li>
  <li>robust statistics (median/MAD)</li>
  <li>seasonality-aware comparisons</li>
</ul>

<h3 id="102-privacy-limited-debugging">10.2 Privacy-limited debugging</h3>
<p>Mitigation:</p>
<ul>
  <li>federated analytics</li>
  <li>opt-in debug cohorts</li>
  <li>synthetic test harnesses (simulate anomalies)</li>
</ul>

<h3 id="103-confusing-model-issues-with-audio-pipeline-issues">10.3 Confusing model issues with audio pipeline issues</h3>
<p>Mitigation:</p>
<ul>
  <li>detect anomalies at multiple layers:
    <ul>
      <li>signal level</li>
      <li>feature level</li>
      <li>model confidence level
If only signal metrics spike, it’s likely pipeline/transport.</li>
    </ul>
  </li>
</ul>

<h3 id="104-debugging-playbook-what-you-do-during-an-incident">10.4 Debugging playbook (what you do during an incident)</h3>

<p>When you get a spike in speech-related failures, a practical incident flow:</p>

<ol>
  <li><strong>Check transport health</strong>
    <ul>
      <li>are jitter/frame drop metrics spiking?</li>
      <li>is the problem localized to one region/ISP?</li>
    </ul>
  </li>
  <li><strong>Check frontend health</strong>
    <ul>
      <li>is sample rate distribution stable?</li>
      <li>did input route shift (sudden rise in Bluetooth sessions)?</li>
      <li>did VAD speech fraction shift?</li>
    </ul>
  </li>
  <li><strong>Check signal metrics</strong>
    <ul>
      <li>RMS energy distribution shift?</li>
      <li>clipping rate spike?</li>
      <li>zero fraction spike (dropouts)?</li>
    </ul>
  </li>
  <li><strong>Check model metrics</strong>
    <ul>
      <li>confidence collapse?</li>
      <li>repetition loops?</li>
    </ul>
  </li>
  <li><strong>Correlate with change logs</strong>
    <ul>
      <li>app rollout?</li>
      <li>codec library update?</li>
      <li>config change to AGC/VAD?</li>
    </ul>
  </li>
</ol>

<p>This is the same “attribution-first” approach as general anomaly detection: you want the fastest path from “something is wrong” to “what changed”.</p>

<h3 id="105-a-realistic-failure-story-sample-rate-mismatch">10.5 A realistic failure story: sample rate mismatch</h3>

<p>One of the most common “everything broke” incidents:</p>
<ul>
  <li>audio is captured at 44.1kHz but treated as 16kHz</li>
  <li>features are computed on the wrong time scale</li>
  <li>ASR becomes nonsense</li>
</ul>

<p>Symptoms:</p>
<ul>
  <li>WER spikes everywhere</li>
  <li>confidence distribution collapses</li>
  <li>spectral features shift dramatically</li>
</ul>

<p>If you monitor sample rate distribution and feature histograms, you catch this quickly and roll back the offending change.</p>

<hr />

<h2 id="11-state-of-the-art">11. State-of-the-Art</h2>

<p>Trends:</p>
<ul>
  <li>self-supervised embeddings used as “universal audio features” for detection</li>
  <li>on-device anomaly detection as part of privacy-first speech stacks</li>
  <li>better attribution via causal analysis (rollout correlation, device firmware mapping)</li>
</ul>

<h3 id="111-toward-closed-loop-speech-reliability">11.1 Toward “closed-loop” speech reliability</h3>

<p>The next step beyond detection is closed-loop control:</p>
<ul>
  <li>detect anomalies quickly</li>
  <li>apply safe mitigations automatically</li>
  <li>measure whether mitigations improved user-facing metrics</li>
  <li>keep a rollback path if mitigations regress quality</li>
</ul>

<p>This turns speech reliability into a control system:</p>
<ul>
  <li>detectors produce signals</li>
  <li>mitigations are actions</li>
  <li>user experience metrics are feedback</li>
</ul>

<p>The hard part is safety:
you need guardrails, canarying, and time-bounded actions to avoid oscillations and “self-inflicted incidents”.</p>

<hr />

<h2 id="12-key-takeaways">12. Key Takeaways</h2>

<ol>
  <li><strong>Speech anomalies are often system issues</strong>: detect signal, feature, model, and transport anomalies separately.</li>
  <li><strong>Layered detection wins</strong>: on-device for fast/privacy-safe action, server for fleet attribution.</li>
  <li><strong>Pattern recognition is the shared skill</strong>: define stable boundaries of “normal” and trigger when those boundaries break.</li>
</ol>

<h3 id="121-a-simple-starter-checklist">12.1 A simple “starter checklist”</h3>

<p>If you’re implementing this at a company, start with:</p>
<ul>
  <li>signal-level rules (RMS, clipping, zero fraction)</li>
  <li>streaming transport metrics (frame drops, jitter)</li>
  <li>segment-aware dashboards (device model, codec, region)</li>
  <li>attribution first (top contributors)</li>
  <li>safe mitigations (fallback codecs, user prompts)</li>
</ul>

<p>Then iterate toward:</p>
<ul>
  <li>feature-level distribution shift detection</li>
  <li>model-confidence drift detection</li>
  <li>selective ML-based detectors for subtle artifacts</li>
</ul>

<h3 id="122-appendix-anomaly-catalog-quick-mapping-from-symptom--suspect">12.2 Appendix: anomaly catalog (quick mapping from symptom → suspect)</h3>

<p>This is a practical “lookup table” teams use during incidents:</p>

<table>
  <thead>
    <tr>
      <th>Symptom</th>
      <th>Likely cause</th>
      <th>What to check first</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">zero_fraction</code> spikes</td>
      <td>dropouts / muted mic / transport holes</td>
      <td>frame drops, jitter buffer underruns</td>
    </tr>
    <tr>
      <td>clipping rate spikes</td>
      <td>AGC misconfiguration, loud environment, mic gain bug</td>
      <td>frontend config changes, device segment</td>
    </tr>
    <tr>
      <td>RMS energy collapses</td>
      <td>input route changed, permissions, mic muted</td>
      <td>input route distribution, OS version</td>
    </tr>
    <tr>
      <td>confidence collapses fleet-wide</td>
      <td>sample rate mismatch, feature extraction bug</td>
      <td>sample rate metrics, mel hist distance</td>
    </tr>
    <tr>
      <td>confidence collapses in one segment</td>
      <td>device firmware / codec regression</td>
      <td>app version, codec type, device model</td>
    </tr>
    <tr>
      <td>repetition loops (“aaaa”)</td>
      <td>decoder instability, corrupted features</td>
      <td>model-level health, feature stats</td>
    </tr>
  </tbody>
</table>

<p>The goal of this table isn’t perfect diagnosis; it’s <strong>fast triage</strong>.</p>

<h3 id="123-appendix-what-telemetry-to-keep-privacy-safe-and-still-useful">12.3 Appendix: what telemetry to keep privacy-safe (and still useful)</h3>

<p>You can get high reliability without uploading raw audio by logging:</p>
<ul>
  <li>aggregated histograms (RMS, clipping, confidence)</li>
  <li>rates (dropout rate, frame drop rate)</li>
  <li>segment identifiers (device model bucket, codec type, region)</li>
</ul>

<p>Avoid logging:</p>
<ul>
  <li>raw transcripts</li>
  <li>speaker embeddings</li>
  <li>unique user identifiers as labels (cardinality + privacy risk)</li>
</ul>

<p>This balances:</p>
<ul>
  <li>debugging usefulness</li>
  <li>privacy constraints</li>
  <li>storage cost and cardinality control</li>
</ul>

<h3 id="124-appendix-how-this-connects-to-the-broader-anomaly-detection-system">12.4 Appendix: how this connects to the broader “anomaly detection” system</h3>

<p>Speech anomaly detection is a specialized instance of anomaly detection:</p>
<ul>
  <li>same architecture patterns (streaming + batch baselines)</li>
  <li>same pitfalls (seasonality, cardinality, alert fatigue)</li>
  <li>but with extra constraints (privacy, device heterogeneity, real-time latency)</li>
</ul>

<p>If you build the general anomaly platform well, speech becomes a “well-instrumented tenant” rather than a one-off system.</p>

<h3 id="125-appendix-synthetic-corruption-recipes-for-reliable-evaluation">12.5 Appendix: synthetic corruption recipes (for reliable evaluation)</h3>

<p>One of the best ways to evaluate anomaly detectors without user audio is to create synthetic corruptions:</p>

<ul>
  <li><strong>Clipping</strong>
    <ul>
      <li>multiply amplitude and clamp to [-1, 1]</li>
      <li>expected detector: clipping rate spikes</li>
    </ul>
  </li>
  <li><strong>Dropouts</strong>
    <ul>
      <li>zero out random 50–200ms spans</li>
      <li>expected detector: zero fraction spikes, jitter/PLC metrics may spike in streaming</li>
    </ul>
  </li>
  <li><strong>Sample rate mismatch</strong>
    <ul>
      <li>resample to 44.1kHz but label as 16kHz (or vice versa)</li>
      <li>expected detector: feature distribution shifts, confidence collapses</li>
    </ul>
  </li>
  <li><strong>Codec artifacts</strong>
    <ul>
      <li>apply low bitrate compression and packet loss simulation</li>
      <li>expected detector: spectral flatness/centroid shifts, transport metrics spike</li>
    </ul>
  </li>
</ul>

<p>These recipes make incident replay far more robust because you can validate detectors against known failure modes without collecting real user audio.</p>

<h3 id="126-appendix-on-device-vs-server-trade-offs-what-to-decide-explicitly">12.6 Appendix: on-device vs server trade-offs (what to decide explicitly)</h3>

<p>A crisp decision framework:</p>
<ul>
  <li>detect <strong>privacy-sensitive anomalies</strong> on-device (raw audio never leaves)</li>
  <li>detect <strong>fleet regressions</strong> on server using aggregated telemetry (histograms, rates)</li>
  <li>keep mitigations local when possible (codec fallback, user prompt)</li>
  <li>page humans only when impact is high and attribution is clear</li>
</ul>

<p>If you decide these explicitly, the system becomes operable:
you avoid “we can’t debug because privacy” and “we leaked privacy to debug”.</p>

<h3 id="127-appendix-an-incident-response-checklist-speech-edition">12.7 Appendix: an incident response checklist (speech edition)</h3>

<p>When speech quality suddenly degrades:</p>

<ol>
  <li><strong>Scope</strong>
    <ul>
      <li>which product surface (wake word, dictation, commands)?</li>
      <li>which segments (device model, codec, region)?</li>
    </ul>
  </li>
  <li><strong>Transport</strong>
    <ul>
      <li>jitter and frame drops (streaming)</li>
      <li>jitter buffer underruns / PLC rate</li>
    </ul>
  </li>
  <li><strong>Frontend</strong>
    <ul>
      <li>sample rate distribution</li>
      <li>input route distribution (Bluetooth spikes)</li>
      <li>VAD speech fraction shifts</li>
    </ul>
  </li>
  <li><strong>Signal</strong>
    <ul>
      <li>RMS and clipping distributions</li>
      <li>zero fraction / dropout rate</li>
    </ul>
  </li>
  <li><strong>Model</strong>
    <ul>
      <li>confidence distribution shifts</li>
      <li>“no speech” and repetition anomalies</li>
    </ul>
  </li>
  <li><strong>Changes</strong>
    <ul>
      <li>app rollout, codec updates, AGC/VAD config changes</li>
    </ul>
  </li>
</ol>

<p>This checklist makes the investigation systematic, which is critical when you can’t “just listen to the audio”.</p>

<h3 id="128-appendix-what-to-page-on-avoiding-alert-fatigue">12.8 Appendix: what to page on (avoiding alert fatigue)</h3>

<p>For paging alerts, require:</p>
<ul>
  <li>a clear impact proxy (command failure, confidence collapse, WER proxy spike)</li>
  <li>attribution to a segment (device/version/region)</li>
  <li>correlation with a change event or a sustained shift</li>
</ul>

<p>Otherwise, keep it as notify/log-only signals for investigation.</p>

<h3 id="129-appendix-cardinality-discipline-for-speech-telemetry">12.9 Appendix: cardinality discipline for speech telemetry</h3>

<p>Speech telemetry can explode in cardinality if you log:</p>
<ul>
  <li>per-user IDs</li>
  <li>per-utterance IDs</li>
  <li>free-form text fields</li>
</ul>

<p>High cardinality is bad for:</p>
<ul>
  <li>storage cost</li>
  <li>streaming state cost</li>
  <li>alert reliability (too few points per series)</li>
</ul>

<p>Practical discipline:</p>
<ul>
  <li>bucket device models into a manageable taxonomy</li>
  <li>bucket locales and regions</li>
  <li>treat codec/input-route as enums (small set)</li>
  <li>aggregate metrics per window (1m/5m) and per segment</li>
</ul>

<p>This keeps your anomaly system stable and makes fleet attribution possible without turning your TSDB into a fire.</p>

<h3 id="1210-appendix-a-minimal-speech-reliability-dashboard">12.10 Appendix: a minimal “speech reliability dashboard”</h3>

<p>If you can build only one dashboard, include:</p>

<ul>
  <li><strong>User impact</strong>
    <ul>
      <li>command success / completion rate (or best proxy)</li>
      <li>“no speech detected” rate</li>
      <li>user retry/correction rate</li>
    </ul>
  </li>
  <li><strong>Signal health</strong>
    <ul>
      <li>RMS distribution (p50/p95)</li>
      <li>clipping rate</li>
      <li>zero fraction</li>
    </ul>
  </li>
  <li><strong>Transport health (streaming)</strong>
    <ul>
      <li>frame drop rate</li>
      <li>jitter/underrun rate</li>
      <li>PLC/concealment rate</li>
    </ul>
  </li>
  <li><strong>Attribution panels</strong>
    <ul>
      <li>by app version</li>
      <li>by codec type</li>
      <li>by device bucket</li>
      <li>by region</li>
    </ul>
  </li>
</ul>

<p>This dashboard makes anomalies obvious and shortens “where is it happening?” to a few minutes.</p>

<hr />

<p><strong>Originally published at:</strong> <a href="https://www.arunbaby.com/speech-tech/0052-speech-anomaly-detection/">arunbaby.com/speech-tech/0052-speech-anomaly-detection</a></p>

<p><em>If you found this helpful, consider sharing it with others who might benefit.</em></p>


        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#anomaly-detection" class="page__taxonomy-item p-category" rel="tag">anomaly-detection</a><span class="sep">, </span>
    
      <a href="/tags/#audio-quality" class="page__taxonomy-item p-category" rel="tag">audio-quality</a><span class="sep">, </span>
    
      <a href="/tags/#monitoring" class="page__taxonomy-item p-category" rel="tag">monitoring</a><span class="sep">, </span>
    
      <a href="/tags/#on-device" class="page__taxonomy-item p-category" rel="tag">on-device</a><span class="sep">, </span>
    
      <a href="/tags/#production" class="page__taxonomy-item p-category" rel="tag">production</a><span class="sep">, </span>
    
      <a href="/tags/#streaming" class="page__taxonomy-item p-category" rel="tag">streaming</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#speech-tech" class="page__taxonomy-item p-category" rel="tag">speech-tech</a>
    
    </span>
  </p>


        
      </footer>

      <div class="page__related page__related--full">
  <h2 class="page__related-title">Related across topics</h2>
  <style>
    /* Make section span full content width and use 2 equal columns */
    .page__related--full { float: inline-start; width: 100%; padding: 0; }
    .cross-related-grid { display: grid; grid-template-columns: repeat(2, minmax(0, 1fr)); gap: 2rem; }
    @media (max-width: 768px) { .cross-related-grid { grid-template-columns: 1fr; } }
    /* Ensure archive cards stretch nicely in the grid */
    .cross-related-grid .list__item, .cross-related-grid .grid__item { width: auto; float: none; margin: 0; }
  </style>
  <div class="cross-related-grid">
    



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/dsa/0052-trapping-rain-water/" rel="permalink">Trapping Rain Water
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          22 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“Water doesn’t care about every bar—only the highest walls to the left and right.”
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ml-system-design/0052-anomaly-detection/" rel="permalink">Anomaly Detection
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          21 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“Anomaly detection is trapping rain water for metrics: find the boundaries of ‘normal’ and measure what overflows.”
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/speech-tech/0052-speech-anomaly-detection/" rel="permalink">Speech Anomaly Detection
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          19 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“If ASR is the brain, anomaly detection is the nervous system—it tells you when the audio reality changed.”
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ai-agents/0052-long-context-agent-strategies/" rel="permalink">Long-Context Agent Strategies
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          22 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“Long context isn’t ‘more tokens’—it’s a strategy for keeping the right boundaries of information.”
</p>
  </article>
</div>

  </div>
</div>

      <section class="page__share">
  <h4 class="page__share-title">Share on</h4>

  <a href="https://twitter.com/intent/tweet?via=arunbaby0&text=Speech+Anomaly+Detection%20https%3A%2F%2Fwww.arunbaby.com%2Fspeech-tech%2F0052-speech-anomaly-detection%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.arunbaby.com%2Fspeech-tech%2F0052-speech-anomaly-detection%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.arunbaby.com/speech-tech/0052-speech-anomaly-detection/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/speech-tech/0051-privacy-preserving-speech/" class="pagination--pager" title="Privacy-preserving Speech">Previous</a>
    
    
      <a href="/speech-tech/0053-audio-quality-validation/" class="pagination--pager" title="Audio Quality Validation">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 1990 - 2143 <a href="https://www.arunbaby.com">Arun Baby</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JRJPEC9SS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0JRJPEC9SS', { 'anonymize_ip': false});
</script>








  </body>
</html>
