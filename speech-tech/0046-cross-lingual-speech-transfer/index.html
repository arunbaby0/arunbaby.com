<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Cross-Lingual Speech Transfer - Arun Baby</title>
<meta name="description" content="“Teach a model one language and it learns to hear them all.”">


  <meta name="author" content="Arun Baby">
  
  <meta property="article:author" content="Arun Baby">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Arun Baby">
<meta property="og:title" content="Cross-Lingual Speech Transfer">
<meta property="og:url" content="https://www.arunbaby.com/speech-tech/0046-cross-lingual-speech-transfer/">


  <meta property="og:description" content="“Teach a model one language and it learns to hear them all.”">



  <meta property="og:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">



  <meta name="twitter:site" content="@arunbaby0">
  <meta name="twitter:title" content="Cross-Lingual Speech Transfer">
  <meta name="twitter:description" content="“Teach a model one language and it learns to hear them all.”">
  <meta name="twitter:url" content="https://www.arunbaby.com/speech-tech/0046-cross-lingual-speech-transfer/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">
    
  

  



  <meta property="article:published_time" content="2025-12-21T22:46:31+05:30">





  

  


<link rel="canonical" href="https://www.arunbaby.com/speech-tech/0046-cross-lingual-speech-transfer/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Baby Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          <span class="site-subtitle">Arun Baby</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/dsa/"
                
                
              >DSA</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ml-system-design/"
                
                
              >ML Systems</a>
            </li><li class="masthead__menu-item">
              <a
                href="/speech-tech/"
                
                
              >Speech Tech</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ai-agents/"
                
                
              >AI Agents</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li><li class="masthead__menu-item">
              <a
                href="/statuses/"
                
                
              >Statuses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/contact/"
                
                
              >Contact</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main" class="no-author-sidebar">
  
  <div class="sidebar sticky">
  
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Cross-Lingual Speech Transfer">
    <meta itemprop="description" content="“Teach a model one language and it learns to hear them all.”">
    <meta itemprop="datePublished" content="2025-12-21T22:46:31+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://www.arunbaby.com/speech-tech/0046-cross-lingual-speech-transfer/" itemprop="url">Cross-Lingual Speech Transfer
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          21 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#1-introduction">1. Introduction</a><ul><li><a href="#why-cross-lingual-transfer">Why Cross-Lingual Transfer?</a></li><li><a href="#the-challenge">The Challenge</a></li></ul></li><li><a href="#2-fundamentals-of-speech-transfer">2. Fundamentals of Speech Transfer</a><ul><li><a href="#21-what-transfers-across-languages">2.1 What Transfers Across Languages?</a></li><li><a href="#22-language-family-effects">2.2 Language Family Effects</a></li><li><a href="#23-key-research-breakthroughs">2.3 Key Research Breakthroughs</a></li></ul></li><li><a href="#3-architecture-patterns">3. Architecture Patterns</a><ul><li><a href="#31-multilingual-pretraining-architecture">3.1 Multilingual Pretraining Architecture</a></li><li><a href="#32-fine-tuning-architecture">3.2 Fine-Tuning Architecture</a></li></ul></li><li><a href="#4-cross-lingual-transfer-strategies">4. Cross-Lingual Transfer Strategies</a><ul><li><a href="#41-strategy-selection-based-on-data-availability">4.1 Strategy Selection Based on Data Availability</a></li><li><a href="#42-phoneme-based-transfer">4.2 Phoneme-Based Transfer</a></li><li><a href="#43-multi-source-transfer">4.3 Multi-Source Transfer</a></li></ul></li><li><a href="#5-training-pipeline">5. Training Pipeline</a></li><li><a href="#6-production-deployment">6. Production Deployment</a><ul><li><a href="#61-multi-language-server-architecture">6.1 Multi-Language Server Architecture</a></li><li><a href="#62-efficient-multi-language-serving">6.2 Efficient Multi-Language Serving</a></li></ul></li><li><a href="#7-quality-metrics-and-evaluation">7. Quality Metrics and Evaluation</a></li><li><a href="#8-real-world-case-study-metas-mms">8. Real-World Case Study: Meta’s MMS</a></li><li><a href="#9-common-failure-modes">9. Common Failure Modes</a><ul><li><a href="#failure-mode-1-tone-confusion">Failure Mode 1: Tone Confusion</a></li><li><a href="#failure-mode-2-code-switching-boundaries">Failure Mode 2: Code-Switching Boundaries</a></li><li><a href="#failure-mode-3-unique-phoneme-collapse">Failure Mode 3: Unique Phoneme Collapse</a></li></ul></li><li><a href="#10-connection-to-transfer-learning-systems">10. Connection to Transfer Learning Systems</a></li><li><a href="#11-key-takeaways">11. Key Takeaways</a></li></ul>
            </nav>
          </aside>
        
        <p><strong>“Teach a model one language and it learns to hear them all.”</strong></p>

<h2 id="1-introduction">1. Introduction</h2>

<p>Cross-lingual speech transfer is the art of leveraging speech recognition knowledge from high-resource languages (English, Mandarin) to enable ASR in low-resource languages (Swahili, Welsh, Yoruba). With over 7,000 languages spoken worldwide and labeled speech data for fewer than 100, cross-lingual transfer is essential for democratizing speech technology.</p>

<h3 id="why-cross-lingual-transfer">Why Cross-Lingual Transfer?</h3>

<p>The fundamental insight: <strong>speech sounds are universal</strong>. All humans share the same vocal apparatus, producing sounds from a finite phonetic inventory. A model trained on English learns:</p>
<ul>
  <li>Acoustic patterns (formants, pitch, duration)</li>
  <li>Phonetic concepts (stops, fricatives, vowels)</li>
  <li>Temporal dynamics (coarticulation, rhythm)</li>
</ul>

<p>These representations transfer remarkably well across languages.</p>

<h3 id="the-challenge">The Challenge</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>High-Resource Languages           Low-Resource Languages
┌──────────────────────┐         ┌──────────────────────┐
│ English: 60,000 hrs  │         │ Welsh: 50 hrs        │
│ Mandarin: 40,000 hrs │   →     │ Yoruba: 20 hrs       │
│ Spanish: 30,000 hrs  │ Transfer │ Māori: 10 hrs        │
│ French: 25,000 hrs   │         │ Quechua: 5 hrs       │
└──────────────────────┘         └──────────────────────┘

Challenge: Train robust ASR with 1000x less data
</code></pre></div></div>

<h2 id="2-fundamentals-of-speech-transfer">2. Fundamentals of Speech Transfer</h2>

<h3 id="21-what-transfers-across-languages">2.1 What Transfers Across Languages?</h3>

<p>Research has identified a hierarchy of transferable representations:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>┌─────────────────────────────────────────────────────────────────┐
│                 Speech Representation Hierarchy                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ Layer 1-3: Acoustic Features (HIGHLY TRANSFERABLE)       │   │
│  │ - Formant patterns, pitch contours, energy               │   │
│  │ - Transfer: ~95% across all languages                    │   │
│  └──────────────────────────────────────────────────────────┘   │
│                           ↓                                     │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ Layer 4-8: Phonetic Features (VERY TRANSFERABLE)         │   │
│  │ - Manner/place of articulation, voicing                  │   │
│  │ - Transfer: ~85% across language families                │   │
│  └──────────────────────────────────────────────────────────┘   │
│                           ↓                                     │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ Layer 9-12: Phoneme Representations (MODERATELY TRANS.)  │   │
│  │ - Language-specific phone inventory                      │   │
│  │ - Transfer: ~70% within families, ~50% across            │   │
│  └──────────────────────────────────────────────────────────┘   │
│                           ↓                                     │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │ Layer 13+: Linguistic Features (LESS TRANSFERABLE)       │   │
│  │ - Word boundaries, morphology, syntax                    │   │
│  │ - Transfer: ~40%, language-specific fine-tuning needed   │   │
│  └──────────────────────────────────────────────────────────┘   │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
</code></pre></div></div>

<h3 id="22-language-family-effects">2.2 Language Family Effects</h3>

<p>Transfer works best within language families:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Transfer effectiveness matrix (approximate WER reduction %)
</span><span class="n">TRANSFER_MATRIX</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># Source → Target
</span>    <span class="p">(</span><span class="sh">"</span><span class="s">Germanic</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Germanic</span><span class="sh">"</span><span class="p">):</span> <span class="mf">0.85</span><span class="p">,</span>    <span class="c1"># English → German
</span>    <span class="p">(</span><span class="sh">"</span><span class="s">Germanic</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Romance</span><span class="sh">"</span><span class="p">):</span> <span class="mf">0.70</span><span class="p">,</span>     <span class="c1"># English → Spanish
</span>    <span class="p">(</span><span class="sh">"</span><span class="s">Indo-European</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Indo-European</span><span class="sh">"</span><span class="p">):</span> <span class="mf">0.65</span><span class="p">,</span>  <span class="c1"># English → Hindi
</span>    <span class="p">(</span><span class="sh">"</span><span class="s">Indo-European</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Sino-Tibetan</span><span class="sh">"</span><span class="p">):</span> <span class="mf">0.45</span><span class="p">,</span>   <span class="c1"># English → Mandarin
</span>    <span class="p">(</span><span class="sh">"</span><span class="s">Indo-European</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Niger-Congo</span><span class="sh">"</span><span class="p">):</span> <span class="mf">0.50</span><span class="p">,</span>    <span class="c1"># English → Swahili
</span>    <span class="p">(</span><span class="sh">"</span><span class="s">Any</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Tonal language</span><span class="sh">"</span><span class="p">):</span> <span class="mf">0.55</span><span class="p">,</span>   <span class="c1"># Non-tonal → Tonal needs adaptation
</span><span class="p">}</span>

<span class="k">def</span> <span class="nf">estimate_transfer_benefit</span><span class="p">(</span><span class="n">source_lang</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">target_lang</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Estimate expected WER reduction from transfer learning.
    
    Based on linguistic distance and empirical studies.
    </span><span class="sh">"""</span>
    <span class="n">source_family</span> <span class="o">=</span> <span class="nf">get_language_family</span><span class="p">(</span><span class="n">source_lang</span><span class="p">)</span>
    <span class="n">target_family</span> <span class="o">=</span> <span class="nf">get_language_family</span><span class="p">(</span><span class="n">target_lang</span><span class="p">)</span>
    
    <span class="c1"># Check tone compatibility
</span>    <span class="n">source_tonal</span> <span class="o">=</span> <span class="nf">is_tonal</span><span class="p">(</span><span class="n">source_lang</span><span class="p">)</span>
    <span class="n">target_tonal</span> <span class="o">=</span> <span class="nf">is_tonal</span><span class="p">(</span><span class="n">target_lang</span><span class="p">)</span>
    
    <span class="n">base_transfer</span> <span class="o">=</span> <span class="n">TRANSFER_MATRIX</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span>
        <span class="p">(</span><span class="n">source_family</span><span class="p">,</span> <span class="n">target_family</span><span class="p">),</span>
        <span class="mf">0.50</span>  <span class="c1"># Default for distant languages
</span>    <span class="p">)</span>
    
    <span class="c1"># Tone mismatch penalty
</span>    <span class="k">if</span> <span class="n">target_tonal</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">source_tonal</span><span class="p">:</span>
        <span class="n">base_transfer</span> <span class="o">*=</span> <span class="mf">0.85</span>
    
    <span class="k">return</span> <span class="n">base_transfer</span>
</code></pre></div></div>

<h3 id="23-key-research-breakthroughs">2.3 Key Research Breakthroughs</h3>

<table>
  <thead>
    <tr>
      <th>Model</th>
      <th>Year</th>
      <th>Innovation</th>
      <th>Languages</th>
      <th>Approach</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Wav2Vec 2.0</td>
      <td>2020</td>
      <td>Self-supervised pretraining</td>
      <td>1 → many</td>
      <td>Contrastive learning</td>
    </tr>
    <tr>
      <td>XLSR-53</td>
      <td>2020</td>
      <td>Multilingual pretrain</td>
      <td>53</td>
      <td>Cross-lingual representations</td>
    </tr>
    <tr>
      <td>XLS-R</td>
      <td>2021</td>
      <td>Scaled multilingual</td>
      <td>128</td>
      <td>436K hours, 128 languages</td>
    </tr>
    <tr>
      <td>Whisper</td>
      <td>2022</td>
      <td>Weakly supervised</td>
      <td>97</td>
      <td>680K hours, multitask</td>
    </tr>
    <tr>
      <td>MMS</td>
      <td>2023</td>
      <td>Massive scale</td>
      <td>1,107</td>
      <td>491K hours, largest coverage</td>
    </tr>
  </tbody>
</table>

<h2 id="3-architecture-patterns">3. Architecture Patterns</h2>

<h3 id="31-multilingual-pretraining-architecture">3.1 Multilingual Pretraining Architecture</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>┌─────────────────────────────────────────────────────────────────┐
│              Multilingual Speech Pretraining                     │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Raw Audio (any language)                                       │
│       │                                                         │
│       ▼                                                         │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │ Feature Encoder (CNN)                                   │    │
│  │ - 7 conv layers                                         │    │
│  │ - Language-agnostic acoustic features                   │    │
│  └─────────────────────────────────────────────────────────┘    │
│       │                                                         │
│       ▼                                                         │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │ Transformer Encoder (24 layers)                         │    │
│  │ - Self-attention across time                            │    │
│  │ - Learns cross-lingual representations                  │    │
│  └─────────────────────────────────────────────────────────┘    │
│       │                                                         │
│       ▼                                                         │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │ Contrastive Learning Head                               │    │
│  │ - Masks portions of input                               │    │
│  │ - Predicts correct representation                       │    │
│  └─────────────────────────────────────────────────────────┘    │
│                                                                 │
│  Training: 100+ languages, unlabeled audio only                 │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
</code></pre></div></div>

<h3 id="32-fine-tuning-architecture">3.2 Fine-Tuning Architecture</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">Wav2Vec2ForCTC</span><span class="p">,</span> <span class="n">Wav2Vec2Processor</span>

<span class="k">class</span> <span class="nc">CrossLingualASR</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Cross-lingual ASR model with language-specific adaptation.
    
    Architecture:
    - Pretrained multilingual encoder (frozen or fine-tuned)
    - Language-specific projection
    - CTC head for target language
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">pretrained_model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">"</span><span class="s">facebook/wav2vec2-xlsr-53-espeak-cv-ft</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">target_vocab_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
        <span class="n">freeze_encoder_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span>
        <span class="n">use_adapter</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
        <span class="n">adapter_hidden_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">256</span>
    <span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="c1"># Load pretrained multilingual model
</span>        <span class="n">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">Wav2Vec2ForCTC</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">pretrained_model</span><span class="p">)</span>
        
        <span class="c1"># Freeze early layers (universal acoustic features)
</span>        <span class="n">self</span><span class="p">.</span><span class="nf">_freeze_layers</span><span class="p">(</span><span class="n">freeze_encoder_layers</span><span class="p">)</span>
        
        <span class="c1"># Language-specific adapter (optional)
</span>        <span class="n">self</span><span class="p">.</span><span class="n">use_adapter</span> <span class="o">=</span> <span class="n">use_adapter</span>
        <span class="k">if</span> <span class="n">use_adapter</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">adapter</span> <span class="o">=</span> <span class="nc">LanguageAdapter</span><span class="p">(</span>
                <span class="n">input_size</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">hidden_size</span><span class="p">,</span>
                <span class="n">hidden_size</span><span class="o">=</span><span class="n">adapter_hidden_size</span>
            <span class="p">)</span>
        
        <span class="c1"># New CTC head for target language
</span>        <span class="n">self</span><span class="p">.</span><span class="n">lm_head</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span>
            <span class="n">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">hidden_size</span><span class="p">,</span>
            <span class="n">target_vocab_size</span>
        <span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_freeze_layers</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Freeze the first N transformer layers.</span><span class="sh">"""</span>
        <span class="c1"># Freeze feature extractor
</span>        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">.</span><span class="n">wav2vec2</span><span class="p">.</span><span class="n">feature_extractor</span><span class="p">.</span><span class="nf">parameters</span><span class="p">():</span>
            <span class="n">param</span><span class="p">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="bp">False</span>
        
        <span class="c1"># Freeze early transformer layers
</span>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">.</span><span class="n">wav2vec2</span><span class="p">.</span><span class="n">encoder</span><span class="p">.</span><span class="n">layers</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_layers</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">layer</span><span class="p">.</span><span class="nf">parameters</span><span class="p">():</span>
                    <span class="n">param</span><span class="p">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="bp">False</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">input_values</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
        <span class="n">labels</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="p">):</span>
        <span class="c1"># Get encoder outputs
</span>        <span class="n">outputs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">.</span><span class="nf">wav2vec2</span><span class="p">(</span>
            <span class="n">input_values</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="n">return_dict</span><span class="o">=</span><span class="bp">True</span>
        <span class="p">)</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">last_hidden_state</span>
        
        <span class="c1"># Apply language-specific adapter
</span>        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">use_adapter</span><span class="p">:</span>
            <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">adapter</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
        
        <span class="c1"># CTC projection
</span>        <span class="n">logits</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">lm_head</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
        
        <span class="c1"># Compute CTC loss if labels provided
</span>        <span class="n">loss</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="c1"># Get input lengths from attention mask
</span>            <span class="n">input_lengths</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_get_input_lengths</span><span class="p">(</span><span class="n">attention_mask</span><span class="p">)</span>
            
            <span class="c1"># CTC loss
</span>            <span class="n">log_probs</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">log_softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="nf">ctc_loss</span><span class="p">(</span>
                <span class="n">log_probs</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                <span class="n">labels</span><span class="p">,</span>
                <span class="n">input_lengths</span><span class="p">,</span>
                <span class="n">self</span><span class="p">.</span><span class="nf">_get_label_lengths</span><span class="p">(</span><span class="n">labels</span><span class="p">),</span>
                <span class="n">blank</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">zero_infinity</span><span class="o">=</span><span class="bp">True</span>
            <span class="p">)</span>
        
        <span class="k">return</span> <span class="p">{</span><span class="sh">"</span><span class="s">loss</span><span class="sh">"</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="sh">"</span><span class="s">logits</span><span class="sh">"</span><span class="p">:</span> <span class="n">logits</span><span class="p">}</span>
    
    <span class="k">def</span> <span class="nf">_get_input_lengths</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">attention_mask</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">None</span>
        <span class="k">return</span> <span class="n">attention_mask</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_get_label_lengths</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="c1"># Labels are padded with -100
</span>        <span class="nf">return </span><span class="p">(</span><span class="n">labels</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">100</span><span class="p">).</span><span class="nf">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">LanguageAdapter</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Lightweight adapter for language-specific adaptation.
    
    Adds only ~1% parameters but enables effective transfer.
    Based on </span><span class="sh">"</span><span class="s">Parameter-Efficient Transfer Learning for NLP</span><span class="sh">"</span><span class="s"> (Houlsby et al.)
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">down_project</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">GELU</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">up_project</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">layer_norm</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LayerNorm</span><span class="p">(</span><span class="n">input_size</span><span class="p">)</span>
        
        <span class="c1"># Initialize for identity-like behavior
</span>        <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="nf">zeros_</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">up_project</span><span class="p">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="nf">zeros_</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">up_project</span><span class="p">.</span><span class="n">bias</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">layer_norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">down_project</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">activation</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">up_project</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">residual</span> <span class="o">+</span> <span class="n">x</span>
</code></pre></div></div>

<h2 id="4-cross-lingual-transfer-strategies">4. Cross-Lingual Transfer Strategies</h2>

<h3 id="41-strategy-selection-based-on-data-availability">4.1 Strategy Selection Based on Data Availability</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span> <span class="n">enum</span> <span class="kn">import</span> <span class="n">Enum</span>
<span class="kn">from</span> <span class="n">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">List</span>

<span class="k">class</span> <span class="nc">TransferStrategy</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="n">ZERO_SHOT</span> <span class="o">=</span> <span class="sh">"</span><span class="s">zero_shot</span><span class="sh">"</span>           <span class="c1"># No target language data
</span>    <span class="n">FEW_SHOT</span> <span class="o">=</span> <span class="sh">"</span><span class="s">few_shot</span><span class="sh">"</span>             <span class="c1"># &lt; 1 hour labeled data
</span>    <span class="n">LOW_RESOURCE</span> <span class="o">=</span> <span class="sh">"</span><span class="s">low_resource</span><span class="sh">"</span>     <span class="c1"># 1-10 hours
</span>    <span class="n">MEDIUM_RESOURCE</span> <span class="o">=</span> <span class="sh">"</span><span class="s">medium_resource</span><span class="sh">"</span>  <span class="c1"># 10-100 hours
</span>    <span class="n">HIGH_RESOURCE</span> <span class="o">=</span> <span class="sh">"</span><span class="s">high_resource</span><span class="sh">"</span>   <span class="c1"># 100+ hours
</span>
<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">TransferConfig</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">Configuration for cross-lingual transfer.</span><span class="sh">"""</span>
    <span class="n">strategy</span><span class="p">:</span> <span class="n">TransferStrategy</span>
    <span class="n">freeze_encoder</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="n">freeze_layers</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">use_adapter</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="n">adapter_size</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">warmup_steps</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">gradient_accumulation</span><span class="p">:</span> <span class="nb">int</span>
    
    
<span class="k">def</span> <span class="nf">get_transfer_config</span><span class="p">(</span>
    <span class="n">target_hours</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">source_languages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">target_language</span><span class="p">:</span> <span class="nb">str</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TransferConfig</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Recommend transfer configuration based on data availability.
    </span><span class="sh">"""</span>
    
    <span class="k">if</span> <span class="n">target_hours</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="nc">TransferConfig</span><span class="p">(</span>
            <span class="n">strategy</span><span class="o">=</span><span class="n">TransferStrategy</span><span class="p">.</span><span class="n">ZERO_SHOT</span><span class="p">,</span>
            <span class="n">freeze_encoder</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">freeze_layers</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span>  <span class="c1"># Freeze all
</span>            <span class="n">use_adapter</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
            <span class="n">adapter_size</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>  <span class="c1"># No training
</span>            <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">gradient_accumulation</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span>
    
    <span class="k">elif</span> <span class="n">target_hours</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="nc">TransferConfig</span><span class="p">(</span>
            <span class="n">strategy</span><span class="o">=</span><span class="n">TransferStrategy</span><span class="p">.</span><span class="n">FEW_SHOT</span><span class="p">,</span>
            <span class="n">freeze_encoder</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">freeze_layers</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>  <span class="c1"># Freeze most
</span>            <span class="n">use_adapter</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">adapter_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>  <span class="c1"># Very small adapter
</span>            <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
            <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
            <span class="n">gradient_accumulation</span><span class="o">=</span><span class="mi">8</span>
        <span class="p">)</span>
    
    <span class="k">elif</span> <span class="n">target_hours</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">:</span>
        <span class="k">return</span> <span class="nc">TransferConfig</span><span class="p">(</span>
            <span class="n">strategy</span><span class="o">=</span><span class="n">TransferStrategy</span><span class="p">.</span><span class="n">LOW_RESOURCE</span><span class="p">,</span>
            <span class="n">freeze_encoder</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
            <span class="n">freeze_layers</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>  <span class="c1"># Freeze 2/3
</span>            <span class="n">use_adapter</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">adapter_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="mf">3e-5</span><span class="p">,</span>
            <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
            <span class="n">gradient_accumulation</span><span class="o">=</span><span class="mi">4</span>
        <span class="p">)</span>
    
    <span class="k">elif</span> <span class="n">target_hours</span> <span class="o">&lt;</span> <span class="mi">100</span><span class="p">:</span>
        <span class="k">return</span> <span class="nc">TransferConfig</span><span class="p">(</span>
            <span class="n">strategy</span><span class="o">=</span><span class="n">TransferStrategy</span><span class="p">.</span><span class="n">MEDIUM_RESOURCE</span><span class="p">,</span>
            <span class="n">freeze_encoder</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
            <span class="n">freeze_layers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>  <span class="c1"># Freeze 1/3
</span>            <span class="n">use_adapter</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">adapter_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="mf">2e-5</span><span class="p">,</span>
            <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
            <span class="n">gradient_accumulation</span><span class="o">=</span><span class="mi">2</span>
        <span class="p">)</span>
    
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="nc">TransferConfig</span><span class="p">(</span>
            <span class="n">strategy</span><span class="o">=</span><span class="n">TransferStrategy</span><span class="p">.</span><span class="n">HIGH_RESOURCE</span><span class="p">,</span>
            <span class="n">freeze_encoder</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
            <span class="n">freeze_layers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>  <span class="c1"># Fine-tune all
</span>            <span class="n">use_adapter</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>  <span class="c1"># Full fine-tuning
</span>            <span class="n">adapter_size</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
            <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span>
            <span class="n">gradient_accumulation</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span>
</code></pre></div></div>

<h3 id="42-phoneme-based-transfer">4.2 Phoneme-Based Transfer</h3>

<p>When target language has unique phonemes:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">PhonemeAdapter</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Map between source and target phoneme inventories.
    
    Essential for languages with sounds not in the pretrained model.
    </span><span class="sh">"""</span>
    
    <span class="c1"># IPA phoneme categories
</span>    <span class="n">MANNER_FEATURES</span> <span class="o">=</span> <span class="p">{</span>
        <span class="sh">'</span><span class="s">plosive</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">p</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">t</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">d</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">k</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">g</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">ʔ</span><span class="sh">'</span><span class="p">],</span>
        <span class="sh">'</span><span class="s">nasal</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">m</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">n</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">ŋ</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">ɲ</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">ɴ</span><span class="sh">'</span><span class="p">],</span>
        <span class="sh">'</span><span class="s">fricative</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">f</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">v</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">s</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">z</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">ʃ</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">ʒ</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">h</span><span class="sh">'</span><span class="p">],</span>
        <span class="sh">'</span><span class="s">affricate</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">tʃ</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">dʒ</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">ts</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">dz</span><span class="sh">'</span><span class="p">],</span>
        <span class="sh">'</span><span class="s">approximant</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">l</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">r</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">j</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">w</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">ɹ</span><span class="sh">'</span><span class="p">],</span>
        <span class="sh">'</span><span class="s">vowel</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">e</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">i</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">o</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">u</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">ə</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">æ</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">ɔ</span><span class="sh">'</span><span class="p">],</span>
    <span class="p">}</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">source_phonemes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">target_phonemes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">source</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">source_phonemes</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">target</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">target_phonemes</span><span class="p">)</span>
        
        <span class="c1"># Find phonemes needing mapping
</span>        <span class="n">self</span><span class="p">.</span><span class="n">missing_in_source</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">target</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">source</span>
        <span class="n">self</span><span class="p">.</span><span class="n">mapping</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_create_mapping</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">_create_mapping</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Map target phonemes to closest source phonemes.</span><span class="sh">"""</span>
        <span class="n">mapping</span> <span class="o">=</span> <span class="p">{}</span>
        
        <span class="k">for</span> <span class="n">target_phone</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">missing_in_source</span><span class="p">:</span>
            <span class="n">closest</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_find_closest_phoneme</span><span class="p">(</span><span class="n">target_phone</span><span class="p">)</span>
            <span class="n">mapping</span><span class="p">[</span><span class="n">target_phone</span><span class="p">]</span> <span class="o">=</span> <span class="n">closest</span>
            
        <span class="k">return</span> <span class="n">mapping</span>
    
    <span class="k">def</span> <span class="nf">_find_closest_phoneme</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">phone</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Find closest phoneme based on articulatory features.</span><span class="sh">"""</span>
        <span class="c1"># Get features of target phoneme
</span>        <span class="n">target_features</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_get_features</span><span class="p">(</span><span class="n">phone</span><span class="p">)</span>
        
        <span class="n">best_match</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="n">best_score</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        
        <span class="k">for</span> <span class="n">source_phone</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">source</span><span class="p">:</span>
            <span class="n">source_features</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_get_features</span><span class="p">(</span><span class="n">source_phone</span><span class="p">)</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_feature_similarity</span><span class="p">(</span><span class="n">target_features</span><span class="p">,</span> <span class="n">source_features</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">score</span> <span class="o">&gt;</span> <span class="n">best_score</span><span class="p">:</span>
                <span class="n">best_score</span> <span class="o">=</span> <span class="n">score</span>
                <span class="n">best_match</span> <span class="o">=</span> <span class="n">source_phone</span>
        
        <span class="k">return</span> <span class="n">best_match</span>
    
    <span class="k">def</span> <span class="nf">_get_features</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">phone</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Extract articulatory features for a phoneme.</span><span class="sh">"""</span>
        <span class="n">features</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">manner</span><span class="sh">'</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">voiced</span><span class="sh">'</span><span class="p">:</span> <span class="n">phone</span><span class="p">.</span><span class="nf">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">d</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">g</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">v</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">z</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">ʒ</span><span class="sh">'</span><span class="p">],</span>
            <span class="sh">'</span><span class="s">front</span><span class="sh">'</span><span class="p">:</span> <span class="n">phone</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">i</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">e</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">æ</span><span class="sh">'</span><span class="p">],</span>
            <span class="sh">'</span><span class="s">back</span><span class="sh">'</span><span class="p">:</span> <span class="n">phone</span> <span class="ow">in</span> <span class="p">[</span><span class="sh">'</span><span class="s">u</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">o</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">ɔ</span><span class="sh">'</span><span class="p">],</span>
        <span class="p">}</span>
        
        <span class="k">for</span> <span class="n">manner</span><span class="p">,</span> <span class="n">phones</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">MANNER_FEATURES</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">phone</span> <span class="ow">in</span> <span class="n">phones</span><span class="p">:</span>
                <span class="n">features</span><span class="p">[</span><span class="sh">'</span><span class="s">manner</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">manner</span>
                <span class="k">break</span>
        
        <span class="k">return</span> <span class="n">features</span>
    
    <span class="k">def</span> <span class="nf">_feature_similarity</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">f1</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">f2</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Compute similarity between feature sets.</span><span class="sh">"""</span>
        <span class="n">score</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">f1</span><span class="p">[</span><span class="sh">'</span><span class="s">manner</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="n">f2</span><span class="p">[</span><span class="sh">'</span><span class="s">manner</span><span class="sh">'</span><span class="p">]:</span>
            <span class="n">score</span> <span class="o">+=</span> <span class="mf">0.5</span>
        <span class="k">if</span> <span class="n">f1</span><span class="p">[</span><span class="sh">'</span><span class="s">voiced</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="n">f2</span><span class="p">[</span><span class="sh">'</span><span class="s">voiced</span><span class="sh">'</span><span class="p">]:</span>
            <span class="n">score</span> <span class="o">+=</span> <span class="mf">0.25</span>
        <span class="k">if</span> <span class="n">f1</span><span class="p">[</span><span class="sh">'</span><span class="s">front</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="n">f2</span><span class="p">[</span><span class="sh">'</span><span class="s">front</span><span class="sh">'</span><span class="p">]</span> <span class="ow">and</span> <span class="n">f1</span><span class="p">[</span><span class="sh">'</span><span class="s">back</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="n">f2</span><span class="p">[</span><span class="sh">'</span><span class="s">back</span><span class="sh">'</span><span class="p">]:</span>
            <span class="n">score</span> <span class="o">+=</span> <span class="mf">0.25</span>
        <span class="k">return</span> <span class="n">score</span>
    
    <span class="k">def</span> <span class="nf">adapt_labels</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">Convert target phoneme labels using mapping.</span><span class="sh">"""</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="n">mapping</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">]</span>
</code></pre></div></div>

<h3 id="43-multi-source-transfer">4.3 Multi-Source Transfer</h3>

<p>Leverage multiple high-resource languages:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MultiSourceTransfer</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Transfer from multiple source languages.
    
    Research shows multi-source transfer outperforms single-source,
    especially when sources cover the target</span><span class="sh">'</span><span class="s">s phoneme inventory.
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">source_models</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>  <span class="c1"># {language: model}
</span>        <span class="n">target_language</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">fusion_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">"</span><span class="s">attention</span><span class="sh">"</span>
    <span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">source_models</span> <span class="o">=</span> <span class="n">source_models</span>
        <span class="n">self</span><span class="p">.</span><span class="n">target_language</span> <span class="o">=</span> <span class="n">target_language</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fusion_method</span> <span class="o">=</span> <span class="n">fusion_method</span>
        
        <span class="c1"># Compute language similarities
</span>        <span class="n">self</span><span class="p">.</span><span class="n">source_weights</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_compute_language_weights</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">_compute_language_weights</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Weight source languages by similarity to target.</span><span class="sh">"""</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="p">{}</span>
        
        <span class="k">for</span> <span class="n">lang</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">source_models</span><span class="p">:</span>
            <span class="c1"># Factors: linguistic distance, phoneme overlap, data quality
</span>            <span class="n">similarity</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_compute_similarity</span><span class="p">(</span><span class="n">lang</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">target_language</span><span class="p">)</span>
            <span class="n">weights</span><span class="p">[</span><span class="n">lang</span><span class="p">]</span> <span class="o">=</span> <span class="n">similarity</span>
        
        <span class="c1"># Normalize
</span>        <span class="n">total</span> <span class="o">=</span> <span class="nf">sum</span><span class="p">(</span><span class="n">weights</span><span class="p">.</span><span class="nf">values</span><span class="p">())</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">/</span><span class="n">total</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">weights</span><span class="p">.</span><span class="nf">items</span><span class="p">()}</span>
    
    <span class="k">def</span> <span class="nf">_compute_similarity</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">source</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Compute linguistic similarity.</span><span class="sh">"""</span>
        <span class="c1"># Based on language family, phoneme inventory, etc.
</span>        <span class="c1"># Simplified for illustration
</span>        <span class="n">SIMILARITIES</span> <span class="o">=</span> <span class="p">{</span>
            <span class="p">(</span><span class="sh">'</span><span class="s">english</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">german</span><span class="sh">'</span><span class="p">):</span> <span class="mf">0.8</span><span class="p">,</span>
            <span class="p">(</span><span class="sh">'</span><span class="s">english</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">french</span><span class="sh">'</span><span class="p">):</span> <span class="mf">0.6</span><span class="p">,</span>
            <span class="p">(</span><span class="sh">'</span><span class="s">english</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">mandarin</span><span class="sh">'</span><span class="p">):</span> <span class="mf">0.3</span><span class="p">,</span>
            <span class="p">(</span><span class="sh">'</span><span class="s">mandarin</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">cantonese</span><span class="sh">'</span><span class="p">):</span> <span class="mf">0.85</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">return</span> <span class="n">SIMILARITIES</span><span class="p">.</span><span class="nf">get</span><span class="p">((</span><span class="n">source</span><span class="p">,</span> <span class="n">target</span><span class="p">),</span> <span class="mf">0.5</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">get_combined_features</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Get features from all source models and combine.
        </span><span class="sh">"""</span>
        <span class="n">features</span> <span class="o">=</span> <span class="p">{}</span>
        
        <span class="k">for</span> <span class="n">lang</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">source_models</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
            <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
                <span class="n">feat</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">get_features</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
            <span class="n">features</span><span class="p">[</span><span class="n">lang</span><span class="p">]</span> <span class="o">=</span> <span class="n">feat</span>
        
        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">fusion_method</span> <span class="o">==</span> <span class="sh">"</span><span class="s">weighted_avg</span><span class="sh">"</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">_weighted_average</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">self</span><span class="p">.</span><span class="n">fusion_method</span> <span class="o">==</span> <span class="sh">"</span><span class="s">attention</span><span class="sh">"</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">_attention_fusion</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">self</span><span class="p">.</span><span class="n">fusion_method</span> <span class="o">==</span> <span class="sh">"</span><span class="s">concat</span><span class="sh">"</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">_concatenate</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_weighted_average</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">features</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Weighted average based on language similarity.</span><span class="sh">"""</span>
        <span class="n">combined</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">for</span> <span class="n">lang</span><span class="p">,</span> <span class="n">feat</span> <span class="ow">in</span> <span class="n">features</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">source_weights</span><span class="p">[</span><span class="n">lang</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">combined</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">combined</span> <span class="o">=</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">feat</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">combined</span> <span class="o">+=</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">feat</span>
        <span class="k">return</span> <span class="n">combined</span>
    
    <span class="k">def</span> <span class="nf">_attention_fusion</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">features</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Learn attention weights during fine-tuning.</span><span class="sh">"""</span>
        <span class="c1"># Stack features: (num_sources, batch, seq_len, hidden)
</span>        <span class="n">stacked</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">(</span><span class="nf">list</span><span class="p">(</span><span class="n">features</span><span class="p">.</span><span class="nf">values</span><span class="p">()),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        
        <span class="c1"># Apply learned attention
</span>        <span class="c1"># (Implementation would include learnable query)
</span>        <span class="k">return</span> <span class="n">stacked</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Simplified
</span></code></pre></div></div>

<h2 id="5-training-pipeline">5. Training Pipeline</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">get_linear_schedule_with_warmup</span>
<span class="kn">import</span> <span class="n">wandb</span>

<span class="k">class</span> <span class="nc">CrossLingualTrainer</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Training pipeline for cross-lingual ASR.
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">CrossLingualASR</span><span class="p">,</span>
        <span class="n">train_dataset</span><span class="p">,</span>
        <span class="n">eval_dataset</span><span class="p">,</span>
        <span class="n">config</span><span class="p">:</span> <span class="n">TransferConfig</span><span class="p">,</span>
        <span class="n">output_dir</span><span class="p">:</span> <span class="nb">str</span>
    <span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="n">self</span><span class="p">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span>
        <span class="n">self</span><span class="p">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">eval_dataset</span>
        <span class="n">self</span><span class="p">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
        <span class="n">self</span><span class="p">.</span><span class="n">output_dir</span> <span class="o">=</span> <span class="n">output_dir</span>
        
        <span class="c1"># Setup training
</span>        <span class="n">self</span><span class="p">.</span><span class="n">train_loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span>
            <span class="n">train_dataset</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
            <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">collate_fn</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">_collate_fn</span>
        <span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">eval_loader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span>
            <span class="n">eval_dataset</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
            <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
            <span class="n">collate_fn</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">_collate_fn</span>
        <span class="p">)</span>
        
        <span class="c1"># Optimizer (only trainable params)
</span>        <span class="n">trainable_params</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="p">.</span><span class="n">requires_grad</span><span class="p">]</span>
        <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">AdamW</span><span class="p">(</span>
            <span class="n">trainable_params</span><span class="p">,</span>
            <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.01</span>
        <span class="p">)</span>
        
        <span class="c1"># Scheduler
</span>        <span class="n">total_steps</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">train_loader</span><span class="p">)</span> <span class="o">*</span> <span class="mi">10</span>  <span class="c1"># 10 epochs
</span>        <span class="n">self</span><span class="p">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="nf">get_linear_schedule_with_warmup</span><span class="p">(</span>
            <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">,</span>
            <span class="n">num_warmup_steps</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">warmup_steps</span><span class="p">,</span>
            <span class="n">num_training_steps</span><span class="o">=</span><span class="n">total_steps</span>
        <span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Run training loop.</span><span class="sh">"""</span>
        
        <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">"</span><span class="s">cuda</span><span class="sh">"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="sh">"</span><span class="s">cpu</span><span class="sh">"</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="n">best_wer</span> <span class="o">=</span> <span class="nf">float</span><span class="p">(</span><span class="sh">'</span><span class="s">inf</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">patience</span> <span class="o">=</span> <span class="mi">3</span>
        <span class="n">patience_counter</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
            <span class="c1"># Training
</span>            <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
            <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
            
            <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">train_loader</span><span class="p">):</span>
                <span class="c1"># Move to device
</span>                <span class="n">batch</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">.</span><span class="nf">items</span><span class="p">()}</span>
                
                <span class="c1"># Forward pass
</span>                <span class="n">outputs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="sh">"</span><span class="s">loss</span><span class="sh">"</span><span class="p">]</span>
                
                <span class="c1"># Backward pass
</span>                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">/</span> <span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">gradient_accumulation</span>
                <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
                
                <span class="nf">if </span><span class="p">(</span><span class="n">batch_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">gradient_accumulation</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="nf">clip_grad_norm_</span><span class="p">(</span>
                        <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> 
                        <span class="n">max_norm</span><span class="o">=</span><span class="mf">1.0</span>
                    <span class="p">)</span>
                    <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
                    <span class="n">self</span><span class="p">.</span><span class="n">scheduler</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
                    <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
                
                <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>
            
            <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">train_loader</span><span class="p">)</span>
            
            <span class="c1"># Evaluation
</span>            <span class="n">wer</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_evaluate</span><span class="p">()</span>
            
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s">: Loss=</span><span class="si">{</span><span class="n">avg_loss</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">, WER=</span><span class="si">{</span><span class="n">wer</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="o">%</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
            
            <span class="c1"># Early stopping
</span>            <span class="k">if</span> <span class="n">wer</span> <span class="o">&lt;</span> <span class="n">best_wer</span><span class="p">:</span>
                <span class="n">best_wer</span> <span class="o">=</span> <span class="n">wer</span>
                <span class="n">self</span><span class="p">.</span><span class="nf">_save_checkpoint</span><span class="p">(</span><span class="sh">"</span><span class="s">best</span><span class="sh">"</span><span class="p">)</span>
                <span class="n">patience_counter</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">patience_counter</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="n">patience_counter</span> <span class="o">&gt;=</span> <span class="n">patience</span><span class="p">:</span>
                    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Early stopping at epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
                    <span class="k">break</span>
        
        <span class="k">return</span> <span class="n">best_wer</span>
    
    <span class="k">def</span> <span class="nf">_evaluate</span><span class="p">(</span><span class="n">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Evaluate model and return WER.</span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
        <span class="n">all_preds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">all_refs</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">eval_loader</span><span class="p">:</span>
                <span class="n">device</span> <span class="o">=</span> <span class="nf">next</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()).</span><span class="n">device</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">.</span><span class="nf">items</span><span class="p">()}</span>
                
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
                <span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="sh">"</span><span class="s">logits</span><span class="sh">"</span><span class="p">]</span>
                
                <span class="c1"># Decode predictions
</span>                <span class="n">pred_ids</span> <span class="o">=</span> <span class="n">logits</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">preds</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_decode</span><span class="p">(</span><span class="n">pred_ids</span><span class="p">)</span>
                <span class="n">refs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_decode</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="sh">"</span><span class="s">labels</span><span class="sh">"</span><span class="p">])</span>
                
                <span class="n">all_preds</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
                <span class="n">all_refs</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span><span class="n">refs</span><span class="p">)</span>
        
        <span class="c1"># Compute WER
</span>        <span class="n">wer</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_compute_wer</span><span class="p">(</span><span class="n">all_preds</span><span class="p">,</span> <span class="n">all_refs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">wer</span>
    
    <span class="k">def</span> <span class="nf">_compute_wer</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">predictions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">references</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Compute Word Error Rate.</span><span class="sh">"""</span>
        <span class="kn">from</span> <span class="n">jiwer</span> <span class="kn">import</span> <span class="n">wer</span>
        <span class="k">return</span> <span class="nf">wer</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_decode</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">token_ids</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">Decode token IDs to text.</span><span class="sh">"""</span>
        <span class="c1"># Use CTC decoding (greedy or beam search)
</span>        <span class="c1"># Simplified implementation
</span>        <span class="n">texts</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">ids</span> <span class="ow">in</span> <span class="n">token_ids</span><span class="p">:</span>
            <span class="c1"># Remove blanks and duplicates
</span>            <span class="n">prev</span> <span class="o">=</span> <span class="bp">None</span>
            <span class="n">decoded</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="nb">id</span> <span class="ow">in</span> <span class="n">ids</span><span class="p">.</span><span class="nf">tolist</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">id</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">id</span> <span class="o">!=</span> <span class="n">prev</span><span class="p">:</span>  <span class="c1"># 0 is blank
</span>                    <span class="n">decoded</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nb">id</span><span class="p">)</span>
                <span class="n">prev</span> <span class="o">=</span> <span class="nb">id</span>
            <span class="n">texts</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="nf">map</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">decoded</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">texts</span>
    
    <span class="k">def</span> <span class="nf">_collate_fn</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Collate function for DataLoader.</span><span class="sh">"""</span>
        <span class="c1"># Pad audio to same length
</span>        <span class="c1"># Pad labels with -100 for CTC loss
</span>        <span class="k">pass</span>
    
    <span class="k">def</span> <span class="nf">_save_checkpoint</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Save model checkpoint.</span><span class="sh">"""</span>
        <span class="n">torch</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span>
            <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">state_dict</span><span class="p">(),</span>
            <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">self</span><span class="p">.</span><span class="n">output_dir</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s">.pt</span><span class="sh">"</span>
        <span class="p">)</span>
</code></pre></div></div>

<h2 id="6-production-deployment">6. Production Deployment</h2>

<h3 id="61-multi-language-server-architecture">6.1 Multi-Language Server Architecture</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>┌─────────────────────────────────────────────────────────────────┐
│              Cross-Lingual ASR Production System                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Audio Input                                                    │
│       │                                                         │
│       ▼                                                         │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │ Language Identification (LID)                            │    │
│  │ - Fast acoustic-based detection                         │    │
│  │ - &lt;50ms latency                                         │    │
│  └─────────────────────────────────────────────────────────┘    │
│       │                                                         │
│       ▼                                                         │
│  ┌─────────────────────────────────────────────────────────┐    │
│  │ Model Router                                            │    │
│  │                                                         │    │
│  │  ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌──────────┐    │    │
│  │  │ English  │ │ Spanish  │ │ Mandarin │ │ Universal│    │    │
│  │  │ Adapter  │ │ Adapter  │ │ Adapter  │ │ Model    │    │    │
│  │  └──────────┘ └──────────┘ └──────────┘ └──────────┘    │    │
│  │                                                         │    │
│  │  Shared Encoder: XLSR-53 (loaded once, 1.2GB)          │    │
│  │  Per-lang adapter: ~10MB each                          │    │
│  │                                                         │    │
│  └─────────────────────────────────────────────────────────┘    │
│       │                                                         │
│       ▼                                                         │
│  Transcription (language-specific post-processing)              │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
</code></pre></div></div>

<h3 id="62-efficient-multi-language-serving">6.2 Efficient Multi-Language Serving</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MultiLingualASRServer</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Production server supporting 100+ languages efficiently.
    
    Key optimizations:
    - Single shared encoder (largest component)
    - Lightweight language-specific adapters
    - Dynamic adapter loading
    - Batching across languages
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">base_encoder_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">adapter_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">supported_languages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">"</span><span class="s">cuda</span><span class="sh">"</span>
    <span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="c1"># Load shared encoder once
</span>        <span class="n">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_load_encoder</span><span class="p">(</span><span class="n">base_encoder_path</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
        
        <span class="c1"># Load adapters lazily
</span>        <span class="n">self</span><span class="p">.</span><span class="n">adapter_dir</span> <span class="o">=</span> <span class="n">adapter_dir</span>
        <span class="n">self</span><span class="p">.</span><span class="n">adapters</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">self</span><span class="p">.</span><span class="n">adapter_cache_size</span> <span class="o">=</span> <span class="mi">20</span>  <span class="c1"># Keep 20 adapters in memory
</span>        <span class="n">self</span><span class="p">.</span><span class="n">adapter_lru</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="c1"># Language identification model
</span>        <span class="n">self</span><span class="p">.</span><span class="n">lid_model</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_load_lid_model</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">transcribe</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">audio</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">language</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Transcribe audio, optionally with specified language.
        </span><span class="sh">"""</span>
        <span class="c1"># Auto-detect language if not specified
</span>        <span class="k">if</span> <span class="n">language</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">language</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_detect_language</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
        
        <span class="c1"># Get appropriate adapter
</span>        <span class="n">adapter</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_get_adapter</span><span class="p">(</span><span class="n">language</span><span class="p">)</span>
        
        <span class="c1"># Run inference
</span>        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="c1"># Encode audio
</span>            <span class="n">features</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">encoder</span><span class="p">(</span><span class="n">audio</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">device</span><span class="p">))</span>
            
            <span class="c1"># Apply language adapter
</span>            <span class="n">features</span> <span class="o">=</span> <span class="nf">adapter</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
            
            <span class="c1"># Decode
</span>            <span class="n">transcription</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_decode</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">language</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">transcription</span>
    
    <span class="k">def</span> <span class="nf">_get_adapter</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">language</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Get adapter with LRU caching.</span><span class="sh">"""</span>
        <span class="k">if</span> <span class="n">language</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">adapters</span><span class="p">:</span>
            <span class="c1"># Check cache limit
</span>            <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">adapters</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">self</span><span class="p">.</span><span class="n">adapter_cache_size</span><span class="p">:</span>
                <span class="c1"># Remove least recently used
</span>                <span class="n">oldest</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">adapter_lru</span><span class="p">.</span><span class="nf">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="k">del</span> <span class="n">self</span><span class="p">.</span><span class="n">adapters</span><span class="p">[</span><span class="n">oldest</span><span class="p">]</span>
                <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">empty_cache</span><span class="p">()</span>
            
            <span class="c1"># Load adapter
</span>            <span class="n">adapter_path</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">self</span><span class="p">.</span><span class="n">adapter_dir</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">language</span><span class="si">}</span><span class="s">_adapter.pt</span><span class="sh">"</span>
            <span class="n">adapter</span> <span class="o">=</span> <span class="nc">LanguageAdapter</span><span class="p">(</span><span class="n">hidden_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">adapter_size</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
            <span class="n">adapter</span><span class="p">.</span><span class="nf">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">adapter_path</span><span class="p">))</span>
            <span class="n">adapter</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">adapter</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
            
            <span class="n">self</span><span class="p">.</span><span class="n">adapters</span><span class="p">[</span><span class="n">language</span><span class="p">]</span> <span class="o">=</span> <span class="n">adapter</span>
        
        <span class="c1"># Update LRU order
</span>        <span class="k">if</span> <span class="n">language</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">adapter_lru</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">adapter_lru</span><span class="p">.</span><span class="nf">remove</span><span class="p">(</span><span class="n">language</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">adapter_lru</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">language</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">adapters</span><span class="p">[</span><span class="n">language</span><span class="p">]</span>
    
    <span class="k">def</span> <span class="nf">_detect_language</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Detect language from audio.</span><span class="sh">"""</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="n">probs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">lid_model</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
            <span class="n">language_idx</span> <span class="o">=</span> <span class="n">probs</span><span class="p">.</span><span class="nf">argmax</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">LANGUAGE_MAP</span><span class="p">[</span><span class="n">language_idx</span><span class="p">.</span><span class="nf">item</span><span class="p">()]</span>
    
    <span class="k">def</span> <span class="nf">batch_transcribe</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">audios</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">languages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">
        Batch transcription with language-aware routing.
        
        Groups by language for efficient batching.
        </span><span class="sh">"""</span>
        <span class="c1"># Group by language
</span>        <span class="n">language_groups</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">lang</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">audios</span><span class="p">,</span> <span class="n">languages</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">lang</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">language_groups</span><span class="p">:</span>
                <span class="n">language_groups</span><span class="p">[</span><span class="n">lang</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">language_groups</span><span class="p">[</span><span class="n">lang</span><span class="p">].</span><span class="nf">append</span><span class="p">((</span><span class="n">i</span><span class="p">,</span> <span class="n">audio</span><span class="p">))</span>
        
        <span class="n">results</span> <span class="o">=</span> <span class="p">[</span><span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="nf">len</span><span class="p">(</span><span class="n">audios</span><span class="p">)</span>
        
        <span class="c1"># Process each language group
</span>        <span class="k">for</span> <span class="n">lang</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">language_groups</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
            <span class="n">indices</span><span class="p">,</span> <span class="n">group_audios</span> <span class="o">=</span> <span class="nf">zip</span><span class="p">(</span><span class="o">*</span><span class="n">group</span><span class="p">)</span>
            
            <span class="c1"># Batch process
</span>            <span class="n">adapter</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_get_adapter</span><span class="p">(</span><span class="n">lang</span><span class="p">)</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">stack</span><span class="p">([</span><span class="n">a</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">group_audios</span><span class="p">])</span>
            
            <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
                <span class="n">features</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">encoder</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
                <span class="n">features</span> <span class="o">=</span> <span class="nf">adapter</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
                <span class="n">transcriptions</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_batch_decode</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">lang</span><span class="p">)</span>
            
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">trans</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">transcriptions</span><span class="p">):</span>
                <span class="n">results</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">trans</span>
        
        <span class="k">return</span> <span class="n">results</span>
</code></pre></div></div>

<h2 id="7-quality-metrics-and-evaluation">7. Quality Metrics and Evaluation</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">CrossLingualEvaluator</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Comprehensive evaluation for cross-lingual ASR.
    </span><span class="sh">"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">reference_data</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">
        Args:
            reference_data: {language: [(audio_path, transcription), ...]}
        </span><span class="sh">"""</span>
        <span class="n">self</span><span class="p">.</span><span class="n">reference_data</span> <span class="o">=</span> <span class="n">reference_data</span>
    
    <span class="k">def</span> <span class="nf">evaluate_language</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">language</span><span class="p">:</span> <span class="nb">str</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">Evaluate on a single language.</span><span class="sh">"""</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">references</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">audio_path</span><span class="p">,</span> <span class="n">reference</span> <span class="ow">in</span> <span class="n">self</span><span class="p">.</span><span class="n">reference_data</span><span class="p">[</span><span class="n">language</span><span class="p">]:</span>
            <span class="n">audio</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_load_audio</span><span class="p">(</span><span class="n">audio_path</span><span class="p">)</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">transcribe</span><span class="p">(</span><span class="n">audio</span><span class="p">,</span> <span class="n">language</span><span class="o">=</span><span class="n">language</span><span class="p">)</span>
            
            <span class="n">predictions</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
            <span class="n">references</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">reference</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">wer</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="nf">_compute_wer</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="p">),</span>
            <span class="sh">'</span><span class="s">cer</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="nf">_compute_cer</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="p">),</span>
            <span class="sh">'</span><span class="s">substitutions</span><span class="sh">'</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="nf">_analyze_errors</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="p">),</span>
        <span class="p">}</span>
    
    <span class="k">def</span> <span class="nf">evaluate_cross_lingual_transfer</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">source_languages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">target_language</span><span class="p">:</span> <span class="nb">str</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Evaluate transfer effectiveness.
        </span><span class="sh">"""</span>
        <span class="c1"># Baseline: Target language only (or zero-shot)
</span>        <span class="n">target_metrics</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">evaluate_language</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">target_language</span><span class="p">)</span>
        
        <span class="c1"># Analyze phoneme-level transfer
</span>        <span class="n">phoneme_analysis</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_analyze_phoneme_transfer</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span> 
            <span class="n">source_languages</span><span class="p">,</span> 
            <span class="n">target_language</span>
        <span class="p">)</span>
        
        <span class="k">return</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">target_wer</span><span class="sh">'</span><span class="p">:</span> <span class="n">target_metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">wer</span><span class="sh">'</span><span class="p">],</span>
            <span class="sh">'</span><span class="s">target_cer</span><span class="sh">'</span><span class="p">:</span> <span class="n">target_metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">cer</span><span class="sh">'</span><span class="p">],</span>
            <span class="sh">'</span><span class="s">phoneme_transfer</span><span class="sh">'</span><span class="p">:</span> <span class="n">phoneme_analysis</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">error_analysis</span><span class="sh">'</span><span class="p">:</span> <span class="n">target_metrics</span><span class="p">[</span><span class="sh">'</span><span class="s">substitutions</span><span class="sh">'</span><span class="p">],</span>
        <span class="p">}</span>
    
    <span class="k">def</span> <span class="nf">_analyze_phoneme_transfer</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">sources</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">target</span><span class="p">:</span> <span class="nb">str</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Analyze which phonemes transfer well.
        </span><span class="sh">"""</span>
        <span class="c1"># Get phoneme inventories
</span>        <span class="n">source_phonemes</span> <span class="o">=</span> <span class="nf">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">lang</span> <span class="ow">in</span> <span class="n">sources</span><span class="p">:</span>
            <span class="n">source_phonemes</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">_get_phoneme_inventory</span><span class="p">(</span><span class="n">lang</span><span class="p">))</span>
        
        <span class="n">target_phonemes</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_get_phoneme_inventory</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
        
        <span class="c1"># Categorize phonemes
</span>        <span class="n">shared</span> <span class="o">=</span> <span class="n">source_phonemes</span> <span class="o">&amp;</span> <span class="n">target_phonemes</span>
        <span class="n">unique_to_target</span> <span class="o">=</span> <span class="n">target_phonemes</span> <span class="o">-</span> <span class="n">source_phonemes</span>
        
        <span class="c1"># Evaluate performance on each category
</span>        <span class="n">shared_accuracy</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_evaluate_phoneme_category</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">shared</span><span class="p">)</span>
        <span class="n">unique_accuracy</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">_evaluate_phoneme_category</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">unique_to_target</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="p">{</span>
            <span class="sh">'</span><span class="s">shared_phoneme_count</span><span class="sh">'</span><span class="p">:</span> <span class="nf">len</span><span class="p">(</span><span class="n">shared</span><span class="p">),</span>
            <span class="sh">'</span><span class="s">unique_phoneme_count</span><span class="sh">'</span><span class="p">:</span> <span class="nf">len</span><span class="p">(</span><span class="n">unique_to_target</span><span class="p">),</span>
            <span class="sh">'</span><span class="s">shared_accuracy</span><span class="sh">'</span><span class="p">:</span> <span class="n">shared_accuracy</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">unique_accuracy</span><span class="sh">'</span><span class="p">:</span> <span class="n">unique_accuracy</span><span class="p">,</span>
            <span class="sh">'</span><span class="s">transfer_gap</span><span class="sh">'</span><span class="p">:</span> <span class="n">shared_accuracy</span> <span class="o">-</span> <span class="n">unique_accuracy</span><span class="p">,</span>
        <span class="p">}</span>
    
    <span class="k">def</span> <span class="nf">_compute_wer</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="p">):</span>
        <span class="kn">from</span> <span class="n">jiwer</span> <span class="kn">import</span> <span class="n">wer</span>
        <span class="k">return</span> <span class="nf">wer</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_compute_cer</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="p">):</span>
        <span class="kn">from</span> <span class="n">jiwer</span> <span class="kn">import</span> <span class="n">cer</span>
        <span class="k">return</span> <span class="nf">cer</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="8-real-world-case-study-metas-mms">8. Real-World Case Study: Meta’s MMS</h2>

<p>Meta’s Massively Multilingual Speech (MMS) project demonstrates cross-lingual transfer at unprecedented scale:</p>

<p><strong>Scale:</strong></p>
<ul>
  <li>1,107 languages (10x previous coverage)</li>
  <li>491,000 hours of audio</li>
  <li>Models from 30M to 1B parameters</li>
</ul>

<p><strong>Key Innovations:</strong></p>
<ol>
  <li><strong>Data sourcing</strong>: Religious texts available in many languages</li>
  <li><strong>Wav2Vec 2.0 pretraining</strong>: Self-supervised on unlabeled audio</li>
  <li><strong>Adapter-based fine-tuning</strong>: Efficient multi-language deployment</li>
</ol>

<p><strong>Results by resource level:</strong></p>

<table>
  <thead>
    <tr>
      <th>Category</th>
      <th>Languages</th>
      <th>Average WER</th>
      <th>Improvement</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>High-resource (&gt;100h)</td>
      <td>~50</td>
      <td>9.1%</td>
      <td>Baseline</td>
    </tr>
    <tr>
      <td>Medium-resource (10-100h)</td>
      <td>~200</td>
      <td>18.5%</td>
      <td>vs 45% scratch</td>
    </tr>
    <tr>
      <td>Low-resource (1-10h)</td>
      <td>~400</td>
      <td>28.3%</td>
      <td>vs 65% scratch</td>
    </tr>
    <tr>
      <td>Very low (&lt;1h)</td>
      <td>~450</td>
      <td>41.2%</td>
      <td>vs 80%+ scratch</td>
    </tr>
  </tbody>
</table>

<h2 id="9-common-failure-modes">9. Common Failure Modes</h2>

<h3 id="failure-mode-1-tone-confusion">Failure Mode 1: Tone Confusion</h3>

<p><strong>Problem:</strong> Non-tonal source models struggle with tonal languages
<strong>Example:</strong> Mandarin tone errors (mā/má/mǎ/mà all map to “ma”)</p>

<p><strong>Solution:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ToneAdapter</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Additional adapter for tone prediction.
    </span><span class="sh">"""</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">num_tones</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">tone_classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_tones</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">):</span>
        <span class="c1"># Predict tone alongside phonemes
</span>        <span class="n">tone_logits</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">tone_classifier</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tone_logits</span>
</code></pre></div></div>

<h3 id="failure-mode-2-code-switching-boundaries">Failure Mode 2: Code-Switching Boundaries</h3>

<p><strong>Problem:</strong> Model fails when speakers switch languages mid-sentence
<strong>Solution:</strong> Train with code-switched data or use language ID per segment</p>

<h3 id="failure-mode-3-unique-phoneme-collapse">Failure Mode 3: Unique Phoneme Collapse</h3>

<p><strong>Problem:</strong> Target language phonemes not in source collapse to nearest neighbor
<strong>Example:</strong> Click consonants in Zulu mapped to stops</p>

<p><strong>Solution:</strong> Add target-specific phoneme prototypes during fine-tuning</p>

<h2 id="10-connection-to-transfer-learning-systems">10. Connection to Transfer Learning Systems</h2>

<p>Cross-lingual speech transfer and general transfer learning share core principles:</p>

<table>
  <thead>
    <tr>
      <th>Concept</th>
      <th>ML Transfer Learning</th>
      <th>Cross-Lingual Speech</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Universal features</td>
      <td>Early CNN layers</td>
      <td>Acoustic encoder layers</td>
    </tr>
    <tr>
      <td>Task-specific</td>
      <td>Classification head</td>
      <td>Language-specific decoder</td>
    </tr>
    <tr>
      <td>Domain shift</td>
      <td>Vision → Medical</td>
      <td>English → Mandarin</td>
    </tr>
    <tr>
      <td>Adaptation method</td>
      <td>LoRA, adapters</td>
      <td>Language adapters</td>
    </tr>
    <tr>
      <td>Negative transfer</td>
      <td>Wrong pretrained model</td>
      <td>Wrong source language</td>
    </tr>
  </tbody>
</table>

<p>Both implement the same fundamental insight: <strong>hierarchical representations where lower levels are more universal</strong>.</p>

<h2 id="11-key-takeaways">11. Key Takeaways</h2>

<ol>
  <li><strong>Acoustic features are universal</strong> - Lower encoder layers transfer across all languages</li>
  <li><strong>Phoneme overlap matters</strong> - Transfer works best within language families</li>
  <li><strong>Adapters are efficient</strong> - Add &lt;1% parameters for new languages</li>
  <li><strong>Less is more for low-resource</strong> - Freeze more layers when data is scarce</li>
  <li><strong>Tone needs special handling</strong> - Non-tonal → tonal requires explicit adaptation</li>
  <li><strong>Multi-source beats single-source</strong> - Combine multiple high-resource languages</li>
  <li><strong>Production efficiency</strong> - Share encoder, load adapters dynamically</li>
</ol>

<p>Cross-lingual transfer is transforming speech technology by making ASR accessible for thousands of languages previously underserved. The key insight—that human speech shares universal acoustic properties—enables knowledge transfer that would otherwise require impossibly large datasets.</p>

<hr />

<p><strong>Originally published at:</strong> <a href="https://www.arunbaby.com/speech-tech/0046-cross-lingual-speech-transfer/">arunbaby.com/speech-tech/0046-cross-lingual-speech-transfer</a></p>

<p><em>If you found this helpful, consider sharing it with others who might benefit.</em></p>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#cross-lingual" class="page__taxonomy-item p-category" rel="tag">cross-lingual</a><span class="sep">, </span>
    
      <a href="/tags/#domain-adaptation" class="page__taxonomy-item p-category" rel="tag">domain-adaptation</a><span class="sep">, </span>
    
      <a href="/tags/#low-resource-languages" class="page__taxonomy-item p-category" rel="tag">low-resource-languages</a><span class="sep">, </span>
    
      <a href="/tags/#multilingual-asr" class="page__taxonomy-item p-category" rel="tag">multilingual-asr</a><span class="sep">, </span>
    
      <a href="/tags/#speech-recognition" class="page__taxonomy-item p-category" rel="tag">speech-recognition</a><span class="sep">, </span>
    
      <a href="/tags/#transfer-learning" class="page__taxonomy-item p-category" rel="tag">transfer-learning</a><span class="sep">, </span>
    
      <a href="/tags/#wav2vec" class="page__taxonomy-item p-category" rel="tag">wav2vec</a><span class="sep">, </span>
    
      <a href="/tags/#whisper" class="page__taxonomy-item p-category" rel="tag">whisper</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#speech-tech" class="page__taxonomy-item p-category" rel="tag">speech-tech</a>
    
    </span>
  </p>


        
      </footer>

      <div class="page__related page__related--full">
  <h2 class="page__related-title">Related across topics</h2>
  <style>
    /* Make section span full content width and use 2 equal columns */
    .page__related--full { float: inline-start; width: 100%; padding: 0; }
    .cross-related-grid { display: grid; grid-template-columns: repeat(2, minmax(0, 1fr)); gap: 2rem; }
    @media (max-width: 768px) { .cross-related-grid { grid-template-columns: 1fr; } }
    /* Ensure archive cards stretch nicely in the grid */
    .cross-related-grid .list__item, .cross-related-grid .grid__item { width: auto; float: none; margin: 0; }
  </style>
  <div class="cross-related-grid">
    



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/dsa/0046-binary-tree-max-path-sum/" rel="permalink">Binary Tree Maximum Path Sum
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          17 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“Every path has a peak—find the one with the maximum sum.”
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ml-system-design/0046-transfer-learning/" rel="permalink">Transfer Learning Systems
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          26 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“Why learn from scratch when you can stand on the shoulders of giants?”
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ai-agents/0046-token-efficiency-optimization/" rel="permalink">Token Efficiency Optimization
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          22 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“Every token has a cost—make each one count.”
</p>
  </article>
</div>

  </div>
</div>

      <section class="page__share">
  <h4 class="page__share-title">Share on</h4>

  <a href="https://twitter.com/intent/tweet?via=arunbaby0&text=Cross-Lingual+Speech+Transfer%20https%3A%2F%2Fwww.arunbaby.com%2Fspeech-tech%2F0046-cross-lingual-speech-transfer%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.arunbaby.com%2Fspeech-tech%2F0046-cross-lingual-speech-transfer%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.arunbaby.com/speech-tech/0046-cross-lingual-speech-transfer/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/speech-tech/0045-speech-emotion-recognition/" class="pagination--pager" title="Speech Emotion Recognition">Previous</a>
    
    
      <a href="/speech-tech/0047-speech-model-export/" class="pagination--pager" title="Speech Model Export (ONNX/TFLite)">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 1990 - 2143 <a href="https://www.arunbaby.com">Arun Baby</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JRJPEC9SS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0JRJPEC9SS', { 'anonymize_ip': false});
</script>








  </body>
</html>
