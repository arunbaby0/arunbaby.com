<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Cost-efficient Speech Systems - Arun Baby</title>
<meta name="description" content="Strategies for building profitable speech recognition systems by optimizing the entire pipeline from signal processing to hardware.">


  <meta name="author" content="Arun Baby">
  
  <meta property="article:author" content="Arun Baby">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Arun Baby">
<meta property="og:title" content="Cost-efficient Speech Systems">
<meta property="og:url" content="https://www.arunbaby.com/speech-tech/0022-cost-efficient-speech-systems/">


  <meta property="og:description" content="Strategies for building profitable speech recognition systems by optimizing the entire pipeline from signal processing to hardware.">



  <meta property="og:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">



  <meta name="twitter:site" content="@arunbaby0">
  <meta name="twitter:title" content="Cost-efficient Speech Systems">
  <meta name="twitter:description" content="Strategies for building profitable speech recognition systems by optimizing the entire pipeline from signal processing to hardware.">
  <meta name="twitter:url" content="https://www.arunbaby.com/speech-tech/0022-cost-efficient-speech-systems/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">
    
  

  



  <meta property="article:published_time" content="2025-12-21T10:58:19+05:30">





  

  


<link rel="canonical" href="https://www.arunbaby.com/speech-tech/0022-cost-efficient-speech-systems/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Baby Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          <span class="site-subtitle">Arun Baby</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/dsa/"
                
                
              >DSA</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ml-system-design/"
                
                
              >ML Systems</a>
            </li><li class="masthead__menu-item">
              <a
                href="/speech-tech/"
                
                
              >Speech Tech</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ai-agents/"
                
                
              >AI Agents</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li><li class="masthead__menu-item">
              <a
                href="/statuses/"
                
                
              >Statuses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/contact/"
                
                
              >Contact</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main" class="no-author-sidebar">
  
  <div class="sidebar sticky">
  
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Cost-efficient Speech Systems">
    <meta itemprop="description" content="Strategies for building profitable speech recognition systems by optimizing the entire pipeline from signal processing to hardware.">
    <meta itemprop="datePublished" content="2025-12-21T10:58:19+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://www.arunbaby.com/speech-tech/0022-cost-efficient-speech-systems/" itemprop="url">Cost-efficient Speech Systems
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          13 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#the-challenge-the-cost-of-audio">The Challenge: The Cost of Audio</a></li><li><a href="#a-brief-history-of-speech-recognition">A Brief History of Speech Recognition</a></li><li><a href="#the-physics-of-sound-where-the-data-comes-from">The Physics of Sound: Where the Data Comes From</a></li><li><a href="#the-cost-drivers-in-speech">The Cost Drivers in Speech</a></li><li><a href="#signal-processing-101-the-hidden-costs">Signal Processing 101: The Hidden Costs</a></li><li><a href="#high-level-architecture-the-efficient-pipeline">High-Level Architecture: The Efficient Pipeline</a></li><li><a href="#strategy-1-the-gatekeeper-voice-activity-detection">Strategy 1: The Gatekeeper (Voice Activity Detection)</a><ul><li><a href="#vad-algorithms">VAD Algorithms</a></li></ul></li><li><a href="#strategy-2-efficient-architectures">Strategy 2: Efficient Architectures</a><ul><li><a href="#1-streaming-models-transducer--rnn-t">1. Streaming Models (Transducer / RNN-T)</a></li><li><a href="#2-batch-models-transformers--conformer">2. Batch Models (Transformers / Conformer)</a></li><li><a href="#3-whisper-the-elephant-in-the-room">3. Whisper (The Elephant in the Room)</a></li></ul></li><li><a href="#strategy-3-decoding-optimization">Strategy 3: Decoding Optimization</a><ul><li><a href="#beam-search-pruning">Beam Search Pruning</a></li><li><a href="#language-model-lm-integration">Language Model (LM) Integration</a></li></ul></li><li><a href="#strategy-4-hardware-selection">Strategy 4: Hardware Selection</a><ul><li><a href="#cpu-vs-gpu">CPU vs. GPU</a></li><li><a href="#the-rise-of-tinyml">The Rise of “TinyML”</a></li></ul></li><li><a href="#deep-dive-quantization-math">Deep Dive: Quantization Math</a></li><li><a href="#detailed-case-study-the-call-center">Detailed Case Study: The Call Center</a></li><li><a href="#implementation-the-vad-pipeline">Implementation: The VAD Pipeline</a></li><li><a href="#tutorial-deploying-speech-on-raspberry-pi">Tutorial: Deploying Speech on Raspberry Pi</a></li><li><a href="#checklist-for-cost-efficient-speech">Checklist for Cost-Efficient Speech</a></li><li><a href="#appendix-a-the-mathematics-of-sound-fourier-transform">Appendix A: The Mathematics of Sound (Fourier Transform)</a></li><li><a href="#appendix-b-python-code-for-simple-asr">Appendix B: Python Code for Simple ASR</a></li><li><a href="#conclusion">Conclusion</a></li></ul>
            </nav>
          </aside>
        
        <p><strong>Strategies for building profitable speech recognition systems by optimizing the entire pipeline from signal processing to hardware.</strong></p>

<h2 id="the-challenge-the-cost-of-audio">The Challenge: The Cost of Audio</h2>

<p>Speech processing is heavy. Unlike text, which is lightweight and discrete, audio is continuous, high-dimensional, and noisy. Transcribing a single hour of audio involves processing 57.6 million samples (at 16kHz). When you scale this to thousands of concurrent streams—like a call center or a voice assistant—the compute costs can be astronomical.</p>

<p>Building a state-of-the-art ASR (Automatic Speech Recognition) system is “easy” if you have infinite budget. You just throw the largest Transformer model at it. The real engineering challenge is building a system that is <strong>good enough</strong> while being <strong>cheap enough</strong> to be profitable.</p>

<p>In this guide, we will dissect the speech pipeline layer by layer to find savings. We will cover Voice Activity Detection (VAD), efficient model architectures, decoding strategies, and hardware choices. We will also dive into the math of quantization and show you how to deploy a speech model on a $35 Raspberry Pi.</p>

<h2 id="a-brief-history-of-speech-recognition">A Brief History of Speech Recognition</h2>

<p>To understand where we are, we must look back.</p>
<ul>
  <li><strong>1950s-70s:</strong> Simple digit recognition (Audrey, Shoebox). Based on template matching. Extremely limited.</li>
  <li><strong>1980s-2000s:</strong> The Era of <strong>Hidden Markov Models (HMMs)</strong> and Gaussian Mixture Models (GMMs). These were statistical models that were very efficient but had a ceiling on accuracy. They ran on weak CPUs.</li>
  <li><strong>2010s:</strong> <strong>Deep Neural Networks (DNNs)</strong> replaced GMMs. Accuracy skyrocketed, but so did compute costs.</li>
  <li><strong>2015+:</strong> <strong>End-to-End Models</strong> (Listen-Attend-Spell, DeepSpeech). No more complex pipelines, just one giant neural net.</li>
  <li><strong>2020+:</strong> <strong>Transformers &amp; Conformers</strong> (Whisper). State-of-the-art accuracy, but massive computational requirements.</li>
</ul>

<p>We are now in the era of “Model Distillation,” trying to get Transformer-level accuracy with GMM-level efficiency.</p>

<h2 id="the-physics-of-sound-where-the-data-comes-from">The Physics of Sound: Where the Data Comes From</h2>

<p>Sound is a pressure wave.</p>
<ul>
  <li><strong>Frequency (Pitch):</strong> Measured in Hertz (Hz). Human voice is mostly 300Hz - 3400Hz.</li>
  <li><strong>Amplitude (Loudness):</strong> Measured in Decibels (dB).</li>
  <li><strong>Sampling Rate:</strong> The Nyquist-Shannon theorem says to capture a frequency <code class="language-plaintext highlighter-rouge">f</code>, you must sample at <code class="language-plaintext highlighter-rouge">2f</code>. Since human speech goes up to ~8kHz (for fricatives like ‘s’ and ‘f’), we need 16kHz sampling.</li>
  <li><strong>Bit Depth:</strong> 16-bit audio gives 65,536 levels of loudness. This is standard.</li>
</ul>

<p><strong>Cost Insight:</strong>
Using 44.1kHz (CD quality) for speech is wasteful. It triples your data size (storage cost) and compute load (processing cost) with zero gain in ASR accuracy. Always downsample to 16kHz immediately.</p>

<h2 id="the-cost-drivers-in-speech">The Cost Drivers in Speech</h2>

<p>Where does the money go?</p>

<ol>
  <li><strong>Decoder Search (Beam Search):</strong> The ASR model outputs probabilities for each character/token at each time step. Finding the most likely sentence requires searching through a massive tree of possibilities. This “Beam Search” is CPU-intensive.</li>
  <li><strong>Model Depth (FLOPs):</strong> Modern models like Conformer or Whisper have hundreds of millions of parameters. Every millisecond of audio requires billions of floating-point operations.</li>
  <li><strong>Memory Bandwidth:</strong> Audio features are large. Moving them from RAM to GPU memory is often the bottleneck, not the compute itself.</li>
  <li><strong>Streaming vs. Batch:</strong> Streaming (real-time) is inherently inefficient because you cannot batch requests effectively. You are forced to process small chunks, which kills hardware utilization.</li>
</ol>

<h2 id="signal-processing-101-the-hidden-costs">Signal Processing 101: The Hidden Costs</h2>

<p>Before the model even sees the data, we process it.</p>
<ul>
  <li><strong>Feature Extraction:</strong> We convert raw waves into Spectrograms or MFCCs (Mel-Frequency Cepstral Coefficients).
    <ul>
      <li><strong>Math:</strong> This involves Fourier Transforms (FFT). While fast (<code class="language-plaintext highlighter-rouge">O(N log N)</code>), doing this for thousands of streams adds up.</li>
      <li><strong>Optimization:</strong> Use GPU-accelerated feature extraction (like <code class="language-plaintext highlighter-rouge">torchaudio</code> or <code class="language-plaintext highlighter-rouge">Kaldi</code> on GPU) instead of CPU-based <code class="language-plaintext highlighter-rouge">librosa</code>.</li>
    </ul>
  </li>
</ul>

<h2 id="high-level-architecture-the-efficient-pipeline">High-Level Architecture: The Efficient Pipeline</h2>

<pre><code class="language-ascii">+-----------+    +-------------+    +-------------+    +-------------+
| Raw Audio | -&gt; | VAD Filter  | -&gt; | Feature Ext | -&gt; |  ASR Model  |
+-----------+    +-------------+    +-------------+    +-------------+
                      |                    |                  |
                 (Silence?)           (MFCCs/Spec)       (Transducer)
                      |                    |                  |
                      v                    v                  v
                 +---------+        +-------------+    +-------------+
                 | Discard |        | GPU/DSP Acc |    | Text Output |
                 +---------+        +-------------+    +-------------+
</code></pre>

<h2 id="strategy-1-the-gatekeeper-voice-activity-detection">Strategy 1: The Gatekeeper (Voice Activity Detection)</h2>

<p>The single most effective way to save money in a speech system is: <strong>Don’t process silence.</strong></p>

<p>In a typical phone call, one person speaks only 40-50% of the time. The rest is silence or the other person talking. If you run your expensive ASR model on the silence, you are burning money.</p>

<h3 id="vad-algorithms">VAD Algorithms</h3>

<p><strong>1. Energy-Based VAD (The Cheapest)</strong></p>
<ul>
  <li><strong>Logic:</strong> Calculate the energy (volume) of the audio frame. If it’s above a threshold, it’s speech.</li>
  <li><strong>Pros:</strong> Extremely fast, practically free.</li>
  <li><strong>Cons:</strong> Fails miserably with background noise (air conditioner, traffic).</li>
</ul>

<p><strong>2. Gaussian Mixture Models (WebRTC VAD)</strong></p>
<ul>
  <li><strong>Logic:</strong> Uses statistical models to distinguish speech frequencies from noise frequencies.</li>
  <li><strong>Pros:</strong> Very fast, standard in the industry (used in Chrome/Zoom).</li>
  <li><strong>Cons:</strong> Can clip the start of sentences.</li>
</ul>

<p><strong>3. Neural VAD (Silero / Pyannote)</strong></p>
<ul>
  <li><strong>Logic:</strong> A small deep learning model trained to detect speech.</li>
  <li><strong>Pros:</strong> Highly accurate, robust to noise.</li>
  <li><strong>Cons:</strong> Requires some compute (though much less than ASR).</li>
</ul>

<p><strong>Implementation Strategy:</strong>
Use a <strong>Cascade</strong>.</p>
<ol>
  <li>Run Energy VAD. If Silent -&gt; Discard.</li>
  <li>If Energy &gt; Threshold, run Neural VAD. If Silent -&gt; Discard.</li>
  <li>If Speech -&gt; Send to ASR.</li>
</ol>

<h2 id="strategy-2-efficient-architectures">Strategy 2: Efficient Architectures</h2>

<p>Not all models are created equal.</p>

<h3 id="1-streaming-models-transducer--rnn-t">1. Streaming Models (Transducer / RNN-T)</h3>
<p>For real-time applications (Siri, Alexa), you need <strong>RNN-Transducers (RNN-T)</strong>.</p>
<ul>
  <li><strong>Why?</strong> They are designed to output text token-by-token as audio comes in. They are compact and often run on-device (Edge), reducing server costs to <strong>zero</strong>.</li>
</ul>

<h3 id="2-batch-models-transformers--conformer">2. Batch Models (Transformers / Conformer)</h3>
<p>For offline transcription (generating subtitles for a video), use <strong>Encoder-Decoder</strong> models.</p>
<ul>
  <li><strong>Why?</strong> You can process the entire file at once. The “Attention” mechanism can look at the whole future context, giving higher accuracy.</li>
  <li><strong>Cost Tip:</strong> Use <strong>Flash Attention</strong>. It’s a kernel optimization that speeds up Transformer attention by 2-4x and reduces memory usage.</li>
</ul>

<h3 id="3-whisper-the-elephant-in-the-room">3. Whisper (The Elephant in the Room)</h3>
<p>OpenAI’s Whisper is fantastic but heavy.</p>
<ul>
  <li><strong>Optimization:</strong> Use <code class="language-plaintext highlighter-rouge">faster-whisper</code> or <code class="language-plaintext highlighter-rouge">whisper.cpp</code>. These are optimized implementations (using CTranslate2 or C++) that are 4-5x faster than the original PyTorch code.</li>
</ul>

<h2 id="strategy-3-decoding-optimization">Strategy 3: Decoding Optimization</h2>

<p>The model gives you probabilities. Turning them into text is the expensive part.</p>

<h3 id="beam-search-pruning">Beam Search Pruning</h3>
<p>Beam Search keeps the “Top K” most likely sentences at each step.</p>
<ul>
  <li><strong>Beam Width:</strong> A width of 10 gives better accuracy than width 1, but costs 10x more.</li>
  <li><strong>Optimization:</strong> Use <strong>Adaptive Beam Width</strong>. Start with a small width. If the model is confident (high probability), keep it small. If the model is confused (flat probability distribution), widen the beam.</li>
</ul>

<h3 id="language-model-lm-integration">Language Model (LM) Integration</h3>
<ul>
  <li><strong>Shallow Fusion:</strong> You decode with the ASR model, and “score” the candidates with an external Language Model (n-gram or neural).</li>
  <li><strong>Cost:</strong> Neural LMs are expensive.</li>
  <li><strong>Fix:</strong> Use a simple <strong>n-gram LM</strong> (KenLM) for the first pass. It’s purely a lookup table (very fast). Only use a Neural LM for re-scoring the final top 5 candidates.</li>
</ul>

<h2 id="strategy-4-hardware-selection">Strategy 4: Hardware Selection</h2>

<h3 id="cpu-vs-gpu">CPU vs. GPU</h3>
<ul>
  <li><strong>GPU (NVIDIA T4):</strong> Best for <strong>Batch Processing</strong>. If you have 1000 files, load them onto a GPU and process in parallel. Throughput is king.</li>
  <li><strong>CPU (Intel/AMD):</strong> Best for <strong>Real-time Streaming</strong> of single streams. The latency overhead of moving small audio chunks to the GPU (PCIe transfer) often outweighs the compute speedup.</li>
  <li><strong>DSP (Digital Signal Processor):</strong> Used in mobile phones/headphones. Extremely low power, but hard to program.</li>
</ul>

<h3 id="the-rise-of-tinyml">The Rise of “TinyML”</h3>
<p>Running speech recognition on the edge (on the user’s phone or IoT device) is the ultimate cost saver.</p>
<ul>
  <li><strong>TensorFlow Lite Micro:</strong> Run keyword spotting (“Hey Google”) on a $2 microcontroller.</li>
  <li><strong>Privacy:</strong> Users love it because audio never leaves their device.</li>
  <li><strong>Cost:</strong> You pay $0 for server compute.</li>
</ul>

<h2 id="deep-dive-quantization-math">Deep Dive: Quantization Math</h2>

<p>How do we shrink a model? We turn 32-bit floats into 8-bit integers.
Formula: <code class="language-plaintext highlighter-rouge">Q = round(S * (R - Z))</code></p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">R</code>: Real value (FP32)</li>
  <li><code class="language-plaintext highlighter-rouge">S</code>: Scale factor</li>
  <li><code class="language-plaintext highlighter-rouge">Z</code>: Zero point</li>
  <li><code class="language-plaintext highlighter-rouge">Q</code>: Quantized value (INT8)</li>
</ul>

<p><strong>Why does this save money?</strong></p>
<ol>
  <li><strong>Memory:</strong> 4x smaller model = 4x less RAM. You can fit a larger model on a cheaper GPU.</li>
  <li><strong>Compute:</strong> Integer math is much faster than Floating Point math on modern CPUs.</li>
</ol>

<h2 id="detailed-case-study-the-call-center">Detailed Case Study: The Call Center</h2>

<p><strong>Scenario:</strong>
A call center records 10,000 hours of calls per day. They need to transcribe them for compliance and sentiment analysis.</p>
<ul>
  <li><strong>Requirement:</strong> Transcription must be available within 1 hour of the call ending.</li>
  <li><strong>Current State:</strong> Using a cloud API (Google/AWS) at $0.024 per minute.</li>
  <li><strong>Daily Cost:</strong> 10,000 hours * 60 mins * $0.024 = <strong>$14,400 / day</strong> ($432k/month). Ouch.</li>
</ul>

<p><strong>The Optimization Plan:</strong></p>

<p><strong>Step 1: Build In-House Solution</strong>
Cloud APIs have a huge markup. Deploying open-source Whisper (Medium) on your own servers is cheaper.</p>

<p><strong>Step 2: VAD Filtering</strong>
Call center audio is dual-channel (Agent and Customer).</p>
<ul>
  <li>There is a lot of silence (listening).</li>
  <li>You implement aggressive VAD. You find that 40% of the audio is silence.</li>
  <li><strong>Savings:</strong> You now process only 6,000 hours.</li>
</ul>

<p><strong>Step 3: Batching &amp; Hardware</strong>
Since the requirement is “within 1 hour” (not real-time), you can batch.</p>
<ul>
  <li>You spin up <code class="language-plaintext highlighter-rouge">g4dn.2xlarge</code> instances (NVIDIA T4).</li>
  <li>You use <code class="language-plaintext highlighter-rouge">faster-whisper</code> with INT8 quantization.</li>
  <li>Throughput: One T4 can process ~40 concurrent streams of real-time audio speed.</li>
  <li>Total processing time needed: 6,000 hours.</li>
  <li>With 40x speedup, you need 150 GPU-hours.</li>
  <li>Cost of T4 Spot Instance: $0.20/hr.</li>
  <li><strong>Daily Compute Cost:</strong> 150 * $0.20 = <strong>$30</strong>.</li>
</ul>

<p><strong>Step 4: Storage &amp; Overhead</strong>
Add storage, data transfer, and management node costs. Let’s say <strong>$100/day</strong>.</p>

<p><strong>Total New Cost:</strong> <strong>$130 / day</strong>.
<strong>Old Cost:</strong> <strong>$14,400 / day</strong>.
<strong>Savings:</strong> <strong>99%</strong>.</p>

<p><em>Note: This ignores engineering salaries, but even with a team of 5 engineers ($2M/year), the ROI is instant.</em></p>

<h2 id="implementation-the-vad-pipeline">Implementation: The VAD Pipeline</h2>

<p>Here is a Python snippet showing how to use <code class="language-plaintext highlighter-rouge">webrtcvad</code> to filter audio before sending it to an ASR system.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">webrtcvad</span>
<span class="kn">import</span> <span class="n">collections</span>
<span class="kn">import</span> <span class="n">sys</span>

<span class="k">class</span> <span class="nc">VADFilter</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">aggressiveness</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">vad</span> <span class="o">=</span> <span class="n">webrtcvad</span><span class="p">.</span><span class="nc">Vad</span><span class="p">(</span><span class="n">aggressiveness</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="mi">16000</span>
        <span class="n">self</span><span class="p">.</span><span class="n">frame_duration_ms</span> <span class="o">=</span> <span class="mi">30</span> <span class="c1"># Must be 10, 20, or 30
</span>
    <span class="k">def</span> <span class="nf">read_frames</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio_bytes</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Generator that yields 30ms frames</span><span class="sh">"""</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">sample_rate</span> <span class="o">*</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">frame_duration_ms</span> <span class="o">/</span> <span class="mf">1000.0</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># 2 bytes per sample
</span>        <span class="n">offset</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="n">offset</span> <span class="o">+</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="nf">len</span><span class="p">(</span><span class="n">audio_bytes</span><span class="p">):</span>
            <span class="k">yield</span> <span class="n">audio_bytes</span><span class="p">[</span><span class="n">offset</span><span class="p">:</span><span class="n">offset</span> <span class="o">+</span> <span class="n">n</span><span class="p">]</span>
            <span class="n">offset</span> <span class="o">+=</span> <span class="n">n</span>

    <span class="k">def</span> <span class="nf">filter_audio</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">audio_bytes</span><span class="p">):</span>
        <span class="sh">"""</span><span class="s">Returns only the speech segments</span><span class="sh">"""</span>
        <span class="n">frames</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">read_frames</span><span class="p">(</span><span class="n">audio_bytes</span><span class="p">)</span>
        <span class="n">speech_frames</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">frames</span><span class="p">:</span>
            <span class="n">is_speech</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">vad</span><span class="p">.</span><span class="nf">is_speech</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">sample_rate</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">is_speech</span><span class="p">:</span>
                <span class="n">speech_frames</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="sa">b</span><span class="sh">''</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">speech_frames</span><span class="p">)</span>

<span class="c1"># Usage
# raw_audio = load_wav("call_center_recording.wav")
# vad = VADFilter()
# clean_audio = vad.filter_audio(raw_audio)
# asr_model.transcribe(clean_audio)
</span></code></pre></div></div>

<h2 id="tutorial-deploying-speech-on-raspberry-pi">Tutorial: Deploying Speech on Raspberry Pi</h2>

<p>Let’s get hands-on. We will deploy a keyword spotter on a Raspberry Pi 4.</p>

<p><strong>Prerequisites:</strong></p>
<ul>
  <li>Raspberry Pi 4 (2GB RAM is enough)</li>
  <li>USB Microphone</li>
</ul>

<p><strong>Step 1: Install Dependencies</strong></p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt-get update
<span class="nb">sudo </span>apt-get <span class="nb">install </span>python3-pip libatlas-base-dev
pip3 <span class="nb">install </span>tensorflow-aarch64
</code></pre></div></div>

<p><strong>Step 2: Download a TFLite Model</strong>
We will use a pre-trained model for “Yes/No”.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget https://storage.googleapis.com/download.tensorflow.org/models/tflite/conv_actions_tflite.zip
unzip conv_actions_tflite.zip
</code></pre></div></div>

<p><strong>Step 3: Run Inference Script</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># Load TFLite model and allocate tensors.
</span><span class="n">interpreter</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">lite</span><span class="p">.</span><span class="nc">Interpreter</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="sh">"</span><span class="s">conv_actions_frozen.tflite</span><span class="sh">"</span><span class="p">)</span>
<span class="n">interpreter</span><span class="p">.</span><span class="nf">allocate_tensors</span><span class="p">()</span>

<span class="c1"># Get input and output tensors.
</span><span class="n">input_details</span> <span class="o">=</span> <span class="n">interpreter</span><span class="p">.</span><span class="nf">get_input_details</span><span class="p">()</span>
<span class="n">output_details</span> <span class="o">=</span> <span class="n">interpreter</span><span class="p">.</span><span class="nf">get_output_details</span><span class="p">()</span>

<span class="c1"># ... (Audio capture code using PyAudio) ...
</span></code></pre></div></div>

<p><strong>Result:</strong> You now have a voice-controlled switch running locally for $35 one-time cost. No cloud bills!</p>

<h2 id="checklist-for-cost-efficient-speech">Checklist for Cost-Efficient Speech</h2>

<ol class="task-list">
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" /><strong>VAD:</strong> Are you processing silence? Stop it.</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" /><strong>Sample Rate:</strong> Are you using 44.1kHz? Downsample to 16kHz. Speech doesn’t need high fidelity.</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" /><strong>Model Size:</strong> Do you need Whisper-Large? Try Tiny or Base first.</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" /><strong>Quantization:</strong> Are you using INT8?</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" /><strong>Batching:</strong> If it’s not live, batch it.</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" /><strong>Mono vs Stereo:</strong> If speakers are on separate channels, process them separately (and apply VAD to each).</li>
</ol>

<h2 id="appendix-a-the-mathematics-of-sound-fourier-transform">Appendix A: The Mathematics of Sound (Fourier Transform)</h2>

<p>The Discrete Fourier Transform (DFT) is the engine of speech processing. It converts time-domain signals into frequency-domain signals.</p>

<p><strong>The Formula:</strong>
<code class="language-plaintext highlighter-rouge">X[k] = Σ (from n=0 to N-1) x[n] * e^(-i * 2π * k * n / N)</code></p>

<p>Where:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">x[n]</code> is the input signal (amplitude at time <code class="language-plaintext highlighter-rouge">n</code>).</li>
  <li><code class="language-plaintext highlighter-rouge">X[k]</code> is the output spectrum (amplitude at frequency <code class="language-plaintext highlighter-rouge">k</code>).</li>
  <li><code class="language-plaintext highlighter-rouge">e^(-i...)</code> is Euler’s formula, representing rotation in the complex plane.</li>
</ul>

<p><strong>Why it matters for cost:</strong>
Calculating this naively is <code class="language-plaintext highlighter-rouge">O(N^2)</code>. The Fast Fourier Transform (FFT) algorithm (Cooley-Tukey) does it in <code class="language-plaintext highlighter-rouge">O(N log N)</code>. Without FFT, real-time speech recognition would be impossible on standard hardware.</p>

<h2 id="appendix-b-python-code-for-simple-asr">Appendix B: Python Code for Simple ASR</h2>

<p>Here is a conceptual implementation of a simple “Template Matching” ASR system using Dynamic Time Warping (DTW). This was the state-of-the-art in the 1980s!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">scipy.spatial.distance</span> <span class="kn">import</span> <span class="n">cdist</span>

<span class="k">def</span> <span class="nf">dtw</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Computes Dynamic Time Warping distance between two sequences.
    This is essentially the </span><span class="sh">'</span><span class="s">Minimum Path Sum</span><span class="sh">'</span><span class="s"> problem!
    </span><span class="sh">"""</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">m</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="nf">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">dtw_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">dtw_matrix</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">inf</span>
    <span class="n">dtw_matrix</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">inf</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">cost</span> <span class="o">=</span> <span class="nf">abs</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">y</span><span class="p">[</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="c1"># Take min of (match, insertion, deletion)
</span>            <span class="n">dtw_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">cost</span> <span class="o">+</span> <span class="nf">min</span><span class="p">(</span><span class="n">dtw_matrix</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span>    <span class="c1"># Insertion
</span>                                          <span class="n">dtw_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>    <span class="c1"># Deletion
</span>                                          <span class="n">dtw_matrix</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># Match
</span>                                          
    <span class="k">return</span> <span class="n">dtw_matrix</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">]</span>

<span class="c1"># Usage
# template = load_features("hello_template.wav")
# input_audio = load_features("user_input.wav")
# distance = dtw(template, input_audio)
# if distance &lt; threshold: print("Detected 'Hello'")
</span></code></pre></div></div>

<h2 id="conclusion">Conclusion</h2>

<p>Cost efficiency in speech systems is about <strong>context</strong>.</p>
<ul>
  <li>Is it real-time? -&gt; Use RNN-T on CPU.</li>
  <li>Is it offline? -&gt; Use Conformer/Whisper on GPU (Batch).</li>
  <li>Is it simple commands? -&gt; Use TinyML on Edge.</li>
</ul>

<p>By understanding the trade-offs between accuracy, latency, and cost, you can architect systems that are robust, scalable, and financially sustainable.</p>

<hr />

<p><strong>Originally published at:</strong> <a href="https://www.arunbaby.com/speech-tech/0022-cost-efficient-speech-systems/">arunbaby.com/speech-tech/0022-cost-efficient-speech-systems</a></p>

<p><em>If you found this helpful, consider sharing it with others who might benefit.</em></p>


        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#asr" class="page__taxonomy-item p-category" rel="tag">asr</a><span class="sep">, </span>
    
      <a href="/tags/#edge-computing" class="page__taxonomy-item p-category" rel="tag">edge-computing</a><span class="sep">, </span>
    
      <a href="/tags/#optimization" class="page__taxonomy-item p-category" rel="tag">optimization</a><span class="sep">, </span>
    
      <a href="/tags/#quantization" class="page__taxonomy-item p-category" rel="tag">quantization</a><span class="sep">, </span>
    
      <a href="/tags/#rtos" class="page__taxonomy-item p-category" rel="tag">rtos</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#speech-tech" class="page__taxonomy-item p-category" rel="tag">speech-tech</a>
    
    </span>
  </p>


        
      </footer>

      <div class="page__related page__related--full">
  <h2 class="page__related-title">Related across topics</h2>
  <style>
    /* Make section span full content width and use 2 equal columns */
    .page__related--full { float: inline-start; width: 100%; padding: 0; }
    .cross-related-grid { display: grid; grid-template-columns: repeat(2, minmax(0, 1fr)); gap: 2rem; }
    @media (max-width: 768px) { .cross-related-grid { grid-template-columns: 1fr; } }
    /* Ensure archive cards stretch nicely in the grid */
    .cross-related-grid .list__item, .cross-related-grid .grid__item { width: auto; float: none; margin: 0; }
  </style>
  <div class="cross-related-grid">
    



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/dsa/0022-minimum-path-sum/" rel="permalink">Minimum Path Sum
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          21 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">The classic grid optimization problem that bridges the gap between simple recursion and 2D Dynamic Programming.
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ml-system-design/0022-cost-optimization-for-ml/" rel="permalink">Cost Optimization for ML
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          16 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">A comprehensive guide to FinOps for Machine Learning: reducing TCO without compromising accuracy or latency.
</p>
  </article>
</div>

  </div>
</div>

      <section class="page__share">
  <h4 class="page__share-title">Share on</h4>

  <a href="https://twitter.com/intent/tweet?via=arunbaby0&text=Cost-efficient+Speech+Systems%20https%3A%2F%2Fwww.arunbaby.com%2Fspeech-tech%2F0022-cost-efficient-speech-systems%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.arunbaby.com%2Fspeech-tech%2F0022-cost-efficient-speech-systems%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.arunbaby.com/speech-tech/0022-cost-efficient-speech-systems/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/speech-tech/0021-speech-architecture-search/" class="pagination--pager" title="Speech Architecture Search">Previous</a>
    
    
      <a href="/speech-tech/0023-asr-beam-search-implementation/" class="pagination--pager" title="ASR Beam Search Implementation">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 1990 - 2143 <a href="https://www.arunbaby.com">Arun Baby</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JRJPEC9SS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0JRJPEC9SS', { 'anonymize_ip': false});
</script>








  </body>
</html>
