<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Token Efficiency Optimization - Arun Baby</title>
<meta name="description" content="“Every token costs money. Every wasted token is wasted money.”">


  <meta name="author" content="Arun Baby">
  
  <meta property="article:author" content="Arun Baby">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Arun Baby">
<meta property="og:title" content="Token Efficiency Optimization">
<meta property="og:url" content="https://www.arunbaby.com/ai-agents/0046-token-efficiency-optimization/">


  <meta property="og:description" content="“Every token costs money. Every wasted token is wasted money.”">



  <meta property="og:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">



  <meta name="twitter:site" content="@arunbaby0">
  <meta name="twitter:title" content="Token Efficiency Optimization">
  <meta name="twitter:description" content="“Every token costs money. Every wasted token is wasted money.”">
  <meta name="twitter:url" content="https://www.arunbaby.com/ai-agents/0046-token-efficiency-optimization/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">
    
  

  



  <meta property="article:published_time" content="2025-12-22T11:01:30+05:30">





  

  


<link rel="canonical" href="https://www.arunbaby.com/ai-agents/0046-token-efficiency-optimization/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Baby Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          <span class="site-subtitle">Arun Baby</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/dsa/"
                
                
              >DSA</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ml-system-design/"
                
                
              >ML Systems</a>
            </li><li class="masthead__menu-item">
              <a
                href="/speech-tech/"
                
                
              >Speech Tech</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ai-agents/"
                
                
              >AI Agents</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li><li class="masthead__menu-item">
              <a
                href="/statuses/"
                
                
              >Statuses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/contact/"
                
                
              >Contact</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main" class="no-author-sidebar">
  
  <div class="sidebar sticky">
  
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Token Efficiency Optimization">
    <meta itemprop="description" content="“Every token costs money. Every wasted token is wasted money.”">
    <meta itemprop="datePublished" content="2025-12-22T11:01:30+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://www.arunbaby.com/ai-agents/0046-token-efficiency-optimization/" itemprop="url">Token Efficiency Optimization
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          13 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#1-introduction-why-token-efficiency-matters">1. Introduction: Why Token Efficiency Matters</a></li><li><a href="#2-understanding-where-tokens-go">2. Understanding Where Tokens Go</a><ul><li><a href="#21-the-anatomy-of-an-agent-request">2.1 The Anatomy of an Agent Request</a></li><li><a href="#22-measuring-your-token-distribution">2.2 Measuring Your Token Distribution</a></li></ul></li><li><a href="#3-optimizing-the-system-prompt">3. Optimizing the System Prompt</a><ul><li><a href="#31-the-conciseness-principle">3.1 The Conciseness Principle</a></li><li><a href="#32-remove-redundancy">3.2 Remove Redundancy</a></li><li><a href="#33-use-structure-over-prose">3.3 Use Structure Over Prose</a></li><li><a href="#34-dynamic-system-prompts">3.4 Dynamic System Prompts</a></li></ul></li><li><a href="#4-optimizing-tool-definitions">4. Optimizing Tool Definitions</a><ul><li><a href="#41-the-hidden-cost-of-tools">4.1 The Hidden Cost of Tools</a></li><li><a href="#42-dynamic-tool-selection">4.2 Dynamic Tool Selection</a></li><li><a href="#43-compress-tool-descriptions">4.3 Compress Tool Descriptions</a></li><li><a href="#44-parameter-description-optimization">4.4 Parameter Description Optimization</a></li></ul></li><li><a href="#5-managing-conversation-history">5. Managing Conversation History</a><ul><li><a href="#51-the-explosion-problem">5.1 The Explosion Problem</a></li><li><a href="#52-strategy-1-sliding-window">5.2 Strategy 1: Sliding Window</a></li><li><a href="#53-strategy-2-summarization">5.3 Strategy 2: Summarization</a></li><li><a href="#54-strategy-3-importance-based-retention">5.4 Strategy 3: Importance-Based Retention</a></li><li><a href="#55-strategy-4-hybrid-approach">5.5 Strategy 4: Hybrid Approach</a></li></ul></li><li><a href="#6-optimizing-retrieved-context-rag">6. Optimizing Retrieved Context (RAG)</a><ul><li><a href="#61-the-over-retrieval-trap">6.1 The Over-Retrieval Trap</a></li><li><a href="#62-smarter-retrieval-strategies">6.2 Smarter Retrieval Strategies</a></li><li><a href="#63-query-the-model-for-what-it-needs">6.3 Query the Model for What It Needs</a></li></ul></li><li><a href="#7-optimizing-model-responses">7. Optimizing Model Responses</a><ul><li><a href="#71-set-appropriate-max_tokens">7.1 Set Appropriate max_tokens</a></li><li><a href="#72-request-concise-responses">7.2 Request Concise Responses</a></li><li><a href="#73-structured-output">7.3 Structured Output</a></li></ul></li><li><a href="#8-caching-avoiding-redundant-computation">8. Caching: Avoiding Redundant Computation</a><ul><li><a href="#81-exact-match-caching">8.1 Exact Match Caching</a></li><li><a href="#82-semantic-caching">8.2 Semantic Caching</a></li><li><a href="#83-what-to-cache">8.3 What to Cache</a></li></ul></li><li><a href="#9-model-selection-and-routing">9. Model Selection and Routing</a><ul><li><a href="#91-the-model-spectrum">9.1 The Model Spectrum</a></li><li><a href="#92-query-routing">9.2 Query Routing</a></li><li><a href="#93-cascading">9.3 Cascading</a></li></ul></li><li><a href="#10-measuring-and-monitoring">10. Measuring and Monitoring</a><ul><li><a href="#101-key-metrics-to-track">10.1 Key Metrics to Track</a></li><li><a href="#102-alerting-on-anomalies">10.2 Alerting on Anomalies</a></li></ul></li><li><a href="#11-connection-to-transfer-learning">11. Connection to Transfer Learning</a></li><li><a href="#12-key-takeaways">12. Key Takeaways</a></li></ul>
            </nav>
          </aside>
        
        <p><strong>“Every token costs money. Every wasted token is wasted money.”</strong></p>

<h2 id="1-introduction-why-token-efficiency-matters">1. Introduction: Why Token Efficiency Matters</h2>

<p>When you’re building a prototype AI agent, token efficiency might seem like a minor concern. You’re focused on making it work, not making it cheap. But as you scale to production—hundreds of thousands or millions of requests—tokens become the dominant cost.</p>

<p>Let’s do some quick math. Say your agent:</p>
<ul>
  <li>Uses GPT-4 Turbo ($0.01 per 1K input tokens, $0.03 per 1K output tokens)</li>
  <li>Processes 100,000 requests per day</li>
  <li>Uses 3,000 tokens per request on average</li>
</ul>

<p><strong>Monthly cost: 100,000 × 30 × 3 × $0.02 = $180,000 per month</strong></p>

<p>Now imagine you can reduce token usage by 50% through smart optimization:</p>

<p><strong>Optimized monthly cost: $90,000 per month</strong></p>

<p>That’s $1 million in annual savings from efficiency alone. Token optimization isn’t just technical housekeeping—it’s a strategic business decision.</p>

<hr />

<h2 id="2-understanding-where-tokens-go">2. Understanding Where Tokens Go</h2>

<p>Before optimizing, you need to understand where your tokens are actually being spent. Most developers are surprised by the breakdown.</p>

<h3 id="21-the-anatomy-of-an-agent-request">2.1 The Anatomy of an Agent Request</h3>

<p>A typical AI agent request includes several components:</p>

<p><strong>System Prompt (15-40% of tokens)</strong></p>

<p>The system prompt tells the model who it is, how to behave, and what tools are available. This is sent with <em>every single request</em>, making it the most impactful area to optimize.</p>

<p>Example breakdown:</p>
<ul>
  <li>Base instructions: 200-500 tokens</li>
  <li>Tool definitions: 500-2,000 tokens (if you have many tools)</li>
  <li>Examples (few-shot): 300-1,000 tokens</li>
  <li>Guardrails and safety instructions: 100-300 tokens</li>
</ul>

<p><strong>Conversation History (20-50% of tokens)</strong></p>

<p>For multi-turn conversations, you include previous messages. This grows with every turn:</p>
<ul>
  <li>Turn 1: 500 tokens</li>
  <li>Turn 5: 2,500 tokens</li>
  <li>Turn 10: 5,000 tokens</li>
</ul>

<p>Without management, conversation history can dominate your token usage.</p>

<p><strong>User Query (5-15% of tokens)</strong></p>

<p>The actual question or request from the user. Often the smallest component!</p>

<p><strong>Retrieved Context (10-30% of tokens)</strong></p>

<p>If you’re using RAG (Retrieval-Augmented Generation), you inject relevant documents. Easy to over-retrieve.</p>

<p><strong>Model Response (10-30% of tokens)</strong></p>

<p>The tokens generated by the model. You pay even more for these (typically 2-3x the input token rate).</p>

<h3 id="22-measuring-your-token-distribution">2.2 Measuring Your Token Distribution</h3>

<p>The first step in optimization is measurement. Log the token counts for each component:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Request ID: abc123
├── System prompt:        800 tokens (27%)
├── Tool definitions:     600 tokens (20%)
├── Conversation history: 900 tokens (30%)
├── User query:          150 tokens (5%)
├── Retrieved context:    400 tokens (13%)
└── Response:            150 tokens (5%)
Total: 3,000 tokens
</code></pre></div></div>

<p>Once you see where tokens are going, you can prioritize optimization efforts.</p>

<hr />

<h2 id="3-optimizing-the-system-prompt">3. Optimizing the System Prompt</h2>

<p>Since the system prompt is sent with every request, even small reductions compound enormously.</p>

<h3 id="31-the-conciseness-principle">3.1 The Conciseness Principle</h3>

<p>Many system prompts are written like novels. They don’t need to be. LLMs are good at understanding concise instructions.</p>

<p><strong>Before (verbose):</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>You are a helpful customer service assistant for Acme Corporation. Your primary 
responsibility is to assist customers with their inquiries in a professional, 
friendly, and helpful manner. You should always strive to provide accurate 
information and resolve customer issues to the best of your ability. If you 
don't know something, it's perfectly acceptable to say so rather than guessing.
</code></pre></div></div>

<p><strong>After (concise):</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>You're Acme's support AI. Be helpful, accurate, and friendly. If unsure, say so.
</code></pre></div></div>

<p>The meaning is identical; the token count dropped from ~70 to ~20.</p>

<h3 id="32-remove-redundancy">3.2 Remove Redundancy</h3>

<p>LLMs don’t need things repeated. If you say “be professional” once, you don’t need to say it again in different words.</p>

<p><strong>Common redundancies to remove:</strong></p>
<ul>
  <li>Restating the same rule in different words</li>
  <li>Explaining obvious things (“You can use the tools available to you”)</li>
  <li>Excessive politeness (“Please always remember to…”)</li>
</ul>

<h3 id="33-use-structure-over-prose">3.3 Use Structure Over Prose</h3>

<p>Bullet points and structured formats are often more token-efficient than paragraphs:</p>

<p><strong>Before:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>When helping with refunds, you should first verify the customer's identity by 
asking for their email address. Then, look up their order history to find the 
relevant order. Check if the order is within the refund window. If it is, 
process the refund. If it isn't, explain the policy kindly.
</code></pre></div></div>

<p><strong>After:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Refund process:
1. Verify identity (email)
2. Look up order
3. Check refund window
4. If eligible: process
5. If not: explain policy
</code></pre></div></div>

<p>Clearer AND shorter.</p>

<h3 id="34-dynamic-system-prompts">3.4 Dynamic System Prompts</h3>

<p>Not every request needs every instruction. Build your system prompt based on context:</p>

<p><strong>Detected intent: billing question</strong>
→ Include: billing guidelines, refund policy
→ Exclude: technical troubleshooting steps, account security protocols</p>

<p><strong>Detected intent: password reset</strong>
→ Include: security verification, reset procedures
→ Exclude: billing information, product features</p>

<p>This requires more engineering but can reduce system prompt tokens by 40-60%.</p>

<hr />

<h2 id="4-optimizing-tool-definitions">4. Optimizing Tool Definitions</h2>

<p>If your agent has tools, their definitions can consume massive token budgets.</p>

<h3 id="41-the-hidden-cost-of-tools">4.1 The Hidden Cost of Tools</h3>

<p>Each tool you provide to the model includes:</p>
<ul>
  <li>Tool name and description</li>
  <li>Parameters (names, types, descriptions)</li>
  <li>Examples of usage</li>
</ul>

<p>A single tool might be 50-200 tokens. If you have 15 tools, that’s 750-3,000 tokens <em>per request</em>.</p>

<h3 id="42-dynamic-tool-selection">4.2 Dynamic Tool Selection</h3>

<p>The solution: don’t send all tools every time. Analyze the user’s query and send only relevant tools.</p>

<p><strong>User asks about billing:</strong> Send payment tools, refund tools, invoice tools (3 tools)
<strong>User asks about their account:</strong> Send profile tools, settings tools (2 tools)
<strong>User asks technical question:</strong> Send documentation search, ticket creation tools (2 tools)</p>

<p>This requires a lightweight classification step, but the token savings are substantial.</p>

<h3 id="43-compress-tool-descriptions">4.3 Compress Tool Descriptions</h3>

<p>Tool descriptions tend to be over-written:</p>

<p><strong>Before:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>This tool allows you to search through the company's internal knowledge base 
to find relevant articles, documentation, and FAQs that might help answer 
the customer's question. Use this when you need to look up information.
</code></pre></div></div>

<p><strong>After:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Search knowledge base for articles/docs. Use for factual lookups.
</code></pre></div></div>

<p>The model understands both equally well.</p>

<h3 id="44-parameter-description-optimization">4.4 Parameter Description Optimization</h3>

<p>Parameter descriptions are often excessive:</p>

<p><strong>Before:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>query (string, required): The search query to look for in the knowledge base. 
This should be a clear, concise description of what information you're looking 
for. Try to include relevant keywords.
</code></pre></div></div>

<p><strong>After:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>query (string, required): Search terms
</code></pre></div></div>

<hr />

<h2 id="5-managing-conversation-history">5. Managing Conversation History</h2>

<p>For multi-turn conversations, history management is critical.</p>

<h3 id="51-the-explosion-problem">5.1 The Explosion Problem</h3>

<p>Without management, history grows linearly (or worse) with each turn:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Turn 1:  500 tokens (initial query + response)
Turn 5:  2,500 tokens 
Turn 10: 5,000 tokens
Turn 20: 10,000 tokens  ← This might exceed context limits!
</code></pre></div></div>

<p>Not only does cost increase, but you may hit context window limits.</p>

<h3 id="52-strategy-1-sliding-window">5.2 Strategy 1: Sliding Window</h3>

<p>Keep only the last N turns. Simple but effective.</p>

<p><strong>Trade-off:</strong> The model loses context about earlier parts of the conversation. Works well when recent context is most relevant.</p>

<h3 id="53-strategy-2-summarization">5.3 Strategy 2: Summarization</h3>

<p>Periodically summarize older messages into a compact form:</p>

<p><strong>Original history (500 tokens):</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>User: I'm having trouble with my order #12345
Agent: I see your order. What's the issue?
User: It arrived damaged
Agent: I'm sorry about that. Can you describe the damage?
User: The box was crushed and items inside broken
Agent: I'll arrange a replacement. Do you want the same items?
User: Yes please
</code></pre></div></div>

<p><strong>Summarized (50 tokens):</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[Earlier: Customer reported order #12345 arrived with crushed box and broken 
items. Agent arranged replacement of same items.]
</code></pre></div></div>

<p>90% token reduction while preserving essential context.</p>

<h3 id="54-strategy-3-importance-based-retention">5.4 Strategy 3: Importance-Based Retention</h3>

<p>Not all messages are equally important. Assign importance scores:</p>

<ul>
  <li><strong>High importance:</strong> Key decisions, confirmed information, user preferences</li>
  <li><strong>Medium importance:</strong> Questions, clarifications</li>
  <li><strong>Low importance:</strong> Acknowledgments, pleasantries</li>
</ul>

<p>When pruning, remove low-importance messages first.</p>

<h3 id="55-strategy-4-hybrid-approach">5.5 Strategy 4: Hybrid Approach</h3>

<p>Combine strategies for best results:</p>

<ol>
  <li>Keep last 3 turns in full (recency)</li>
  <li>Summarize turns 4-10 (recent context)</li>
  <li>Highly condense or drop turns 11+ (distant history)</li>
</ol>

<p>This preserves recent context while managing overall size.</p>

<hr />

<h2 id="6-optimizing-retrieved-context-rag">6. Optimizing Retrieved Context (RAG)</h2>

<p>If you’re retrieving documents to augment the prompt, over-retrieval is a common problem.</p>

<h3 id="61-the-over-retrieval-trap">6.1 The Over-Retrieval Trap</h3>

<p>It’s tempting to retrieve many chunks “just in case”:</p>
<ul>
  <li>10 chunks × 200 tokens = 2,000 tokens of context</li>
</ul>

<p>But often, only 1-2 chunks are actually relevant. The rest is noise that:</p>
<ul>
  <li>Costs tokens</li>
  <li>May confuse the model</li>
  <li>Dilutes the signal from relevant content</li>
</ul>

<h3 id="62-smarter-retrieval-strategies">6.2 Smarter Retrieval Strategies</h3>

<p><strong>Retrieve less, but better:</strong></p>
<ul>
  <li>Improve embedding quality</li>
  <li>Use re-ranking to filter initial results</li>
  <li>Retrieve 10, re-rank, keep top 3</li>
</ul>

<p><strong>Contextual retrieval:</strong></p>
<ul>
  <li>Include conversation history in the retrieval query</li>
  <li>Retrieve based on inferred intent, not just keywords</li>
</ul>

<p><strong>Chunk summarization:</strong></p>
<ul>
  <li>Instead of full chunks, retrieve chunk summaries</li>
  <li>Expand to full content only if needed</li>
</ul>

<h3 id="63-query-the-model-for-what-it-needs">6.3 Query the Model for What It Needs</h3>

<p>Instead of always retrieving, ask the model first:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>User: What's your return policy?

Model: "I need to look up the return policy to answer accurately."

[Only now do you retrieve the return policy document]
</code></pre></div></div>

<p>This avoids unnecessary retrieval for questions the model can answer from its training.</p>

<hr />

<h2 id="7-optimizing-model-responses">7. Optimizing Model Responses</h2>

<p>You also pay for output tokens—often at a higher rate than input tokens.</p>

<h3 id="71-set-appropriate-max_tokens">7.1 Set Appropriate max_tokens</h3>

<p>The <code class="language-plaintext highlighter-rouge">max_tokens</code> parameter limits response length. Set it based on expected response type:</p>

<table>
  <thead>
    <tr>
      <th>Query Type</th>
      <th>Appropriate max_tokens</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Yes/No question</td>
      <td>20-50</td>
    </tr>
    <tr>
      <td>Factual lookup</td>
      <td>100-200</td>
    </tr>
    <tr>
      <td>Explanation</td>
      <td>300-500</td>
    </tr>
    <tr>
      <td>Code generation</td>
      <td>500-1000</td>
    </tr>
  </tbody>
</table>

<p>Don’t set max_tokens to 4096 “just in case.”</p>

<h3 id="72-request-concise-responses">7.2 Request Concise Responses</h3>

<p>Explicitly ask for concise answers in your system prompt:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Respond concisely. Avoid unnecessary preamble ("I'd be happy to help...") 
and verbose explanations. Use lists over paragraphs when appropriate.
</code></pre></div></div>

<h3 id="73-structured-output">7.3 Structured Output</h3>

<p>Request JSON or structured output when appropriate:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Respond with a JSON object containing:
- answer: The direct answer
- confidence: high/medium/low
- sources: List of source IDs used

No additional text.
</code></pre></div></div>

<p>Structured output is often more compact and easier to parse.</p>

<hr />

<h2 id="8-caching-avoiding-redundant-computation">8. Caching: Avoiding Redundant Computation</h2>

<p>The greenest token is one you never use. Caching eliminates redundant LLM calls entirely.</p>

<h3 id="81-exact-match-caching">8.1 Exact Match Caching</h3>

<p>Cache responses for identical queries:</p>
<ul>
  <li>User asks “What are your hours?” → Cached response</li>
  <li>Same question again → Return cached answer, no LLM call</li>
</ul>

<p><strong>Limitation:</strong> Only works for exact matches. “What are your hours?” and “When are you open?” are different strings but the same question.</p>

<h3 id="82-semantic-caching">8.2 Semantic Caching</h3>

<p>Cache based on semantic similarity:</p>

<ol>
  <li>Compute embedding of new query</li>
  <li>Compare to cached query embeddings</li>
  <li>If similarity &gt; threshold, return cached response</li>
</ol>

<p><strong>Trade-off:</strong> Requires embedding computation per query, but much cheaper than a full LLM call.</p>

<h3 id="83-what-to-cache">8.3 What to Cache</h3>

<p>Not everything should be cached:</p>

<p><strong>Good for caching:</strong></p>
<ul>
  <li>Static information (business hours, policies)</li>
  <li>Common questions with stable answers</li>
  <li>Computationally expensive retrievals</li>
</ul>

<p><strong>Bad for caching:</strong></p>
<ul>
  <li>Personalized information (account status)</li>
  <li>Time-sensitive data (stock prices)</li>
  <li>Questions dependent on conversation context</li>
</ul>

<hr />

<h2 id="9-model-selection-and-routing">9. Model Selection and Routing</h2>

<p>Different queries need different models. Using GPT-4 for every request is overkill.</p>

<h3 id="91-the-model-spectrum">9.1 The Model Spectrum</h3>

<table>
  <thead>
    <tr>
      <th>Model</th>
      <th>Relative Cost</th>
      <th>Best For</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>GPT-3.5 Turbo</td>
      <td>$0.002/1K</td>
      <td>Simple queries, classification</td>
    </tr>
    <tr>
      <td>GPT-4 Turbo</td>
      <td>$0.02/1K</td>
      <td>Complex reasoning, nuanced tasks</td>
    </tr>
    <tr>
      <td>Claude 3 Haiku</td>
      <td>$0.0025/1K</td>
      <td>Simple, fast responses</td>
    </tr>
    <tr>
      <td>Claude 3 Sonnet</td>
      <td>$0.015/1K</td>
      <td>Balanced capability</td>
    </tr>
    <tr>
      <td>Claude 3 Opus</td>
      <td>$0.075/1K</td>
      <td>Highest capability tasks</td>
    </tr>
  </tbody>
</table>

<p>10x cost difference between simplest and most capable!</p>

<h3 id="92-query-routing">9.2 Query Routing</h3>

<p>Build a classifier that routes queries to appropriate models:</p>

<p><strong>Simple queries (70% of traffic):</strong></p>
<ul>
  <li>“What are your hours?”</li>
  <li>“How do I reset my password?”</li>
  <li>“Is my order shipped?”
→ Route to cheap/fast model</li>
</ul>

<p><strong>Complex queries (30% of traffic):</strong></p>
<ul>
  <li>“Compare these three plans and recommend one for my situation…”</li>
  <li>“Debug this code and explain the issue…”</li>
  <li>“Draft a formal complaint letter…”
→ Route to capable model</li>
</ul>

<p>If 70% of queries go to a 10x cheaper model, you reduce costs by ~60%.</p>

<h3 id="93-cascading">9.3 Cascading</h3>

<p>Start with a cheap model; escalate if needed:</p>

<ol>
  <li>Send query to GPT-3.5</li>
  <li>Check response quality (confidence, coherence)</li>
  <li>If quality is low, resend to GPT-4</li>
</ol>

<p>Most queries are handled cheaply; only difficult ones escalate.</p>

<hr />

<h2 id="10-measuring-and-monitoring">10. Measuring and Monitoring</h2>

<p>Optimization requires ongoing measurement.</p>

<h3 id="101-key-metrics-to-track">10.1 Key Metrics to Track</h3>

<p><strong>Token metrics:</strong></p>
<ul>
  <li>Average tokens per request (total, by component)</li>
  <li>Token distribution (system, history, context, response)</li>
  <li>Tokens per dollar spent</li>
</ul>

<p><strong>Efficiency metrics:</strong></p>
<ul>
  <li>Cache hit rate</li>
  <li>Model routing distribution</li>
  <li>Summarization compression ratio</li>
</ul>

<p><strong>Business metrics:</strong></p>
<ul>
  <li>Cost per conversation</li>
  <li>Cost per resolved ticket</li>
  <li>Cost per successful task</li>
</ul>

<h3 id="102-alerting-on-anomalies">10.2 Alerting on Anomalies</h3>

<p>Set alerts for:</p>
<ul>
  <li>Sudden increase in average tokens per request</li>
  <li>Cache hit rate dropping</li>
  <li>Unusual routing patterns (too many queries escalating to expensive models)</li>
</ul>

<hr />

<h2 id="11-connection-to-transfer-learning">11. Connection to Transfer Learning</h2>

<p>Token efficiency shares a pattern with today’s transfer learning topic:</p>

<table>
  <thead>
    <tr>
      <th>Transfer Learning</th>
      <th>Token Efficiency</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Reuse learned knowledge</td>
      <td>Cache computed responses</td>
    </tr>
    <tr>
      <td>Don’t train from scratch</td>
      <td>Don’t regenerate static content</td>
    </tr>
    <tr>
      <td>Fine-tune only what’s needed</td>
      <td>Send only needed context</td>
    </tr>
    <tr>
      <td>Parameter efficiency (adapters)</td>
      <td>Token efficiency (compression)</td>
    </tr>
  </tbody>
</table>

<p>Both are fundamentally about <strong>avoiding redundant work</strong>—whether that’s redundant learning or redundant token usage.</p>

<hr />

<h2 id="12-key-takeaways">12. Key Takeaways</h2>

<ol>
  <li>
    <p><strong>Measure before optimizing</strong>: Know where your tokens are going. System prompt and tool definitions often dominate.</p>
  </li>
  <li>
    <p><strong>System prompt optimization compounds</strong>: Every token saved is saved on every request. A 200-token reduction across 1M requests is 200M tokens saved.</p>
  </li>
  <li>
    <p><strong>Manage conversation history aggressively</strong>: Summarize, prune, and use sliding windows. History is the fastest-growing component.</p>
  </li>
  <li>
    <p><strong>Use dynamic context</strong>: Not every request needs every tool, every instruction, or every retrieved document.</p>
  </li>
  <li>
    <p><strong>Cache semantically similar queries</strong>: The cheapest token is one you don’t use at all.</p>
  </li>
  <li>
    <p><strong>Route to appropriate models</strong>: Use expensive models only when necessary. 70% of queries might be handleable by cheaper models.</p>
  </li>
  <li>
    <p><strong>Monitor continuously</strong>: Token usage patterns change as your product evolves. Keep measuring.</p>
  </li>
</ol>

<p>Token efficiency isn’t just about cost savings—it’s about building sustainable, scalable AI systems. The most successful production agents are those that deliver value without burning money on every request.</p>

<hr />

<p><strong>Originally published at:</strong> <a href="https://www.arunbaby.com/ai-agents/0046-token-efficiency-optimization/">arunbaby.com/ai-agents/0046-token-efficiency-optimization</a></p>

<p><em>If you found this helpful, consider sharing it with others who might benefit.</em></p>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#context-management" class="page__taxonomy-item p-category" rel="tag">context-management</a><span class="sep">, </span>
    
      <a href="/tags/#cost-reduction" class="page__taxonomy-item p-category" rel="tag">cost-reduction</a><span class="sep">, </span>
    
      <a href="/tags/#llm-efficiency" class="page__taxonomy-item p-category" rel="tag">llm-efficiency</a><span class="sep">, </span>
    
      <a href="/tags/#prompt-engineering" class="page__taxonomy-item p-category" rel="tag">prompt-engineering</a><span class="sep">, </span>
    
      <a href="/tags/#token-optimization" class="page__taxonomy-item p-category" rel="tag">token-optimization</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#ai-agents" class="page__taxonomy-item p-category" rel="tag">ai-agents</a>
    
    </span>
  </p>


        
      </footer>

      <div class="page__related page__related--full">
  <h2 class="page__related-title">Related across topics</h2>
  <style>
    /* Make section span full content width and use 2 equal columns */
    .page__related--full { float: inline-start; width: 100%; padding: 0; }
    .cross-related-grid { display: grid; grid-template-columns: repeat(2, minmax(0, 1fr)); gap: 2rem; }
    @media (max-width: 768px) { .cross-related-grid { grid-template-columns: 1fr; } }
    /* Ensure archive cards stretch nicely in the grid */
    .cross-related-grid .list__item, .cross-related-grid .grid__item { width: auto; float: none; margin: 0; }
  </style>
  <div class="cross-related-grid">
    



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/dsa/0046-binary-tree-max-path-sum/" rel="permalink">Binary Tree Maximum Path Sum
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          13 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“Every path has a peak—find the one with the maximum sum.”
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ml-system-design/0046-transfer-learning/" rel="permalink">Transfer Learning Systems
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          13 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“Why train from scratch when you can stand on the shoulders of giants?”
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/speech-tech/0046-cross-lingual-speech-transfer/" rel="permalink">Cross-Lingual Speech Transfer
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          13 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">“A child learns their first language in years; their second language in months. Speech models can do the same.”
</p>
  </article>
</div>

  </div>
</div>

      <section class="page__share">
  <h4 class="page__share-title">Share on</h4>

  <a href="https://twitter.com/intent/tweet?via=arunbaby0&text=Token+Efficiency+Optimization%20https%3A%2F%2Fwww.arunbaby.com%2Fai-agents%2F0046-token-efficiency-optimization%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.arunbaby.com%2Fai-agents%2F0046-token-efficiency-optimization%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.arunbaby.com/ai-agents/0046-token-efficiency-optimization/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/ai-agents/0045-data-leakage-prevention/" class="pagination--pager" title="Data Leakage Prevention">Previous</a>
    
    
      <a href="/ai-agents/0047-cost-management-for-agents/" class="pagination--pager" title="Cost Management for AI Agents">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 1990 - 2143 <a href="https://www.arunbaby.com">Arun Baby</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JRJPEC9SS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0JRJPEC9SS', { 'anonymize_ip': false});
</script>








  </body>
</html>
