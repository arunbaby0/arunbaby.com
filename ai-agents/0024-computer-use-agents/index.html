<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Computer Use Agents - Arun Baby</title>
<meta name="description" content="“Moving from ‘Chatting’ with an AI to ‘Co-working’ with an OS.”">


  <meta name="author" content="Arun Baby">
  
  <meta property="article:author" content="Arun Baby">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Arun Baby">
<meta property="og:title" content="Computer Use Agents">
<meta property="og:url" content="https://www.arunbaby.com/ai-agents/0024-computer-use-agents/">


  <meta property="og:description" content="“Moving from ‘Chatting’ with an AI to ‘Co-working’ with an OS.”">



  <meta property="og:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">



  <meta name="twitter:site" content="@arunbaby0">
  <meta name="twitter:title" content="Computer Use Agents">
  <meta name="twitter:description" content="“Moving from ‘Chatting’ with an AI to ‘Co-working’ with an OS.”">
  <meta name="twitter:url" content="https://www.arunbaby.com/ai-agents/0024-computer-use-agents/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">
    
  

  



  <meta property="article:published_time" content="2025-12-20T22:24:35+05:30">





  

  


<link rel="canonical" href="https://www.arunbaby.com/ai-agents/0024-computer-use-agents/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Baby Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          <span class="site-subtitle">Arun Baby</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/dsa/"
                
                
              >DSA</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ml-system-design/"
                
                
              >ML Systems</a>
            </li><li class="masthead__menu-item">
              <a
                href="/speech-tech/"
                
                
              >Speech Tech</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ai-agents/"
                
                
              >AI Agents</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li><li class="masthead__menu-item">
              <a
                href="/statuses/"
                
                
              >Statuses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/contact/"
                
                
              >Contact</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main" class="">
  
  <div class="sidebar sticky">
  
    


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="https://www.arunbaby.com/">
        <img src="/assets/images/profile-photo.png" alt="Arun Baby" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="https://www.arunbaby.com/" itemprop="url">Arun Baby</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>Becoming <strong>Unlabelable</strong></p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">India</span>
        </li>
      

      
        
          
            <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i><span class="label">Twitter</span></a></li>
          
        
          
            <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span class="label">LinkedIn</span></a></li>
          
        
          
            <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i><span class="label">Google Scholar</span></a></li>
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Computer Use Agents">
    <meta itemprop="description" content="“Moving from ‘Chatting’ with an AI to ‘Co-working’ with an OS.”">
    <meta itemprop="datePublished" content="2025-12-20T22:24:35+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://www.arunbaby.com/ai-agents/0024-computer-use-agents/" itemprop="url">Computer Use Agents
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          18 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#1-introduction-the-agent-as-an-operator">1. Introduction: The Agent as an Operator</a></li><li><a href="#2-the-action-space-mouse-keyboard-and-screen">2. The Action Space: Mouse, Keyboard, and Screen</a><ul><li><a href="#21-the-toolset">2.1 The Toolset</a></li><li><a href="#22-the-coordinate-problem">2.2 The Coordinate Problem</a></li></ul></li><li><a href="#3-the-vision-action-loop-how-it-works">3. The Vision-Action Loop: How it Works</a></li><li><a href="#4-the-engineering-challenge-latency-and-cost">4. The Engineering Challenge: Latency and Cost</a></li><li><a href="#5-security-and-sandboxing-the-blast-radius">5. Security and Sandboxing: The “Blast Radius”</a></li><li><a href="#6-logic-link-tokenization-as-an-action-space">6. Logic Link: Tokenization as an Action Space</a></li><li><a href="#7-case-study-the-auto-installer-agent">7. Case Study: The “Auto-Installer” Agent</a></li><li><a href="#8-deep-dive-anthropics-computer-use-architecture">8. Deep Dive: Anthropic’s “Computer Use” Architecture</a><ul><li><a href="#81-the-tool-definition-contract">8.1 The Tool-Definition Contract</a></li><li><a href="#82-the-redaction-layer">8.2 The Redaction Layer</a></li></ul></li><li><a href="#9-virtualization-where-should-the-agent-live">9. Virtualization: Where should the agent live?</a><ul><li><a href="#91-the-thin-sandbox-docker--vnc">9.1 The “Thin” Sandbox (Docker + VNC)</a></li><li><a href="#92-the-thick-sandbox-qemu--virtualbox">9.2 The “Thick” Sandbox (QEMU / VirtualBox)</a></li><li><a href="#93-cloud-native-sandboxes-e2b--multion">9.3 Cloud-Native Sandboxes (E2B / MultiOn)</a></li></ul></li><li><a href="#10-benchmarking-how-do-we-measure-computer-use">10. Benchmarking: How do we measure “Computer Use”?</a></li><li><a href="#11-pattern-visual-action-grounding-vag">11. Pattern: Visual Action Grounding (VAG)</a></li><li><a href="#12-errors-and-recovery-the-stuck-agent">12. Errors and Recovery: The “Stuck” Agent</a></li><li><a href="#13-pattern-human-agent-handoff-in-computer-use">13. Pattern: Human-Agent Handoff in Computer Use</a></li><li><a href="#14-ethics--policy-the-bad-actor-problem">14. Ethics &amp; Policy: The “Bad Actor” Problem</a></li><li><a href="#15-the-future-vision-language-action-vla-models">15. The Future: Vision-Language-Action (VLA) Models</a></li><li><a href="#16-advanced-technique-the-hybrid-os-access-pattern">16. Advanced Technique: The Hybrid OS Access Pattern</a></li><li><a href="#17-case-study-the-corporate-auditor-agent">17. Case Study: The “Corporate Auditor” Agent</a></li><li><a href="#18-engineering-the-feedback-loop-the-self-healing-click">18. Engineering the Feedback Loop: The “Self-Healing” Click</a></li><li><a href="#18-pattern-local-first-computer-use">18. Pattern: Local-First Computer Use</a></li><li><a href="#19-privacy-by-design-the-context-free-ui">19. Privacy-By-Design: The “Context-Free” UI</a></li><li><a href="#20-performance-analysis-the-action-to-observation-latency">20. Performance Analysis: The “Action-to-Observation” Latency</a></li><li><a href="#21-pattern-advanced-action-sequences-macros-for-agents">21. Pattern: Advanced Action Sequences (Macros for Agents)</a></li><li><a href="#22-designing-memory-for-computer-use-the-visual-history">22. Designing Memory for Computer Use: The “Visual History”</a></li><li><a href="#23-the-future-the-universal-operating-system">23. The Future: The “Universal Operating System”</a></li><li><a href="#24-pattern-the-cold-start-problem-for-os-agents">24. Pattern: The “Cold Start” Problem for OS Agents</a></li><li><a href="#25-vision-action-calibration-correcting-for-offsets">25. Vision-Action Calibration: Correcting for Offsets</a></li><li><a href="#26-enterprise-grade-security-air-gapping-and-immutable-logs">26. Enterprise-Grade Security: Air-Gapping and Immutable Logs</a></li><li><a href="#27-summary--junior-engineer-roadmap">27. Summary &amp; Junior Engineer Roadmap</a></li></ul>
            </nav>
          </aside>
        
        <p><strong>“Moving from ‘Chatting’ with an AI to ‘Co-working’ with an OS.”</strong></p>

<h2 id="1-introduction-the-agent-as-an-operator">1. Introduction: The Agent as an Operator</h2>

<p>A <strong>Computer Use Agent</strong> goes a step further than browsing and screenshot understanding: it treats the entire Operating System (Windows, macOS, Linux) as its environment.</p>

<p>Instead of just interacting with a DOM tree or a mobile app, these agents operate the <strong>Mouse and Keyboard</strong> just like a human. They can open Excel, move files between folders, install software, and debug code in a local VS Code instance.</p>

<p>This transition from “Web Navigation” to “OS Control” is the current frontier of AI Agent engineering, popularized by models like <strong>Anthropic’s Claude 3.5 Sonnet (Computer Use)</strong> and benchmarks like <strong>OSWorld</strong>.</p>

<hr />

<h2 id="2-the-action-space-mouse-keyboard-and-screen">2. The Action Space: Mouse, Keyboard, and Screen</h2>

<p>For an agent to control a computer, it needs a specific “Vocabulary” of actions. In ML terms, this is its <strong>Action Space</strong>.</p>

<h3 id="21-the-toolset">2.1 The Toolset</h3>
<p>A typical Computer Use Agent has access to the following tools:</p>
<ul>
  <li><strong><code class="language-plaintext highlighter-rouge">mouse_move(x, y)</code>:</strong> Moves the cursor to precise coordinates.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">left_click()</code> / <code class="language-plaintext highlighter-rouge">right_click()</code> / <code class="language-plaintext highlighter-rouge">double_click()</code>:</strong> Standard interactions.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">type(text)</code>:</strong> Enters strings into the currently focused element.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">key(shortcut)</code>:</strong> Executes system commands like <code class="language-plaintext highlighter-rouge">ctrl+c</code>, <code class="language-plaintext highlighter-rouge">alt+tab</code>, or <code class="language-plaintext highlighter-rouge">cmd+space</code>.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">screenshot()</code>:</strong> The only way the agent “sees” the effect of its actions.</li>
</ul>

<h3 id="22-the-coordinate-problem">2.2 The Coordinate Problem</h3>
<p>Screenshots are usually resized before being sent to an LLM (e.g., to 1024x1024). But the actual screen might be 1920x1080.</p>
<ul>
  <li><strong>Junior Tip:</strong> You must implement a <strong>Coordinate Scaling</strong> function. If the model says “Click at (512, 512)” on a 1024x1024 image, your code must translate that back to your OS’s native resolution (e.g., 960x540) before executing the click.</li>
</ul>

<hr />

<h2 id="3-the-vision-action-loop-how-it-works">3. The Vision-Action Loop: How it Works</h2>

<p>Computer use is a continuous loop of <code class="language-plaintext highlighter-rouge">See -&gt; Think -&gt; Act -&gt; Observe</code>.</p>

<ol>
  <li><strong>State Capture:</strong> The agent takes a screenshot of the current desktop.</li>
  <li><strong>Context Injection:</strong> The screenshot is sent to the MLLM along with the user’s goal (e.g., “Find the latest invoice in my downloads and move it to the ‘Expenses’ folder”).</li>
  <li><strong>Action Prediction:</strong> The model outputs a tool call: <code class="language-plaintext highlighter-rouge">mouse_move(120, 450)</code> followed by <code class="language-plaintext highlighter-rouge">left_click()</code>.</li>
  <li><strong>Execution:</strong> The orchestration layer (Python + PyAutoGUI or a specialized VM API) moves the real mouse and clicks.</li>
  <li><strong>Observation:</strong> The agent takes a <em>new</em> screenshot to see if the click worked (e.g., “Did the file highlight?”).</li>
</ol>

<hr />

<h2 id="4-the-engineering-challenge-latency-and-cost">4. The Engineering Challenge: Latency and Cost</h2>

<p>Operating a GUI is token-expensive.</p>
<ul>
  <li>A “simple” task like moving a file might take 10 discrete steps.</li>
  <li>If each step sends a high-res screenshot to GPT-4V or Claude 3.5, you are spending ~$0.10 and waiting 30-50 seconds for the entire task.</li>
  <li><strong>Optimization Strategy:</strong> Use <strong>Visual Diffing</strong>. Instead of sending a full screenshot every turn, only send a screenshot if the pixels have changed significantly since the last action.</li>
</ul>

<hr />

<h2 id="5-security-and-sandboxing-the-blast-radius">5. Security and Sandboxing: The “Blast Radius”</h2>

<p>Giving an AI control of your mouse and keyboard is a massive security risk. An agent could accidentally delete your <code class="language-plaintext highlighter-rouge">system32</code> folder or send an embarrassing email to your boss.</p>

<p><strong>The Golden Rule:</strong> Always run Computer Use Agents in a <strong>Sandbox</strong>.</p>
<ol>
  <li><strong>Vitual Machines (VMs):</strong> Use tools like <strong>Orbstack</strong>, <strong>VirtualBox</strong>, or <strong>AWS EC2</strong> instances. If the agent makes a mistake, you can simply “Snapshot” back to a clean state.</li>
  <li><strong>Docker Containers with VNC:</strong> Run a Linux desktop environment inside Docker. This allows you to restrict network access (no internet for the agent) and limit file access to specific shared volumes.</li>
  <li><strong>Ephemeral Environments:</strong> Benchmarks like <strong>OSWorld</strong> spin up a fresh VM for every task and destroy it once the agent finishes.</li>
</ol>

<hr />

<h2 id="6-logic-link-tokenization-as-an-action-space">6. Logic Link: Tokenization as an Action Space</h2>

<p>In our ML section, we discuss <strong>Tokenization (BPE/SentencePiece)</strong>. How does this relate to Computer Use?</p>

<p>In NLP, we break down “Unstructured Text” into a “Structured Vocabulary” (Tokens).
In Computer Use, we break down a “Infinite GUI” into a “Structured Action Vocabulary” (Move, Click, Type).</p>

<p>Just as a model learns which <em>sub-word</em> comes next, a Computer Use Agent learns which <em>sub-action</em> comes next. If the agent sees an “Open” dialog, its “Action Word” should highly likely be <code class="language-plaintext highlighter-rouge">mouse_move</code> followed by <code class="language-plaintext highlighter-rouge">click</code>.</p>

<hr />

<h2 id="7-case-study-the-auto-installer-agent">7. Case Study: The “Auto-Installer” Agent</h2>

<p>Imagine an agent tasked with: <em>“Install the latest version of VS Code and configure the ‘Material Theme’.”</em></p>

<p><strong>The Loop:</strong></p>
<ol>
  <li><strong>Search:</strong> Opens Chrome. Types “VS Code download”.</li>
  <li><strong>Navigate:</strong> Clicks the first link. Finds the “Download for Windows” button.</li>
  <li><strong>Execute:</strong> Opens the <code class="language-plaintext highlighter-rouge">.exe</code> from the downloads bar.</li>
  <li><strong>Interact:</strong> This is the hard part. The installer has “Next”, “I Agree”, “Install” buttons. The agent must visually find these buttons and Wait for the progress bar to finish.</li>
  <li><strong>Configure:</strong> Opens the app, calls the command palette (<code class="language-plaintext highlighter-rouge">cmd+shift+p</code>), types “Install Extensions”, and searches for the theme.</li>
</ol>

<p><strong>Why this fails:</strong> Most agents fail because they click “too fast” before the UI has rendered. <strong>Temporal Awareness</strong> (waiting for an element to appear) is a core skill for Computer Use engineers.</p>

<hr />

<hr />

<h2 id="8-deep-dive-anthropics-computer-use-architecture">8. Deep Dive: Anthropic’s “Computer Use” Architecture</h2>

<p>When Anthropic released Claude 3.5 Sonnet with “Computer Use” capabilities, they introduced a specific orchestration pattern that has now become the industry standard.</p>

<h3 id="81-the-tool-definition-contract">8.1 The Tool-Definition Contract</h3>
<p>Unlike previous models that just “wrote code” to control the mouse, Claude’s computer use tools are defined with a strict schema. The model doesn’t just output <code class="language-plaintext highlighter-rouge">mouse_click</code>; it outputs a structured request:</p>
<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
 </span><span class="nl">"action"</span><span class="p">:</span><span class="w"> </span><span class="s2">"mouse_move"</span><span class="p">,</span><span class="w">
 </span><span class="nl">"coordinate"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mi">450</span><span class="p">,</span><span class="w"> </span><span class="mi">210</span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<h3 id="82-the-redaction-layer">8.2 The Redaction Layer</h3>
<p>One of the most important parts of the Anthropic architecture is the <strong>Privacy Redaction Layer</strong>. Since the agent is seeing your whole screen, it might see:</p>
<ul>
  <li>Open bank tabs.</li>
  <li>Private Slack messages.</li>
  <li>Saved passwords in the browser.</li>
  <li><strong>The Pattern:</strong> Before the screenshot is sent to the LLM, a local script (using local OCR or a mini-YOLO model) identifies “PII” (Personally Identifiable Information) and applies a black box mask. This ensures the “Brain” (the cloud model) never sees sensitive data.</li>
</ul>

<hr />

<h2 id="9-virtualization-where-should-the-agent-live">9. Virtualization: Where should the agent live?</h2>

<p>As a junior engineer, you shouldn’t just run an agent on your local machine. You need an isolated environment.</p>

<h3 id="91-the-thin-sandbox-docker--vnc">9.1 The “Thin” Sandbox (Docker + VNC)</h3>
<ul>
  <li><strong>Pros:</strong> Extremely fast to start, low memory usage.</li>
  <li><strong>Cons:</strong> No access to “Real” OS features (drivers, specialized hardware).</li>
  <li><strong>Usage:</strong> Great for web browsing or testing simple Python scripts.</li>
  <li><strong>Architecture:</strong> <code class="language-plaintext highlighter-rouge">Docker -&gt; X11 Server -&gt; VNC -&gt; Python Orchestrator</code>.</li>
</ul>

<h3 id="92-the-thick-sandbox-qemu--virtualbox">9.2 The “Thick” Sandbox (QEMU / VirtualBox)</h3>
<ul>
  <li><strong>Pros:</strong> Full hardware virtualization. The agent can reboot the machine, install drivers, and change BIOS settings.</li>
  <li><strong>Cons:</strong> Slow to start (minutes), heavy resource usage (4GB+ RAM).</li>
  <li><strong>Usage:</strong> Essential for testing system-level automation or complex software installations (e.g., SQL Server, Docker-in-Docker).</li>
</ul>

<h3 id="93-cloud-native-sandboxes-e2b--multion">9.3 Cloud-Native Sandboxes (E2B / MultiOn)</h3>
<p>There are now services that provide “Sandboxes as a Service.”</p>
<ul>
  <li><strong>E2B:</strong> Provides a micro-VM (Firecracker) that starts in &lt;100ms and gives the agent a full filesystem and terminal.</li>
  <li><strong>Benefit:</strong> You don’t have to manage the infrasctruture. You just get an API to “Execute code” or “Interact with screen.”</li>
</ul>

<hr />

<h2 id="10-benchmarking-how-do-we-measure-computer-use">10. Benchmarking: How do we measure “Computer Use”?</h2>

<p>How do you know if your agent is actually “Good” at using a computer? You use <strong>OSWorld</strong>.</p>

<p><strong>The OSWorld Benchmark:</strong></p>
<ul>
  <li><strong>The Environment:</strong> A full Linux Mint desktop with 100+ real-world apps (Chrome, VLC, LibreOffice, GIMP).</li>
  <li><strong>The Tasks:</strong> “Find the email from Sally in Thunderbird and save the attachment to a new folder named ‘Sally_Data’ in the Documents directory.”</li>
  <li><strong>The Metric:</strong> <strong>Success Rate</strong>. Did the file end up in the right place?</li>
  <li><strong>SOTA (State of the Art):</strong> As of late 2024, top models like Claude 3.5 Sonnet achieve ~15-20% success on the most complex tasks. This shows how hard “Computer Use” still is!</li>
</ul>

<hr />

<h2 id="11-pattern-visual-action-grounding-vag">11. Pattern: Visual Action Grounding (VAG)</h2>

<p>If the model says “Click the blue button,” but there are two blue buttons, the agent will fail. We use <strong>VAG</strong> to solve this.</p>

<p><strong>The Workflow:</strong></p>
<ol>
  <li><strong>State Representation:</strong> The agent takes a screenshot.</li>
  <li><strong>Element Tagging:</strong> A local script uses <strong>OmniParser</strong> or <strong>Set-of-Mark (SoM)</strong> to draw a red box around every clickable item on the screen and assign it a number (e.g., <code class="language-plaintext highlighter-rouge">[1]</code>, <code class="language-plaintext highlighter-rouge">[2]</code>, <code class="language-plaintext highlighter-rouge">[3]</code>).</li>
  <li><strong>Prompting:</strong> The agent is told: “To click the Search button, choose ID [4].”</li>
  <li><strong>Result:</strong> This drastically reduces coordinate errors because the model is picking an ID from a list rather than guessing pixel coordinates.</li>
</ol>

<hr />

<h2 id="12-errors-and-recovery-the-stuck-agent">12. Errors and Recovery: The “Stuck” Agent</h2>

<p>In Computer Use, agents get “Stuck” frequently.</p>
<ul>
  <li><em>Cause:</em> A pop-up appeared that the agent didn’t expect.</li>
  <li><em>Cause:</em> The mouse clicked 2 pixels too far to the left.</li>
  <li><em>The Fix:</em> <strong>Self-Correction Loops</strong>.</li>
  <li>The agent must take a screenshot <em>after</em> every action.</li>
  <li>It must compare “Expected State” vs “Actual State.”</li>
  <li>If they don’t match, the agent must “Backtrack” (e.g., hit <code class="language-plaintext highlighter-rouge">Esc</code>) and try a different approach.</li>
</ul>

<hr />

<hr />

<h2 id="13-pattern-human-agent-handoff-in-computer-use">13. Pattern: Human-Agent Handoff in Computer Use</h2>

<p>What happens when the agent hits a “captcha” or a biometric login (FaceID)?</p>

<p><strong>The Handoff Protocol:</strong></p>
<ol>
  <li><strong>Suspension:</strong> The agent detects a “Blocked” state.</li>
  <li><strong>Notification:</strong> It sends a message to the user: <em>“I encountered a Captcha. Please solve it so I can continue.”</em></li>
  <li><strong>Human Interaction:</strong> The human opens the window, solves the captcha, and closes it.</li>
  <li><strong>Resumption:</strong> The agent takes a new screenshot, verifies the captcha is gone, and resumes its loop.
    <ul>
      <li><strong>Junior Tip:</strong> Never try to build an “Auto-Captcha Solver.” It’s a cat-and-mouse game that usually leads to your IP being banned. Handoff is the professional way to handle edge cases.</li>
    </ul>
  </li>
</ol>

<hr />

<h2 id="14-ethics--policy-the-bad-actor-problem">14. Ethics &amp; Policy: The “Bad Actor” Problem</h2>

<p>Computer Use agents are the ultimate tool for <strong>Shadow IT</strong> and <strong>Malware</strong>.</p>

<p><strong>The Risks:</strong></p>
<ul>
  <li><strong>Ad Fraud:</strong> Agents clicking on ads automatically.</li>
  <li><strong>Data Exfiltration:</strong> An agent being told to “Sync my local files to this random URL.”</li>
  <li><strong>Account Takeover:</strong> If an agent has access to your logged-in browser, it has access to everything.</li>
</ul>

<p><strong>Policy for Engineers:</strong></p>
<ul>
  <li><strong>Read-Only by Default:</strong> Start your agent with tools that can only “See” and “Move Mouse” but not “Click” or “Type” until you trust it.</li>
  <li><strong>Audit Logging:</strong> Every mouse click must be recorded in a database with a timestamp and the confidence score. If something goes wrong, you need a “Flight Recorder” to see why.</li>
</ul>

<hr />

<h2 id="15-the-future-vision-language-action-vla-models">15. The Future: Vision-Language-Action (VLA) Models</h2>

<p>Right now, we use a separate MLLM (Vision) and a separate Python script (Action). The future is <strong>End-to-End VLA</strong>.
Models like <strong>Google RT-2</strong> or <strong>Figure 01</strong> don’t output “Click at (x,y)”. They output <strong>Motor Torque Commands</strong> or <strong>System Keycodes</strong> directly.</p>

<ul>
  <li><strong>Benefit:</strong> These models “understand” the relationship between pixels and physics. They know that to “drag” a file, you must press down, move, and <em>then</em> release. This eliminates the “Coordination Gap” that plagues current agents.</li>
</ul>

<hr />

<hr />

<h2 id="16-advanced-technique-the-hybrid-os-access-pattern">16. Advanced Technique: The Hybrid OS Access Pattern</h2>

<p>Pure “Pixel-based” computer use is robust but inefficient. Professional agents use a <strong>Hybrid Pattern</strong>.</p>

<p><strong>The Logic:</strong></p>
<ul>
  <li><strong>The API Layer:</strong> If the app has an API (e.g., Google Calendar), the agent uses a JSON tool call. This is 100% reliable and instantaneous.</li>
  <li><strong>The Accessibility Layer:</strong> On Windows/macOS, every app publishes an “Accessibility Tree” (used by screen readers). This tree gives the agent the <strong>Exact Text and Location</strong> of every button without needing vision.</li>
  <li><strong>The Vision Layer:</strong> If the app is a game or a legacy tool with no accessibility metadata, the agent falls back to pure Vision.</li>
</ul>

<p><strong>The “Fallthrough” Code:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">click_button</span><span class="p">(</span><span class="n">label</span><span class="p">):</span>
 <span class="c1"># 1. Try to find the button in the Accessibility Tree (Fast/Reliable)
</span> <span class="n">coord</span> <span class="o">=</span> <span class="n">accessibility_api</span><span class="p">.</span><span class="nf">get_coordinates</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
 <span class="k">if</span> <span class="n">coord</span><span class="p">:</span> <span class="k">return</span> <span class="n">mouse</span><span class="p">.</span><span class="nf">click</span><span class="p">(</span><span class="n">coord</span><span class="p">)</span>

 <span class="c1"># 2. If not found, run Vision (Slower/Contextual)
</span> <span class="n">screenshot</span> <span class="o">=</span> <span class="n">cam</span><span class="p">.</span><span class="nf">capture</span><span class="p">()</span>
 <span class="n">coord</span> <span class="o">=</span> <span class="n">mllm</span><span class="p">.</span><span class="nf">detect_button</span><span class="p">(</span><span class="n">screenshot</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
 <span class="k">if</span> <span class="n">coord</span><span class="p">:</span> <span class="k">return</span> <span class="n">mouse</span><span class="p">.</span><span class="nf">click</span><span class="p">(</span><span class="n">coord</span><span class="p">)</span>

 <span class="k">raise</span> <span class="nc">Exception</span><span class="p">(</span><span class="sh">"</span><span class="s">Button not found</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<hr />

<h2 id="17-case-study-the-corporate-auditor-agent">17. Case Study: The “Corporate Auditor” Agent</h2>

<p>Imagine a large bank auditing 10,000 expense reports.</p>
<ul>
  <li><strong>The OS Environment:</strong> A Windows VM with Excel, an internal Java-based legacy portal, and Outlook.</li>
  <li><strong>The Task:</strong> “Cross-reference the receipt in Outlook with the entry in the Java Portal. If it matches, update the Excel master sheet.”</li>
  <li><strong>The Execution:</strong>
    <ol>
      <li><strong>Outlook (API):</strong> Fetch the latest 50 emails.</li>
      <li><strong>Vision (Computer Use):</strong> Since the Java portal is 20 years old and has no API, the agent uses screenshots to navigate the menu, type the transaction ID, and read the “Status” field.</li>
      <li><strong>Excel (Library):</strong> Use <code class="language-plaintext highlighter-rouge">openpyxl</code> to append a row.</li>
    </ol>
  </li>
  <li><strong>The Result:</strong> A task that would take a human 5 minutes per report (830 hours total) is completed by 10 parallel agents in a single weekend.</li>
</ul>

<hr />

<h2 id="18-engineering-the-feedback-loop-the-self-healing-click">18. Engineering the Feedback Loop: The “Self-Healing” Click</h2>

<p>Sometimes, the model detects a button, but the click lands on the edge and nothing happens.</p>

<p><strong>The Solution:</strong></p>
<ul>
  <li><strong>Pre-Click State:</strong> Hash of the current screenshot.</li>
  <li><strong>Post-Click State:</strong> Hash of the screenshot 500ms after the click.</li>
  <li><strong>Verification:</strong> If <code class="language-plaintext highlighter-rouge">Hash_Pre == Hash_Post</code>, the UI didn’t change. The agent knows the action failed and automatically retries with a slight coordinate offset.</li>
</ul>

<hr />

<hr />

<h2 id="18-pattern-local-first-computer-use">18. Pattern: Local-First Computer Use</h2>

<p>As local models (like <strong>Llama-3-Vision</strong> or <strong>Qwen2-VL</strong>) become more powerful, we are moving away from the cloud.</p>

<p><strong>The Local Stack:</strong></p>
<ul>
  <li><strong>Model:</strong> Qwen2-VL-7B (quantized to 4-bit) running on an Apple M3 or NVIDIA RTX 4090.</li>
  <li><strong>Latency:</strong> Instead of 10s per turn (Cloud), we get 2s per turn (Local).</li>
  <li><strong>Privacy:</strong> No screenshots ever leave your machine. This is the only way some industries (Healthcare, Defense) will ever adopt computer use agents.</li>
</ul>

<hr />

<h2 id="19-privacy-by-design-the-context-free-ui">19. Privacy-By-Design: The “Context-Free” UI</h2>

<p>One advanced strategy for protecting data is to <strong>Strip the background</strong>.</p>

<p><strong>The Workflow:</strong></p>
<ol>
  <li><strong>Detection:</strong> Use a small local model to find all buttons and text fields.</li>
  <li><strong>Synthesis:</strong> Create a “Synthetic Screenshot” that only contains the wireframe of the UI elements (boxes and generic labels), with no actual user data (no emails, no balances).</li>
  <li><strong>Prompting:</strong> Send the wireframe to the cloud LLM.</li>
  <li><strong>Result:</strong> The LLM decides to “Click the Transfer button,” but it never saw the account balance.</li>
</ol>

<hr />

<h2 id="20-performance-analysis-the-action-to-observation-latency">20. Performance Analysis: The “Action-to-Observation” Latency</h2>

<p>In computer use, <strong>Latency is UX</strong>. If the agent clicks a button but takes 5 seconds to realize a pop-up appeared, the user will be frustrated.</p>

<p><strong>The Benchmark:</strong></p>
<ul>
  <li><strong>Perception Latency:</strong> Time to capture and process the image (Goal: &lt;500ms).</li>
  <li><strong>Cognition Latency:</strong> Time for the LLM to output the next action (Goal: &lt;2s).</li>
  <li><strong>Execution Latency:</strong> Time for the OS to process the click and render the change (Goal: &lt;100ms).</li>
  <li><strong>Target:</strong> A total loop time of <strong>&lt;5 seconds</strong> is necessary for an agent to feel “Responsive.”</li>
</ul>

<hr />

<hr />

<h2 id="21-pattern-advanced-action-sequences-macros-for-agents">21. Pattern: Advanced Action Sequences (Macros for Agents)</h2>

<p>A common problem in computer use is the “Click-by-Click” slowness. If an agent needs to “Save a PDF,” it might take 5 turns. We can solve this using <strong>Macros</strong>.</p>

<p><strong>The Pattern:</strong></p>
<ol>
  <li><strong>Recording:</strong> A human records a sequence of actions (e.g., File -&gt; Save As -&gt; Desktop).</li>
  <li><strong>Naming:</strong> You define this sequence as a single tool <code class="language-plaintext highlighter-rouge">save_as_pdf()</code>.</li>
  <li><strong>Execution:</strong> The agent calls the macro tool. The orchestrator executes the 5 steps in 200ms without calling the LLM in between.
    <ul>
      <li><strong>Result:</strong> This drastically reduces token usage and makes the agent feel “Senior” in its OS knowledge.</li>
    </ul>
  </li>
</ol>

<hr />

<h2 id="22-designing-memory-for-computer-use-the-visual-history">22. Designing Memory for Computer Use: The “Visual History”</h2>

<p>Unlike text agents that remember a chat history, Computer Use agents need to remember <strong>Visual States</strong>.</p>

<p><strong>The Blueprint:</strong></p>
<ul>
  <li><strong>The Strip:</strong> Store a thumbnail of the screen for the last 10 actions.</li>
  <li><strong>The Annotation:</strong> Label each thumbnail with the action taken (e.g., “Clicked Search”).</li>
  <li><strong>The Benefit:</strong> If the agent gets stuck, it can “Review the Tape” to see exactly where the UI diverged from its expectations.</li>
</ul>

<hr />

<h2 id="23-the-future-the-universal-operating-system">23. The Future: The “Universal Operating System”</h2>

<p>We are moving toward an era where the “Desktop” and the “Web” merge.</p>
<ul>
  <li><strong>Virtual Browser Isolation:</strong> Agents running inside a remote browser that has access to local files.</li>
  <li><strong>Agentic OS:</strong> An operating system built from the ground up to be controlled by LLMs, where every button has a unique, persistent ID that never changes between updates.</li>
</ul>

<hr />

<hr />

<h2 id="24-pattern-the-cold-start-problem-for-os-agents">24. Pattern: The “Cold Start” Problem for OS Agents</h2>

<p>When an agent first boots into a new OS environment, it is “Blind” to the installed software and file structure.</p>

<p><strong>The Discovery Loop:</strong></p>
<ol>
  <li><strong>System Inventory:</strong> The agent runs shell commands (<code class="language-plaintext highlighter-rouge">ls</code>, <code class="language-plaintext highlighter-rouge">ps</code>, <code class="language-plaintext highlighter-rouge">env</code>) to understand what apps are running and what files are available.</li>
  <li><strong>UI Cataloging:</strong> The agent opens the “Start Menu” or “Applications Folder” and takes a screenshot to identify where its primary tools are located.</li>
  <li><strong>Indexing:</strong> The agent builds a local “Mental Map” of the OS before taking its first user-directed action.
    <ul>
      <li><strong>Result:</strong> This 60-second “Warm-up” phase increases success rates by 40% compared to agents that jump straight into a task.</li>
    </ul>
  </li>
</ol>

<hr />

<h2 id="25-vision-action-calibration-correcting-for-offsets">25. Vision-Action Calibration: Correcting for Offsets</h2>

<p>Screenshots often have a “DPI Scale” (e.g., 200% on Retina displays). If the model sees a button at <code class="language-plaintext highlighter-rouge">(500, 500)</code>, but the OS expects coordinates in physical pixels, the click will miss.</p>

<p><strong>The Calibration Routine:</strong></p>
<ol>
  <li><strong>Test Click:</strong> The agent performs a “Right Click” in a dead-zone (e.g., the center of the desktop).</li>
  <li><strong>Observation:</strong> It takes a screenshot and finds the “Context Menu” that appeared.</li>
  <li><strong>Calculation:</strong> It measures the distance between where it <em>thought</em> it clicked and where the menu <em>actually</em> appeared.</li>
  <li><strong>Offset Application:</strong> It applies this <code class="language-plaintext highlighter-rouge">(dx, dy)</code> correction to every subsequent click.</li>
</ol>

<hr />

<h2 id="26-enterprise-grade-security-air-gapping-and-immutable-logs">26. Enterprise-Grade Security: Air-Gapping and Immutable Logs</h2>

<p>For high-security clients (Banks, Government), “Computer Use” is only acceptable with <strong>Zero-Trust</strong> architectures.</p>

<ul>
  <li><strong>Air-Gapping:</strong> The VM has no physical network card. It communicates with the Orchestrator through a “Virtual Serial Port” or a shared “Read-Only” memory buffer.</li>
  <li><strong>Immutable Screenshots:</strong> Every single frame shown to the AI is signed with a high-security Certificate. If anyone (even a rogue admin) tries to modify the logs to hide an agent’s action, the signature breaks.</li>
  <li><strong>The “Kill Switch”:</strong> A physical hardware button on the human’s desk that cuts power to the VM if the agent starts behaving erratically.</li>
</ul>

<hr />

<h2 id="27-summary--junior-engineer-roadmap">27. Summary &amp; Junior Engineer Roadmap</h2>

<p>Computer Use Agents move the AI away from the chat box and into the workstation.</p>

<p><strong>Your Roadmap to Mastery:</strong></p>
<ol>
  <li><strong>Master PyAutoGUI:</strong> Learn how to programmatically control the mouse and keyboard in Python.</li>
  <li><strong>Coordinate Math:</strong> Understand how to map 2D image coordinates to OS coordinates.</li>
  <li><strong>Virtualization:</strong> Learn how to set up a Proxmox or Docker-VNC environment for safe testing.</li>
  <li><strong>Benchmarking:</strong> Explore <strong>OSWorld</strong> or <strong>Tau Bench</strong> to see how your agent stacks up against state-of-the-art models.</li>
</ol>

<p><strong>Further reading (optional):</strong> If you want to keep humans in control during high-risk computer actions, see <a href="/ai-agents/0025-human-in-the-loop-patterns/">Human-in-the-Loop Patterns</a>.</p>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#anthropic-computer-use" class="page__taxonomy-item p-category" rel="tag">anthropic-computer-use</a><span class="sep">, </span>
    
      <a href="/tags/#computer-use" class="page__taxonomy-item p-category" rel="tag">computer-use</a><span class="sep">, </span>
    
      <a href="/tags/#os-automation" class="page__taxonomy-item p-category" rel="tag">os-automation</a><span class="sep">, </span>
    
      <a href="/tags/#tool-use-vision" class="page__taxonomy-item p-category" rel="tag">tool-use-vision</a><span class="sep">, </span>
    
      <a href="/tags/#virtualization" class="page__taxonomy-item p-category" rel="tag">virtualization</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#ai-agents" class="page__taxonomy-item p-category" rel="tag">ai-agents</a>
    
    </span>
  </p>


        
      </footer>

      <div class="page__related page__related--full">
  <h2 class="page__related-title">Related across topics</h2>
  <style>
    /* Make section span full content width and use 2 equal columns */
    .page__related--full { float: inline-start; width: 100%; padding: 0; }
    .cross-related-grid { display: grid; grid-template-columns: repeat(2, minmax(0, 1fr)); gap: 2rem; }
    @media (max-width: 768px) { .cross-related-grid { grid-template-columns: 1fr; } }
    /* Ensure archive cards stretch nicely in the grid */
    .cross-related-grid .list__item, .cross-related-grid .grid__item { width: auto; float: none; margin: 0; }
  </style>
  <div class="cross-related-grid">
    



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/dsa/0024-word-break/" rel="permalink">Word Break
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          20 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">The fundamental string segmentation problem that powers spell checkers, search engines, and tokenizers.
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ml-system-design/0024-tokenization-systems/" rel="permalink">Tokenization Systems
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          16 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">The critical preprocessing step that defines the vocabulary and capabilities of Large Language Models.
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/speech-tech/0024-speech-tokenization/" rel="permalink">Speech Tokenization
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          15 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">The breakthrough that allows us to treat audio like text, enabling GPT-style models for speech.
</p>
  </article>
</div>

  </div>
</div>

      <section class="page__share">
  <h4 class="page__share-title">Share on</h4>

  <a href="https://twitter.com/intent/tweet?via=arunbaby0&text=Computer+Use+Agents%20https%3A%2F%2Fwww.arunbaby.com%2Fai-agents%2F0024-computer-use-agents%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.arunbaby.com%2Fai-agents%2F0024-computer-use-agents%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.arunbaby.com/ai-agents/0024-computer-use-agents/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/ai-agents/0023-ui-automation-agents/" class="pagination--pager" title="UI Automation Agents">Previous</a>
    
    
      <a href="/ai-agents/0025-human-in-the-loop-patterns/" class="pagination--pager" title="Human-in-the-Loop Patterns">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 1990 - 2143 <a href="https://www.arunbaby.com">Arun Baby</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JRJPEC9SS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0JRJPEC9SS', { 'anonymize_ip': false});
</script>








  </body>
</html>
