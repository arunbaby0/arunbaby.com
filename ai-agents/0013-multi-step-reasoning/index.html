<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Multi-Step Reasoning - Arun Baby</title>
<meta name="description" content="“Thinking Fast and Slow: How to make LLMs stop guessing and start solving.”">


  <meta name="author" content="Arun Baby">
  
  <meta property="article:author" content="Arun Baby">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Arun Baby">
<meta property="og:title" content="Multi-Step Reasoning">
<meta property="og:url" content="https://www.arunbaby.com/ai-agents/0013-multi-step-reasoning/">


  <meta property="og:description" content="“Thinking Fast and Slow: How to make LLMs stop guessing and start solving.”">



  <meta property="og:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">



  <meta name="twitter:site" content="@arunbaby0">
  <meta name="twitter:title" content="Multi-Step Reasoning">
  <meta name="twitter:description" content="“Thinking Fast and Slow: How to make LLMs stop guessing and start solving.”">
  <meta name="twitter:url" content="https://www.arunbaby.com/ai-agents/0013-multi-step-reasoning/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">
    
  

  



  <meta property="article:published_time" content="2025-12-21T22:46:31+05:30">





  

  


<link rel="canonical" href="https://www.arunbaby.com/ai-agents/0013-multi-step-reasoning/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Baby Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          <span class="site-subtitle">Arun Baby</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/dsa/"
                
                
              >DSA</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ml-system-design/"
                
                
              >ML Systems</a>
            </li><li class="masthead__menu-item">
              <a
                href="/speech-tech/"
                
                
              >Speech Tech</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ai-agents/"
                
                
              >AI Agents</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li><li class="masthead__menu-item">
              <a
                href="/statuses/"
                
                
              >Statuses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/contact/"
                
                
              >Contact</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main" class="no-author-sidebar">
  
  <div class="sidebar sticky">
  
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Multi-Step Reasoning">
    <meta itemprop="description" content="“Thinking Fast and Slow: How to make LLMs stop guessing and start solving.”">
    <meta itemprop="datePublished" content="2025-12-21T22:46:31+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://www.arunbaby.com/ai-agents/0013-multi-step-reasoning/" itemprop="url">Multi-Step Reasoning
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          8 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#1-introduction-the-system-1-trap">1. Introduction: The System 1 Trap</a></li><li><a href="#2-chain-of-thought-cot-the-lets-think-revolution">2. Chain of Thought (CoT): The “Let’s Think” Revolution</a><ul><li><a href="#21-the-mechanic-computational-space">2.1 The Mechanic: Computational Space</a></li><li><a href="#22-zero-shot-vs-few-shot-cot">2.2 Zero-Shot vs. Few-Shot CoT</a></li><li><a href="#23-limits-of-cot">2.3 Limits of CoT</a></li></ul></li><li><a href="#3-self-consistency-democracy-for-tokens">3. Self-Consistency: Democracy for Tokens</a><ul><li><a href="#31-the-algorithm">3.1 The Algorithm</a></li><li><a href="#32-why-it-works">3.2 Why it works</a></li></ul></li><li><a href="#4-tree-of-thoughts-tot-searching-the-space">4. Tree of Thoughts (ToT): Searching the Space</a><ul><li><a href="#41-the-architecture">4.1 The Architecture</a></li><li><a href="#42-application-in-agents-the-devin-pattern">4.2 Application in Agents: The “Devin” Pattern</a></li></ul></li><li><a href="#5-program-aided-language-models-pal">5. Program-Aided Language Models (PAL)</a></li><li><a href="#6-the-future-reasoning-tokens-o1">6. The Future: Reasoning Tokens (o1)</a><ul><li><a href="#61-training-for-thought">6.1 Training for Thought</a></li><li><a href="#62-the-paradigm-shift">6.2 The Paradigm Shift</a></li></ul></li><li><a href="#7-code-implementing-self-consistency">7. Code: Implementing Self-Consistency</a></li><li><a href="#8-summary">8. Summary</a></li></ul>
            </nav>
          </aside>
        
        <p><strong>“Thinking Fast and Slow: How to make LLMs stop guessing and start solving.”</strong></p>

<h2 id="1-introduction-the-system-1-trap">1. Introduction: The System 1 Trap</h2>

<p>Standard LLMs are <strong>probability engines</strong>, not logic engines. When you ask <em>“What is 15 * 27?”</em>, the model doesn’t “calculate” it using an ALU (Arithmetic Logic Unit). It predicts the most likely next token based on its training distribution.</p>
<ul>
  <li>If it has seen <code class="language-plaintext highlighter-rouge">15 * 27 = 405</code> a thousand times, it outputs <code class="language-plaintext highlighter-rouge">405</code> (Recitation).</li>
  <li>If it hasn’t, it might output <code class="language-plaintext highlighter-rouge">415</code> because the digits “feel” right (Hallucination).</li>
</ul>

<p>This is <strong>System 1 Thinking</strong> (Intuitive, Fast, Error-Prone, Pattern-Matching), as described by Daniel Kahneman.
For creative writing, System 1 is great. For Agents, it is a disaster.
Agents need to execute code, manage budgets, and delete files. We cannot afford “intuitive guesses.” We need <strong>System 2 Thinking</strong> (Logical, Slow, Deliberate, Algorithm-Following).</p>

<p>In this post, we will explore the Prompt Engineering and Architectural patterns used to force LLMs into System 2 mode: <strong>Chain of Thought (CoT), Self-Consistency, Tree of Thoughts (ToT), and Program-Aided Language Models (PAL).</strong> Finally, we will demystify OpenAI’s new <strong>o1 (Reasoning Tokens)</strong> paradigm.</p>

<hr />

<h2 id="2-chain-of-thought-cot-the-lets-think-revolution">2. Chain of Thought (CoT): The “Let’s Think” Revolution</h2>

<p>In 2022, a paper from Google titled <em>“Chain of Thought Prompting Elicits Reasoning in Large Language Models”</em> changed the trajectory of AI. The discovery was surprisingly simple: <strong>If you ask the model to explain its work significantly before giving the answer, its accuracy roughly triples on math/logic tasks.</strong></p>

<h3 id="21-the-mechanic-computational-space">2.1 The Mechanic: Computational Space</h3>
<p>Why does this work? It’s not magic; it’s <strong>Computational Space</strong>.</p>
<ul>
  <li><strong>Without CoT:</strong> The model must transform Input -&gt; Answer (<code class="language-plaintext highlighter-rouge">Input: 15*27</code>, <code class="language-plaintext highlighter-rouge">Output: 405</code>) in a single forward pass per output digit. It has almost zero depth to “carry the one” or store intermediate variables.</li>
  <li><strong>With CoT:</strong> The model outputs <code class="language-plaintext highlighter-rouge">10 * 27 = 270</code>. <code class="language-plaintext highlighter-rouge">5 * 27 = 135</code>. <code class="language-plaintext highlighter-rouge">270 + 135...</code>.</li>
  <li>By forcing it to generate these text tokens, we are giving the transformer layers more <strong>hops</strong> to process the state.</li>
  <li>We are effectively letting it write to a “Scratchpad” (the Context Window) which it can then <strong>attend to</strong> for the final calculation.</li>
  <li><strong>Time = Compute.</strong> Generating more tokens takes more time, allowing for more computation.</li>
</ul>

<h3 id="22-zero-shot-vs-few-shot-cot">2.2 Zero-Shot vs. Few-Shot CoT</h3>
<ul>
  <li><strong>Zero-Shot CoT:</strong> Just appending the magic phrase: <em>“Let’s think step by step.”</em> (Kojima et al., 2022).</li>
  <li><em>Result:</em> Massive boost for large models (GPT-4), minimal boost for small models (Llama-8B).</li>
  <li><strong>Few-Shot CoT:</strong> Providing 3 examples of Questions + Step-by-Step reasoning in the prompt.</li>
  <li><em>Result:</em> Superior performance. It enforces the <strong>Structure</strong> of the reasoning. It prevents the model from being “lazy” and just jumping to the answer.</li>
</ul>

<h3 id="23-limits-of-cot">2.3 Limits of CoT</h3>
<p>CoT is linear. It assumes the problem can be solved in a straight line from A -&gt; B -&gt; C.
If the model makes a mistake at Step B (e.g., <code class="language-plaintext highlighter-rouge">5 * 27 = 125</code>), the error propagates to Step C. The model rarely “Backtracks” in a standard CoT because it is autoregressive (always moving forward).</p>

<hr />

<h2 id="3-self-consistency-democracy-for-tokens">3. Self-Consistency: Democracy for Tokens</h2>

<p>CoT isn’t perfect. Sometimes the reasoning chain goes off the rails due to the probabilistic nature (Temperature &gt; 0).
<strong>Self-Consistency</strong> (Wang et al., 2022) is an ensemble technique that exploits this randomness.</p>

<h3 id="31-the-algorithm">3.1 The Algorithm</h3>
<ol>
  <li>Take the prompt (with CoT).</li>
  <li>Run the model <strong>5 to 10 times</strong> in parallel (at high Temperature, e.g., 0.7).
    <ul>
      <li><em>Path A:</em> “Reasoning… 5+6=11.”</li>
      <li><em>Path B:</em> “Reasoning… 5+6=11.”</li>
      <li><em>Path C:</em> “Reasoning… 5+6=10.” (Hallucination)</li>
      <li><em>Path D:</em> “Reasoning… 5+6=11.”</li>
      <li><em>Path E:</em> “Reasoning… 5+6=12.”</li>
    </ul>
  </li>
  <li><strong>Vote (Marginalization):</strong> We look only at the <strong>Final Answers</strong>.
    <ul>
      <li>“11”: 3 votes.</li>
      <li>“10”: 1 vote.</li>
      <li>“12”: 1 vote.</li>
    </ul>
  </li>
  <li><strong>Result:</strong> Output “11”.</li>
</ol>

<h3 id="32-why-it-works">3.2 Why it works</h3>
<p>Reasoning paths are diverse, but correct answers are usually unique. There are infinite ways to be wrong (hallucinate random numbers), but usually only one way to be right. By sampling multiple paths, the “Signal” (Truth) interferes constructively, while the “Noise” (Hallucinations) cancels out.</p>
<ul>
  <li><strong>Trade-off:</strong> It costs <strong>N</strong> times more tokens and money.</li>
</ul>

<hr />

<h2 id="4-tree-of-thoughts-tot-searching-the-space">4. Tree of Thoughts (ToT): Searching the Space</h2>

<p>For planning tasks (e.g., “Write a novel,” “Solve a 24-puzzle,” “Debug a complex codebase”), a single linear chain isn’t enough. You need to explore options, backtrack, and prune dead ends.
<strong>Tree of Thoughts</strong> (Yao et al., 2023) applies classical search algorithms (BFS/DFS) to LLM thoughts.</p>

<h3 id="41-the-architecture">4.1 The Architecture</h3>
<ol>
  <li><strong>Decomposition:</strong> Break the problem into steps.</li>
  <li><strong>Generation:</strong> At Step 1, generate 3 possible next moves (Thoughts).</li>
  <li><strong>Evaluation (The Critic):</strong> Use a “Judge” prompt to score each move (Sure/Likely/Impossible).</li>
  <li><strong>Search:</strong>
    <ul>
      <li>If “Impossible”, <strong>Prune</strong> the branch.</li>
      <li>If “Sure”, keep generating from there.</li>
      <li>If “Likely”, keep as a backup.</li>
      <li>This usually requires a <strong>Controller Script</strong> (Python) to manage the state tree.</li>
    </ul>
  </li>
</ol>

<h3 id="42-application-in-agents-the-devin-pattern">4.2 Application in Agents: The “Devin” Pattern</h3>
<p>This is how autonomous coding agents work conceptually.</p>
<ul>
  <li><em>Task:</em> Fix bug in <code class="language-plaintext highlighter-rouge">main.py</code>.</li>
  <li><em>Thought 1:</em> “Maybe it’s a typo.” -&gt; Action: <code class="language-plaintext highlighter-rouge">cat main.py</code>. -&gt; Observation: No typo. -&gt; <strong>Backtrack.</strong></li>
  <li><em>Thought 2:</em> “Maybe it’s a logic error.” -&gt; Action: <code class="language-plaintext highlighter-rouge">test_logic.py</code>. -&gt; Observation: Fails. -&gt; <strong>Proceed.</strong></li>
</ul>

<p>ToT turns the “Stream of Consciousness” into a “Graph of Consciousness.”</p>

<hr />

<h2 id="5-program-aided-language-models-pal">5. Program-Aided Language Models (PAL)</h2>

<p>For math and logic, LLMs are bad calculators. Even with CoT, they fail <code class="language-plaintext highlighter-rouge">3284 * 1293</code> often.
<strong>PAL</strong> (Gao et al., 2022) says: <em>“Don’t ask the LLM to calculate. Ask it to write a Python program to calculate.”</em></p>

<ul>
  <li><strong>Prompt:</strong> “Roger has 5 balls…”</li>
  <li><strong>PAL Output:</strong>
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">balls_initial</span> <span class="o">=</span> <span class="mi">5</span>
 <span class="n">cans</span> <span class="o">=</span> <span class="mi">2</span>
 <span class="n">balls_per_can</span> <span class="o">=</span> <span class="mi">3</span>
 <span class="n">total</span> <span class="o">=</span> <span class="n">balls_initial</span> <span class="o">+</span> <span class="p">(</span><span class="n">cans</span> <span class="o">*</span> <span class="n">balls_per_can</span><span class="p">)</span>
 <span class="nf">print</span><span class="p">(</span><span class="n">total</span><span class="p">)</span>
</code></pre></div>    </div>
  </li>
  <li><strong>Execution:</strong> The runtime executes the Python code.</li>
  <li><strong>Result:</strong> Exact precision.</li>
  <li><strong>Agent Takeaway:</strong> Always offload deterministic logic (Math, Date handling, String manipulation) to <strong>Tools/Code</strong>, never rely on the LLM’s weights.</li>
</ul>

<hr />

<h2 id="6-the-future-reasoning-tokens-o1">6. The Future: Reasoning Tokens (o1)</h2>

<p>In late 2024, OpenAI released <strong>o1</strong>. It introduced the concept of <strong>Hidden Reasoning Chains</strong>.</p>

<h3 id="61-training-for-thought">6.1 Training for Thought</h3>
<p>Instead of the user prompting “Let’s think step by step,” the model is trained via <strong>Reinforcement Learning</strong> to generating its own CoT.</p>
<ul>
  <li>It generates thousands of “Thought Tokens” that are <strong>Hidden</strong> from the user.</li>
  <li>It backtracks, corrects itself (“Wait, that’s wrong”), and tries new angles.</li>
  <li>Only when it is confident does it emit the visible “Answer Tokens.”</li>
</ul>

<h3 id="62-the-paradigm-shift">6.2 The Paradigm Shift</h3>
<ul>
  <li><strong>Inference-Time Compute:</strong> We used to think inference was constant cost ($O(N)$). Now, we treat inference like search. We can spend more time (and money) to get a better answer.</li>
  <li><strong>The “Thinking” Placeholder:</strong> While o1 is processing, it shows “Thinking…”. This is actually the model generating hidden tokens.</li>
  <li><strong>Implication:</strong> We are moving from “Prompt Engineering Reason” to “Buying Reason.” We pay for the compute time of the model’s reflection.</li>
</ul>

<hr />

<h2 id="7-code-implementing-self-consistency">7. Code: Implementing Self-Consistency</h2>

<p>A robust Python pattern to perform voting on reasoning chains.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="n">re</span>
<span class="kn">import</span> <span class="n">openai</span>

<span class="k">def</span> <span class="nf">generate_self_consistency_answer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
 <span class="sh">"""</span><span class="s">
 Generates N responses and returns the most common numeric answer.
 </span><span class="sh">"""</span>
 <span class="n">answers</span> <span class="o">=</span> <span class="p">[]</span>
 <span class="n">reasoning_traces</span> <span class="o">=</span> <span class="p">[]</span>

 <span class="c1"># Run N parallel requests (or one request with n=5 if supported)
</span> <span class="c1"># High temperature is key for diversity
</span> <span class="n">responses</span> <span class="o">=</span> <span class="n">openai</span><span class="p">.</span><span class="n">chat</span><span class="p">.</span><span class="n">completions</span><span class="p">.</span><span class="nf">create</span><span class="p">(</span>
 <span class="n">model</span><span class="o">=</span><span class="sh">"</span><span class="s">gpt-4o</span><span class="sh">"</span><span class="p">,</span>
 <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">prompt</span> <span class="o">+</span> <span class="sh">"</span><span class="se">\n</span><span class="s">Let</span><span class="sh">'</span><span class="s">s think step by step.</span><span class="sh">"</span><span class="p">}],</span>
 <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
 <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span>
 <span class="p">)</span>

 <span class="k">for</span> <span class="n">choice</span> <span class="ow">in</span> <span class="n">responses</span><span class="p">.</span><span class="n">choices</span><span class="p">:</span>
 <span class="n">text</span> <span class="o">=</span> <span class="n">choice</span><span class="p">.</span><span class="n">message</span><span class="p">.</span><span class="n">content</span>
 <span class="n">reasoning_traces</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

 <span class="c1"># Simple extraction logic (in production, use structured output)
</span> <span class="c1"># Find the last number in the text
</span> <span class="n">numbers</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">findall</span><span class="p">(</span><span class="sa">r</span><span class="sh">"</span><span class="s">[-+]?\d*\.\d+|\d+</span><span class="sh">"</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
 <span class="k">if</span> <span class="n">numbers</span><span class="p">:</span>
 <span class="n">answers</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">numbers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

 <span class="c1"># Voting
</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">answers</span><span class="p">:</span>
 <span class="k">return</span> <span class="bp">None</span><span class="p">,</span> <span class="n">reasoning_traces</span>

 <span class="n">vote_counts</span> <span class="o">=</span> <span class="nc">Counter</span><span class="p">(</span><span class="n">answers</span><span class="p">)</span>
 <span class="n">most_common</span><span class="p">,</span> <span class="n">count</span> <span class="o">=</span> <span class="n">vote_counts</span><span class="p">.</span><span class="nf">most_common</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
 <span class="n">confidence</span> <span class="o">=</span> <span class="n">count</span> <span class="o">/</span> <span class="n">n</span>

 <span class="k">return</span> <span class="p">{</span>
 <span class="sh">"</span><span class="s">final_answer</span><span class="sh">"</span><span class="p">:</span> <span class="n">most_common</span><span class="p">,</span>
 <span class="sh">"</span><span class="s">confidence</span><span class="sh">"</span><span class="p">:</span> <span class="n">confidence</span><span class="p">,</span>
 <span class="sh">"</span><span class="s">votes</span><span class="sh">"</span><span class="p">:</span> <span class="nf">dict</span><span class="p">(</span><span class="n">vote_counts</span><span class="p">),</span>
 <span class="sh">"</span><span class="s">traces</span><span class="sh">"</span><span class="p">:</span> <span class="n">reasoning_traces</span>
 <span class="p">}</span>

<span class="c1"># Usage
</span><span class="n">prompt</span> <span class="o">=</span> <span class="sh">"</span><span class="s">If I have 3 apples and buy 2 dozen more, then eat 5, how many do I have?</span><span class="sh">"</span>
<span class="n">result</span> <span class="o">=</span> <span class="nf">generate_self_consistency_answer</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Consensus Answer: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="sh">'</span><span class="s">final_answer</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Confidence: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="sh">'</span><span class="s">confidence</span><span class="sh">'</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s">%</span><span class="sh">"</span><span class="p">)</span>
<span class="c1"># Output: 22 (Confidence 100%)
# Logic: 3 + 24 - 5 = 22.
</span></code></pre></div></div>

<hr />

<h2 id="8-summary">8. Summary</h2>

<p>Multi-Step Reasoning turns an LLM from a Text Predictor into a Logic Engine.</p>

<ol>
  <li><strong>CoT:</strong> The baseline. Always force the model to “show its work.”</li>
  <li><strong>Self-Consistency:</strong> The reliability layer. Run it 5 times and vote.</li>
  <li><strong>ToT:</strong> The search layer. For hard problems, explore the tree.</li>
  <li><strong>PAL:</strong> The cheat code. Use Python for math.</li>
</ol>

<p>For an autonomous agent, <strong>never</strong> accept the first token as truth for a critical decision. Force the model to think, verify, and vote before acting.</p>

<p>Reasoning is efficient, but it becomes actionable when combined with tools in the <strong>ReAct Pattern</strong>.</p>

<hr />

<p><strong>Originally published at:</strong> <a href="https://www.arunbaby.com/ai-agents/0013-multi-step-reasoning/">arunbaby.com/ai-agents/0013-multi-step-reasoning</a></p>

<p><em>If you found this helpful, consider sharing it with others who might benefit.</em></p>


        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#chain-of-thought" class="page__taxonomy-item p-category" rel="tag">chain-of-thought</a><span class="sep">, </span>
    
      <a href="/tags/#o1" class="page__taxonomy-item p-category" rel="tag">o1</a><span class="sep">, </span>
    
      <a href="/tags/#pal" class="page__taxonomy-item p-category" rel="tag">pal</a><span class="sep">, </span>
    
      <a href="/tags/#reasoning" class="page__taxonomy-item p-category" rel="tag">reasoning</a><span class="sep">, </span>
    
      <a href="/tags/#self-consistency" class="page__taxonomy-item p-category" rel="tag">self-consistency</a><span class="sep">, </span>
    
      <a href="/tags/#tot" class="page__taxonomy-item p-category" rel="tag">tot</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#ai-agents" class="page__taxonomy-item p-category" rel="tag">ai-agents</a>
    
    </span>
  </p>


        
      </footer>

      <div class="page__related page__related--full">
  <h2 class="page__related-title">Related across topics</h2>
  <style>
    /* Make section span full content width and use 2 equal columns */
    .page__related--full { float: inline-start; width: 100%; padding: 0; }
    .cross-related-grid { display: grid; grid-template-columns: repeat(2, minmax(0, 1fr)); gap: 2rem; }
    @media (max-width: 768px) { .cross-related-grid { grid-template-columns: 1fr; } }
    /* Ensure archive cards stretch nicely in the grid */
    .cross-related-grid .list__item, .cross-related-grid .grid__item { width: auto; float: none; margin: 0; }
  </style>
  <div class="cross-related-grid">
    



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/dsa/0013-container-with-most-water/" rel="permalink">Container With Most Water
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          24 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Master the two-pointer greedy technique that powers resource optimization in production ML systems.
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ml-system-design/0013-resource-allocation-for-ml/" rel="permalink">Resource Allocation for ML
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          28 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Build production ML infrastructure that dynamically allocates resources using greedy optimization to maximize throughput and minimize costs.
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/speech-tech/0013-compute-allocation-for-speech-models/" rel="permalink">Compute Allocation for Speech Models
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          23 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Optimize speech pipeline throughput by allocating compute to bottleneck stages using greedy resource management.
</p>
  </article>
</div>

  </div>
</div>

      <section class="page__share">
  <h4 class="page__share-title">Share on</h4>

  <a href="https://twitter.com/intent/tweet?via=arunbaby0&text=Multi-Step+Reasoning%20https%3A%2F%2Fwww.arunbaby.com%2Fai-agents%2F0013-multi-step-reasoning%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.arunbaby.com%2Fai-agents%2F0013-multi-step-reasoning%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.arunbaby.com/ai-agents/0013-multi-step-reasoning/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/ai-agents/0012-context-window-management/" class="pagination--pager" title="Context Window Management">Previous</a>
    
    
      <a href="/ai-agents/0014-react-pattern-deep-dive/" class="pagination--pager" title="The ReAct Pattern Deep Dive">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 1990 - 2143 <a href="https://www.arunbaby.com">Arun Baby</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JRJPEC9SS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0JRJPEC9SS', { 'anonymize_ip': false});
</script>








  </body>
</html>
