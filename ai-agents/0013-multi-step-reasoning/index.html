<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Multi-Step Reasoning - Arun Baby</title>
<meta name="description" content="“Thinking Fast and Slow: How to make LLMs stop guessing.”">


  <meta name="author" content="Arun Baby">
  
  <meta property="article:author" content="Arun Baby">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Arun Baby">
<meta property="og:title" content="Multi-Step Reasoning">
<meta property="og:url" content="https://www.arunbaby.com/ai-agents/0013-multi-step-reasoning/">


  <meta property="og:description" content="“Thinking Fast and Slow: How to make LLMs stop guessing.”">



  <meta property="og:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">



  <meta name="twitter:site" content="@arunbaby0">
  <meta name="twitter:title" content="Multi-Step Reasoning">
  <meta name="twitter:description" content="“Thinking Fast and Slow: How to make LLMs stop guessing.”">
  <meta name="twitter:url" content="https://www.arunbaby.com/ai-agents/0013-multi-step-reasoning/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">
    
  

  



  <meta property="article:published_time" content="2025-12-14T23:01:57+05:30">





  

  


<link rel="canonical" href="https://www.arunbaby.com/ai-agents/0013-multi-step-reasoning/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Baby Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          <span class="site-subtitle">Arun Baby</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/dsa/"
                
                
              >DSA</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ml-system-design/"
                
                
              >ML Systems</a>
            </li><li class="masthead__menu-item">
              <a
                href="/speech-tech/"
                
                
              >Speech Tech</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ai-agents/"
                
                
              >AI Agents</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li><li class="masthead__menu-item">
              <a
                href="/statuses/"
                
                
              >Statuses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/contact/"
                
                
              >Contact</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main" class="">
  
  <div class="sidebar sticky">
  
    


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="https://www.arunbaby.com/">
        <img src="/assets/images/profile-photo.png" alt="Arun Baby" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="https://www.arunbaby.com/" itemprop="url">Arun Baby</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>Becoming <strong>Unlabelable</strong></p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">India</span>
        </li>
      

      
        
          
            <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i><span class="label">Twitter</span></a></li>
          
        
          
            <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span class="label">LinkedIn</span></a></li>
          
        
          
            <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i><span class="label">Google Scholar</span></a></li>
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Multi-Step Reasoning">
    <meta itemprop="description" content="“Thinking Fast and Slow: How to make LLMs stop guessing.”">
    <meta itemprop="datePublished" content="2025-12-14T23:01:57+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://www.arunbaby.com/ai-agents/0013-multi-step-reasoning/" itemprop="url">Multi-Step Reasoning
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          6 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#1-introduction-the-system-1-trap">1. Introduction: The System 1 Trap</a></li><li><a href="#2-chain-of-thought-cot-the-lets-think-revolution">2. Chain of Thought (CoT): The “Let’s Think” Revolution</a><ul><li><a href="#21-the-mechanic">2.1 The Mechanic</a></li><li><a href="#22-why-it-works">2.2 Why it works</a></li><li><a href="#23-zero-shot-vs-few-shot-cot">2.3 Zero-Shot vs. Few-Shot CoT</a></li></ul></li><li><a href="#3-self-consistency-democracy-for-tokens">3. Self-Consistency: Democracy for Tokens</a><ul><li><a href="#31-the-algorithm">3.1 The Algorithm</a></li><li><a href="#32-why-it-works">3.2 Why it works</a></li></ul></li><li><a href="#4-tree-of-thoughts-tot-searching-the-space">4. Tree of Thoughts (ToT): Searching the Space</a><ul><li><a href="#41-the-algorithm">4.1 The Algorithm</a></li><li><a href="#42-application-in-agents">4.2 Application in Agents</a></li></ul></li><li><a href="#5-the-future-reasoning-tokens-o1">5. The Future: Reasoning Tokens (o1)</a></li><li><a href="#6-code-implementing-self-consistency">6. Code: Implementing Self-Consistency</a></li><li><a href="#7-summary">7. Summary</a></li></ul>
            </nav>
          </aside>
        
        <p><strong>“Thinking Fast and Slow: How to make LLMs stop guessing.”</strong></p>

<h2 id="1-introduction-the-system-1-trap">1. Introduction: The System 1 Trap</h2>

<p>Standard LLMs are <strong>probability engines</strong>, not logic engines. When you ask * “What is 15 * 27?”*, the model doesn’t “calculate” it. It predicts the most likely next token based on training data. If it has seen <code class="language-plaintext highlighter-rouge">15 * 27 = 405</code> a thousand times, it outputs <code class="language-plaintext highlighter-rouge">405</code>. If it hasn’t, it might output <code class="language-plaintext highlighter-rouge">415</code> because the digits “feel” right.</p>

<p>This is <strong>System 1 Thinking</strong> (Intuitive, Fast, Error-Prone).</p>

<p>For Agents, this is a disaster. Agents execute code, manage money, and delete files. We cannot afford “intuitive guesses.” We need <strong>System 2 Thinking</strong> (Logical, Slow, Deliberate).</p>

<p>In this post, we will explore the techniques to force LLMs into System 2 mode: <strong>Chain of Thought (CoT), Self-Consistency, and Tree of Thoughts (ToT).</strong> We will also look at the future of <strong>“Reasoning Tokens”</strong> (introduced by OpenAI’s o1 model), which separates the “Thinking Process” from the “Final Answer.”</p>

<hr />

<h2 id="2-chain-of-thought-cot-the-lets-think-revolution">2. Chain of Thought (CoT): The “Let’s Think” Revolution</h2>

<p>In 2022, a paper from Google titled <em>“Chain of Thought Prompting Elicits Reasoning in Large Language Models”</em> changed everything. The discovery was simple: <strong>If you ask the model to explain its work, it gets the answer right.</strong></p>

<h3 id="21-the-mechanic">2.1 The Mechanic</h3>
<ul>
  <li><strong>Standard Prompt:</strong>
    <ul>
      <li>Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 balls. How many does he have?</li>
      <li>A: 11.</li>
    </ul>
  </li>
  <li><strong>CoT Prompt:</strong>
    <ul>
      <li>Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 balls. How many does he have? <strong>Let’s think step by step.</strong></li>
      <li>A: Roger started with 5 balls. 2 cans * 3 balls/can = 6 balls. 5 + 6 = 11. The answer is 11.</li>
    </ul>
  </li>
</ul>

<h3 id="22-why-it-works">2.2 Why it works</h3>
<p>It’s not magic; it’s <strong>Computational Space</strong>.
An LLM has limited computation per token. It cannot solve a 3-step logic puzzle in a single forward pass used to generate the token “11”.
By forcing it to generate the text “2 cans * 3 balls…”, we are giving the transformer layers more <strong>hops</strong> to process the intermediate state. We are effectively letting it write to a “Scratchpad” (the Context Window) which it can then attend to for the final calc.</p>

<h3 id="23-zero-shot-vs-few-shot-cot">2.3 Zero-Shot vs. Few-Shot CoT</h3>
<ul>
  <li><strong>Zero-Shot:</strong> Just appending “Let’s think step by step.” (Works well on big models).</li>
  <li><strong>Few-Shot:</strong> Providing 3 examples of Questions + Step-by-Step reasoning. (Works much better, enforces the <em>structure</em> of the reasoning).</li>
</ul>

<hr />

<h2 id="3-self-consistency-democracy-for-tokens">3. Self-Consistency: Democracy for Tokens</h2>

<p>CoT isn’t perfect. Sometimes the reasoning chain goes off the rails.
<strong>Self-Consistency</strong> is an ensemble technique.</p>

<h3 id="31-the-algorithm">3.1 The Algorithm</h3>
<ol>
  <li>Take the prompt (with CoT).</li>
  <li>Run the model <strong>5 times</strong> (at high Temperature, e.g., 0.7).
    <ul>
      <li><em>Path A:</em> “5+6=11.”</li>
      <li><em>Path B:</em> “5+6=11.”</li>
      <li><em>Path C:</em> “5+6=10.” (Halucination)</li>
      <li><em>Path D:</em> “5+6=11.”</li>
      <li><em>Path E:</em> “5+6=12.”</li>
    </ul>
  </li>
  <li><strong>Vote:</strong> The answer “11” appears 3 times. “10” appears once. “12” appears once.</li>
  <li><strong>Result:</strong> Output “11”.</li>
</ol>

<h3 id="32-why-it-works">3.2 Why it works</h3>
<p>Reasoning paths are diverse, but correct answers are unique. There are many ways to be wrong, but usually only one way to be right. By sampling multiple paths, the “Signal” (Truth) interferes constructively, while the “Noise” (Hallucinations) cancels out.</p>
<ul>
  <li><strong>Trade-off:</strong> It costs 5x more tokens and latency.</li>
</ul>

<hr />

<h2 id="4-tree-of-thoughts-tot-searching-the-space">4. Tree of Thoughts (ToT): Searching the Space</h2>

<p>For planning tasks (e.g., “Write a novel” or “Solve a 24-puzzle”), a single linear chain isn’t enough. You need to explore options, backtrack, and prune dead ends.</p>

<h3 id="41-the-algorithm">4.1 The Algorithm</h3>
<ol>
  <li><strong>Decomposition:</strong> Break the problem into steps.</li>
  <li><strong>Generation:</strong> At Step 1, generate 3 possible next moves.</li>
  <li><strong>Evaluation:</strong> Use a “Judge” prompt to score each move (Good/Bad/Maybe).</li>
  <li><strong>Search:</strong>
    <ul>
      <li>If “Bad”, prune the branch.</li>
      <li>If “Good”, keep generating from there.</li>
      <li>(Uses BFS or DFS search algorithms).</li>
    </ul>
  </li>
</ol>

<h3 id="42-application-in-agents">4.2 Application in Agents</h3>
<p>This is how autonomous coding agents (like Devin) work conceptually.</p>
<ul>
  <li><em>Task:</em> Fix bug.</li>
  <li><em>Thought 1:</em> “Maybe it’s a typo.” -&gt; Check file. -&gt; (No typo). -&gt; <strong>Backtrack.</strong></li>
  <li><em>Thought 2:</em> “Maybe it’s a logic error.” -&gt; Check function. -&gt; (Found it). -&gt; <strong>Proceed.</strong></li>
</ul>

<p>ToT requires an <strong>Agent Loop</strong>, not just a single prompt.</p>

<hr />

<h2 id="5-the-future-reasoning-tokens-o1">5. The Future: Reasoning Tokens (o1)</h2>

<p>In late 2024, OpenAI released <strong>o1</strong>. It introduced the concept of <strong>Hidden Reasoning Chains</strong>.
Instead of the user prompting “Let’s think step by step,” the model performs a massive CoT internally before emitting the first user-visible token.</p>

<ul>
  <li><strong>Training:</strong> The model is trained via Reinforcement Learning to “Think longer” for hard problems.</li>
  <li><strong>Behavior:</strong> It outputs “Thinking…” (placeholder) while it generates thousands of internal reasoning tokens that verify its own logic.</li>
  <li><strong>Implication:</strong> We are moving from “Prompt Engineering Reason” to “Buying Reason.” We pay for the compute time of the model’s reflection.</li>
</ul>

<hr />

<h2 id="6-code-implementing-self-consistency">6. Code: Implementing Self-Consistency</h2>

<p>A Python function to perform voting on reasoning chains.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="n">re</span>

<span class="k">def</span> <span class="nf">generate_cot__answer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Generates N responses and returns the most common numeric answer.
    </span><span class="sh">"""</span>
    <span class="n">answers</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="c1"># High temperature for diversity
</span>        <span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="n">chat</span><span class="p">.</span><span class="n">completions</span><span class="p">.</span><span class="nf">create</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="sh">"</span><span class="s">gpt-4o</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="n">prompt</span> <span class="o">+</span> <span class="sh">"</span><span class="se">\n</span><span class="s">Let</span><span class="sh">'</span><span class="s">s think step by step.</span><span class="sh">"</span><span class="p">}],</span>
            <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span> 
        <span class="p">)</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">response</span><span class="p">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">message</span><span class="p">.</span><span class="n">content</span>
        
        <span class="c1"># Simple regex to find the last number (Simulated "Answer extraction")
</span>        <span class="c1"># In prod, ask the model to output JSON {"reasoning": "...", "final_answer": "11"}
</span>        <span class="n">numbers</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">findall</span><span class="p">(</span><span class="sa">r</span><span class="sh">"</span><span class="s">[-+]?\d*\.\d+|\d+</span><span class="sh">"</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">numbers</span><span class="p">:</span>
            <span class="n">answers</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">numbers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># Assume last number is the answer
</span>            
    <span class="c1"># Voting
</span>    <span class="n">vote_counts</span> <span class="o">=</span> <span class="nc">Counter</span><span class="p">(</span><span class="n">answers</span><span class="p">)</span>
    <span class="n">most_common</span><span class="p">,</span> <span class="n">count</span> <span class="o">=</span> <span class="n">vote_counts</span><span class="p">.</span><span class="nf">most_common</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="n">most_common</span><span class="p">,</span> <span class="n">vote_counts</span>

<span class="c1"># Usage
</span><span class="n">prompt</span> <span class="o">=</span> <span class="sh">"</span><span class="s">If I have 3 apples and buy 2 dozen more, then eat 5, how many do I have?</span><span class="sh">"</span>
<span class="n">final_ans</span><span class="p">,</span> <span class="n">details</span> <span class="o">=</span> <span class="nf">generate_cot__answer</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Consensus Answer: </span><span class="si">{</span><span class="n">final_ans</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Votes: </span><span class="si">{</span><span class="n">details</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<hr />

<h2 id="7-summary">7. Summary</h2>

<p>Multi-Step Reasoning turns an LLM from a Text Predictor into a Logic Engine.</p>
<ul>
  <li><strong>CoT</strong> gives it time to think.</li>
  <li><strong>Self-Consistency</strong> filters out luck.</li>
  <li><strong>Tree of Thoughts</strong> allows it to explore.</li>
</ul>

<p>For an agent, <strong>never</strong> accept the first token as truth for a critical decision. Force the model to show its work.</p>

<p>In the next post, we will revisit the <strong>ReAct Pattern</strong>, combining reasoning with tools in a rigid loop.</p>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#chain-of-thought" class="page__taxonomy-item p-category" rel="tag">chain-of-thought</a><span class="sep">, </span>
    
      <a href="/tags/#o1" class="page__taxonomy-item p-category" rel="tag">o1</a><span class="sep">, </span>
    
      <a href="/tags/#reasoning" class="page__taxonomy-item p-category" rel="tag">reasoning</a><span class="sep">, </span>
    
      <a href="/tags/#self-consistency" class="page__taxonomy-item p-category" rel="tag">self-consistency</a><span class="sep">, </span>
    
      <a href="/tags/#tot" class="page__taxonomy-item p-category" rel="tag">tot</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#ai-agents" class="page__taxonomy-item p-category" rel="tag">ai-agents</a>
    
    </span>
  </p>


        
      </footer>

      

      <section class="page__share">
  <h4 class="page__share-title">Share on</h4>

  <a href="https://twitter.com/intent/tweet?via=arunbaby0&text=Multi-Step+Reasoning%20https%3A%2F%2Fwww.arunbaby.com%2Fai-agents%2F0013-multi-step-reasoning%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.arunbaby.com%2Fai-agents%2F0013-multi-step-reasoning%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.arunbaby.com/ai-agents/0013-multi-step-reasoning/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/ai-agents/0012-context-window-management/" class="pagination--pager" title="Context Window Management">Previous</a>
    
    
      <a href="/ai-agents/0014-react-pattern-deep-dive/" class="pagination--pager" title="The ReAct Pattern Deep Dive">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 1990 - 2143 <a href="https://www.arunbaby.com">Arun Baby</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JRJPEC9SS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0JRJPEC9SS', { 'anonymize_ip': false});
</script>








  </body>
</html>
