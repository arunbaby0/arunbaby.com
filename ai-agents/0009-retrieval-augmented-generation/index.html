<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Retrieval-Augmented Generation (RAG) - Arun Baby</title>
<meta name="description" content="“Giving the Brain a Library: The Foundation of Knowledge-Intensive Agents.”">


  <meta name="author" content="Arun Baby">
  
  <meta property="article:author" content="Arun Baby">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Arun Baby">
<meta property="og:title" content="Retrieval-Augmented Generation (RAG)">
<meta property="og:url" content="https://www.arunbaby.com/ai-agents/0009-retrieval-augmented-generation/">


  <meta property="og:description" content="“Giving the Brain a Library: The Foundation of Knowledge-Intensive Agents.”">



  <meta property="og:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">



  <meta name="twitter:site" content="@arunbaby0">
  <meta name="twitter:title" content="Retrieval-Augmented Generation (RAG)">
  <meta name="twitter:description" content="“Giving the Brain a Library: The Foundation of Knowledge-Intensive Agents.”">
  <meta name="twitter:url" content="https://www.arunbaby.com/ai-agents/0009-retrieval-augmented-generation/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="https://www.arunbaby.com/assets/images/profile-photo.png">
    
  

  



  <meta property="article:published_time" content="2025-12-31T09:51:02+05:30">





  

  


<link rel="canonical" href="https://www.arunbaby.com/ai-agents/0009-retrieval-augmented-generation/">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Arun Baby Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
           
          <span class="site-subtitle">Arun Baby</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/about/"
                
                
              >About</a>
            </li><li class="masthead__menu-item">
              <a
                href="/dsa/"
                
                
              >DSA</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ml-system-design/"
                
                
              >ML Systems</a>
            </li><li class="masthead__menu-item">
              <a
                href="/speech-tech/"
                
                
              >Speech Tech</a>
            </li><li class="masthead__menu-item">
              <a
                href="/ai-agents/"
                
                
              >AI Agents</a>
            </li><li class="masthead__menu-item">
              <a
                href="/publications/"
                
                
              >Publications</a>
            </li><li class="masthead__menu-item">
              <a
                href="/statuses/"
                
                
              >Statuses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/contact/"
                
                
              >Contact</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main" class="no-author-sidebar">
  
  <div class="sidebar sticky">
  
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Retrieval-Augmented Generation (RAG)">
    <meta itemprop="description" content="“Giving the Brain a Library: The Foundation of Knowledge-Intensive Agents.”">
    <meta itemprop="datePublished" content="2025-12-31T09:51:02+05:30">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://www.arunbaby.com/ai-agents/0009-retrieval-augmented-generation/" itemprop="url">Retrieval-Augmented Generation (RAG)
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          7 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#1-introduction-the-hallucination-problem">1. Introduction: The Hallucination Problem</a></li><li><a href="#2-the-mechanics-of-rag">2. The Mechanics of RAG</a><ul><li><a href="#21-phase-1-indexing-the-etl-pipeline">2.1 Phase 1: Indexing (The ETL Pipeline)</a></li><li><a href="#22-phase-2-retrieval-the-agent-loop">2.2 Phase 2: Retrieval (The Agent Loop)</a></li></ul></li><li><a href="#3-deep-dive-vector-database-internals">3. Deep Dive: Vector Database Internals</a><ul><li><a href="#31-hnsw-hierarchical-navigable-small-worlds">3.1 HNSW (Hierarchical Navigable Small Worlds)</a></li><li><a href="#32-ivf-inverted-file-index">3.2 IVF (Inverted File Index)</a></li></ul></li><li><a href="#4-naive-rag-vs-advanced-rag">4. Naive RAG vs. Advanced RAG</a><ul><li><a href="#41-failure-modes">4.1 Failure Modes</a></li><li><a href="#42-advanced-patterns">4.2 Advanced Patterns</a></li></ul></li><li><a href="#5-rag-evaluation-ragas">5. RAG Evaluation (RAGAS)</a></li><li><a href="#6-making-rag-a-tool">6. Making RAG a Tool</a><ul><li><a href="#the-agentic-rag-pattern">The Agentic RAG Pattern</a></li><li><a href="#the-self-querying-retriever">The “Self-Querying” Retriever</a></li></ul></li><li><a href="#7-pseudo-code-semantic-search-logic">7. Pseudo-Code: Semantic Search Logic</a></li><li><a href="#8-summary">8. Summary</a></li></ul>
            </nav>
          </aside>
        
        <p><strong>“Giving the Brain a Library: The Foundation of Knowledge-Intensive Agents.”</strong></p>

<h2 id="1-introduction-the-hallucination-problem">1. Introduction: The Hallucination Problem</h2>

<p>LLMs are geniuses with amnesia. They are “Frozen-in-Time” encyclopedias. A base model like GPT-4 knows everything about the world up to its training cutoff (e.g., Oct 2023). It knows <strong>nothing</strong> about:</p>
<ol>
  <li><strong>Recent Events:</strong> The winner of the Super Bowl yesterday.</li>
  <li><strong>Private Data:</strong> Your company’s internal wiki, your emails, or your proprietary codebase.</li>
  <li><strong>Specific Domains:</strong> The nuances of your specific 200-page HR policy.</li>
</ol>

<p>When you ask an agent about these topics, it faces a dilemma: admit ignorance (which it is trained to avoid) or hallucinate (make up a plausible-sounding answer). For an autonomous agent executing actions, hallucination is fatal. You cannot have an agent acting on a hallucinated stock price or deleting a file it “thinks” is unused.</p>

<p><strong>Retrieval-Augmented Generation (RAG)</strong> is the architectural solution. Instead of relying on the model’s <em>internal</em> weights (Parametric Memory), we allow it to look up information in an <em>external</em> database (Non-Parametric Memory) before answering.</p>

<p>For Agents, RAG is not just a feature; it is a <strong>Core Organ</strong>. It is the bridge between reasoning and reality.</p>

<hr />

<h2 id="2-the-mechanics-of-rag">2. The Mechanics of RAG</h2>

<p>RAG is fundamentally a data pipeline followed by an inference step. It consists of two distinct phases: <strong>Indexing</strong> (Offline) and <strong>Retrieval</strong> (Runtime).</p>

<h3 id="21-phase-1-indexing-the-etl-pipeline">2.1 Phase 1: Indexing (The ETL Pipeline)</h3>
<p>How do we turn a PDF into numbers that a machine can “understand”?</p>

<ol>
  <li><strong>Loading:</strong> Ingest data. Text, PDFs, Markdown, HTML, Notion pages, Slack dumps.</li>
  <li><strong>Splitting (Chunking):</strong> LLMs have context limits. We can’t feed a 500-page book in one go. We split it into smaller “Chunks” (e.g., 500 tokens).
    <ul>
      <li><em>The Pivot:</em> Chunking is an art. If you chunk too small, you lose context (“It costs $5” - what is <em>it</em>?). If you chunk too big, you confuse the retrieval.</li>
      <li><em>Strategy:</em> <strong>Recursive Character Splitting</strong> (split by paragraphs, then sentences) is the standard.</li>
    </ul>
  </li>
  <li><strong>Embedding:</strong> We pass each chunk through an <strong>Embedding Model</strong> (e.g., OpenAI <code class="language-plaintext highlighter-rouge">text-embedding-3-small</code>, <code class="language-plaintext highlighter-rouge">bge-m3</code>).
    <ul>
      <li><em>Input:</em> “The sky is blue.”</li>
      <li><em>Output:</em> <code class="language-plaintext highlighter-rouge">[0.12, -0.45, 0.88, ...]</code> (A vector of 1536 floating point numbers).</li>
      <li><em>Concept:</em> This vector represents the <strong>semantic meaning</strong> of the text in a high-dimensional latent space.</li>
    </ul>
  </li>
  <li><strong>Storing:</strong> Save the Vectors + Original Text + Metadata in a <strong>Vector Database</strong> (Pinecone, Weaviate, Chroma).</li>
</ol>

<h3 id="22-phase-2-retrieval-the-agent-loop">2.2 Phase 2: Retrieval (The Agent Loop)</h3>
<p>When the user asks a question:</p>

<ol>
  <li><strong>Query Embedding:</strong> User asks “What is our vacation policy?”. We embed this query into a vector using the <em>same model</em> as indexing.</li>
  <li><strong>Semantic Search (k-NN):</strong> We query the Vector DB: “Find the top 3 chunks geometrically closest to this query vector.”
    <ul>
      <li><em>Result:</em> Chunk A (“Vacation Policy…”), Chunk B (“Leave types…”).</li>
    </ul>
  </li>
  <li><strong>Context Injection:</strong> We construct a prompt:
 ``text
 System: Answer the user using ONLY the context below. Do not use outside knowledge.
 Context:
    <ul>
      <li>Vacation Policy: 20 days per year…</li>
      <li>Leave types: Sick, Annual…</li>
    </ul>
  </li>
</ol>

<p>User: What is our vacation policy?
 ``</p>
<ol>
  <li><strong>Generation:</strong> The LLM reads the context and answers “You get 20 days pear year.”</li>
</ol>

<hr />

<h2 id="3-deep-dive-vector-database-internals">3. Deep Dive: Vector Database Internals</h2>

<p>How does a database find the “nearest neighbor” among 100 million vectors in 10 milliseconds? It doesn’t compare them all (that would be O(N)). It uses <strong>Approximate Nearest Neighbors (ANN)</strong> algorithms.</p>

<h3 id="31-hnsw-hierarchical-navigable-small-worlds">3.1 HNSW (Hierarchical Navigable Small Worlds)</h3>
<p>This is the industry standard algorithm (used by Pinecone, Weaviate).</p>
<ul>
  <li><strong>Concept:</strong> It builds a multi-layer graph.</li>
  <li><em>Top Layer:</em> Like an express highway. Long jumps across the vector space.</li>
  <li><em>Bottom Layer:</em> Local roads. Dense connections between close neighbors.</li>
  <li><strong>Search:</strong> The query starts at the top, zooms to the general neighborhood of the data, and drills down to the local connections.</li>
  <li><strong>Tradeoff:</strong> Fast search, but high memory usage (Requires storing the graph structure).</li>
</ul>

<h3 id="32-ivf-inverted-file-index">3.2 IVF (Inverted File Index)</h3>
<p>Used by FAISS.</p>
<ul>
  <li><strong>Concept:</strong> Cluster the vectors into 1000 “Voronoi Cells” (centroids).</li>
  <li><strong>Search:</strong> First, find which cell the query belongs to. Then scan only the vectors in that cell.</li>
  <li><strong>Tradeoff:</strong> Very efficient, but recall can drop (if the answer is just on the border of another cell).</li>
</ul>

<hr />

<h2 id="4-naive-rag-vs-advanced-rag">4. Naive RAG vs. Advanced RAG</h2>

<p>The standard pipeline is called “Naive RAG.” It works for simple demos but fails in production.</p>

<h3 id="41-failure-modes">4.1 Failure Modes</h3>
<ul>
  <li><strong>Keyword Misses:</strong> “Vacation” vs “Time Off.” Vectors handle typical synonyms, but specific jargon (Product IDs like <code class="language-plaintext highlighter-rouge">XJ-900</code> vs <code class="language-plaintext highlighter-rouge">XJ900</code>) often fails semantic search.</li>
  <li><strong>Loss of Context:</strong> Retrieving a chunk that says “He agreed to the terms” is useless if the chunk doesn’t say <em>who</em> “He” is.</li>
  <li><strong>Distraction:</strong> Retrieving 10 chunks, 9 of which are irrelevant, can confuse the LLM (“Lost in the Middle”).</li>
</ul>

<h3 id="42-advanced-patterns">4.2 Advanced Patterns</h3>
<ol>
  <li><strong>Hybrid Search (Alpha):</strong> Combine Vector Search (Semantic) with Keyword Search (BM25/Splade).
    <ul>
      <li><em>Formula:</em> <code class="language-plaintext highlighter-rouge">Score = \alpha \cdot VectorScore + (1-\alpha) \cdot KeywordScore</code>.</li>
      <li><em>Why:</em> Ensures exact matches for IDs and Names work while retaining semantic understanding.</li>
    </ul>
  </li>
  <li><strong>Re-Ranking (The Cross-Encoder):</strong>
    <ul>
      <li>Retrieve top 50 results (fast &amp; loose).</li>
      <li>Pass them through a powerful “Re-Ranker Model” (e.g., Cohere Rerank) that compares the Query and Document interacting token-by-token.</li>
      <li>Take the top 5.</li>
      <li><em>Impact:</em> Increases accuracy by 20-30%.</li>
    </ul>
  </li>
  <li><strong>Parent-Child Indexing:</strong>
    <ul>
      <li><em>Index:</em> Small chunks (sentences) for precise search.</li>
      <li><em>Retrieve:</em> The Parent chunk (full paragraph) for context.</li>
      <li><em>Why:</em> “Small to search, Big to read.”</li>
    </ul>
  </li>
</ol>

<hr />

<h2 id="5-rag-evaluation-ragas">5. RAG Evaluation (RAGAS)</h2>

<p>How do you look at your RAG system and say “It’s good”? Feeling good isn’t engineering.
We use the <strong>RAGAS</strong> (RAG Assessment) framework, which defines metrics calculated by an LLM-as-a-Judge.</p>

<ol>
  <li><strong>Faithfulness:</strong> Does the answer come <em>solely</em> from the retrieved context? (Low hallucination).</li>
  <li><strong>Answer Relevance:</strong> Does the answer actually address the user query?</li>
  <li><strong>Context Precision:</strong> Did we retrieve the <em>right</em> chunks? (Signal-to-noise ratio).</li>
  <li><strong>Context Recall:</strong> Did we retrieve <em>all</em> the necessary info?</li>
</ol>

<hr />

<h2 id="6-making-rag-a-tool">6. Making RAG a Tool</h2>

<p>For an agent, RAG is just another <strong>Tool</strong>.
We don’t hard-code the retrieval. We give the agent a tool call.</p>

<h3 id="the-agentic-rag-pattern">The Agentic RAG Pattern</h3>
<ul>
  <li><strong>Tool:</strong> <code class="language-plaintext highlighter-rouge">search_knowledge_base(query: str, filters: dict)</code></li>
  <li><strong>Description:</strong> “Use this tool to look up technical documentation. You can filter by year or tag.”</li>
</ul>

<h3 id="the-self-querying-retriever">The “Self-Querying” Retriever</h3>
<p>An advanced pattern where the LLM writes a Structured Database Query.</p>
<ul>
  <li><em>User:</em> “Show me emails from Alice last week.”</li>
  <li><em>LLM:</em> <code class="language-plaintext highlighter-rouge">search(query="from Alice", filter={"date": "&gt; 2023-10-01"})</code></li>
  <li><em>Runtime:</em> Applies a Metadata Filter on the Vector DB. This is vastly superior to pure semantic search for structured questions.</li>
</ul>

<hr />

<h2 id="7-pseudo-code-semantic-search-logic">7. Pseudo-Code: Semantic Search Logic</h2>

<p>Understanding the inner loop of a vector search engine (conceptual).</p>

<p>``python
def semantic_search(query, k=5):
 # 1. Embed Query
 query_vector = model.embed(query)</p>

<p># 2. Score All Documents (Naive Calculation)
 scores = []
 for doc in database:
 # Cosine Similarity = (A . B) / (|A| * |B|)
 score = dot_product(query_vector, doc.vector)
 scores.append((score, doc))</p>

<p># 3. Sort (Rank)
 scores.sort(reverse=True)</p>

<p># 4. Filter (Optional Hybrid Step)
 # Check for keyword matches if needed</p>

<p># 5. Return Top K
 return scores[:k]
``</p>

<hr />

<h2 id="8-summary">8. Summary</h2>

<p>RAG turns an LLM from a Dreamer into a Librarian.</p>
<ul>
  <li><strong>Vectors</strong> encode meaning.</li>
  <li><strong>Vector DBs</strong> enable fast search (HNSW).</li>
  <li><strong>Agents</strong> use retrieval as a tool to ground their answers in fact.</li>
</ul>

<p>However, RAG is only as good as the incoming data. If you feed it messy PDFs, you get messy vectors.
Next, we must look at the input side of this pipeline: <strong>Document Processing</strong>. How do we actually read messy PDFs, Tables, and Charts?</p>

<hr />

<p><strong>Originally published at:</strong> <a href="https://www.arunbaby.com/ai-agents/0009-retrieval-augmented-generation/">arunbaby.com/ai-agents/0009-retrieval-augmented-generation</a></p>

<p><em>If you found this helpful, consider sharing it with others who might benefit.</em></p>


        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#embeddings" class="page__taxonomy-item p-category" rel="tag">embeddings</a><span class="sep">, </span>
    
      <a href="/tags/#hnsw" class="page__taxonomy-item p-category" rel="tag">hnsw</a><span class="sep">, </span>
    
      <a href="/tags/#knowledge-retrieval" class="page__taxonomy-item p-category" rel="tag">knowledge-retrieval</a><span class="sep">, </span>
    
      <a href="/tags/#rag" class="page__taxonomy-item p-category" rel="tag">rag</a><span class="sep">, </span>
    
      <a href="/tags/#ragas" class="page__taxonomy-item p-category" rel="tag">ragas</a><span class="sep">, </span>
    
      <a href="/tags/#vector-db" class="page__taxonomy-item p-category" rel="tag">vector-db</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#ai-agents" class="page__taxonomy-item p-category" rel="tag">ai-agents</a>
    
    </span>
  </p>


        
      </footer>

      <div class="page__related page__related--full">
  <h2 class="page__related-title">Related across topics</h2>
  <style>
    /* Make section span full content width and use 2 equal columns */
    .page__related--full { float: inline-start; width: 100%; padding: 0; }
    .cross-related-grid { display: grid; grid-template-columns: repeat(2, minmax(0, 1fr)); gap: 2rem; }
    @media (max-width: 768px) { .cross-related-grid { grid-template-columns: 1fr; } }
    /* Ensure archive cards stretch nicely in the grid */
    .cross-related-grid .list__item, .cross-related-grid .grid__item { width: auto; float: none; margin: 0; }
  </style>
  <div class="cross-related-grid">
    



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/dsa/0009-binary-search/" rel="permalink">Binary Search
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          28 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Master binary search to understand logarithmic algorithms and efficient searching, foundational for optimization and search systems.
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ml-system-design/0009-online-learning-systems/" rel="permalink">Online Learning Systems
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          24 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Design systems that learn continuously from streaming data, adapting to changing patterns without full retraining.
</p>
  </article>
</div>




<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/speech-tech/0009-keyword-spotting/" rel="permalink">Real-time Keyword Spotting
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          25 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Build lightweight models that detect specific keywords in audio streams with minimal latency and power consumption for voice interfaces.
</p>
  </article>
</div>

  </div>
</div>

      <section class="page__share">
  <h4 class="page__share-title">Share on</h4>

  <a href="https://twitter.com/intent/tweet?via=arunbaby0&text=Retrieval-Augmented+Generation+%28RAG%29%20https%3A%2F%2Fwww.arunbaby.com%2Fai-agents%2F0009-retrieval-augmented-generation%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.arunbaby.com%2Fai-agents%2F0009-retrieval-augmented-generation%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://www.arunbaby.com/ai-agents/0009-retrieval-augmented-generation/" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/ai-agents/0008-agent-workflow-patterns/" class="pagination--pager" title="Agent Workflow Patterns">Previous</a>
    
    
      <a href="/ai-agents/0010-document-processing/" class="pagination--pager" title="Document Processing for Agents">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>

      
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://twitter.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/arunbaby0" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/arunbaby0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://scholar.google.co.in/citations?user=6fSYWhkAAAAJ" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-graduation-cap" aria-hidden="true"></i> Google Scholar</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 1990 - 2143 <a href="https://www.arunbaby.com">Arun Baby</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0JRJPEC9SS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0JRJPEC9SS', { 'anonymize_ip': false});
</script>








  </body>
</html>
